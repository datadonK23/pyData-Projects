[
{"authors": ["Zi Yin"], "title": ["PIP Distance: A Unitary-invariant Metric for Understanding Functionality\n  and Dimensionality of Vector Embeddings"], "date": ["2018-03-01T17:02:17Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.00502v3"], "summary": ["  In this paper, we present a theoretical framework for understanding vector\nembedding, a fundamental building block of many deep learning models,\nespecially in NLP. We discover a natural unitary-invariance in vector\nembeddings, which is required by the distributional hypothesis. This\nunitary-invariance states the fact that two embeddings are essentially\nequivalent if one can be obtained from the other by performing a\nrelative-geometry preserving transformation, for example a rotation. This idea\nleads to the Pairwise Inner Product (PIP) loss, a natural unitary-invariant\nmetric for the distance between two embeddings. We demonstrate that the PIP\nloss captures the difference in functionality between embeddings. By\nformulating the embedding training process as matrix factorization under noise,\nwe reveal a fundamental bias-variance tradeoff in dimensionality selection.\nWith tools from perturbation and stability theory, we provide an upper bound on\nthe PIP loss using the signal spectrum and noise variance, both of which can be\nreadily inferred from data. Our framework sheds light on many empirical\nphenomena, including the existence of an optimal dimension, and the robustness\nof embeddings against over-parametrization. The bias-variance tradeoff of PIP\nloss explicitly answers the fundamental open problem of dimensionality\nselection for vector embeddings.\n"]},
{"authors": ["Subhadeep Karan", "Matthew Eichhorn", "Blake Hurlburt", "Grant Iraci", "Jaroslaw Zola"], "title": ["Fast Counting in Machine Learning Applications"], "date": ["2018-04-12T17:34:41Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04640v1"], "summary": ["  We propose scalable methods to execute counting queries in machine learning\napplications. To achieve memory and computational efficiency, we abstract\ncounting queries and their context such that the counts can be aggregated as a\nstream. We demonstrate performance and scalability of the resulting approach on\nrandom queries, and through extensive experimentation using Bayesian networks\nlearning and association rule mining. Our methods significantly outperform\ncommonly used ADtrees and hash tables, and are practical alternatives for\nprocessing large-scale data.\n"]},
{"authors": ["Octavian-Eugen Ganea", "Gary B\u00e9cigneul", "Thomas Hofmann"], "title": ["Hyperbolic Entailment Cones for Learning Hierarchical Embeddings"], "date": ["2018-04-03T19:25:10Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01882v2"], "summary": ["  Learning graph representations via low-dimensional embeddings that preserve\nrelevant network properties is an important class of problems in machine\nlearning. We here present a novel method to embed directed acyclic graphs.\nFollowing prior work, we first advocate for using hyperbolic spaces which\nprovably model tree-like structures better than Euclidean geometry. Second, we\nview hierarchical relations as partial orders defined using a family of nested\ngeodesically convex cones. We prove that these entailment cones admit an\noptimal shape with a closed form expression both in the Euclidean and\nhyperbolic spaces. Moreover, they canonically define the embedding learning\nprocess. Experiments show significant improvements of our method over strong\nrecent baselines both in terms of representational capacity and generalization.\n"]},
{"authors": ["Jovana Mitrovic", "Dino Sejdinovic", "Yee Whye Teh"], "title": ["Causal Inference via Kernel Deviance Measures"], "date": ["2018-04-12T16:51:04Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04622v1"], "summary": ["  Discovering the causal structure among a set of variables is a fundamental\nproblem in many areas of science. In this paper, we propose Kernel Conditional\nDeviance for Causal Inference (KCDC) a fully nonparametric causal discovery\nmethod based on purely observational data. From a novel interpretation of the\nnotion of asymmetry between cause and effect, we derive a corresponding\nasymmetry measure using the framework of reproducing kernel Hilbert spaces.\nBased on this, we propose three decision rules for causal discovery. We\ndemonstrate the wide applicability of our method across a range of diverse\nsynthetic datasets. Furthermore, we test our method on real-world time series\ndata and the real-world benchmark dataset Tubingen Cause-Effect Pairs where we\noutperform existing state-of-the-art methods.\n"]},
{"authors": ["Babak Esmaeili", "Hao Wu", "Sarthak Jain", "N. Siddharth", "Brooks Paige", "Jan-Willem van de Meent"], "title": ["Hierarchical Disentangled Representations"], "date": ["2018-04-06T00:11:26Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02086v2"], "summary": ["  Deep latent-variable models learn representations of high-dimensional data in\nan unsupervised manner. A number of recent efforts have focused on learning\nrepresentations that disentangle statistically independent axes of variation,\noften by introducing suitable modifications of the objective function. We\nsynthesize this growing body of literature by formulating a generalization of\nthe evidence lower bound that explicitly represents the trade-offs between\nsparsity of the latent code, bijectivity of representations, and coverage of\nthe support of the empirical data distribution. Our objective is also suitable\nto learning hierarchical representations that disentangle blocks of variables\nwhilst allowing for some degree of correlations within blocks. Experiments on a\nrange of datasets demonstrate that learned representations contain\ninterpretable features, are able to learn discrete attributes, and generalize\nto unseen combinations of factors.\n"]},
{"authors": ["Amirhossein Javaheri", "Hadi Zayyani", "Mario A. T. Figueiredo", "Farrokh Marvasti"], "title": ["Impulsive Noise Robust Sparse Recovery via Continuous Mixed Norm"], "date": ["2018-04-12T16:40:07Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04614v1"], "summary": ["  This paper investigates the problem of sparse signal recovery in the presence\nof additive impulsive noise. The heavytailed impulsive noise is well modelled\nwith stable distributions. Since there is no explicit formulation for the\nprobability density function of $S\\alpha S$ distribution, alternative\napproximations like Generalized Gaussian Distribution (GGD) are used which\nimpose $\\ell_p$-norm fidelity on the residual error. In this paper, we exploit\na Continuous Mixed Norm (CMN) for robust sparse recovery instead of\n$\\ell_p$-norm. We show that in blind conditions, i.e., in case where the\nparameters of noise distribution are unknown, incorporating CMN can lead to\nnear optimal recovery. We apply Alternating Direction Method of Multipliers\n(ADMM) for solving the problem induced by utilizing CMN for robust sparse\nrecovery. In this approach, CMN is replaced with a surrogate function and\nMajorization-Minimization technique is incorporated to solve the problem.\nSimulation results confirm the efficiency of the proposed method compared to\nsome recent algorithms in the literature for impulsive noise robust sparse\nrecovery.\n"]},
{"authors": ["Dimitri P. Bertsekas"], "title": ["Feature-Based Aggregation and Deep Reinforcement Learning: A Survey and\n  Some New Implementations"], "date": ["2018-04-12T15:46:12Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04577v1"], "summary": ["  In this paper we discuss policy iteration methods for approximate solution of\na finite-state discounted Markov decision problem, with a focus on\nfeature-based aggregation methods and their connection with deep reinforcement\nlearning schemes. We introduce features of the states of the original problem,\nand we formulate a smaller \"aggregate\" Markov decision problem, whose states\nrelate to the features. The optimal cost function of the aggregate problem, a\nnonlinear function of the features, serves as an architecture for approximation\nin value space of the optimal cost function or the cost functions of policies\nof the original problem. We discuss properties and possible implementations of\nthis type of aggregation, including a new approach to approximate policy\niteration. In this approach the policy improvement operation combines\nfeature-based aggregation with reinforcement learning based on deep neural\nnetworks, which is used to obtain the needed features. We argue that the cost\nfunction of a policy may be approximated much more accurately by the nonlinear\nfunction of the features provided by aggregation, than by the linear function\nof the features provided by deep reinforcement learning, thereby potentially\nleading to more effective policy improvement.\n"]},
{"authors": ["Jan-Peter Calliess"], "title": ["Lazily Adapted Constant Kinky Inference for Nonparametric Regression and\n  Model-Reference Adaptive Control"], "date": ["2016-12-31T23:25:59Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1701.00178v2"], "summary": ["  Techniques known as Nonlinear Set Membership prediction, Lipschitz\nInterpolation or Kinky Inference are approaches to machine learning that\nutilise presupposed Lipschitz properties to compute inferences over unobserved\nfunction values. Provided a bound on the true best Lipschitz constant of the\ntarget function is known a priori they offer convergence guarantees as well as\nbounds around the predictions. Considering a more general setting that builds\non Hoelder continuity relative to pseudo-metrics, we propose an online method\nfor estimating the Hoelder constant online from function value observations\nthat possibly are corrupted by bounded observational errors. Utilising this to\ncompute adaptive parameters within a kinky inference rule gives rise to a\nnonparametric machine learning method, for which we establish strong universal\napproximation guarantees. That is, we show that our prediction rule can learn\nany continuous function in the limit of increasingly dense data to within a\nworst-case error bound that depends on the level of observational uncertainty.\nWe apply our method in the context of nonparametric model-reference adaptive\ncontrol (MRAC). Across a range of simulated aircraft roll-dynamics and\nperformance metrics our approach outperforms recently proposed alternatives\nthat were based on Gaussian processes and RBF-neural networks. For\ndiscrete-time systems, we provide guarantees on the tracking success of our\nlearning-based controllers both for the batch and the online learning setting.\n"]},
{"authors": ["Carlo Vittorio Cannistraci", "Alessandro Muscoloni"], "title": ["Latent Geometry Inspired Graph Dissimilarities Enhance Affinity\n  Propagation Community Detection in Complex Networks"], "date": ["2018-04-12T15:23:39Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04566v1"], "summary": ["  Affinity propagation is one of the most effective algorithms for data\nclustering in high-dimensional feature space. However the numerous attempts to\ntest its performance for community detection in real complex networks have been\nattaining results very far from the state of the art methods such as Infomap\nand Louvain. Yet, all these studies agreed that the crucial problem is to\nconvert the network topology in a 'smart-enough' dissimilarity matrix that is\nable to properly address the message passing procedure behind affinity\npropagation clustering. Here we discuss how to leverage network latent geometry\nnotions in order to design dissimilarity matrices for affinity propagation\ncommunity detection. Our results demonstrate that the dissimilarity measures we\ndesigned bring affinity propagation to outperform current state of the art\nmethods for community detection, not only on several original real networks,\nbut also when their structure is corrupted by noise artificially induced by\nmissing or spurious connectivity.\n"]},
{"authors": ["Pierre-Antoine Ganaye", "Micha\u00ebl Sdika", "Hugues Benoit-Cattin"], "title": ["Towards integrating spatial localization in convolutional neural\n  networks for brain image segmentation"], "date": ["2018-04-12T15:20:48Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04563v1"], "summary": ["  Semantic segmentation is an established while rapidly evolving field in\nmedical imaging. In this paper we focus on the segmentation of brain Magnetic\nResonance Images (MRI) into cerebral structures using convolutional neural\nnetworks (CNN). CNNs achieve good performance by finding effective high\ndimensional image features describing the patch content only. In this work, we\npropose different ways to introduce spatial constraints into the network to\nfurther reduce prediction inconsistencies.\n  A patch based CNN architecture was trained, making use of multiple scales to\ngather contextual information. Spatial constraints were introduced within the\nCNN through a distance to landmarks feature or through the integration of a\nprobability atlas. We demonstrate experimentally that using spatial information\nhelps to reduce segmentation inconsistencies.\n"]},
{"authors": ["Boris Karanov", "Mathieu Chagnon", "F\u00e9lix Thouin", "Tobias A. Eriksson", "Henning B\u00fclow", "Domani\u00e7 Lavery", "Polina Bayvel", "Laurent Schmalen"], "title": ["End-to-end Deep Learning of Optical Fiber Communications"], "date": ["2018-04-11T17:07:43Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04097v2"], "summary": ["  In this paper, we implement an optical fiber communication system as an\nend-to-end deep neural network, including the complete chain of transmitter,\nchannel model, and receiver. This approach enables the optimization of the\ntransceiver in a single end-to-end process. We illustrate the benefits of this\nmethod by applying it to intensity modulation/direct detection (IM/DD) systems\nand show that we can achieve bit error rates below the 6.7\\% hard-decision\nforward error correction (HD-FEC) threshold. We model all componentry of the\ntransmitter and receiver, as well as the fiber channel, and apply deep learning\nto find transmitter and receiver configurations minimizing the symbol error\nrate. We propose and verify in simulations a training method that yields robust\nand flexible transceivers that allow---without reconfiguration---reliable\ntransmission over a large range of link dispersions. The results from\nend-to-end deep learning are successfully verified for the first time in an\nexperiment. In particular, we achieve information rates of 42\\,Gb/s below the\nHD-FEC threshold at distances beyond 40\\,km. We find that our results\noutperform conventional IM/DD solutions based on 2 and 4 level pulse amplitude\nmodulation (PAM2/PAM4) with feedforward equalization (FFE) at the receiver. Our\nstudy is the first step towards end-to-end deep learning-based optimization of\noptical fiber communication systems.\n"]},
{"authors": ["E. Veronica Belmega", "Panayotis Mertikopoulos", "Romain Negrel", "Luca Sanguinetti"], "title": ["Online convex optimization and no-regret learning: Algorithms,\n  guarantees and applications"], "date": ["2018-04-12T14:22:35Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04529v1"], "summary": ["  Spurred by the enthusiasm surrounding the \"Big Data\" paradigm, the\nmathematical and algorithmic tools of online optimization have found widespread\nuse in problems where the trade-off between data exploration and exploitation\nplays a predominant role. This trade-off is of particular importance to several\nbranches and applications of signal processing, such as data mining,\nstatistical inference, multimedia indexing and wireless communications (to name\nbut a few). With this in mind, the aim of this tutorial paper is to provide a\ngentle introduction to online optimization and learning algorithms that are\nasymptotically optimal in hindsight - i.e., they approach the performance of a\nvirtual algorithm with unlimited computational power and full knowledge of the\nfuture, a property known as no-regret. Particular attention is devoted to\nidentifying the algorithms' theoretical performance guarantees and to establish\nlinks with classic optimization paradigms (both static and stochastic). To\nallow a better understanding of this toolbox, we provide several examples\nthroughout the tutorial ranging from metric learning to wireless resource\nallocation problems.\n"]},
{"authors": ["Twan van Laarhoven"], "title": ["Generative models for local network community detection"], "date": ["2018-04-12T12:34:57Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04469v1"], "summary": ["  Local network community detection aims to find a single community in a large\nnetwork, while inspecting only a small part of that network around a given seed\nnode. This is much cheaper than finding all communities in a network. Most\nmethods for local community detection are formulated as ad-hoc optimization\nproblems. In this work, we instead start from a generative model for networks\nwith community structure. By assuming that the network is uniform, we can\napproximate the structure of unobserved parts of the network to obtain a method\nfor local community detection. We apply this local approximation technique to\ntwo variants of the stochastic block model. To our knowledge, this results in\nthe first local community detection methods based on probabilistic models.\nInterestingly, in the limit, one of the proposed approximations corresponds to\nconductance, a popular metric in this field. Experiments on real and synthetic\ndatasets show comparable or improved results compared to state-of-the-art local\ncommunity detection algorithms.\n"]},
{"authors": ["Daniel Worrall", "Gabriel Brostow"], "title": ["CubeNet: Equivariance to 3D Rotation and Translation"], "date": ["2018-04-12T12:14:18Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04458v1"], "summary": ["  3D Convolutional Neural Networks are sensitive to transformations applied to\ntheir input. This is a problem because a voxelized version of a 3D object, and\nits rotated clone, will look unrelated to each other after passing through to\nthe last layer of a network. Instead, an idealized model would preserve a\nmeaningful representation of the voxelized object, while explaining the\npose-difference between the two inputs. An equivariant representation vector\nhas two components: the invariant identity part, and a discernable encoding of\nthe transformation. Models that can't explain pose-differences risk \"diluting\"\nthe representation, in pursuit of optimizing a classification or regression\nloss function.\n  We introduce a Group Convolutional Neural Network with linear equivariance to\ntranslations and right angle rotations in three dimensions. We call this\nnetwork CubeNet, reflecting its cube-like symmetry. By construction, this\nnetwork helps preserve a 3D shape's global and local signature, as it is\ntransformed through successive layers. We apply this network to a variety of 3D\ninference problems, achieving state-of-the-art on the ModelNet10 classification\nchallenge, and comparable performance on the ISBI 2012 Connectome Segmentation\nBenchmark. To the best of our knowledge, this is the first 3D rotation\nequivariant CNN for voxel representations.\n"]},
{"authors": ["Stefan Depeweg", "Constantin A. Rothkopf", "Frank J\u00e4kel"], "title": ["Solving Bongard Problems with a Visual Language and Pragmatic Reasoning"], "date": ["2018-04-12T12:05:28Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04452v1"], "summary": ["  More than 50 years ago Bongard introduced 100 visual concept learning\nproblems as a testbed for intelligent vision systems. These problems are now\nknown as Bongard problems. Although they are well known in the cognitive\nscience and AI communities only moderate progress has been made towards\nbuilding systems that can solve a substantial subset of them. In the system\npresented here, visual features are extracted through image processing and then\ntranslated into a symbolic visual vocabulary. We introduce a formal language\nthat allows representing complex visual concepts based on this vocabulary.\nUsing this language and Bayesian inference, complex visual concepts can be\ninduced from the examples that are provided in each Bongard problem. Contrary\nto other concept learning problems the examples from which concepts are induced\nare not random in Bongard problems, instead they are carefully chosen to\ncommunicate the concept, hence requiring pragmatic reasoning. Taking pragmatic\nreasoning into account we find good agreement between the concepts with high\nposterior probability and the solutions formulated by Bongard himself. While\nthis approach is far from solving all Bongard problems, it solves the biggest\nfraction yet.\n"]},
{"authors": ["Jeroen Manders", "Elena Marchiori", "Twan van Laarhoven"], "title": ["Simple Domain Adaptation with Class Prediction Uncertainty Alignment"], "date": ["2018-04-12T11:56:42Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04448v1"], "summary": ["  Unsupervised domain adaptation tries to adapt a classifier trained on a\nlabeled source domain to a related but unlabeled target domain. Methods based\non adversarial learning try to learn a representation that is at the same time\ndiscriminative for the labels yet incapable of discriminating the domains. We\npropose a very simple and efficient method based on this approach which only\naligns predicted class probabilities across domains. Experiments show that this\nstrikingly simple adversarial domain adaptation method is robust to overfitting\nand achieves state-of-the-art results on datasets for image classification.\n"]},
{"authors": ["Lin Zhang", "Neerav Karani", "Christine Tanner", "Ender Konukoglu"], "title": ["Temporal Interpolation via Motion Field Prediction"], "date": ["2018-04-12T11:44:55Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04440v1"], "summary": ["  Navigated 2D multi-slice dynamic Magnetic Resonance (MR) imaging enables high\ncontrast 4D MR imaging during free breathing and provides in-vivo observations\nfor treatment planning and guidance. Navigator slices are vital for\nretrospective stacking of 2D data slices in this method. However, they also\nprolong the acquisition sessions. Temporal interpolation of navigator slices an\nbe used to reduce the number of navigator acquisitions without degrading\nspecificity in stacking. In this work, we propose a convolutional neural\nnetwork (CNN) based method for temporal interpolation via motion field\nprediction. The proposed formulation incorporates the prior knowledge that a\nmotion field underlies changes in the image intensities over time. Previous\napproaches that interpolate directly in the intensity space are prone to\nproduce blurry images or even remove structures in the images. Our method\navoids such problems and faithfully preserves the information in the image.\nFurther, an important advantage of our formulation is that it provides an\nunsupervised estimation of bi-directional motion fields. We show that these\nmotion fields can be used to halve the number of registrations required during\n4D reconstruction, thus substantially reducing the reconstruction time.\n"]},
{"authors": ["Avraham Ruderman", "Neil Rabinowitz", "Ari S. Morcos", "Daniel Zoran"], "title": ["Learned Deformation Stability in Convolutional Neural Networks"], "date": ["2018-04-12T11:44:05Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04438v1"], "summary": ["  Conventional wisdom holds that interleaved pooling layers in convolutional\nneural networks lead to stability to small translations and deformations. In\nthis work, we investigate this claim empirically. We find that while pooling\nconfers stability to deformation at initialization, the deformation stability\nat each layer changes significantly over the course of training and even\ndecreases in some layers, suggesting that deformation stability is not\nunilaterally helpful. Surprisingly, after training, the pattern of deformation\nstability across layers is largely independent of whether or not pooling was\npresent. We then show that a significant factor in determining deformation\nstability is filter smoothness. Moreover, filter smoothness and deformation\nstability are not simply a consequence of the distribution of input images, but\ndepend crucially on the joint distribution of images and labels. This work\ndemonstrates a way in which biases such as deformation stability can in fact be\nlearned and provides an example of understanding how a simple property of\nlearned network weights contributes to the overall network computation.\n"]},
{"authors": ["Jiangchao Yao", "Ivor Tsang", "Ya Zhang"], "title": ["Variational Composite Autoencoders"], "date": ["2018-04-12T11:36:42Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04435v1"], "summary": ["  Learning in the latent variable model is challenging in the presence of the\ncomplex data structure or the intractable latent variable. Previous variational\nautoencoders can be low effective due to the straightforward encoder-decoder\nstructure. In this paper, we propose a variational composite autoencoder to\nsidestep this issue by amortizing on top of the hierarchical latent variable\nmodel. The experimental results confirm the advantages of our model.\n"]},
{"authors": ["Bruno Ordozgoiti", "Alberto Mozo", "Jes\u00fas Garc\u00eda L\u00f3pez de Lacalle"], "title": ["Regularized Greedy Column Subset Selection"], "date": ["2018-04-12T10:56:44Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04421v1"], "summary": ["  The Column Subset Selection Problem provides a natural framework for\nunsupervised feature selection. Despite being a hard combinatorial optimization\nproblem, there exist efficient algorithms that provide good approximations. The\ndrawback of the problem formulation is that it incorporates no form of\nregularization, and is therefore very sensitive to noise when presented with\nscarce data. In this paper we propose a regularized formulation of this\nproblem, and derive a correct greedy algorithm that is similar in efficiency to\nexisting greedy methods for the unregularized problem. We study its adequacy\nfor feature selection and propose suitable formulations. Additionally, we\nderive a lower bound for the error of the proposed problems. Through various\nnumerical experiments on real and synthetic data, we demonstrate the\nsignificantly increased robustness and stability of our method, as well as the\nimproved conditioning of its output, all while remaining efficient for\npractical use.\n"]},
{"authors": ["Alon Rozental", "Daniel Fleischer"], "title": ["Amobee at SemEval-2018 Task 1: GRU Neural Network with a CNN Attention\n  Mechanism for Sentiment Classification"], "date": ["2018-04-12T09:04:50Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04380v1"], "summary": ["  This paper describes the participation of Amobee in the shared sentiment\nanalysis task at SemEval 2018. We participated in all the English sub-tasks and\nthe Spanish valence tasks. Our system consists of three parts: training\ntask-specific word embeddings, training a model consisting of\ngated-recurrent-units (GRU) with a convolution neural network (CNN) attention\nmechanism and training stacking-based ensembles for each of the sub-tasks. Our\nalgorithm reached 3rd and 1st places in the valence ordinal classification\nsub-tasks in English and Spanish, respectively.\n"]},
{"authors": ["Philippe Wenk", "Alkis Gotovos", "Stefan Bauer", "Nico Gorbach", "Andreas Krause", "Joachim M. Buhmann"], "title": ["Fast Gaussian Process Based Gradient Matching for Parameter\n  Identification in Systems of Nonlinear ODEs"], "date": ["2018-04-12T08:54:20Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04378v1"], "summary": ["  Parameter identification and comparison of dynamical systems is a challenging\ntask in many fields. Bayesian approaches based on Gaussian process regression\nover time-series data have been successfully applied to infer the parameters of\na dynamical system without explicitly solving it. While the benefits in\ncomputational cost are well established, a rigorous mathematical framework has\nbeen missing. We offer a novel interpretation which leads to a better\nunderstanding and improvements in state-of-the-art performance in terms of\naccuracy for nonlinear dynamical systems.\n"]},
{"authors": ["Henry Gouk", "Eibe Frank", "Bernhard Pfahringer", "Michael Cree"], "title": ["Regularisation of Neural Networks by Enforcing Lipschitz Continuity"], "date": ["2018-04-12T08:18:30Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04368v1"], "summary": ["  We investigate the effect of explicitly enforcing the Lipschitz continuity of\nneural networks. Our main hypothesis is that constraining the Lipschitz\nconstant of a networks will have a regularising effect. To this end, we provide\na simple technique for computing the Lipschitz constant of a feed forward\nneural network composed of commonly used layer types. This technique is then\nutilised to formulate training a Lipschitz continuous neural network as a\nconstrained optimisation problem, which can be easily solved using projected\nstochastic gradient methods. Our evaluation study shows that, in isolation, our\nmethod performs comparatively to state-of-the-art regularisation techniques.\nMoreover, when combined with existing approaches to regularising neural\nnetworks the performance gains are cumulative.\n"]},
{"authors": ["Rohith Aralikatti", "Dilip Margam", "Tanay Sharma", "Thanda Abhinav", "Shankar M Venkatesan"], "title": ["Global SNR Estimation of Speech Signals using Entropy and Uncertainty\n  Estimates from Dropout Networks"], "date": ["2018-04-12T07:15:20Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04353v1"], "summary": ["  This paper demonstrates two novel methods to estimate the global SNR of\nspeech signals. In both methods, Deep Neural Network-Hidden Markov Model\n(DNN-HMM) acoustic model used in speech recognition systems is leveraged for\nthe additional task of SNR estimation. In the first method, the entropy of the\nDNN-HMM output is computed. Recent work on bayesian deep learning has shown\nthat a DNN-HMM trained with dropout can be used to estimate model uncertainty\nby approximating it as a deep Gaussian process. In the second method, this\napproximation is used to obtain model uncertainty estimates. Noise specific\nregressors are used to predict the SNR from the entropy and model uncertainty.\nThe DNN-HMM is trained on GRID corpus and tested on different noise profiles\nfrom the DEMAND noise database at SNR levels ranging from -10 dB to 30 dB.\n"]},
{"authors": ["Mingming Gong", "Kun Zhang", "Biwei Huang", "Clark Glymour", "Dacheng Tao", "Kayhan Batmanghelich"], "title": ["Causal Generative Domain Adaptation Networks"], "date": ["2018-04-12T06:10:46Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04333v1"], "summary": ["  We propose a new generative model for domain adaptation, in which training\ndata (source domain) and test data (target domain) come from different\ndistributions. An essential problem in domain adaptation is to understand how\nthe distribution shifts across domains. For this purpose, we propose a\ngenerative domain adaptation network to understand and identify the domain\nchanges, which enables the generation of new domains. In addition, focusing on\nsingle domain adaptation, we demonstrate how our model recovers the joint\ndistribution on the target domain from unlabeled target domain data by\ntransferring valuable information between domains. Finally, to improve transfer\nefficiency, we build a causal generative domain adaptation network by\ndecomposing the joint distribution of features and labels into a series of\ncausal modules according to a causal model. Due to the modularity property of a\ncausal model, we can improve the identification of distribution changes by\nmodeling each causal modules separately. With the proposed adaptation networks,\nthe predictive model on the target domain can be easily trained on data sampled\nfrom the learned networks. We demonstrate the efficacy of our method on both\nsynthetic and real data experiments.\n"]},
{"authors": ["Makoto Naruse", "Eiji Yamamoto", "Takashi Nakao", "Takuma Akimoto", "Hayato Saigo", "Kazuya Okamura", "Izumi Ojima", "Georg Northoff", "Hirokazu Hori"], "title": ["Local reservoir model for choice-based learning"], "date": ["2018-04-12T05:35:14Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04324v1"], "summary": ["  Decision making based on behavioral and neural observations of living systems\nhas been extensively studied in brain science, psychology, and other\ndisciplines. Decision-making mechanisms have also been experimentally\nimplemented in physical processes, such as single photons and chaotic lasers.\nThe findings of these experiments suggest that there is a certain common basis\nin describing decision making, regardless of its physical realizations. In this\nstudy, we propose a local reservoir model to account for choice-based learning\n(CBL). CBL describes decision consistency as a phenomenon where making a\ncertain decision increases the possibility of making that same decision again\nlater, which has been intensively investigated in neuroscience, psychology,\netc. Our proposed model is inspired by the viewpoint that a decision is\naffected by its local environment, which is referred to as a local reservoir.\nIf the size of the local reservoir is large enough, consecutive decision making\nwill not be affected by previous decisions, thus showing lower degrees of\ndecision consistency in CBL. In contrast, if the size of the local reservoir\ndecreases, a biased distribution occurs within it, which leads to higher\ndegrees of decision consistency in CBL. In this study, an analytical approach\non local reservoirs is presented, as well as several numerical demonstrations.\nFurthermore, a physical architecture for CBL based on single photons is\ndiscussed, and the effects of local reservoirs is numerically demonstrated.\nDecision consistency in human decision-making tasks and in recruiting empirical\ndata are evaluated based on local reservoir. In summary, the proposed local\nreservoir model paves a path toward establishing a foundation for computational\nmechanisms and the systematic analysis of decision making on different levels.\n"]},
{"authors": ["Lars Ruthotto", "Eldad Haber"], "title": ["Deep Neural Networks motivated by Partial Differential Equations"], "date": ["2018-04-12T01:40:55Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04272v1"], "summary": ["  Partial differential equations (PDEs) are indispensable for modeling many\nphysical phenomena and also commonly used for solving image processing tasks.\nIn the latter area, PDE-based approaches interpret image data as\ndiscretizations of multivariate functions and the output of image processing\nalgorithms as solutions to certain PDEs. Posing image processing problems in\nthe infinite dimensional setting provides powerful tools for their analysis and\nsolution. Over the last three decades, the reinterpretation of classical image\nprocessing tasks through the PDE lens has been creating multiple celebrated\napproaches that benefit a vast area of tasks including image segmentation,\ndenoising, registration, and reconstruction.\n  In this paper, we establish a new PDE-interpretation of deep convolution\nneural networks (CNN) that are commonly used for learning tasks involving\nspeech, image, and video data. Our interpretation includes convolution residual\nneural networks (ResNet), which are among the most promising approaches for\ntasks such as image classification having improved the state-of-the-art\nperformance in prestigious benchmark challenges. Despite their recent\nsuccesses, deep ResNets still face some critical challenges associated with\ntheir design, immense computational costs and memory requirements, and lack of\nunderstanding of their reasoning.\n  Guided by well-established PDE theory, we derive three new ResNet\narchitectures that fall two new classes: parabolic and hyperbolic CNNs. We\ndemonstrate how PDE theory can provide new insights and algorithms for deep\nlearning and demonstrate the competitiveness of three new CNN architectures\nusing numerical experiments.\n"]},
{"authors": ["Jaime Lorenzo-Trueba", "Junichi Yamagishi", "Tomoki Toda", "Daisuke Saito", "Fernando Villavicencio", "Tomi Kinnunen", "Zhenhua Ling"], "title": ["The Voice Conversion Challenge 2018: Promoting Development of Parallel\n  and Nonparallel Methods"], "date": ["2018-04-12T00:14:10Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04262v1"], "summary": ["  We present the Voice Conversion Challenge 2018, designed as a follow up to\nthe 2016 edition with the aim of providing a common framework for evaluating\nand comparing different state-of-the-art voice conversion (VC) systems. The\nobjective of the challenge was to perform speaker conversion (i.e. transform\nthe vocal identity) of a source speaker to a target speaker while maintaining\nlinguistic information. As an update to the previous challenge, we considered\nboth parallel and non-parallel data to form the Hub and Spoke tasks,\nrespectively. A total of 23 teams from around the world submitted their\nsystems, 11 of them additionally participated in the optional Spoke task. A\nlarge-scale crowdsourced perceptual evaluation was then carried out to rate the\nsubmitted converted speech in terms of naturalness and similarity to the target\nspeaker identity. In this paper, we present a brief summary of the\nstate-of-the-art techniques for VC, followed by a detailed explanation of the\nchallenge tasks and the results that were obtained.\n"]},
{"authors": ["Rodney LaLonde", "Ulas Bagci"], "title": ["Capsules for Object Segmentation"], "date": ["2018-04-11T21:57:57Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04241v1"], "summary": ["  Convolutional neural networks (CNNs) have shown remarkable results over the\nlast several years for a wide range of computer vision tasks. A new\narchitecture recently introduced by Sabour et al., referred to as a capsule\nnetworks with dynamic routing, has shown great initial results for digit\nrecognition and small image classification. The success of capsule networks\nlies in their ability to preserve more information about the input by replacing\nmax-pooling layers with convolutional strides and dynamic routing, allowing for\npreservation of part-whole relationships in the data. This preservation of the\ninput is demonstrated by reconstructing the input from the output capsule\nvectors. Our work expands the use of capsule networks to the task of object\nsegmentation for the first time in the literature. We extend the idea of\nconvolutional capsules with locally-connected routing and propose the concept\nof deconvolutional capsules. Further, we extend the masked reconstruction to\nreconstruct the positive input class. The proposed\nconvolutional-deconvolutional capsule network, called SegCaps, shows strong\nresults for the task of object segmentation with substantial decrease in\nparameter space. As an example application, we applied the proposed SegCaps to\nsegment pathological lungs from low dose CT scans and compared its accuracy and\nefficiency with other U-Net-based architectures. SegCaps is able to handle\nlarge image sizes (512 x 512) as opposed to baseline capsules (typically less\nthan 32 x 32). The proposed SegCaps reduced the number of parameters of U-Net\narchitecture by 95.4% while still providing a better segmentation accuracy.\n"]},
{"authors": ["Noam Shazeer", "Mitchell Stern"], "title": ["Adafactor: Adaptive Learning Rates with Sublinear Memory Cost"], "date": ["2018-04-11T21:42:32Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04235v1"], "summary": ["  In several recently proposed stochastic optimization methods (e.g. RMSProp,\nAdam, Adadelta), parameter updates are scaled by the inverse square roots of\nexponential moving averages of squared past gradients. Maintaining these\nper-parameter second-moment estimators requires memory equal to the number of\nparameters. For the case of neural network weight matrices, we propose\nmaintaining only the per-row and per-column sums of these moving averages, and\nestimating the per-parameter second moments based on these sums. We demonstrate\nempirically that this method produces similar results to the baseline.\nSecondly, we show that adaptive methods can produce larger-than-desired updates\nwhen the decay rate of the second moment accumulator is too slow. We propose\nupdate clipping and a gradually increasing decay rate scheme as remedies.\nCombining these methods and dropping momentum, we achieve comparable results to\nthe published Adam regime in training the Transformer model on the WMT 2014\nEnglish-German machine translation task, while using very little auxiliary\nstorage in the optimizer. Finally, we propose scaling the parameter updates\nbased on the scale of the parameters themselves.\n"]},
{"authors": ["Hugo Caselles-Dupr\u00e9", "Florian Lesaint", "Jimena Royo-Letelier"], "title": ["Word2Vec applied to Recommendation: Hyperparameters Matter"], "date": ["2018-04-11T20:37:35Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04212v1"], "summary": ["  Skip-gram with negative sampling, a popular variant of Word2vec originally\ndesigned and tuned to create word embeddings for Natural Language Processing,\nhas been used to create item embeddings with successful applications in\nrecommendation. While these fields do not share the same type of data, neither\nevaluate on the same tasks, recommendation applications tend to use the same\nalready tuned hyperparameters values, even if optimal hyperparameters values\nare often known to be data and task dependent. We thus investigate the marginal\nimportance of each hyperparameter in a recommendation setting, with an\nextensive joint hyperparameter optimization on various datasets. Results reveal\nthat optimizing neglected hyperparameters, namely negative sampling\ndistribution, number of epochs, subsampling parameter and window-size,\nsignificantly improves performance on a recommendation task, and can increase\nit up to a factor of $10$.\n"]},
{"authors": ["Boheng Zhang", "Shenglei Huang", "Shaohan Hu"], "title": ["Multi-scale Neural Networks for Retinal Blood Vessels Segmentation"], "date": ["2018-04-11T20:25:36Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04206v1"], "summary": ["  Existing supervised approaches didn't make use of the low-level features\nwhich are actually effective to this task. And another deficiency is that they\ndidn't consider the relation between pixels, which means effective features are\nnot extracted. In this paper, we proposed a novel convolutional neural network\nwhich make sufficient use of low-level features together with high-level\nfeatures and involves atrous convolution to get multi-scale features which\nshould be considered as effective features. Our model is tested on three\nstandard benchmarks - DRIVE, STARE, and CHASE databases. The results presents\nthat our model significantly outperforms existing approaches in terms of\naccuracy, sensitivity, specificity, the area under the ROC curve and the\nhighest prediction speed. Our work provides evidence of the power of wide and\ndeep neural networks in retinal blood vessels segmentation task which could be\napplied on other medical images tasks.\n"]},
{"authors": ["Ziyi Zhao", "Krittaphat Pugdeethosapol", "Sheng Lin", "Zhe Li", "Caiwen Ding", "Yanzhi Wang", "Qinru Qiu"], "title": ["Learning Topics using Semantic Locality"], "date": ["2018-04-11T20:23:23Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04205v1"], "summary": ["  The topic modeling discovers the latent topic probability of the given text\ndocuments. To generate the more meaningful topic that better represents the\ngiven document, we proposed a new feature extraction technique which can be\nused in the data preprocessing stage. The method consists of three steps.\nFirst, it generates the word/word-pair from every single document. Second, it\napplies a two-way TF-IDF algorithm to word/word-pair for semantic filtering.\nThird, it uses the K-means algorithm to merge the word pairs that have the\nsimilar semantic meaning.\n  Experiments are carried out on the Open Movie Database (OMDb), Reuters\nDataset and 20NewsGroup Dataset. The mean Average Precision score is used as\nthe evaluation metric. Comparing our results with other state-of-the-art topic\nmodels, such as Latent Dirichlet allocation and traditional Restricted\nBoltzmann Machines. Our proposed data preprocessing can improve the generated\ntopic accuracy by up to 12.99\\%.\n"]},
{"authors": ["David Janz", "Jos van der Westhuizen", "Brooks Paige", "Matt J. Kusner", "Jose Miguel Hernandez-Labato"], "title": ["Learning a Generative Model for Validity in Complex Discrete Structures"], "date": ["2017-12-05T14:36:23Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1712.01664v2"], "summary": ["  Deep generative models have been successfully used to learn representations\nfor high-dimensional discrete spaces by representing discrete objects as\nsequences and employing powerful sequence-based deep models. Unfortunately,\nthese sequence-based models often produce invalid sequences: sequences which do\nnot represent any underlying discrete structure; invalid sequences hinder the\nutility of such models. As a step towards solving this problem, we propose to\nlearn a deep recurrent validator model, which can estimate whether a partial\nsequence can function as the beginning of a full, valid sequence. This\nvalidator provides insight as to how individual sequence elements influence the\nvalidity of the overall sequence, and can be used to constrain sequence based\nmodels to generate valid sequences -- and thus faithfully model discrete\nobjects. Our approach is inspired by reinforcement learning, where an oracle\nwhich can evaluate validity of complete sequences provides a sparse reward\nsignal. We demonstrate its effectiveness as a generative model of Python 3\nsource code for mathematical expressions, and in improving the ability of a\nvariational autoencoder trained on SMILES strings to decode valid molecular\nstructures.\n"]},
{"authors": ["R\u00e9my Sun", "Christoph H. Lampert"], "title": ["KS(conf ): A Light-Weight Test if a ConvNet Operates Outside of Its\n  Specifications"], "date": ["2018-04-11T19:05:51Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04171v1"], "summary": ["  Computer vision systems for automatic image categorization have become\naccurate and reliable enough that they can run continuously for days or even\nyears as components of real-world commercial applications. A major open problem\nin this context, however, is quality control. Good classification performance\ncan only be expected if systems run under the specific conditions, in\nparticular data distributions, that they were trained for. Surprisingly, none\nof the currently used deep network architectures has a built-in functionality\nthat could detect if a network operates on data from a distribution that it was\nnot trained for and potentially trigger a warning to the human users. In this\nwork, we describe KS(conf), a procedure for detecting such outside of the\nspecifications operation. Building on statistical insights, its main step is\nthe applications of a classical Kolmogorov-Smirnov test to the distribution of\npredicted confidence values. We show by extensive experiments using ImageNet,\nAwA2 and DAVIS data on a variety of ConvNets architectures that KS(conf)\nreliably detects out-of-specs situations. It furthermore has a number of\nproperties that make it an excellent candidate for practical deployment: it is\neasy to implement, adds almost no overhead to the system, works with all\nnetworks, including pretrained ones, and requires no a priori knowledge about\nhow the data distribution could change.\n"]},
{"authors": ["Jin-Guo Liu", "Lei Wang"], "title": ["Differentiable Learning of Quantum Circuit Born Machine"], "date": ["2018-04-11T19:01:11Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04168v1"], "summary": ["  Quantum circuit Born machines are generative models which represent the\nprobability distribution of classical dataset as quantum pure states.\nComputational complexity considerations of the quantum sampling problem suggest\nthat the quantum circuits exhibit stronger expressibility compared to classical\nneural networks. One can efficiently draw samples from the quantum circuits via\nprojective measurements on qubits. However, similar to the leading implicit\ngenerative models in deep learning, such as the generative adversarial\nnetworks, the quantum circuits cannot provide the likelihood of the generated\nsamples, which poses a challenge to the training. We devise an efficient\ngradient-based learning algorithm for the quantum circuit Born machine by\nminimizing the kerneled maximum mean discrepancy loss. We simulated generative\nmodeling of the Bars-and-Stripes dataset and Gaussian mixture distributions\nusing deep quantum circuits. Our experiments show the importance of circuit\ndepth and gradient-based optimization algorithm. The proposed learning\nalgorithm is runnable on near-term quantum device and can exhibit quantum\nadvantages for generative modeling.\n"]},
{"authors": ["Alberto Beretta", "Claudia Battistin", "Cl\u00e9lia de Mulatier", "Iacopo Mastromatteo", "Matteo Marsili"], "title": ["The Stochastic complexity of spin models: Are pairwise models really\n  simple?"], "date": ["2017-02-24T11:55:13Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1702.07549v3"], "summary": ["  Models can be simple for different reasons: because they yield a simple and\ncomputationally efficient interpretation of a generic dataset (e.g. in terms of\npairwise dependences) - as in statistical learning - or because they capture\nthe essential ingredients of a specific phenomenon - as e.g. in physics -\nleading to non-trivial falsifiable predictions. In information theory and\nBayesian inference, the simplicity of a model is precisely quantified in the\nstochastic complexity, which measures the number of bits needed to encode its\nparameters. In order to understand how simple models look like, we study the\nstochastic complexity of spin models with interactions of arbitrary order. We\nhighlight the existence of invariances with respect to bijections within the\nspace of operators, which allow us to partition the space of all models into\nequivalence classes, in which models share the same complexity. We thus found\nthat the complexity (or simplicity) of a model is not determined by the order\nof the interactions, but rather by their mutual arrangements. Models where\nstatistical dependencies are localized on non-overlapping groups of few\nvariables (and that afford predictions on independencies that are easy to\nfalsify) are simple. On the contrary, fully connected pairwise models, which\nare often used in statistical learning, appear to be highly complex, because of\ntheir extended set of interactions.\n"]},
{"authors": ["Eshed Ohn-Bar", "Kris Kitani", "Chieko Asakawa"], "title": ["Personalized Dynamics Models for Adaptive Assistive Navigation\n  Interfaces"], "date": ["2018-04-11T17:55:00Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04118v1"], "summary": ["  We explore the role of personalization for assistive navigational systems\n(e.g., service robot, wearable system or smartphone app) that guide visually\nimpaired users through speech, sound and haptic-based instructional guidance.\nBased on our analysis of real-world users, we show that the dynamics of blind\nusers cannot be accounted for by a single universal model but instead must be\nlearned on an individual basis. To learn personalized instructional interfaces,\nwe propose PING (Personalized INstruction Generation agent), a model-based\nreinforcement learning framework which aims to quickly adapt its state\ntransition dynamics model to match the reactions of the user using a novel\nend-to-end learned weighted majority-based regression algorithm. In our\nexperiments, we show that PING learns dynamics models significantly faster\ncompared to baseline transfer learning approaches on real-world data. We find\nthat through better reasoning over personal mobility nuances, interaction with\nsurrounding obstacles, and the current navigation task, PING is able to improve\nthe performance of instructional assistive navigation at the most crucial\njunctions such as turns or veering paths. To enable sufficient planning time\nover user responses, we emphasize prediction of human motion for long horizons.\nSpecifically, the learned dynamics models are shown to consistently improve\nlong-term position prediction by over 1 meter on average (nearly the width of a\nhallway) compared to baseline approaches even when considering a prediction\nhorizon of 20 seconds into the future.\n"]},
{"authors": ["Jo\u00e3o Gante", "Gabriel Falc\u00e3o", "Leonel Sousa"], "title": ["Beamformed Fingerprint Learning for Accurate Millimeter Wave Positioning"], "date": ["2018-04-11T17:36:30Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04112v1"], "summary": ["  With millimeter wave wireless communications, the resulting radiation\nreflects on most visible objects, creating rich multipath environments, namely\nin urban scenarios. The radiation captured by a listening device is thus shaped\nby the obstacles encountered, which carry latent information regarding their\nrelative positions. In this paper, a system to convert the received millimeter\nwave radiation into the device's position is proposed, making use of the\naforementioned hidden information. Using deep learning techniques and a\npre-established codebook of beamforming patterns transmitted by a base station,\nthe simulations show that average estimation errors below 10 meters are\nachievable in realistic outdoors scenarios that contain mostly\nnon-line-of-sight positions, paving the way for new positioning systems.\n"]},
{"authors": ["Fay\u00e7al Ait Aoudia", "Jakob Hoydis"], "title": ["End-to-End Learning of Communications Systems Without a Channel Model"], "date": ["2018-04-06T14:01:00Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02276v2"], "summary": ["  The idea of end-to-end learning of communications systems through neural\nnetwork -based autoencoders has the shortcoming that it requires a\ndifferentiable channel model. We present in this paper a novel learning\nalgorithm which alleviates this problem. The algorithm iterates between\nsupervised training of the receiver and reinforcement learning -based training\nof the transmitter. We demonstrate that this approach works as well as fully\nsupervised methods on additive white Gaussian noise (AWGN) and Rayleigh\nblock-fading (RBF) channels. Surprisingly, while our method converges slower on\nAWGN channels than supervised training, it converges faster on RBF channels.\nOur results are a first step towards learning of communications systems over\nany type of channel without prior assumptions.\n"]},
{"authors": ["Chao Gan", "Ruida Zhou", "Jing Yang", "Cong Shen"], "title": ["Cost-Aware Learning and Optimization for Opportunistic Spectrum Access"], "date": ["2018-04-11T15:28:07Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04048v1"], "summary": ["  In this paper, we investigate cost-aware joint learning and optimization for\nmulti-channel opportunistic spectrum access in a cognitive radio system. We\ninvestigate a discrete time model where the time axis is partitioned into\nframes. Each frame consists of a sensing phase, followed by a transmission\nphase. During the sensing phase, the user is able to sense a subset of channels\nsequentially before it decides to use one of them in the following transmission\nphase. We assume the channel states alternate between busy and idle according\nto independent Bernoulli random processes from frame to frame. To capture the\ninherent uncertainty in channel sensing, we assume the reward of each\ntransmission when the channel is idle is a random variable. We also associate\nrandom costs with sensing and transmission actions. Our objective is to\nunderstand how the costs and reward of the actions would affect the optimal\nbehavior of the user in both offline and online settings, and design the\ncorresponding opportunistic spectrum access strategies to maximize the expected\ncumulative net reward (i.e., reward-minus-cost). We start with an offline\nsetting where the statistics of the channel status, costs and reward are known\nbeforehand. We show that the the optimal policy exhibits a recursive double\nthreshold structure, and the user needs to compare the channel statistics with\nthose thresholds sequentially in order to decide its actions. With such\ninsights, we then study the online setting, where the statistical information\nof the channels, costs and reward are unknown a priori. We judiciously balance\nexploration and exploitation, and show that the cumulative regret scales in\nO(log T). We also establish a matched lower bound, which implies that our\nonline algorithm is order-optimal. Simulation results corroborate our\ntheoretical analysis.\n"]},
{"authors": ["Leshem Choshen", "Lior Fox", "Yonatan Loewenstein"], "title": ["DORA The Explorer: Directed Outreaching Reinforcement Action-Selection"], "date": ["2018-04-11T14:21:53Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04012v1"], "summary": ["  Exploration is a fundamental aspect of Reinforcement Learning, typically\nimplemented using stochastic action-selection. Exploration, however, can be\nmore efficient if directed toward gaining new world knowledge. Visit-counters\nhave been proven useful both in practice and in theory for directed\nexploration. However, a major limitation of counters is their locality. While\nthere are a few model-based solutions to this shortcoming, a model-free\napproach is still missing. We propose $E$-values, a generalization of counters\nthat can be used to evaluate the propagating exploratory value over\nstate-action trajectories. We compare our approach to commonly used RL\ntechniques, and show that using $E$-values improves learning and performance\nover traditional counters. We also show how our method can be implemented with\nfunction approximation to efficiently learn continuous MDPs. We demonstrate\nthis by showing that our approach surpasses state of the art performance in the\nFreeway Atari 2600 game.\n"]},
{"authors": ["Baptiste Wicht", "Jean Hennebert", "Andreas Fischer"], "title": ["DLL: A Blazing Fast Deep Neural Network Library"], "date": ["2018-04-11T13:56:07Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04512v1"], "summary": ["  Deep Learning Library (DLL) is a new library for machine learning with deep\nneural networks that focuses on speed. It supports feed-forward neural networks\nsuch as fully-connected Artificial Neural Networks (ANNs) and Convolutional\nNeural Networks (CNNs). It also has very comprehensive support for Restricted\nBoltzmann Machines (RBMs) and Convolutional RBMs. Our main motivation for this\nwork was to propose and evaluate novel software engineering strategies with\npotential to accelerate runtime for training and inference. Such strategies are\nmostly independent of the underlying deep learning algorithms. On three\ndifferent datasets and for four different neural network models, we compared\nDLL to five popular deep learning frameworks. Experimentally, it is shown that\nthe proposed framework is systematically and significantly faster on CPU and\nGPU. In terms of classification performance, similar accuracies as the other\nframeworks are reported.\n"]},
{"authors": ["Muhammad Naveed Tabassum", "Esa Ollila"], "title": ["Compressive Regularized Discriminant Analysis of High-Dimensional Data\n  with Applications to Microarray Studies"], "date": ["2018-04-11T13:48:56Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03981v1"], "summary": ["  We propose a modification of linear discriminant analysis, referred to as\ncompressive regularized discriminant analysis (CRDA), for analysis of\nhigh-dimensional datasets. CRDA is specially designed for feature elimination\npurpose and can be used as gene selection method in microarray studies. CRDA\nlends ideas from $\\ell_{q,1}$ norm minimization algorithms in the multiple\nmeasurement vectors (MMV) model and utilizes joint-sparsity promoting hard\nthresholding for feature elimination. A regularization of the sample covariance\nmatrix is also needed as we consider the challenging scenario where the number\nof features (variables) is comparable or exceeding the sample size of the\ntraining dataset. A simulation study and four examples of real-life microarray\ndatasets evaluate the performances of CRDA based classifiers. Overall, the\nproposed method gives fewer misclassification errors than its competitors,\nwhile at the same time achieving accurate feature selection.\n"]},
{"authors": ["Hiroshi Inoue"], "title": ["Data Augmentation by Pairing Samples for Images Classification"], "date": ["2018-01-09T13:37:11Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1801.02929v2"], "summary": ["  Data augmentation is a widely used technique in many machine learning tasks,\nsuch as image classification, to virtually enlarge the training dataset size\nand avoid overfitting. Traditional data augmentation techniques for image\nclassification tasks create new samples from the original training data by, for\nexample, flipping, distorting, adding a small amount of noise to, or cropping a\npatch from an original image. In this paper, we introduce a simple but\nsurprisingly effective data augmentation technique for image classification\ntasks. With our technique, named SamplePairing, we synthesize a new sample from\none image by overlaying another image randomly chosen from the training data\n(i.e., taking an average of two images for each pixel). By using two images\nrandomly selected from the training set, we can generate $N^2$ new samples from\n$N$ training samples. This simple data augmentation technique significantly\nimproved classification accuracy for all the tested datasets; for example, the\ntop-1 error rate was reduced from 33.5% to 29.0% for the ILSVRC 2012 dataset\nwith GoogLeNet and from 8.22% to 6.93% in the CIFAR-10 dataset. We also show\nthat our SamplePairing technique largely improved accuracy when the number of\nsamples in the training set was very small. Therefore, our technique is more\nvaluable for tasks with a limited amount of training data, such as medical\nimaging tasks.\n"]},
{"authors": ["Mark Kozdoba", "Shie Mannor"], "title": ["Interdependent Gibbs Samplers"], "date": ["2018-04-11T12:38:50Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03958v1"], "summary": ["  Gibbs sampling, as a model learning method, is known to produce the most\naccurate results available in a variety of domains, and is a de facto standard\nin these domains. Yet, it is also well known that Gibbs random walks usually\nhave bottlenecks, sometimes termed \"local maxima\", and thus samplers often\nreturn suboptimal solutions. In this paper we introduce a variation of the\nGibbs sampler which yields high likelihood solutions significantly more often\nthan the regular Gibbs sampler.\n  Specifically, we show that combining multiple samplers, with certain\ndependence (coupling) between them, results in higher likelihood solutions.\nThis side-steps the well known issue of identifiability, which has been the\nobstacle to combining samplers in previous work. We evaluate the approach on a\nLatent Dirichlet Allocation model, and also on HMM's, where precise computation\nof likelihoods and comparisons to the standard EM algorithm are possible.\n"]},
{"authors": ["Damian Kozbur"], "title": ["Sharp Convergence Rates for Forward Regression in High-Dimensional\n  Sparse Linear Models"], "date": ["2017-02-03T13:33:32Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1702.01000v3"], "summary": ["  Forward regression is a statistical model selection and estimation procedure\nwhich inductively selects covariates that add predictive power into a working\nstatistical regression model. Once a model is selected, unknown regression\nparameters are estimated by least squares. This paper analyzes forward\nregression in high-dimensional sparse linear models. Probabilistic bounds for\nprediction error norm and number of selected covariates are proved. The\nanalysis in this paper gives sharp rates and does not require beta-min or\nirrepresentability conditions.\n"]},
{"authors": ["Aymeric Dieuleveut", "Alain Durmus", "Francis Bach"], "title": ["Bridging the Gap between Constant Step Size Stochastic Gradient Descent\n  and Markov Chains"], "date": ["2017-07-20T06:31:22Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1707.06386v2"], "summary": ["  We consider the minimization of an objective function given access to\nunbiased estimates of its gradient through stochastic gradient descent (SGD)\nwith constant step-size. While the detailed analysis was only performed for\nquadratic functions, we provide an explicit asymptotic expansion of the moments\nof the averaged SGD iterates that outlines the dependence on initial\nconditions, the effect of noise and the step-size, as well as the lack of\nconvergence in the general (non-quadratic) case. For this analysis, we bring\ntools from Markov chain theory into the analysis of stochastic gradient. We\nthen show that Richardson-Romberg extrapolation may be used to get closer to\nthe global optimum and we show empirical improvements of the new extrapolation\nscheme.\n"]},
{"authors": ["Kien Do", "Truyen Tran", "Thin Nguyen", "Svetha Venkatesh"], "title": ["Attentional Multilabel Learning over Graphs: A Message Passing Approach"], "date": ["2018-04-01T13:01:24Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00293v2"], "summary": ["  We address a largely open problem of multilabel classification over graphs.\nUnlike traditional vector input, a graph has rich variable-size substructures\nwhich are related to the labels in some ways. We believe that uncovering these\nrelations might hold the key to classification performance and explainability.\nWe introduce GAML (Graph Attentional Multi-Label learning), a novel graph\nneural network that can handle this problem effectively. GAML regards labels as\nauxiliary nodes and models them in conjunction with the input graph. By\napplying message passing and attention mechanisms to both the label nodes and\nthe input nodes iteratively, GAML can capture the relations between the labels\nand the input subgraphs at various resolution scales. Moreover, our model can\ntake advantage of explicit label dependencies. It also scales linearly with the\nnumber of labels and graph size thanks to our proposed hierarchical attention.\nWe evaluate GAML on an extensive set of experiments with both graph-structured\ninputs and classical unstructured inputs. The results show that GAML\nsignificantly outperforms other competing methods. Importantly, GAML enables\nintuitive visualizations for better understanding of the label-substructure\nrelations and explanation of the model behaviors.\n"]},
{"authors": ["Anil R. Yelundur", "Srinivasan H. Sengamedu", "Bamdev Mishra"], "title": ["Bayesian Semi-Supervised Tensor Decomposition using Natural Gradients\n  for Anomaly Detection"], "date": ["2018-04-11T06:55:06Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03836v1"], "summary": ["  Anomaly Detection has several important applications. In this paper, our\nfocus is on detecting anomalies in seller-reviewer data using tensor\ndecomposition. While tensor-decomposition is mostly unsupervised, we formulate\nBayesian semi-supervised tensor decomposition to take advantage of sparse\nlabeled data. In addition, we use Polya-Gamma data augmentation for the\nsemi-supervised Bayesian tensor decomposition. Finally, we show that the\nPolya-Gamma formulation simplifies calculation of the Fisher information matrix\nfor partial natural gradient learning. Our experimental results show that our\nsemi-supervised approach outperforms state of the art unsupervised baselines.\nAnd that the partial natural gradient learning outperforms stochastic gradient\nlearning and Online-EM with sufficient statistics.\n"]},
{"authors": ["Barret Zoph", "Vijay Vasudevan", "Jonathon Shlens", "Quoc V. Le"], "title": ["Learning Transferable Architectures for Scalable Image Recognition"], "date": ["2017-07-21T18:10:26Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1707.07012v4"], "summary": ["  Developing neural network image classification models often requires\nsignificant architecture engineering. In this paper, we study a method to learn\nthe model architectures directly on the dataset of interest. As this approach\nis expensive when the dataset is large, we propose to search for an\narchitectural building block on a small dataset and then transfer the block to\na larger dataset. The key contribution of this work is the design of a new\nsearch space (the \"NASNet search space\") which enables transferability. In our\nexperiments, we search for the best convolutional layer (or \"cell\") on the\nCIFAR-10 dataset and then apply this cell to the ImageNet dataset by stacking\ntogether more copies of this cell, each with their own parameters to design a\nconvolutional architecture, named \"NASNet architecture\". We also introduce a\nnew regularization technique called ScheduledDropPath that significantly\nimproves generalization in the NASNet models. On CIFAR-10 itself, NASNet\nachieves 2.4% error rate, which is state-of-the-art. On ImageNet, NASNet\nachieves, among the published works, state-of-the-art accuracy of 82.7% top-1\nand 96.2% top-5 on ImageNet. Our model is 1.2% better in top-1 accuracy than\nthe best human-invented architectures while having 9 billion fewer FLOPS - a\nreduction of 28% in computational demand from the previous state-of-the-art\nmodel. When evaluated at different levels of computational cost, accuracies of\nNASNets exceed those of the state-of-the-art human-designed models. For\ninstance, a small version of NASNet also achieves 74% top-1 accuracy, which is\n3.1% better than equivalently-sized, state-of-the-art models for mobile\nplatforms. Finally, the learned features by NASNet used with the Faster-RCNN\nframework surpass state-of-the-art by 4.0% achieving 43.1% mAP on the COCO\ndataset.\n"]},
{"authors": ["Jilei Yang", "Jie Peng"], "title": ["Estimating Time-Varying Graphical Models"], "date": ["2018-04-11T04:54:56Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03811v1"], "summary": ["  In this paper, we study time-varying graphical models based on data measured\nover a temporal grid. Such models are motivated by the needs to describe and\nunderstand evolving interacting relationships among a set of random variables\nin many real applications, for instance the study of how stocks interact with\neach other and how such interactions change over time.\n  We propose a new model, LOcal Group Graphical Lasso Estimation (loggle),\nunder the assumption that the graph topology changes gradually over time.\nSpecifically, loggle uses a novel local group-lasso type penalty to efficiently\nincorporate information from neighboring time points and to impose structural\nsmoothness of the graphs. We implement an ADMM based algorithm to fit the\nloggle model. This algorithm utilizes blockwise fast computation and\npseudo-likelihood approximation to improve computational efficiency. An R\npackage loggle has also been developed.\n  We evaluate the performance of loggle by simulation experiments. We also\napply loggle to S&P 500 stock price data and demonstrate that loggle is able to\nreveal the interacting relationships among stocks and among industrial sectors\nin a time period that covers the recent global financial crisis.\n"]},
{"authors": ["Been Kim", "Martin Wattenberg", "Justin Gilmer", "Carrie Cai", "James Wexler", "Fernanda Viegas", "Rory Sayres"], "title": ["Interpretability Beyond Feature Attribution: Quantitative Testing with\n  Concept Activation Vectors (TCAV)"], "date": ["2017-11-30T09:26:12Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.11279v4"], "summary": ["  The interpretation of deep learning models is a challenge due to their size,\ncomplexity, and often opaque internal state. In addition, many systems, such as\nimage classifiers, operate on low-level features rather than high-level\nconcepts. To address these challenges, we introduce Concept Activation Vectors\n(CAVs), which provide an interpretation of a neural net's internal state in\nterms of human-friendly concepts. The key idea is to view the high-dimensional\ninternal state of a neural net as an aid, not an obstacle. We show how to use\nCAVs as part of a technique, Testing with CAVs (TCAV), that uses directional\nderivatives to quantify the degree to which a user-defined concept is important\nto a classification result--for example, how sensitive a prediction of \"zebra\"\nis to the presence of stripes. Using the domain of image classification as a\ntesting ground, we describe how CAVs may be used to explore hypotheses and\ngenerate insights for a standard image classification network as well as a\nmedical application.\n"]},
{"authors": ["Chen Zhang", "Hao Yan", "Seungho Lee", "Jianjun Shi"], "title": ["Dynamic Multivariate Functional Data Modeling via Sparse Subspace\n  Learning"], "date": ["2018-04-11T03:32:16Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03797v1"], "summary": ["  Multivariate functional data from a complex system are naturally\nhigh-dimensional and have complex cross-correlation structure. The complexity\nof data structure can be observed as that (1) some functions are strongly\ncorrelated with similar features, while some others may have almost no\ncross-correlations with quite diverse features; and (2) the cross-correlation\nstructure may also change over time due to the system evolution. With this\nregard, this paper presents a dynamic subspace learning method for multivariate\nfunctional data modeling. In particular, we consider different functions come\nfrom different subspaces, and only functions of the same subspace have\ncross-correlations with each other. The subspaces can be automatically\nformulated and learned by reformatting the problem as a sparse regression. By\nallowing but regularizing the regression change over time, we can describe the\ncross-correlation dynamics. The model can be efficiently estimated by the fast\niterative shrinkage-thresholding algorithm (FISTA), and the features of every\nsubspace can be extracted using the smooth multi-channel functional PCA.\nNumerical studies together with case studies demonstrate the efficiency and\napplicability of the proposed methodology.\n"]},
{"authors": ["Yue Wang", "Daniel Kifer", "Jaewoo Lee"], "title": ["Differentially Private Confidence Intervals for Empirical Risk\n  Minimization"], "date": ["2018-04-11T03:18:17Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03794v1"], "summary": ["  The process of data mining with differential privacy produces results that\nare affected by two types of noise: sampling noise due to data collection and\nprivacy noise that is designed to prevent the reconstruction of sensitive\ninformation. In this paper, we consider the problem of designing confidence\nintervals for the parameters of a variety of differentially private machine\nlearning models. The algorithms can provide confidence intervals that satisfy\ndifferential privacy (as well as the more recently proposed concentrated\ndifferential privacy) and can be used with existing differentially private\nmechanisms that train models using objective perturbation and output\nperturbation.\n"]},
{"authors": ["Daniel Alabi", "Nicole Immorlica", "Adam Tauman Kalai"], "title": ["When optimizing nonlinear objectives is no harder than linear objectives"], "date": ["2018-04-11T02:51:07Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04503v1"], "summary": ["  Most systems and learning algorithms optimize average performance or average\nloss --- one reason being computational complexity. However, many objectives of\npractical interest are more complex than simply average loss. Examples include\nbalancing performance or loss with fairness across people, as well as balancing\nprecision and recall. We prove that, from a computational perspective, fairly\ngeneral families of complex objectives are not significantly harder to optimize\nthan standard averages, by providing polynomial-time reductions, i.e.,\nalgorithms that optimize complex objectives using linear optimizers. The\nfamilies of objectives included are arbitrary continuous functions of average\ngroup performances and also convex objectives. We illustrate with applications\nto fair machine learning, fair optimization and F1-scores.\n"]},
{"authors": ["Sidi Lu", "Lantao Yu", "Weinan Zhang", "Yong Yu"], "title": ["CoT: Cooperative Training for Generative Modeling"], "date": ["2018-04-11T02:10:55Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03782v1"], "summary": ["  We propose Cooperative Training (CoT) for training generative models that\nmeasure a tractable density function for target data. CoT coordinately trains a\ngenerator $G$ and an auxiliary predictive mediator $M$. The training target of\n$M$ is to estimate a mixture density of the learned distribution $G$ and the\ntarget distribution $P$, and that of $G$ is to minimize the Jensen-Shannon\ndivergence estimated through $M$. CoT achieves independent success without the\nnecessity of pre-training via Maximum Likelihood Estimation or involving\nhigh-variance algorithms like REINFORCE. This low-variance algorithm is\ntheoretically proved to be unbiased for both generative and predictive tasks.\nWe also theoretically and empirically show the superiority of CoT over most\nprevious algorithms, in terms of generative quality and diversity, predictive\ngeneralization ability and computational cost.\n"]},
{"authors": ["Shibani Santurkar", "Ludwig Schmidt", "Aleksander M\u0105dry"], "title": ["A Classification-Based Perspective on GAN Distributions"], "date": ["2017-11-02T23:13:39Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.00970v4"], "summary": ["  A fundamental, and still largely unanswered, question in the context of\nGenerative Adversarial Networks (GANs) is whether GANs are actually able to\ncapture the key characteristics of the datasets they are trained on. The\ncurrent approaches to examining this issue require significant human\nsupervision, such as visual inspection of sampled images, and often offer only\nfairly limited scalability. In this paper, we propose new techniques that\nemploy a classification-based perspective to evaluate synthetic GAN\ndistributions and their capability to accurately reflect the essential\nproperties of the training data. These techniques require only minimal human\nsupervision and can easily be scaled and adapted to evaluate a variety of\nstate-of-the-art GANs on large, popular datasets. Our analysis indicates that\nGANs have significant problems in reproducing the more distributional\nproperties of the training dataset. In particular, when seen through the lens\nof classification, the diversity of GAN data is orders of magnitude less than\nthat of the original data.\n"]},
{"authors": ["Tatsunori B. Hashimoto", "Steve Yadlowsky", "John C. Duchi"], "title": ["Derivative free optimization via repeated classification"], "date": ["2018-04-11T00:45:39Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03761v1"], "summary": ["  We develop an algorithm for minimizing a function using $n$ batched function\nvalue measurements at each of $T$ rounds by using classifiers to identify a\nfunction's sublevel set. We show that sufficiently accurate classifiers can\nachieve linear convergence rates, and show that the convergence rate is tied to\nthe difficulty of active learning sublevel sets. Further, we show that the\nbootstrap is a computationally efficient approximation to the necessary\nclassification scheme.\n  The end result is a computationally efficient derivative-free algorithm\nrequiring no tuning that consistently outperforms other approaches on\nsimulations, standard benchmarks, real-world DNA binding optimization, and\nairfoil design problems whenever batched function queries are natural.\n"]},
{"authors": ["Chen Ma", "Junfeng Wen", "Yoshua Bengio"], "title": ["Universal Successor Representations for Transfer Reinforcement Learning"], "date": ["2018-04-11T00:06:36Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03758v1"], "summary": ["  The objective of transfer reinforcement learning is to generalize from a set\nof previous tasks to unseen new tasks. In this work, we focus on the transfer\nscenario where the dynamics among tasks are the same, but their goals differ.\nAlthough general value function (Sutton et al., 2011) has been shown to be\nuseful for knowledge transfer, learning a universal value function can be\nchallenging in practice. To attack this, we propose (1) to use universal\nsuccessor representations (USR) to represent the transferable knowledge and (2)\na USR approximator (USRA) that can be trained by interacting with the\nenvironment. Our experiments show that USR can be effectively applied to new\ntasks, and the agent initialized by the trained USRA can achieve the goal\nconsiderably faster than random initialization.\n"]},
{"authors": ["Vassilis N. Ioannidis", "Meng Ma", "Athanasios N. Nikolakopoulos", "Georgios B. Giannakis", "Daniel Romero"], "title": ["Kernel-based Inference of Functions over Graphs"], "date": ["2017-11-28T15:43:04Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.10353v2"], "summary": ["  The study of networks has witnessed an explosive growth over the past decades\nwith several ground-breaking methods introduced. A particularly interesting --\nand prevalent in several fields of study -- problem is that of inferring a\nfunction defined over the nodes of a network. This work presents a versatile\nkernel-based framework for tackling this inference problem that naturally\nsubsumes and generalizes the reconstruction approaches put forth recently by\nthe signal processing on graphs community. Both the static and the dynamic\nsettings are considered along with effective modeling approaches for addressing\nreal-world problems. The herein analytical discussion is complemented by a set\nof numerical examples, which showcase the effectiveness of the presented\ntechniques, as well as their merits related to state-of-the-art methods.\n"]},
{"authors": ["Igor Fedorov", "Bhaskar D. Rao"], "title": ["Multimodal Sparse Bayesian Dictionary Learning"], "date": ["2018-04-10T22:27:21Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03740v1"], "summary": ["  The purpose of this paper is to address the problem of learning dictionaries\nfor multimodal datasets, i.e. datasets collected from multiple data sources. We\npresent an algorithm called multimodal sparse Bayesian dictionary learning\n(MSBDL). The MSBDL algorithm is able to leverage information from all available\ndata modalities through a joint sparsity constraint on each modality's sparse\ncodes without restricting the coefficients themselves to be equal. Our\nframework offers a considerable amount of flexibility to practitioners and\naddresses many of the shortcomings of existing multimodal dictionary learning\napproaches. Unlike existing approaches, MSBDL allows the dictionaries for each\ndata modality to have different cardinality. In addition, MSBDL can be used in\nnumerous scenarios, from small datasets to extensive datasets with large\ndimensionality. MSBDL can also be used in supervised settings and allows for\nlearning multimodal dictionaries concurrently with classifiers for each\nmodality.\n"]},
{"authors": ["Swapnil Mishra", "Marian-Andrei Rizoiu", "Lexing Xie"], "title": ["Modeling Popularity in Asynchronous Social Media Streams with Recurrent\n  Neural Networks"], "date": ["2018-04-06T01:12:28Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02101v2"], "summary": ["  Understanding and predicting the popularity of online items is an important\nopen problem in social media analysis. Considerable progress has been made\nrecently in data-driven predictions, and in linking popularity to external\npromotions. However, the existing methods typically focus on a single source of\nexternal influence, whereas for many types of online content such as YouTube\nvideos or news articles, attention is driven by multiple heterogeneous sources\nsimultaneously - e.g. microblogs or traditional media coverage. Here, we\npropose RNN-MAS, a recurrent neural network for modeling asynchronous streams.\nIt is a sequence generator that connects multiple streams of different\ngranularity via joint inference. We show RNN-MAS not only to outperform the\ncurrent state-of-the-art Youtube popularity prediction system by 17%, but also\nto capture complex dynamics, such as seasonal trends of unseen influence. We\ndefine two new metrics: promotion score quantifies the gain in popularity from\none unit of promotion for a Youtube video; the loudness level captures the\neffects of a particular user tweeting about the video. We use the loudness\nlevel to compare the effects of a video being promoted by a single\nhighly-followed user (in the top 1% most followed users) against being promoted\nby a group of mid-followed users. We find that results depend on the type of\ncontent being promoted: superusers are more successful in promoting Howto and\nGaming videos, whereas the cohort of regular users are more influential for\nActivism videos. This work provides more accurate and explainable popularity\npredictions, as well as computational tools for content producers and marketers\nto allocate resources for promotion campaigns.\n"]},
{"authors": ["Canyi Lu", "Jiashi Feng", "Yudong Chen", "Wei Liu", "Zhouchen Lin", "Shuicheng Yan"], "title": ["Tensor Robust Principal Component Analysis with A New Tensor Nuclear\n  Norm"], "date": ["2018-04-10T21:29:30Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03728v1"], "summary": ["  In this paper, we consider the Tensor Robust Principal Component Analysis\n(TRPCA) problem, which aims to exactly recover the low-rank and sparse\ncomponents from their sum. Our model is based on the recently proposed\ntensor-tensor product (or t-product) [13]. Induced by the t-product, we first\nrigorously deduce the tensor spectral norm, tensor nuclear norm, and tensor\naverage rank, and show that the tensor nuclear norm is the convex envelope of\nthe tensor average rank within the unit ball of the tensor spectral norm. These\ndefinitions, their relationships and properties are consistent with matrix\ncases. Equipped with the new tensor nuclear norm, we then solve the TRPCA\nproblem by solving a convex program and provide the theoretical guarantee for\nthe exact recovery. Our TRPCA model and recovery guarantee include matrix RPCA\nas a special case. Numerical experiments verify our results, and the\napplications to image recovery and background modeling problems demonstrate the\neffectiveness of our method.\n"]},
{"authors": ["Alex Nichol", "Vicki Pfau", "Christopher Hesse", "Oleg Klimov", "John Schulman"], "title": ["Gotta Learn Fast: A New Benchmark for Generalization in RL"], "date": ["2018-04-10T21:09:53Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03720v1"], "summary": ["  In this report, we present a new reinforcement learning (RL) benchmark based\non the Sonic the Hedgehog (TM) video game franchise. This benchmark is intended\nto measure the performance of transfer learning and few-shot learning\nalgorithms in the RL domain. We also present and evaluate some baseline\nalgorithms on the new benchmark.\n"]},
{"authors": ["Donniell E. Fishkind", "Sancar Adali", "Heather G. Patsolic", "Lingyao Meng", "Digvijay Singh", "Vince Lyzinski", "Carey E. Priebe"], "title": ["Seeded Graph Matching"], "date": ["2012-09-03T14:45:53Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1209.0367v4"], "summary": ["  Given two graphs, the graph matching problem is to align the two vertex sets\nso as to minimize the number of adjacency disagreements between the two graphs.\nThe seeded graph matching problem is the graph matching problem when we are\nfirst given a partial alignment that we are tasked with completing. In this\npaper, we modify the state-of-the-art approximate graph matching algorithm\n\"FAQ\" of Vogelstein et al. (2015) to make it a fast approximate seeded graph\nmatching algorithm, adapt its applicability to include graphs with differently\nsized vertex sets, and extend the algorithm so as to provide, for each\nindividual vertex, a nomination list of likely matches. We demonstrate the\neffectiveness of our algorithm via simulation and real data experiments;\nindeed, knowledge of even a few seeds can be extremely effective when our\nseeded graph matching algorithm is used to recover a naturally existing\nalignment that is only partially observed.\n"]},
{"authors": ["Alexander Chistyakov", "Ekaterina Lobacheva", "Arseny Kuznetsov", "Alexey Romanenko"], "title": ["Semantic embeddings for program behavior patterns"], "date": ["2018-04-10T17:26:54Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03635v1"], "summary": ["  In this paper, we propose a new feature extraction technique for program\nexecution logs. First, we automatically extract complex patterns from a\nprogram's behavior graph. Then, we embed these patterns into a continuous space\nby training an autoencoder. We evaluate the proposed features on a real-world\nmalicious software detection task. We also find that the embedding space\ncaptures interpretable structures in the space of pattern parts.\n"]},
{"authors": ["Yeping Hu", "Wei Zhan", "Masayoshi Tomizuka"], "title": ["Probabilistic Prediction of Vehicle Semantic Intention and Motion"], "date": ["2018-04-10T17:05:53Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03629v1"], "summary": ["  Accurately predicting the possible behaviors of traffic participants is an\nessential capability for future autonomous vehicles. The majority of current\nresearches fix the number of driving intentions by considering only a specific\nscenario. However, distinct driving environments usually contain various\npossible driving maneuvers. Therefore, a intention prediction method that can\nadapt to different traffic scenarios is needed. To further improve the overall\nvehicle prediction performance, motion information is usually incorporated with\nclassified intentions. As suggested in some literature, the methods that\ndirectly predict possible goal locations can achieve better performance for\nlong-term motion prediction than other approaches due to their automatic\nincorporation of environment constraints. Moreover, by obtaining the temporal\ninformation of the predicted destinations, the optimal trajectories for\npredicted vehicles as well as the desirable path for ego autonomous vehicle\ncould be easily generated. In this paper, we propose a Semantic-based Intention\nand Motion Prediction (SIMP) method, which can be adapted to any driving\nscenarios by using semantic-defined vehicle behaviors. It utilizes a\nprobabilistic framework based on deep neural network to estimate the\nintentions, final locations, and the corresponding time information for\nsurrounding vehicles. An exemplar real-world scenario was used to implement and\nexamine the proposed method.\n"]},
{"authors": ["Julian Katz-Samuels", "Clayton Scott"], "title": ["Nonparametric Preference Completion"], "date": ["2017-05-24T06:04:58Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1705.08621v2"], "summary": ["  We consider the task of collaborative preference completion: given a pool of\nitems, a pool of users and a partially observed item-user rating matrix, the\ngoal is to recover the \\emph{personalized ranking} of each user over all of the\nitems. Our approach is nonparametric: we assume that each item $i$ and each\nuser $u$ have unobserved features $x_i$ and $y_u$, and that the associated\nrating is given by $g_u(f(x_i,y_u))$ where $f$ is Lipschitz and $g_u$ is a\nmonotonic transformation that depends on the user. We propose a $k$-nearest\nneighbors-like algorithm and prove that it is consistent. To the best of our\nknowledge, this is the first consistency result for the collaborative\npreference completion problem in a nonparametric setting. Finally, we\ndemonstrate the performance of our algorithm with experiments on the Netflix\nand Movielens datasets.\n"]},
{"authors": ["Rong Zhu", "Jiming Jiang"], "title": ["Subsampled Optimization: Statistical Guarantees, Mean Squared Error\n  Approximation, and Sampling Method"], "date": ["2018-04-10T16:18:10Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03615v1"], "summary": ["  For optimization on large-scale data, exactly calculating its solution may be\ncomputationally difficulty because of the large size of the data. In this paper\nwe consider subsampled optimization for fast approximating the exact solution.\nIn this approach, one gets a surrogate dataset by sampling from the full data,\nand then obtains an approximate solution by solving the subsampled optimization\nbased on the surrogate. One main theoretical contributions are to provide the\nasymptotic properties of the approximate solution with respect to the exact\nsolution as statistical guarantees, and to rigorously derive an accurate\napproximation of the mean squared error (MSE) and an approximately unbiased MSE\nestimator. These results help us better diagnose the subsampled optimization in\nthe context that a confidence region on the exact solution is provided using\nthe approximate solution. The other consequence of our results is to propose an\noptimal sampling method, Hessian-based sampling, whose probabilities are\nproportional to the norms of Newton directions. Numerical experiments with\nleast-squares and logistic regression show promising performance, in line with\nour results.\n"]},
{"authors": ["Xavier Roynard", "Jean-Emmanuel Deschaud", "Fran\u00e7ois Goulette"], "title": ["Paris-Lille-3D: a large and high-quality ground truth urban point cloud\n  dataset for automatic segmentation and classification"], "date": ["2017-11-30T19:08:52Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1712.00032v2"], "summary": ["  This paper introduces a new Urban Point Cloud Dataset for Automatic\nSegmentation and Classification acquired by Mobile Laser Scanning (MLS). We\ndescribe how the dataset is obtained from acquisition to post-processing and\nlabeling. This dataset can be used to learn classification algorithm, however,\ngiven that a great attention has been paid to the split between the different\nobjects, this dataset can also be used to learn the segmentation. The dataset\nconsists of around 2km of MLS point cloud acquired in two cities. The number of\npoints and range of classes make us consider that it can be used to train\nDeep-Learning methods. Besides we show some results of automatic segmentation\nand classification. The dataset is available at:\nhttp://caor-mines-paristech.fr/fr/paris-lille-3d-dataset/\n"]},
{"authors": ["Christopher P. Burgess", "Irina Higgins", "Arka Pal", "Loic Matthey", "Nick Watters", "Guillaume Desjardins", "Alexander Lerchner"], "title": ["Understanding disentangling in $\u03b2$-VAE"], "date": ["2018-04-10T15:48:18Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03599v1"], "summary": ["  We present new intuitions and theoretical assessments of the emergence of\ndisentangled representation in variational autoencoders. Taking a\nrate-distortion theory perspective, we show the circumstances under which\nrepresentations aligned with the underlying generative factors of variation of\ndata emerge when optimising the modified ELBO bound in $\\beta$-VAE, as training\nprogresses. From these insights, we propose a modification to the training\nregime of $\\beta$-VAE, that progressively increases the information capacity of\nthe latent code during training. This modification facilitates the robust\nlearning of disentangled representations in $\\beta$-VAE, without the previous\ntrade-off in reconstruction accuracy.\n"]},
{"authors": ["William L. Hamilton", "Rex Ying", "Jure Leskovec"], "title": ["Inductive Representation Learning on Large Graphs"], "date": ["2017-06-07T14:51:05Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1706.02216v3"], "summary": ["  Low-dimensional embeddings of nodes in large graphs have proved extremely\nuseful in a variety of prediction tasks, from content recommendation to\nidentifying protein functions. However, most existing approaches require that\nall nodes in the graph are present during training of the embeddings; these\nprevious approaches are inherently transductive and do not naturally generalize\nto unseen nodes. Here we present GraphSAGE, a general, inductive framework that\nleverages node feature information (e.g., text attributes) to efficiently\ngenerate node embeddings for previously unseen data. Instead of training\nindividual embeddings for each node, we learn a function that generates\nembeddings by sampling and aggregating features from a node's local\nneighborhood. Our algorithm outperforms strong baselines on three inductive\nnode-classification benchmarks: we classify the category of unseen nodes in\nevolving information graphs based on citation and Reddit post data, and we show\nthat our algorithm generalizes to completely unseen graphs using a multi-graph\ndataset of protein-protein interactions.\n"]},
{"authors": ["Zihao Xiao", "Jianfei Chen", "Jun Zhu"], "title": ["Towards Training Probabilistic Topic Models on Neuromorphic Multi-chip\n  Systems"], "date": ["2018-04-10T15:01:50Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03578v1"], "summary": ["  Probabilistic topic models are popular unsupervised learning methods,\nincluding probabilistic latent semantic indexing (pLSI) and latent Dirichlet\nallocation (LDA). By now, their training is implemented on general purpose\ncomputers (GPCs), which are flexible in programming but energy-consuming.\nTowards low-energy implementations, this paper investigates their training on\nan emerging hardware technology called the neuromorphic multi-chip systems\n(NMSs). NMSs are very effective for a family of algorithms called spiking\nneural networks (SNNs). We present three SNNs to train topic models. The first\nSNN is a batch algorithm combining the conventional collapsed Gibbs sampling\n(CGS) algorithm and an inference SNN to train LDA. The other two SNNs are\nonline algorithms targeting at both energy- and storage-limited environments.\nThe two online algorithms are equivalent with training LDA by using\nmaximum-a-posterior estimation and maximizing the semi-collapsed likelihood,\nrespectively. They use novel, tailored ordinary differential equations for\nstochastic optimization. We simulate the new algorithms and show that they are\ncomparable with the GPC algorithms, while being suitable for NMS\nimplementation. We also propose an extension to train pLSI and a method to\nprune the network to obey the limited fan-in of some NMSs.\n"]},
{"authors": ["Nico S. Gorbach", "Stefan Bauer", "Joachim M. Buhmann"], "title": ["Scalable Variational Inference for Dynamical Systems"], "date": ["2017-05-19T16:29:00Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1705.07079v2"], "summary": ["  Gradient matching is a promising tool for learning parameters and state\ndynamics of ordinary differential equations. It is a grid free inference\napproach, which, for fully observable systems is at times competitive with\nnumerical integration. However, for many real-world applications, only sparse\nobservations are available or even unobserved variables are included in the\nmodel description. In these cases most gradient matching methods are difficult\nto apply or simply do not provide satisfactory results. That is why, despite\nthe high computational cost, numerical integration is still the gold standard\nin many applications. Using an existing gradient matching approach, we propose\na scalable variational inference framework which can infer states and\nparameters simultaneously, offers computational speedups, improved accuracy and\nworks well even under model misspecifications in a partially observable system.\n"]},
{"authors": ["Philipp Probst", "Marvin Wright", "Anne-Laure Boulesteix"], "title": ["Hyperparameters and Tuning Strategies for Random Forest"], "date": ["2018-04-10T13:30:51Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03515v1"], "summary": ["  The random forest algorithm (RF) has several hyperparameters that have to be\nset by the user, e.g., the number of observations drawn randomly for each tree\nand whether they are drawn with or without replacement, the number of variables\ndrawn randomly for each split, the splitting rule, the minimum number of\nsamples that a node must contain and the number of trees. In this paper, we\nfirst provide a literature review on the parameters' influence on the\nprediction performance and on variable importance measures, also considering\ninteractions between hyperparameters.\n  It is well known that in most cases RF works reasonably well with the default\nvalues of the hyperparameters specified in software packages. Nevertheless,\ntuning the hyperparameters can improve the performance of RF. In the second\npart of this paper, after a brief overview of tuning strategies we demonstrate\nthe application of one of the most established tuning strategies, model-based\noptimization (MBO). To make it easier to use, we provide the tuneRanger R\npackage that tunes RF with MBO automatically. In a benchmark study on several\ndatasets, we compare the prediction performance and runtime of tuneRanger with\nother tuning implementations in R and RF with default hyperparameters.\n"]},
{"authors": ["Chongxuan Li", "Max Welling", "Jun Zhu", "Bo Zhang"], "title": ["Graphical Generative Adversarial Networks"], "date": ["2018-04-10T10:12:38Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03429v1"], "summary": ["  We propose Graphical Generative Adversarial Networks (Graphical-GAN) to model\nstructured data. Graphical-GAN conjoins the power of Bayesian networks on\ncompactly representing the dependency structures among random variables and\nthat of generative adversarial networks on learning expressive dependency\nfunctions. We introduce a structured recognition model to infer the posterior\ndistribution of latent variables given observations. We propose two alternative\ndivergence minimization approaches to learn the generative model and\nrecognition model jointly. The first one treats all variables as a whole, while\nthe second one utilizes the structural information by checking the individual\nlocal factors defined by the generative model and works better in practice.\nFinally, we present two important instances of Graphical-GAN, i.e. Gaussian\nMixture GAN (GMGAN) and State Space GAN (SSGAN), which can successfully learn\nthe discrete and temporal structures on visual datasets, respectively.\n"]},
{"authors": ["Dario Azzimonti", "David Ginsbourger", "Cl\u00e9ment Chevalier", "Julien Bect", "Yann Richet"], "title": ["Adaptive Design of Experiments for Conservative Estimation of Excursion\n  Sets"], "date": ["2016-11-22T11:40:25Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1611.07256v3"], "summary": ["  We consider a Gaussian process model trained on few evaluations of an\nexpensive-to-evaluate deterministic function and we study the problem of\nestimating a fixed excursion set of this function. We focus on conservative\nestimates as they allow control on false positives while minimizing false\nnegatives. We introduce adaptive strategies that sequentially selects new\nevaluations of the function by reducing the uncertainty on conservative\nestimates. Following the Stepwise Uncertainty Reduction approach we obtain new\nevaluations by minimizing adapted criteria. We provide tractable formulae for\nthe conservative criteria and we benchmark the method on random functions\ngenerated under the model assumptions in two and five dimensions. Finally the\nmethod is applied to a reliability engineering test case. Overall, the proposed\nstrategy of minimizing false negatives in conservative estimation achieves\ncompetitive performance both in terms of model based and a-posteriori\nindicators.\n"]},
{"authors": ["Matias Quiroz", "Minh-Ngoc Tran", "Mattias Villani", "Robert Kohn", "Khue-Dung Dang"], "title": ["The block-Poisson estimator for optimally tuned exact subsampling MCMC"], "date": ["2016-03-27T16:25:34Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1603.08232v5"], "summary": ["  Speeding up Markov Chain Monte Carlo (MCMC) for datasets with many\nobservations by data subsampling has recently received considerable attention\nin the literature. The currently available methods are either approximate,\nhighly inefficient or limited to small dimensional models. We propose a\npseudo-marginal MCMC method that estimates the likelihood by data subsampling\nusing a block-Poisson estimator. The estimator is a product of Poisson\nestimators, each based on an independent subset of the observations. The\nconstruction allows us to update a subset of the blocks in each MCMC iteration,\nthereby inducing a controllable correlation between the estimates at the\ncurrent and proposed draw in the Metropolis-Hastings ratio. This makes it\npossible to use highly variable likelihood estimators without adversely\naffecting the sampling efficiency. Poisson estimators are unbiased but not\nnecessarily positive. We therefore follow Lyne et al. (2015) and run the MCMC\non the absolute value of the estimator and use an importance sampling\ncorrection for occasionally negative likelihood estimates to estimate\nexpectations of any function of the parameters. We provide analytically derived\nguidelines to select the optimal tuning parameters for the algorithm by\nminimizing the variance of the importance sampling corrected estimator per unit\nof computing time. The guidelines are derived under idealized conditions, but\nare demonstrated to be quite accurate in empirical experiments. The guidelines\napply to any pseudo-marginal algorithm if the likelihood is estimated by the\nblock-Poisson estimator, including the class of doubly intractable problems in\nLyne et al. (2015). We illustrate the method in a logistic regression example\nand find dramatic improvements compared to regular MCMC without subsampling and\na popular exact subsampling approach recently proposed in the literature.\n"]},
{"authors": ["Tom\u00e1\u0161 Kliegr", "\u0160t\u011bp\u00e1n Bahn\u00edk", "Johannes F\u00fcrnkranz"], "title": ["A review of possible effects of cognitive biases on interpretation of\n  rule-based machine learning models"], "date": ["2018-04-09T13:28:56Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02969v2"], "summary": ["  This paper investigates to what extent do cognitive biases affect human\nunderstanding of interpretable machine learning models, in particular of rules\ndiscovered from data. Twenty cognitive biases (illusions, effects) are covered,\nas are possibly effective debiasing techniques that can be adopted by designers\nof machine learning algorithms and software. While there seems no universal\napproach for eliminating all the identified cognitive biases, it follows from\nour analysis that the effect of most biases can be ameliorated by making\nrule-based models more concise. Due to lack of previous research, our review\ntransfers general results obtained in cognitive psychology to the domain of\nmachine learning. It needs to be succeeded by empirical studies specifically\naimed at the machine learning domain.\n"]},
{"authors": ["Siddhartha Satpathi", "Supratim Deb", "R Srikant", "He Yan"], "title": ["Learning Latent Events from Network Message Logs: A Decomposition Based\n  Approach"], "date": ["2018-04-10T05:44:53Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03346v1"], "summary": ["  In this communication, we describe a novel technique for event mining using a\ndecomposition based approach that combines non-parametric change-point\ndetection with LDA. We prove theoretical guarantees about sample-complexity and\nconsistency of the approach. In a companion paper, we will perform a thorough\nevaluation of our approach with detailed experiments.\n"]},
{"authors": ["Anish Athalye", "Nicholas Carlini"], "title": ["On the Robustness of the CVPR 2018 White-Box Adversarial Example\n  Defenses"], "date": ["2018-04-10T04:54:29Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03286v1"], "summary": ["  Neural networks are known to be vulnerable to adversarial examples. In this\nnote, we evaluate the two white-box defenses that appeared at CVPR 2018 and\nfind they are ineffective: when applying existing techniques, we can reduce the\naccuracy of the defended models to 0%.\n"]},
{"authors": ["Alex Kearney", "Vivek Veeriah", "Jaden B. Travnik", "Richard S. Sutton", "Patrick M. Pilarski"], "title": ["TIDBD: Adapting Temporal-difference Step-sizes Through Stochastic\n  Meta-descent"], "date": ["2018-04-10T04:01:07Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03334v1"], "summary": ["  In this paper, we introduce a method for adapting the step-sizes of temporal\ndifference (TD) learning. The performance of TD methods often depends on well\nchosen step-sizes, yet few algorithms have been developed for setting the\nstep-size automatically for TD learning. An important limitation of current\nmethods is that they adapt a single step-size shared by all the weights of the\nlearning system. A vector step-size enables greater optimization by specifying\nparameters on a per-feature basis. Furthermore, adapting parameters at\ndifferent rates has the added benefit of being a simple form of representation\nlearning. We generalize Incremental Delta Bar Delta (IDBD)---a vectorized\nadaptive step-size method for supervised learning---to TD learning, which we\nname TIDBD. We demonstrate that TIDBD is able to find appropriate step-sizes in\nboth stationary and non-stationary prediction tasks, outperforming ordinary TD\nmethods and TD methods with scalar step-size adaptation; we demonstrate that it\ncan differentiate between features which are relevant and irrelevant for a\ngiven task, performing representation learning; and we show on a real-world\nrobot prediction task that TIDBD is able to outperform ordinary TD methods and\nTD methods augmented with AlphaBound and RMSprop.\n"]},
{"authors": ["Christopher De Sa", "Albert Gu", "Christopher R\u00e9", "Frederic Sala"], "title": ["Representation Tradeoffs for Hyperbolic Embeddings"], "date": ["2018-04-10T03:39:16Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03329v1"], "summary": ["  Hyperbolic embeddings offer excellent quality with few dimensions when\nembedding hierarchical data structures like synonym or type hierarchies. Given\na tree, we give a combinatorial construction that embeds the tree in hyperbolic\nspace with arbitrarily low distortion without using optimization. On WordNet,\nour combinatorial embedding obtains a mean-average-precision of 0.989 with only\ntwo dimensions, while Nickel et al.'s recent construction obtains 0.87 using\n200 dimensions. We provide upper and lower bounds that allow us to characterize\nthe precision-dimensionality tradeoff inherent in any hyperbolic embedding. To\nembed general metric spaces, we propose a hyperbolic generalization of\nmultidimensional scaling (h-MDS). We show how to perform exact recovery of\nhyperbolic points from distances, provide a perturbation analysis, and give a\nrecovery result that allows us to reduce dimensionality. The h-MDS approach\noffers consistently low distortion even with few dimensions across several\ndatasets. Finally, we extract lessons from the algorithms and theory above to\ndesign a PyTorch-based implementation that can handle incomplete information\nand is scalable.\n"]},
{"authors": ["Angus Galloway", "Thomas Tanay", "Graham W. Taylor"], "title": ["Adversarial Training Versus Weight Decay"], "date": ["2018-04-10T01:57:39Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03308v1"], "summary": ["  Performance-critical machine learning models should be robust to input\nperturbations not seen during training. Adversarial training is a method for\nimproving a model's robustness to some perturbations by including them in the\ntraining process, but this tends to exacerbate other vulnerabilities of the\nmodel. The adversarial training framework has the effect of translating the\ndata with respect to the cost function, while weight decay has a scaling\neffect. Although weight decay could be considered a crude regularization\ntechnique, it appears superior to adversarial training as it remains stable\nover a broader range of regimes and reduces all generalization errors. Equipped\nwith these abstractions, we provide key baseline results and methodology for\ncharacterizing robustness. The two approaches can be combined to yield one\nsmall model that demonstrates good robustness to several white-box attacks\nassociated with different metrics.\n"]},
{"authors": ["Milad Zafar Nezhad", "Najibesadat Sadati", "Kai Yang", "Dongxiao Zhu"], "title": ["A Deep Active Survival Analysis Approach for Precision Treatment\n  Recommendations: Application of Prostate Cancer"], "date": ["2018-04-10T00:05:29Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03280v1"], "summary": ["  Survival analysis has been developed and applied in the number of areas\nincluding manufacturing, finance, economics and healthcare. In healthcare\ndomain, usually clinical data are high-dimensional, sparse and complex and\nsometimes there exists few amount of time-to-event (labeled) instances.\nTherefore building an accurate survival model from electronic health records is\nchallenging. With this motivation, we address this issue and provide a new\nsurvival analysis framework using deep learning and active learning with a\nnovel sampling strategy. First, our approach provides better representation\nwith lower dimensions from clinical features using labeled (time-to-event) and\nunlabeled (censored) instances and then actively trains the survival model by\nlabeling the censored data using an oracle. As a clinical assistive tool, we\nintroduce a simple effective treatment recommendation approach based on our\nsurvival model. In the experimental study, we apply our approach on\nSEER-Medicare data related to prostate cancer among African-Americans and white\npatients. The results indicate that our approach outperforms significantly than\nbaseline models.\n"]},
{"authors": ["Pin-Yu Chen", "Dennis Wei"], "title": ["On the Supermodularity of Active Graph-based Semi-supervised Learning\n  with Stieltjes Matrix Regularization"], "date": ["2018-04-09T23:53:11Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03273v1"], "summary": ["  Active graph-based semi-supervised learning (AG-SSL) aims to select a small\nset of labeled examples and utilize their graph-based relation to other\nunlabeled examples to aid in machine learning tasks. It is also closely related\nto the sampling theory in graph signal processing. In this paper, we revisit\nthe original formulation of graph-based SSL and prove the supermodularity of an\nAG-SSL objective function under a broad class of regularization functions\nparameterized by Stieltjes matrices. Under this setting, supermodularity yields\na novel greedy label sampling algorithm with guaranteed performance relative to\nthe optimal sampling set. Compared to three state-of-the-art graph signal\nsampling and recovery methods on two real-life community detection datasets,\nthe proposed AG-SSL method attains superior classification accuracy given\nlimited sample budgets.\n"]},
{"authors": ["Mario Drumond", "Tao Lin", "Martin Jaggi", "Babak Falsafi"], "title": ["End-to-End DNN Training with Block Floating Point Arithmetic"], "date": ["2018-04-04T09:40:59Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01526v2"], "summary": ["  DNNs are ubiquitous datacenter workloads, requiring orders of magnitude more\ncomputing power from servers than traditional workloads. As such, datacenter\noperators are forced to adopt domain-specific accelerators that employ\nhalf-precision floating-point (FP) numeric representations to improve\narithmetic density. Unfortunately, even these representations are not dense\nenough, and are, therefore, sub-optimal for DNNs. We propose a hybrid approach\nthat employs dense block floating-point (BFP) arithmetic on dot product\ncomputations and FP arithmetic elsewhere. While using BFP improves the\nperformance of dot product operations, that compose most of DNN computations,\nallowing values to freely float between dot product operations leads to a\nbetter choice of tensor exponents when converting values to back BFP. We show\nthat models trained with hybrid BFP-FP arithmetic either match or outperform\ntheir FP32 counterparts, leading to more compact models and denser arithmetic\nin computing platforms.\n"]},
{"authors": ["Fernando Fernandes Neto"], "title": ["Building Function Approximators on top of Haar Scattering Networks"], "date": ["2018-04-09T20:56:41Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03236v1"], "summary": ["  In this article we propose building general-purpose function approximators on\ntop of Haar Scattering Networks. We advocate that this architecture enables a\nbetter comprehension of feature extraction, in addition to its implementation\nsimplicity and low computational costs. We show its approximation and feature\nextraction capabilities in a wide range of different problems, which can be\napplied on several phenomena in signal processing, system identification,\neconometrics and other potential fields.\n"]},
{"authors": ["Rohan Anil", "Gabriel Pereyra", "Alexandre Passos", "Robert Ormandi", "George E. Dahl", "Geoffrey E. Hinton"], "title": ["Large scale distributed neural network training through online\n  distillation"], "date": ["2018-04-09T20:56:03Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03235v1"], "summary": ["  Techniques such as ensembling and distillation promise model quality\nimprovements when paired with almost any base model. However, due to increased\ntest-time cost (for ensembles) and increased complexity of the training\npipeline (for distillation), these techniques are challenging to use in\nindustrial settings. In this paper we explore a variant of distillation which\nis relatively straightforward to use as it does not require a complicated\nmulti-stage setup or many new hyperparameters. Our first claim is that online\ndistillation enables us to use extra parallelism to fit very large datasets\nabout twice as fast. Crucially, we can still speed up training even after we\nhave already reached the point at which additional parallelism provides no\nbenefit for synchronous or asynchronous stochastic gradient descent. Two neural\nnetworks trained on disjoint subsets of the data can share knowledge by\nencouraging each model to agree with the predictions the other model would have\nmade. These predictions can come from a stale version of the other model so\nthey can be safely computed using weights that only rarely get transmitted. Our\nsecond claim is that online distillation is a cost-effective way to make the\nexact predictions of a model dramatically more reproducible. We support our\nclaims using experiments on the Criteo Display Ad Challenge dataset, ImageNet,\nand the largest to-date dataset used for neural language modeling, containing\n$6\\times 10^{11}$ tokens and based on the Common Crawl repository of web data.\n"]},
{"authors": ["Wei-Ning Hsu", "James Glass"], "title": ["Scalable Factorized Hierarchical Variational Autoencoder Training"], "date": ["2018-04-09T19:44:29Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03201v1"], "summary": ["  Deep generative models have achieved great success in unsupervised learning\nwith the ability to capture complex nonlinear relationships between latent\ngenerating factors and observations. Among them, a factorized hierarchical\nvariational autoencoder (FHVAE) is a variational inference-based model that\nformulates a hierarchical generative process for sequential data. Specifically,\nan FHVAE model can learn disentangled and interpretable representations, which\nhave been proven useful for numerous speech applications, such as speaker\nverification, robust speech recognition, and voice conversion. However, as we\nwill elaborate in this paper, the training algorithm proposed in the original\npaper is not scalable to datasets of thousands of hours, which makes this model\nless applicable on a larger scale. After identifying limitations in terms of\nruntime, memory, and hyperparameter optimization, we propose a hierarchical\nsampling training algorithm to address all three issues. Our proposed method is\nevaluated comprehensively on a wide variety of datasets, ranging from 3 to\n1,000 hours and involving different types of generating factors, such as\nrecording conditions and noise types. In addition, we also present a new\nvisualization method for qualitatively evaluating the performance with respect\nto interpretability and disentanglement. Models trained with our proposed\nalgorithm demonstrate the desired characteristics on all the datasets.\n"]},
{"authors": ["Andreas Henelius", "Emilia Oikarinen", "Kai Puolam\u00e4ki"], "title": ["Human-Guided Data Exploration"], "date": ["2018-04-09T19:29:41Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03194v1"], "summary": ["  The outcome of the explorative data analysis (EDA) phase is vital for\nsuccessful data analysis. EDA is more effective when the user interacts with\nthe system used to carry out the exploration. In the recently proposed paradigm\nof iterative data mining the user controls the exploration by inputting\nknowledge in the form of patterns observed during the process. The system then\nshows the user views of the data that are maximally informative given the\nuser's current knowledge. Although this scheme is good at showing surprising\nviews of the data to the user, there is a clear shortcoming: the user cannot\nsteer the process. In many real cases we want to focus on investigating\nspecific questions concerning the data. This paper presents the Human Guided\nData Exploration framework, generalising previous research. This framework\nallows the user to incorporate existing knowledge into the exploration process,\nfocus on exploring a subset of the data, and compare different complex\nhypotheses concerning relations in the data. The framework utilises a\ncomputationally efficient constrained randomisation scheme. To showcase the\nframework, we developed a free open-source tool, using which the empirical\nevaluation on real-world datasets was carried out. Our evaluation shows that\nthe ability to focus on particular subsets and being able to compare hypotheses\nare important additions to the interactive iterative data mining process.\n"]},
{"authors": ["Pu Zhao", "Sijia Liu", "Yanzhi Wang", "Xue Lin"], "title": ["An ADMM-Based Universal Framework for Adversarial Attacks on Deep Neural\n  Networks"], "date": ["2018-04-09T19:23:01Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03193v1"], "summary": ["  Deep neural networks (DNNs) are known vulnerable to adversarial attacks. That\nis, adversarial examples, obtained by adding delicately crafted distortions\nonto original legal inputs, can mislead a DNN to classify them as any target\nlabels. In a successful adversarial attack, the targeted mis-classification\nshould be achieved with the minimal distortion added. In the literature, the\nadded distortions are usually measured by L0, L1, L2, and L infinity norms,\nnamely, L0, L1, L2, and L infinity attacks, respectively. However, there lacks\na versatile framework for all types of adversarial attacks.\n  This work for the first time unifies the methods of generating adversarial\nexamples by leveraging ADMM (Alternating Direction Method of Multipliers), an\noperator splitting optimization approach, such that L0, L1, L2, and L infinity\nattacks can be effectively implemented by this general framework with little\nmodifications. Comparing with the state-of-the-art attacks in each category,\nour ADMM-based attacks are so far the strongest, achieving both the 100% attack\nsuccess rate and the minimal distortion.\n"]},
{"authors": ["Paidamoyo Chapfuwa", "Chenyang Tao", "Chunyuan Li", "Courtney Page", "Benjamin Goldstein", "Lawrence Carin", "Ricardo Henao"], "title": ["Adversarial Time-to-Event Modeling"], "date": ["2018-04-09T18:59:05Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03184v1"], "summary": ["  Modern health data science applications leverage abundant molecular and\nelectronic health data, providing opportunities for machine learning to build\nstatistical models to support clinical practice. Time-to-event analysis, also\ncalled survival analysis, stands as one of the most representative examples of\nsuch statistical models. We present a novel deep-network-based approach that\nleverages adversarial learning to address a key challenge in modern\ntime-to-event modeling: nonparametric estimation of event-time distributions.\nWe also introduce a principled cost function to exploit information from\ncensored events (events that occur subsequent to the observation window).\nUnlike most time-to-event models, we focus on the estimation of time-to-event\ndistributions, rather than time ordering. We validate our model on both\nbenchmark and real datasets, demonstrating that the proposed formulation yields\nsignificant performance gains relative to a parametric alternative, which we\nalso propose.\n"]},
{"authors": ["Gauthier Gidel", "Fabian Pedregosa", "Simon Lacoste-Julien"], "title": ["Frank-Wolfe Splitting via Augmented Lagrangian Method"], "date": ["2018-04-09T18:33:29Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03176v1"], "summary": ["  Minimizing a function over an intersection of convex sets is an important\ntask in optimization that is often much more challenging than minimizing it\nover each individual constraint set. While traditional methods such as\nFrank-Wolfe (FW) or proximal gradient descent assume access to a linear or\nquadratic oracle on the intersection, splitting techniques take advantage of\nthe structure of each sets, and only require access to the oracle on the\nindividual constraints. In this work, we develop and analyze the Frank-Wolfe\nAugmented Lagrangian (FW-AL) algorithm, a method for minimizing a smooth\nfunction over convex compact sets related by a \"linear consistency\" constraint\nthat only requires access to a linear minimization oracle over the individual\nconstraints. It is based on the Augmented Lagrangian Method (ALM), also known\nas Method of Multipliers, but unlike most existing splitting methods, it only\nrequires access to linear (instead of quadratic) minimization oracles. We use\nrecent advances in the analysis of Frank-Wolfe and the alternating direction\nmethod of multipliers algorithms to prove a sublinear convergence rate for\nFW-AL over general convex compact sets and a linear convergence rate for\npolytopes.\n"]},
{"authors": ["Penghang Yin", "Minh Pham", "Adam Oberman", "Stanley Osher"], "title": ["Stochastic Backward Euler: An Implicit Gradient Descent Algorithm for\n  $k$-means Clustering"], "date": ["2017-10-21T03:02:29Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.07746v2"], "summary": ["  In this paper, we propose an implicit gradient descent algorithm for the\nclassic $k$-means problem. The implicit gradient step or backward Euler is\nsolved via stochastic fixed-point iteration, in which we randomly sample a\nmini-batch gradient in every iteration. It is the average of the fixed-point\ntrajectory that is carried over to the next gradient step. We draw connections\nbetween the proposed stochastic backward Euler and the recent entropy\nstochastic gradient descent (Entropy-SGD) for improving the training of deep\nneural networks. Numerical experiments on various synthetic and real datasets\nshow that the proposed algorithm provides better clustering results compared to\n$k$-means algorithms in the sense that it decreased the objective function (the\ncluster) and is much more robust to initialization.\n"]},
{"authors": ["Tomohiro Hayase"], "title": ["Cauchy noise loss for stochastic optimization of random matrix models\n  via free deterministic equivalents"], "date": ["2018-04-09T18:00:08Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03154v1"], "summary": ["  Based on free probability theory and stochastic optimization, we introduce a\nnew parameter estimation method of random matrix models. Our method is inspired\nby free deterministic equivalents and iterative methods for computing Cauchy\ntransforms. Moreover, we study an asymptotic property of a generalization gap\nand show numerical experiments of the optimization. We treat two random matrix\nmodels; the compound Wishart model and the information-plus-noise model. In\naddition, we propose a new rank recovery method for the information-plus-noise\nmodel, and experimentally demonstrate that it recovers the true rank even if\nthe rank is not low.\n"]},
{"authors": ["Tiago P. Peixoto"], "title": ["Bayesian stochastic blockmodeling"], "date": ["2017-05-29T14:53:42Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1705.10225v5"], "summary": ["  This chapter provides a self-contained introduction to the use of Bayesian\ninference to extract large-scale modular structures from network data, based on\nthe stochastic block model (SBM), as well as its degree-corrected and\noverlapping generalizations. We focus on nonparametric formulations that allow\ntheir inference in a manner that prevents overfitting, and enables model\nselection. We discuss aspects of the choice of priors, in particular how to\navoid underfitting via increased Bayesian hierarchies, and we contrast the task\nof sampling network partitions from the posterior distribution with finding the\nsingle point estimate that maximizes it, while describing efficient algorithms\nto perform either one. We also show how inferring the SBM can be used to\npredict missing and spurious links, and shed light on the fundamental\nlimitations of the detectability of modular structures in networks.\n"]},
{"authors": ["Alexander Mathis", "Pranav Mamidanna", "Taiga Abe", "Kevin M. Cury", "Venkatesh N. Murthy", "Mackenzie W. Mathis", "Matthias Bethge"], "title": ["Markerless tracking of user-defined features with deep learning"], "date": ["2018-04-09T17:10:39Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03142v1"], "summary": ["  Quantifying behavior is crucial for many applications in neuroscience.\nVideography provides easy methods for the observation and recording of animal\nbehavior in diverse settings, yet extracting particular aspects of a behavior\nfor further analysis can be highly time consuming. In motor control studies,\nhumans or other animals are often marked with reflective markers to assist with\ncomputer-based tracking, yet markers are intrusive (especially for smaller\nanimals), and the number and location of the markers must be determined a\npriori. Here, we present a highly efficient method for markerless tracking\nbased on transfer learning with deep neural networks that achieves excellent\nresults with minimal training data. We demonstrate the versatility of this\nframework by tracking various body parts in a broad collection of experimental\nsettings: mice odor trail-tracking, egg-laying behavior in drosophila, and\nmouse hand articulation in a skilled forelimb task. For example, during the\nskilled reaching behavior, individual joints can be automatically tracked (and\na confidence score is reported). Remarkably, even when a small number of frames\nare labeled ($\\approx 200$), the algorithm achieves excellent tracking\nperformance on test frames that is comparable to human accuracy.\n"]},
{"authors": ["Shahab Asoodeh", "Yi Huang", "Ishanu Chattopadhyay"], "title": ["A Tamper-Free Semi-Universal Communication System for Deletion Channels"], "date": ["2018-04-09T16:13:33Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03707v1"], "summary": ["  We investigate the problem of reliable communication between two legitimate\nparties over deletion channels under an active eavesdropping (aka jamming)\nadversarial model. To this goal, we develop a theoretical framework based on\nprobabilistic finite-state automata to define novel encoding and decoding\nschemes that ensure small error probability in both message decoding as well as\ntamper detecting. We then experimentally verify the reliability and\ntamper-detection property of our scheme.\n"]},
{"authors": ["Dirk Tasche"], "title": ["A plug-in approach to maximising precision at the top and recall at the\n  top"], "date": ["2018-04-09T16:10:45Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03077v1"], "summary": ["  For information retrieval and binary classification, we show that precision\nat the top (or precision at k) and recall at the top (or recall at k) are\nmaximised by thresholding the posterior probability of the positive class. This\nfinding is a consequence of a result on constrained minimisation of the\ncost-sensitive expected classification error which generalises an earlier\nrelated result from the literature.\n"]},
{"authors": ["Justin S. Smith", "Ben Nebgen", "Nicholas Lubbers", "Olexandr Isayev", "Adrian E. Roitberg"], "title": ["Less is more: sampling chemical space with active learning"], "date": ["2018-01-28T23:48:01Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1801.09319v2"], "summary": ["  The development of accurate and transferable machine learning (ML) potentials\nfor predicting molecular energetics is a challenging task. The process of data\ngeneration to train such ML potentials is a task neither well understood nor\nresearched in detail. In this work, we present a fully automated approach for\nthe generation of datasets with the intent of training universal ML potentials.\nIt is based on the concept of active learning (AL) via Query by Committee\n(QBC), which uses the disagreement between an ensemble of ML potentials to\ninfer the reliability of the ensemble's prediction. QBC allows the presented AL\nalgorithm to automatically sample regions of chemical space where the ML\npotential fails to accurately predict the potential energy. AL improves the\noverall fitness of ANAKIN-ME (ANI) deep learning potentials in rigorous test\ncases by mitigating human biases in deciding what new training data to use. AL\nalso reduces the training set size to a fraction of the data required when\nusing naive random sampling techniques. To provide validation of our AL\napproach we develop the COMP6 benchmark (publicly available on GitHub), which\ncontains a diverse set of organic molecules. Through the AL process, it is\nshown that the AL-based potentials perform as well as the ANI-1 potential on\nCOMP6 with only 10% of the data, and vastly outperforms ANI-1 with 25% the\namount of data. Finally, we show that our proposed AL technique develops a\nuniversal ANI potential (ANI-1x) that provides accurate energy and force\npredictions on the entire COMP6 benchmark. This universal ML potential achieves\na level of accuracy on par with the best ML potentials for single molecule or\nmaterials, while remaining applicable to the general class of organic molecules\ncomprised of the elements CHNO.\n"]},
{"authors": ["Parikshit Gopalan", "Vatsal Sharan", "Udi Wieder"], "title": ["Faster Anomaly Detection via Matrix Sketching"], "date": ["2018-04-09T15:47:36Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03065v1"], "summary": ["  We present efficient streaming algorithms to compute two commonly used\nanomaly measures: the rank-$k$ leverage scores (aka Mahalanobis distance) and\nthe rank-$k$ projection distance, in the row-streaming model. We show that\ncommonly used matrix sketching techniques such as the Frequent Directions\nsketch and random projections can be used to approximate these measures. Our\nmain technical contribution is to prove matrix perturbation inequalities for\noperators arising in the computation of these measures.\n"]},
{"authors": ["Giovanni Saponaro", "Pedro Vicente", "Atabak Dehban", "Lorenzo Jamone", "Alexandre Bernardino", "Jos\u00e9 Santos-Victor"], "title": ["Learning at the Ends: From Hand to Tool Affordances in Humanoid Robots"], "date": ["2018-04-09T14:28:15Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03022v1"], "summary": ["  One of the open challenges in designing robots that operate successfully in\nthe unpredictable human environment is how to make them able to predict what\nactions they can perform on objects, and what their effects will be, i.e., the\nability to perceive object affordances. Since modeling all the possible world\ninteractions is unfeasible, learning from experience is required, posing the\nchallenge of collecting a large amount of experiences (i.e., training data).\nTypically, a manipulative robot operates on external objects by using its own\nhands (or similar end-effectors), but in some cases the use of tools may be\ndesirable, nevertheless, it is reasonable to assume that while a robot can\ncollect many sensorimotor experiences using its own hands, this cannot happen\nfor all possible human-made tools.\n  Therefore, in this paper we investigate the developmental transition from\nhand to tool affordances: what sensorimotor skills that a robot has acquired\nwith its bare hands can be employed for tool use? By employing a visual and\nmotor imagination mechanism to represent different hand postures compactly, we\npropose a probabilistic model to learn hand affordances, and we show how this\nmodel can generalize to estimate the affordances of previously unseen tools,\nultimately supporting planning, decision-making and tool selection tasks in\nhumanoid robots. We present experimental results with the iCub humanoid robot,\nand we publicly release the collected sensorimotor data in the form of a hand\nposture affordances dataset.\n"]},
{"authors": ["Neil Caithness", "David Wallom"], "title": ["Anomaly Detection for Industrial Big Data"], "date": ["2018-04-09T14:09:47Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02998v1"], "summary": ["  As the Industrial Internet of Things (IIoT) grows, systems are increasingly\nbeing monitored by arrays of sensors returning time-series data at\never-increasing 'volume, velocity and variety' (i.e. Industrial Big Data). An\nobvious use for these data is real-time systems condition monitoring and\nprognostic time to failure analysis (remaining useful life, RUL). (e.g. See\nwhite papers by Senseye.io, and output of the NASA Prognostics Center of\nExcellence (PCoE).) However, as noted by Agrawal and Choudhary 'Our ability to\ncollect \"big data\" has greatly surpassed our capability to analyze it,\nunderscoring the emergence of the fourth paradigm of science, which is\ndata-driven discovery.' In order to fully utilize the potential of Industrial\nBig Data we need data-driven techniques that operate at scales that process\nmodels cannot. Here we present a prototype technique for data-driven anomaly\ndetection to operate at industrial scale. The method generalizes to application\nwith almost any multivariate dataset based on independent ordinations of\nrepeated (bootstrapped) partitions of the dataset and inspection of the joint\ndistribution of ordinal distances.\n"]},
{"authors": ["Kai Han", "Yunhe Wang", "Chao Zhang", "Chao Li", "Chao Xu"], "title": ["AutoEncoder Inspired Unsupervised Feature Selection"], "date": ["2017-10-23T14:44:17Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.08310v3"], "summary": ["  High-dimensional data in many areas such as computer vision and machine\nlearning tasks brings in computational and analytical difficulty. Feature\nselection which selects a subset from observed features is a widely used\napproach for improving performance and effectiveness of machine learning models\nwith high-dimensional data. In this paper, we propose a novel AutoEncoder\nFeature Selector (AEFS) for unsupervised feature selection which combines\nautoencoder regression and group lasso tasks. Compared to traditional feature\nselection methods, AEFS can select the most important features by excavating\nboth linear and nonlinear information among features, which is more flexible\nthan the conventional self-representation method for unsupervised feature\nselection with only linear assumptions. Experimental results on benchmark\ndataset show that the proposed method is superior to the state-of-the-art\nmethod.\n"]},
{"authors": ["David Manheim", "Scott Garrabrant"], "title": ["Categorizing Variants of Goodhart's Law"], "date": ["2018-03-13T01:15:39Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04585v3"], "summary": ["  There are several distinct failure modes for overoptimization of systems on\nthe basis of metrics. This occurs when a metric which can be used to improve a\nsystem is used to an extent that further optimization is ineffective or\nharmful, and is sometimes termed Goodhart's Law. This class of failure is often\npoorly understood, partly because terminology for discussing them is ambiguous,\nand partly because discussion using this ambiguous terminology ignores\ndistinctions between different failure modes of this general type. This paper\nexpands on an earlier discussion by Garrabrant, which notes there are \"(at\nleast) four different mechanisms\" that relate to Goodhart's Law. This paper is\nintended to explore these mechanisms further, and specify more clearly how they\noccur. This discussion should be helpful in better understanding these types of\nfailures in economic regulation, in public policy, in machine learning, and in\nArtificial Intelligence alignment. The importance of Goodhart effects depends\non the amount of power directed towards optimizing the proxy, and so the\nincreased optimization power offered by artificial intelligence makes it\nespecially critical for that field.\n"]},
{"authors": ["Jochen L. Cremer", "Ioannis Konstantelos", "Simon H. Tindemans", "Goran Strbac"], "title": ["Sample-Derived Disjunctive Rules for Secure Power System Operation"], "date": ["2018-04-09T12:51:53Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02948v1"], "summary": ["  Machine learning techniques have been used in the past using Monte Carlo\nsamples to construct predictors of the dynamic stability of power systems. In\nthis paper we move beyond the task of prediction and propose a comprehensive\napproach to use predictors, such as Decision Trees (DT), within a standard\noptimization framework for pre- and post-fault control purposes. In particular,\nwe present a generalizable method for embedding rules derived from DTs in an\noperation decision-making model. We begin by pointing out the specific\nchallenges entailed when moving from a prediction to a control framework. We\nproceed with introducing the solution strategy based on generalized disjunctive\nprogramming (GDP) as well as a two-step search method for identifying optimal\nhyper-parameters for balancing cost and control accuracy. We showcase how the\nproposed approach constructs security proxies that cover multiple contingencies\nwhile facing high-dimensional uncertainty with respect to operating conditions\nwith the use of a case study on the IEEE 39-bus system. The method is shown to\nachieve efficient system control at a marginal increase in system price\ncompared to an oracle model.\n"]},
{"authors": ["Luiz G A Alves", "Haroldo V Ribeiro", "Francisco A Rodrigues"], "title": ["Crime prediction through urban metrics and statistical learning"], "date": ["2017-12-08T13:38:23Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1712.03834v2"], "summary": ["  Understanding the causes of crime is a longstanding issue in researcher's\nagenda. While it is a hard task to extract causality from data, several linear\nmodels have been proposed to predict crime through the existing correlations\nbetween crime and urban metrics. However, because of non-Gaussian distributions\nand multicollinearity in urban indicators, it is common to find controversial\nconclusions about the influence of some urban indicators on crime. Machine\nlearning ensemble-based algorithms can handle well such problems. Here, we use\na random forest regressor to predict crime and quantify the influence of urban\nindicators on homicides. Our approach can have up to 97% of accuracy on crime\nprediction, and the importance of urban indicators is ranked and clustered in\ngroups of equal influence, which are robust under slightly changes in the data\nsample analyzed. Our results determine the rank of importance of urban\nindicators to predict crime, unveiling that unemployment and illiteracy are the\nmost important variables for describing homicides in Brazilian cities. We\nfurther believe that our approach helps in producing more robust conclusions\nregarding the effects of urban indicators on crime, having potential\napplications for guiding public policies for crime control.\n"]},
{"authors": ["Ray Jiang", "Sven Gowal", "Timothy A. Mann", "Danilo J. Rezende"], "title": ["Optimizing Slate Recommendations via Slate-CVAE"], "date": ["2018-03-05T14:40:56Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.01682v3"], "summary": ["  The slate recommendation problem aims to find the \"optimal\" ordering of a\nsubset of documents to be presented on a surface that we call \"slate\". The\ndefinition of \"optimal\" changes depending on the underlying applications but a\ntypical goal is to maximize user engagement with the slate. Solving this\nproblem at scale is hard due to the combinatorial explosion of documents to\nshow and their display positions on the slate. In this paper, we introduce\nSlate Conditional Variational Auto-Encoders (Slate-CVAE) to generate optimal\nslates. To the best of our knowledge, this is the first conditional generative\nmodel that provides a unified framework for slate recommendation by direct\ngeneration. Slate-CVAE automatically takes into account the format of the slate\nand any biases that the representation causes, thus truly proposing the optimal\nslate. Additionally, to deal with large corpora of documents, we present a\nnovel approach that uses pretrained document embeddings combined with a\nsoft-nearest-neighbors layer within our CVAE model. Experiments show that on\nthe simulated and real-world datasets, Slate-CVAE outperforms recommender\nsystems that consists of greedily ranking documents by a significant margin\nwhile remaining scalable.\n"]},
{"authors": ["Isabelle Augenstein", "Sebastian Ruder", "Anders S\u00f8gaard"], "title": ["Multi-task Learning of Pairwise Sequence Classification Tasks Over\n  Disparate Label Spaces"], "date": ["2018-02-27T14:38:43Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.09913v2"], "summary": ["  We combine multi-task learning and semi-supervised learning by inducing a\njoint embedding space between disparate label spaces and learning transfer\nfunctions between label embeddings, enabling us to jointly leverage unlabelled\ndata and auxiliary, annotated datasets. We evaluate our approach on a variety\nof sequence classification tasks with disparate label spaces. We outperform\nstrong single and multi-task baselines and achieve a new state-of-the-art for\ntopic-based sentiment analysis.\n"]},
{"authors": ["David Ha", "J\u00fcrgen Schmidhuber"], "title": ["World Models"], "date": ["2018-03-27T15:08:55Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10122v3"], "summary": ["  We explore building generative neural network models of popular reinforcement\nlearning environments. Our world model can be trained quickly in an\nunsupervised manner to learn a compressed spatial and temporal representation\nof the environment. By using features extracted from the world model as inputs\nto an agent, we can train a very compact and simple policy that can solve the\nrequired task. We can even train our agent entirely inside of its own\nhallucinated dream generated by its world model, and transfer this policy back\ninto the actual environment.\n  An interactive version of this paper is available at\nhttps://worldmodels.github.io/\n"]},
{"authors": ["Yuchen Zhang", "Percy Liang", "Moses Charikar"], "title": ["A Hitting Time Analysis of Stochastic Gradient Langevin Dynamics"], "date": ["2017-02-18T06:33:55Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1702.05575v3"], "summary": ["  We study the Stochastic Gradient Langevin Dynamics (SGLD) algorithm for\nnon-convex optimization. The algorithm performs stochastic gradient descent,\nwhere in each step it injects appropriately scaled Gaussian noise to the\nupdate. We analyze the algorithm's hitting time to an arbitrary subset of the\nparameter space. Two results follow from our general theory: First, we prove\nthat for empirical risk minimization, if the empirical risk is point-wise close\nto the (smooth) population risk, then the algorithm achieves an approximate\nlocal minimum of the population risk in polynomial time, escaping suboptimal\nlocal minima that only exist in the empirical risk. Second, we show that SGLD\nimproves on one of the best known learnability results for learning linear\nclassifiers under the zero-one loss.\n"]},
{"authors": ["Lei Deng", "Peng Jiao", "Jing Pei", "Zhenzhi Wu", "Guoqi Li"], "title": ["GXNOR-Net: Training deep neural networks with ternary weights and\n  activations without full-precision memory under a unified discretization\n  framework"], "date": ["2017-05-25T17:59:41Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1705.09283v4"], "summary": ["  There is a pressing need to build an architecture that could subsume these\nnetworks under a unified framework that achieves both higher performance and\nless overhead. To this end, two fundamental issues are yet to be addressed. The\nfirst one is how to implement the back propagation when neuronal activations\nare discrete. The second one is how to remove the full-precision hidden weights\nin the training phase to break the bottlenecks of memory/computation\nconsumption. To address the first issue, we present a multi-step neuronal\nactivation discretization method and a derivative approximation technique that\nenable the implementing the back propagation algorithm on discrete DNNs. While\nfor the second issue, we propose a discrete state transition (DST) methodology\nto constrain the weights in a discrete space without saving the hidden weights.\nThrough this way, we build a unified framework that subsumes the binary or\nternary networks as its special cases, and under which a heuristic algorithm is\nprovided at the website https://github.com/AcrossV/Gated-XNOR. More\nparticularly, we find that when both the weights and activations become ternary\nvalues, the DNNs can be reduced to sparse binary networks, termed as gated XNOR\nnetworks (GXNOR-Nets) since only the event of non-zero weight and non-zero\nactivation enables the control gate to start the XNOR logic operations in the\noriginal binary networks. This promises the event-driven hardware design for\nefficient mobile intelligence. We achieve advanced performance compared with\nstate-of-the-art algorithms. Furthermore, the computational sparsity and the\nnumber of states in the discrete space can be flexibly modified to make it\nsuitable for various hardware platforms.\n"]},
{"authors": ["Tuomas Haarnoja", "Kristian Hartikainen", "Pieter Abbeel", "Sergey Levine"], "title": ["Latent Space Policies for Hierarchical Reinforcement Learning"], "date": ["2018-04-09T04:00:30Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02808v1"], "summary": ["  We address the problem of learning hierarchical deep neural network policies\nfor reinforcement learning. Our aim is to design a hierarchical reinforcement\nlearning algorithm that can construct hierarchical representations in bottom-up\nlayerwise fashion. In contrast to methods that explicitly restrict or cripple\nlower layers of a hierarchy to force them to use higher-level modulating\nsignals, each layer in our framework is trained to directly solve the task, but\nacquires a range of diverse strategies via a maximum entropy reinforcement\nlearning objective. Each layer is also augmented with latent random variables,\nwhich are sampled from a prior distribution during the training of that layer.\nThe maximum entropy objective causes these latent variables to be incorporated\ninto the layer's policy, and the higher level layer can directly control the\nbehavior of the lower layer through this latent space. Furthermore, by\nconstraining the mapping from latent variables to actions to be invertible,\nhigher layers retain full expressivity: neither the higher layers nor the lower\nlayers are constrained in their behavior. Our experimental evaluation\ndemonstrates that we can improve on the performance of single-layer policies on\nstandard benchmark tasks simply by adding additional layers, and that our\nmethod can solve more complex sparse-reward tasks by learning higher-level\npolicies on top of high-entropy skills optimized for simple low-level\nobjectives.\n"]},
{"authors": ["Christian H\u00e4ger", "Henry D. Pfister"], "title": ["Deep Learning of the Nonlinear Schr\u00f6dinger Equation in Fiber-Optic\n  Communications"], "date": ["2018-04-09T02:58:42Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02799v1"], "summary": ["  An important problem in fiber-optic communications is to invert the nonlinear\nSchr\\\"odinger equation in real time to reverse the deterministic effects of the\nchannel. Interestingly, the popular split-step Fourier method (SSFM) leads to a\ncomputation graph that is reminiscent of a deep neural network. This\nobservation allows one to leverage tools from machine learning to reduce\ncomplexity. In particular, the main disadvantage of the SSFM is that its\ncomplexity using M steps is at least M times larger than a linear equalizer.\nThis is because the linear SSFM operator is a dense matrix. In previous work,\ntruncation methods such as frequency sampling, wavelets, or least-squares have\nbeen used to obtain \"cheaper\" operators that can be implemented using filters.\nHowever, a large number of filter taps are typically required to limit\ntruncation errors. For example, Ip and Kahn showed that for a 10 Gbaud signal\nand 2000 km optical link, a truncated SSFM with 25 steps would require 70-tap\nfilters in each step and 100 times more operations than linear equalization. We\nfind that, by jointly optimizing all filters with deep learning, the complexity\ncan be reduced significantly for similar accuracy. Using optimized 5-tap and\n3-tap filters in an alternating fashion, one requires only around 2-6 times the\ncomplexity of linear equalization, depending on the implementation.\n"]},
{"authors": ["Su Yan", "Wei Lin", "Tianshu Wu", "Daorui Xiao", "Xu Zheng", "Bo Wu", "Kaipeng Liu"], "title": ["Beyond Keywords and Relevance: A Personalized Ad Retrieval Framework in\n  E-Commerce Sponsored Search"], "date": ["2017-12-29T03:48:25Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1712.10110v4"], "summary": ["  On most sponsored search platforms, advertisers bid on some keywords for\ntheir advertisements (ads). Given a search request, ad retrieval module\nrewrites the query into bidding keywords, and uses these keywords as keys to\nselect Top N ads through inverted indexes. In this way, an ad will not be\nretrieved even if queries are related when the advertiser does not bid on\ncorresponding keywords. Moreover, most ad retrieval approaches regard rewriting\nand ad-selecting as two separated tasks, and focus on boosting relevance\nbetween search queries and ads. Recently, in e-commerce sponsored search more\nand more personalized information has been introduced, such as user profiles,\nlong-time and real-time clicks. Personalized information makes ad retrieval\nable to employ more elements (e.g. real-time clicks) as search signals and\nretrieval keys, however it makes ad retrieval more difficult to measure ads\nretrieved through different signals. To address these problems, we propose a\nnovel ad retrieval framework beyond keywords and relevance in e-commerce\nsponsored search. Firstly, we employ historical ad click data to initialize a\nhierarchical network representing signals, keys and ads, in which personalized\ninformation is introduced. Then we train a model on top of the hierarchical\nnetwork by learning the weights of edges. Finally we select the best edges\naccording to the model, boosting RPM/CTR. Experimental results on our\ne-commerce platform demonstrate that our ad retrieval framework achieves good\nperformance.\n"]},
{"authors": ["Cheng Zhang", "Cengiz \u00d6ztireli", "Stephan Mandt", "Giampiero Salvi"], "title": ["Active Mini-Batch Sampling using Repulsive Point Processes"], "date": ["2018-04-08T22:48:20Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02772v1"], "summary": ["  The convergence speed of stochastic gradient descent (SGD) can be improved by\nactively selecting mini-batches. We explore sampling schemes where similar data\npoints are less likely to be selected in the same mini-batch. In particular, we\nprove that such repulsive sampling schemes lowers the variance of the gradient\nestimator. This generalizes recent work on using Determinantal Point Processes\n(DPPs) for mini-batch diversification (Zhang et al., 2017) to the broader class\nof repulsive point processes. We first show that the phenomenon of variance\nreduction by diversified sampling generalizes in particular to non-stationary\npoint processes. We then show that other point processes may be computationally\nmuch more efficient than DPPs. In particular, we propose and investigate\nPoisson Disk sampling---frequently encountered in the computer graphics\ncommunity---for this task. We show empirically that our approach improves over\nstandard SGD both in terms of convergence speed as well as final model\nperformance.\n"]},
{"authors": ["Jason Altschuler", "Victor-Emmanuel Brunel", "Alan Malek"], "title": ["Best Arm Identification for Contaminated Bandits"], "date": ["2018-02-26T18:59:30Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.09514v2"], "summary": ["  This paper studies active learning in the context of robust statistics.\nSpecifically, we propose the Contaminated Best Arm Identification variant of\nthe multi-armed bandit problem, in which every arm pull has probability\n$\\varepsilon$ of generating a sample from an arbitrary \\emph{contamination}\ndistribution instead of the \\emph{true} underlying distribution. The goal is to\nidentify the best (or approximately best) true distribution with high\nprobability, with a secondary goal of providing guarantees on the quality of\nthat arm's underlying distribution. It is simple to see that in this\ncontamination model there are no consistent estimators for statistics (e.g.\nmedian) of the underlying distribution, and that even with infinite samples,\nstatistics can be estimated only up to some unavoidable bias. We present tight,\nnon-asymptotic sample complexity bounds for estimating the first two robust\nmoments (median and median absolute deviation) with high probability. We then\nshow how to use this algorithmically for our problem by adapting Best Arm\nIdentification algorithms from the classical multi-armed bandit literature. We\ngive matching upper and lower bounds (up to a small logarithmic factor) on\nthese algorithms' sample complexities. These results suggest an inherent\nrobustness of classical Best Arm Identification algorithms.\n"]},
{"authors": ["Dabal Pedamonti"], "title": ["Comparison of non-linear activation functions for deep neural networks\n  on MNIST classification task"], "date": ["2018-04-08T22:16:36Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02763v1"], "summary": ["  Activation functions play a key role in neural networks so it becomes\nfundamental to understand their advantages and disadvantages in order to\nachieve better performances. This paper will first introduce common types of\nnon linear activation functions that are alternative to the well known sigmoid\nfunction and then evaluate their characteristics. Moreover deeper neural\nnetworks will be analysed because they positively influence the final\nperformances compared to shallower networks. They also strictly depend on the\nweight initialisation hence the effect of drawing weights from Gaussian and\nuniform distribution will be analysed making particular attention on how the\nnumber of incoming and outgoing connection to a node influence the whole\nnetwork.\n"]},
{"authors": ["Nikita Puchkin", "Vladimir Spokoiny"], "title": ["Pointwise adaptation via stagewise aggregation of local estimates for\n  multiclass classification"], "date": ["2018-04-08T21:07:46Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02756v1"], "summary": ["  We consider a problem of multiclass classification, where the training sample\n$S_n = \\{(X_i, Y_i)\\}_{i=1}^n$ is generated from the model $\\mathbb p(Y = m | X\n= x) = \\theta_m(x)$, $1 \\leq m \\leq M$, and $\\theta_1(x), \\dots, \\theta_M(x)$\nare unknown Lipschitz functions. Given a test point $X$, our goal is to\nestimate $\\theta_1(X), \\dots, \\theta_M(X)$. An approach based on nonparametric\nsmoothing uses a localization technique, i.e. the weight of observation $(X_i,\nY_i)$ depends on the distance between $X_i$ and $X$. However, local estimates\nstrongly depend on localizing scheme. In our solution we fix several schemes\n$W_1, \\dots, W_K$, compute corresponding local estimates\n$\\widetilde\\theta^{(1)}, \\dots, \\widetilde\\theta^{(K)}$ for each of them and\napply an aggregation procedure. We propose an algorithm, which constructs a\nconvex combination of the estimates $\\widetilde\\theta^{(1)}, \\dots,\n\\widetilde\\theta^{(K)}$ such that the aggregated estimate behaves approximately\nas well as the best one from the collection $\\widetilde\\theta^{(1)}, \\dots,\n\\widetilde\\theta^{(K)}$. We also study theoretical properties of the procedure,\nprove oracle results and establish rates of convergence under mild assumptions.\n"]},
{"authors": ["Krzysztof Chalupka", "Pietro Perona", "Frederick Eberhardt"], "title": ["Fast Conditional Independence Test for Vector Variables with Large\n  Sample Sizes"], "date": ["2018-04-08T20:03:07Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02747v1"], "summary": ["  We present and evaluate the Fast (conditional) Independence Test (FIT) -- a\nnonparametric conditional independence test. The test is based on the idea that\nwhen $P(X \\mid Y, Z) = P(X \\mid Y)$, $Z$ is not useful as a feature to predict\n$X$, as long as $Y$ is also a regressor. On the contrary, if $P(X \\mid Y, Z)\n\\neq P(X \\mid Y)$, $Z$ might improve prediction results. FIT applies to\nthousand-dimensional random variables with a hundred thousand samples in a\nfraction of the time required by alternative methods. We provide an extensive\nevaluation that compares FIT to six extant nonparametric independence tests.\nThe evaluation shows that FIT has low probability of making both Type I and\nType II errors compared to other tests, especially as the number of available\nsamples grows. Our implementation of FIT is publicly available.\n"]},
{"authors": ["Sida Liu", "Adrian Barbu"], "title": ["Unsupervised Learning of Mixture Models with a Uniform Background\n  Component"], "date": ["2018-04-08T19:27:39Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02744v1"], "summary": ["  Gaussian Mixture Models are one of the most studied and mature models in\nunsupervised learning. However, outliers are often present in the data and\ncould influence the cluster estimation. In this paper, we study a new model\nthat assumes that data comes from a mixture of a number of Gaussians as well as\na uniform \"background\" component assumed to contain outliers and other\nnon-interesting observations. We develop a novel method based on robust loss\nminimization that performs well in clustering such GMM with a uniform\nbackground. We give theoretical guarantees for our clustering algorithm to\nobtain best clustering results with high probability. Besides, we show that the\nresult of our algorithm does not depend on initialization or local optima, and\nthe parameter tuning is an easy task. By numeric simulations, we demonstrate\nthat our algorithm enjoys high accuracy and achieves the best clustering\nresults given a large enough sample size. Finally, experimental comparisons\nwith typical clustering methods on real datasets witness the potential of our\nalgorithm in real applications.\n"]},
{"authors": ["Penporn Koanantakool", "Alnur Ali", "Ariful Azad", "Aydin Buluc", "Dmitriy Morozov", "Leonid Oliker", "Katherine Yelick", "Sang-Yun Oh"], "title": ["Communication-Avoiding Optimization Methods for Distributed\n  Massive-Scale Sparse Inverse Covariance Estimation"], "date": ["2017-10-30T04:32:41Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.10769v2"], "summary": ["  Across a variety of scientific disciplines, sparse inverse covariance\nestimation is a popular tool for capturing the underlying dependency\nrelationships in multivariate data. Unfortunately, most estimators are not\nscalable enough to handle the sizes of modern high-dimensional data sets (often\non the order of terabytes), and assume Gaussian samples. To address these\ndeficiencies, we introduce HP-CONCORD, a highly scalable optimization method\nfor estimating a sparse inverse covariance matrix based on a regularized\npseudolikelihood framework, without assuming Gaussianity. Our parallel proximal\ngradient method uses a novel communication-avoiding linear algebra algorithm\nand runs across a multi-node cluster with up to 1k nodes (24k cores), achieving\nparallel scalability on problems with up to ~819 billion parameters (1.28\nmillion dimensions); even on a single node, HP-CONCORD demonstrates\nscalability, outperforming a state-of-the-art method. We also use HP-CONCORD to\nestimate the underlying dependency structure of the brain from fMRI data, and\nuse the result to identify functional regions automatically. The results show\ngood agreement with a clustering from the neuroscience literature.\n"]},
{"authors": ["Volodymyr Leno", "Abel Armas-Cervantes", "Marlon Dumas", "Marcello La Rosa", "Fabrizio M. Maggi"], "title": ["Discovering Process Maps from Event Streams"], "date": ["2018-04-08T15:23:52Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02704v1"], "summary": ["  Automated process discovery is a class of process mining methods that allow\nanalysts to extract business process models from event logs. Traditional\nprocess discovery methods extract process models from a snapshot of an event\nlog stored in its entirety. In some scenarios, however, events keep coming with\na high arrival rate to the extent that it is impractical to store the entire\nevent log and to continuously re-discover a process model from scratch. Such\nscenarios require online process discovery approaches. Given an event stream\nproduced by the execution of a business process, the goal of an online process\ndiscovery method is to maintain a continuously updated model of the process\nwith a bounded amount of memory while at the same time achieving similar\naccuracy as offline methods. However, existing online discovery approaches\nrequire relatively large amounts of memory to achieve levels of accuracy\ncomparable to that of offline methods. Therefore, this paper proposes an\napproach that addresses this limitation by mapping the problem of online\nprocess discovery to that of cache memory management, and applying well-known\ncache replacement policies to the problem of online process discovery. The\napproach has been implemented in .NET, experimentally integrated with the Minit\nprocess mining tool and comparatively evaluated against an existing baseline\nusing real-life datasets.\n"]},
{"authors": ["Mathieu Ravaut", "Satya Gorti"], "title": ["Gradient descent revisited via an adaptive online learning rate"], "date": ["2018-01-27T20:39:24Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1801.09136v2"], "summary": ["  Any gradient descent optimization requires to choose a learning rate. With\ndeeper and deeper models, tuning that learning rate can easily become tedious\nand does not necessarily lead to an ideal convergence. We propose a variation\nof the gradient descent algorithm in the which the learning rate is not fixed.\nInstead, we learn the learning rate itself, either by another gradient descent\n(first-order method), or by Newton's method (second-order). This way, gradient\ndescent for any machine learning algorithm can be optimized.\n"]},
{"authors": ["Takumi Ichimura", "Daisuke Igaue"], "title": ["Hierarchical Modular Reinforcement Learning Method and Knowledge\n  Acquisition of State-Action Rule for Multi-target Problem"], "date": ["2018-04-08T14:39:13Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02698v1"], "summary": ["  Hierarchical Modular Reinforcement Learning (HMRL), consists of 2 layered\nlearning where Profit Sharing works to plan a prey position in the higher layer\nand Q-learning method trains the state-actions to the target in the lower\nlayer. In this paper, we expanded HMRL to multi-target problem to take the\ndistance between targets to the consideration. The function, called `AT field',\ncan estimate the interests for an agent according to the distance between 2\nagents and the advantage/disadvantage of the other agent. Moreover, the\nknowledge related to state-action rules is extracted by C4.5. The action under\nthe situation is decided by using the acquired knowledge. To verify the\neffectiveness of proposed method, some experimental results are reported.\n"]},
{"authors": ["Alberto Bietti", "Julien Mairal"], "title": ["Group Invariance, Stability to Deformations, and Complexity of Deep\n  Convolutional Representations"], "date": ["2017-06-09T18:02:47Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1706.03078v3"], "summary": ["  The success of deep convolutional architectures is often attributed in part\nto their ability to learn multiscale and invariant representations of natural\nsignals. However, a precise study of these properties and how they affect\nlearning guarantees is still missing. In this paper, we consider deep\nconvolutional representations of signals; we study their invariance to\ntranslations and to more general groups of transformations, their stability to\nthe action of diffeomorphisms, and their ability to preserve signal\ninformation. This analysis is carried by introducing a multilayer kernel based\non convolutional kernel networks and by studying the geometry induced by the\nkernel mapping. We then characterize the corresponding reproducing kernel\nHilbert space (RKHS), showing that it contains a large class of convolutional\nneural networks with homogeneous activation functions. This analysis allows us\nto separate data representation from learning, and to provide a canonical\nmeasure of model complexity, the RKHS norm, which controls both stability and\ngeneralization of any learned model. In addition to models in the constructed\nRKHS, our stability analysis also applies to convolutional networks with\ngeneric activations such as rectified linear units, and we discuss its\nrelationship with recent generalization bounds based on spectral norms.\n"]},
{"authors": ["Hassan Jaleel", "Jeff S. Shamma"], "title": ["Path to Stochastic Stability: Comparative Analysis of Stochastic\n  Learning Dynamics in Games"], "date": ["2018-04-08T14:07:46Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02693v1"], "summary": ["  Stochastic stability is a popular solution concept for stochastic learning\ndynamics in games. However, a critical limitation of this solution concept is\nits inability to distinguish between different learning rules that lead to the\nsame steady-state behavior. We address this limitation for the first time and\ndevelop a framework for the comparative analysis of stochastic learning\ndynamics with different update rules but same steady-state behavior. We present\nthe framework in the context of two learning dynamics: Log-Linear Learning\n(LLL) and Metropolis Learning (ML). Although both of these dynamics have the\nsame stochastically stable states, LLL and ML correspond to different\nbehavioral models for decision making. Moreover, we demonstrate through an\nexample setup of sensor coverage game that for each of these dynamics, the\npaths to stochastically stable states exhibit distinctive behaviors. Therefore,\nwe propose multiple criteria to analyze and quantify the differences in the\nshort and medium run behavior of stochastic learning dynamics. We derive and\ncompare upper bounds on the expected hitting time to the set of Nash equilibria\nfor both LLL and ML. For the medium to long-run behavior, we identify a set of\ntools from the theory of perturbed Markov chains that result in a hierarchical\ndecomposition of the state space into collections of states called cycles. We\ncompare LLL and ML based on the proposed criteria and develop invaluable\ninsights into the comparative behavior of the two dynamics.\n"]},
{"authors": ["Valentina Ros", "Gerard Ben Arous", "Giulio Biroli", "Chiara Cammarota"], "title": ["Complex energy landscapes in spiked-tensor and simple glassy models:\n  ruggedness, arrangements of local minima and phase transitions"], "date": ["2018-04-08T13:03:54Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02686v1"], "summary": ["  We study rough high-dimensional landscapes in which an increasingly stronger\npreference for a given configuration emerges. Such energy landscapes arise in\nglass physics and inference. In particular we focus on random Gaussian\nfunctions, and on the spiked-tensor model and generalizations. We thoroughly\nanalyze the statistical properties of the corresponding landscapes and\ncharacterize the associated geometrical phase transitions. In order to perform\nour study, we develop a framework based on the Kac-Rice method that allows to\ncompute the complexity of the landscape, i.e. the logarithm of the typical\nnumber of stationary points and their Hessian. This approach generalizes the\none used to compute rigorously the annealed complexity of mean-field glass\nmodels. We discuss its advantages with respect to previous frameworks, in\nparticular the thermodynamical replica method which is shown to lead to\npartially incorrect predictions.\n"]},
{"authors": ["Fionn Murtagh", "Michael Orlov", "Boris Mirkin"], "title": ["Qualitative Judgement of Research Impact: Domain Taxonomy as a\n  Fundamental Framework for Judgement of the Quality of Research"], "date": ["2016-07-11T23:42:36Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1607.03200v2"], "summary": ["  The appeal of metric evaluation of research impact has attracted considerable\ninterest in recent times. Although the public at large and administrative\nbodies are much interested in the idea, scientists and other researchers are\nmuch more cautious, insisting that metrics are but an auxiliary instrument to\nthe qualitative peer-based judgement. The goal of this article is to propose\navailing of such a well positioned construct as domain taxonomy as a tool for\ndirectly assessing the scope and quality of research. We first show how\ntaxonomies can be used to analyse the scope and perspectives of a set of\nresearch projects or papers. Then we proceed to define a research team or\nresearcher's rank by those nodes in the hierarchy that have been created or\nsignificantly transformed by the results of the researcher. An experimental\ntest of the approach in the data analysis domain is described. Although the\nconcept of taxonomy seems rather simplistic to describe all the richness of a\nresearch domain, its changes and use can be made transparent and subject to\nopen discussions.\n"]},
{"authors": ["Chen Xing", "Devansh Arpit", "Christos Tsirigotis", "Yoshua Bengio"], "title": ["A Walk with SGD"], "date": ["2018-02-24T00:21:10Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.08770v3"], "summary": ["  We present novel empirical observations regarding how stochastic gradient\ndescent (SGD) navigates the loss landscape of over-parametrized deep neural\nnetworks (DNNs). These observations expose the qualitatively different the\nroles of learning rate and batch-size in DNN optimization and generalization.\nSpecifically we study the DNN loss surface along the trajectory of SGD by\ninterpolating the loss surface between parameters from consecutive\n\\textit{iterations} and tracking various metrics during training. We find that\nthe loss interpolation between parameters before and after each training\niteration's update is roughly convex with a minimum (\\textit{valley floor}) in\nbetween for most of the training. Based on this and other metrics, we deduce\nthat for most of the training update steps, SGD moves in valley like regions of\nthe loss surface by jumping from one valley wall to another at a height above\nthe valley floor. This 'bouncing off walls at a height' mechanism helps SGD\ntraverse larger distance for small batch sizes and large learning rates which\nwe find play qualitatively different roles in the dynamics. While a large\nlearning rate maintains a large height from the valley floor, a small batch\nsize injects noise facilitating exploration. We find this mechanism is crucial\nfor generalization because the valley floor has barriers and this exploration\nabove the valley floor allows SGD to quickly travel far away from the\ninitialization point (without being affected by barriers) and find flatter\nregions, corresponding to better generalization.\n"]},
{"authors": ["Shahar Harel", "Kira Radinsky"], "title": ["Accelerating Prototype-Based Drug Discovery using Conditional Diversity\n  Networks"], "date": ["2018-04-08T11:08:08Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02668v1"], "summary": ["  Designing a new drug is a lengthy and expensive process. As the space of\npotential molecules is very large (10^23-10^60), a common technique during drug\ndiscovery is to start from a molecule which already has some of the desired\nproperties. An interdisciplinary team of scientists generates hypothesis about\nthe required changes to the prototype. In this work, we develop an algorithmic\nunsupervised-approach that automatically generates potential drug molecules\ngiven a prototype drug. We show that the molecules generated by the system are\nvalid molecules and significantly different from the prototype drug. Out of the\ncompounds generated by the system, we identified 35 FDA-approved drugs. As an\nexample, our system generated Isoniazid - one of the main drugs for\nTuberculosis. The system is currently being deployed for use in collaboration\nwith pharmaceutical companies to further analyze the additional generated\nmolecules.\n"]},
{"authors": ["Fady Medhat", "David Chesmore", "John Robinson"], "title": ["Environmental Sound Recognition using Masked Conditional Neural Networks"], "date": ["2018-04-08T10:22:02Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02665v1"], "summary": ["  Neural network based architectures used for sound recognition are usually\nadapted from other application domains, which may not harness sound related\nproperties. The ConditionaL Neural Network (CLNN) is designed to consider the\nrelational properties across frames in a temporal signal, and its extension the\nMasked ConditionaL Neural Network (MCLNN) embeds a filterbank behavior within\nthe network, which enforces the network to learn in frequency bands rather than\nbins. Additionally, it automates the exploration of different feature\ncombinations analogous to handcrafting the optimum combination of features for\na recognition task. We applied the MCLNN to the environmental sounds of the\nESC-10 dataset. The MCLNN achieved competitive accuracies compared to\nstate-of-the-art convolutional neural networks and hand-crafted attempts.\n"]},
{"authors": ["Yuji Tokozume", "Yoshitaka Ushiku", "Tatsuya Harada"], "title": ["Between-class Learning for Image Classification"], "date": ["2017-11-28T13:31:14Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.10284v2"], "summary": ["  In this paper, we propose a novel learning method for image classification\ncalled Between-Class learning (BC learning). We generate between-class images\nby mixing two images belonging to different classes with a random ratio. We\nthen input the mixed image to the model and train the model to output the\nmixing ratio. BC learning has the ability to impose constraints on the shape of\nthe feature distributions, and thus the generalization ability is improved. BC\nlearning is originally a method developed for sounds, which can be digitally\nmixed. Mixing two image data does not appear to make sense; however, we argue\nthat because convolutional neural networks have an aspect of treating input\ndata as waveforms, what works on sounds must also work on images. First, we\npropose a simple mixing method using internal divisions, which surprisingly\nproves to significantly improve performance. Second, we propose a mixing method\nthat treats the images as waveforms, which leads to a further improvement in\nperformance. As a result, we achieved 19.4% and 2.26% top-1 errors on\nImageNet-1K and CIFAR-10, respectively.\n"]},
{"authors": ["Mehrad Moradshahi", "Utkarsh Contractor"], "title": ["Language Modeling with Generative AdversarialNetworks"], "date": ["2018-04-08T03:18:13Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02617v1"], "summary": ["  Generative Adversarial Networks (GANs) have been promising in the field of\nimage generation, however, they have been hard to train for language\ngeneration. GANs were originally designed to output differentiable values, so\ndiscrete language generation is challenging for them which causes high levels\nof instability in training GANs. Consequently, past work has resorted to\npre-training with maximum-likelihood or training GANs without pre-training with\na WGAN objective with a gradient penalty. In this study, we present a\ncomparison of those approaches. Furthermore, we present the results of some\nexperiments that indicate better training and convergence of Wasserstein GANs\n(WGANs) when a weaker regularization term is enforcing the Lipschitz\nconstraint.\n"]},
{"authors": ["Michael Arbel", "Arthur Gretton"], "title": ["Kernel Conditional Exponential Family"], "date": ["2017-11-15T00:32:08Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.05363v2"], "summary": ["  A nonparametric family of conditional distributions is introduced, which\ngeneralizes conditional exponential families using functional parameters in a\nsuitable RKHS. An algorithm is provided for learning the generalized natural\nparameter, and consistency of the estimator is established in the well\nspecified case. In experiments, the new method generally outperforms a\ncompeting approach with consistency guarantees, and is competitive with a deep\nconditional density model on datasets that exhibit abrupt transitions and\nheteroscedasticity.\n"]},
{"authors": ["Arun Kumar Kuchibhotla", "Abhishek Chakrabortty"], "title": ["Moving Beyond Sub-Gaussianity in High-Dimensional Statistics:\n  Applications in Covariance Estimation and Linear Regression"], "date": ["2018-04-08T00:27:45Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02605v1"], "summary": ["  Concentration inequalities form an essential toolkit in the study of\nhigh-dimensional statistical methods. Most of the relevant statistics\nliterature is based on the assumptions of sub-Gaussian/sub-exponential random\nvectors. In this paper, we bring together various probability inequalities for\nsums of independent random variables under much weaker exponential type\n(sub-Weibull) tail assumptions. These results extract a part sub-Gaussian tail\nbehavior in finite samples, matching the asymptotics governed by the central\nlimit theorem, and are compactly represented in terms of a new Orlicz\nquasi-norm - the Generalized Bernstein-Orlicz norm - that typifies such tail\nbehaviors.\n  We illustrate the usefulness of these inequalities through the analysis of\nfour fundamental problems in high-dimensional statistics. In the first two\nproblems, we study the rate of convergence of the sample covariance matrix in\nterms of the maximum elementwise norm and the maximum k-sub-matrix operator\nnorm which are key quantities of interest in bootstrap procedures and\nhigh-dimensional structured covariance matrix estimation. The third example\nconcerns the restricted eigenvalue condition, required in high dimensional\nlinear regression, which we verify for all sub-Weibull random vectors under\nonly marginal (not joint) tail assumptions on the covariates. To our knowledge,\nthis is the first unified result obtained in such generality. In the final\nexample, we consider the Lasso estimator for linear regression and establish\nits rate of convergence under much weaker tail assumptions (on the errors as\nwell as the covariates) than those in the existing literature. The common\nfeature in all our results is that the convergence rates under most exponential\ntails match the usual ones under sub-Gaussian assumptions. Finally, we also\nestablish a high-dimensional CLT and tail bounds for empirical processes for\nsub-Weibulls.\n"]},
{"authors": ["Shayak Sen", "Piotr Mardziel", "Anupam Datta", "Matthew Fredrikson"], "title": ["Supervising Feature Influence"], "date": ["2018-03-28T19:16:39Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10815v2"], "summary": ["  Causal influence measures for machine learnt classifiers shed light on the\nreasons behind classification, and aid in identifying influential input\nfeatures and revealing their biases. However, such analyses involve evaluating\nthe classifier using datapoints that may be atypical of its training\ndistribution. Standard methods for training classifiers that minimize empirical\nrisk do not constrain the behavior of the classifier on such datapoints. As a\nresult, training to minimize empirical risk does not distinguish among\nclassifiers that agree on predictions in the training distribution but have\nwildly different causal influences. We term this problem covariate shift in\ncausal testing and formally characterize conditions under which it arises. As a\nsolution to this problem, we propose a novel active learning algorithm that\nconstrains the influence measures of the trained model. We prove that any two\npredictors whose errors are close on both the original training distribution\nand the distribution of atypical points are guaranteed to have causal\ninfluences that are also close. Further, we empirically demonstrate with\nsynthetic labelers that our algorithm trains models that (i) have similar\ncausal influences as the labeler's model, and (ii) generalize better to\nout-of-distribution points while (iii) retaining their accuracy on\nin-distribution points.\n"]},
{"authors": ["Lydia T. Liu", "Sarah Dean", "Esther Rolf", "Max Simchowitz", "Moritz Hardt"], "title": ["Delayed Impact of Fair Machine Learning"], "date": ["2018-03-12T17:20:56Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04383v2"], "summary": ["  Fairness in machine learning has predominantly been studied in static\nclassification settings without concern for how decisions change the underlying\npopulation over time. Conventional wisdom suggests that fairness criteria\npromote the long-term well-being of those groups they aim to protect.\n  We study how static fairness criteria interact with temporal indicators of\nwell-being, such as long-term improvement, stagnation, and decline in a\nvariable of interest. We demonstrate that even in a one-step feedback model,\ncommon fairness criteria in general do not promote improvement over time, and\nmay in fact cause harm in cases where an unconstrained objective would not.\n  We completely characterize the delayed impact of three standard criteria,\ncontrasting the regimes in which these exhibit qualitatively different\nbehavior. In addition, we find that a natural form of measurement error\nbroadens the regime in which fairness criteria perform favorably.\n  Our results highlight the importance of measurement and temporal modeling in\nthe evaluation of fairness criteria, suggesting a range of new challenges and\ntrade-offs.\n"]},
{"authors": ["Xin Wang", "Jaime Lorenzo-Trueba", "Shinji Takaki", "Lauri Juvela", "Junichi Yamagishi"], "title": ["A comparison of recent waveform generation and acoustic modeling methods\n  for neural-network-based speech synthesis"], "date": ["2018-04-07T12:16:50Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02549v1"], "summary": ["  Recent advances in speech synthesis suggest that limitations such as the\nlossy nature of the amplitude spectrum with minimum phase approximation and the\nover-smoothing effect in acoustic modeling can be overcome by using advanced\nmachine learning approaches. In this paper, we build a framework in which we\ncan fairly compare new vocoding and acoustic modeling techniques with\nconventional approaches by means of a large scale crowdsourced evaluation.\nResults on acoustic models showed that generative adversarial networks and an\nautoregressive (AR) model performed better than a normal recurrent network and\nthe AR model performed best. Evaluation on vocoders by using the same AR\nacoustic model demonstrated that a Wavenet vocoder outperformed classical\nsource-filter-based vocoders. Particularly, generated speech waveforms from the\ncombination of AR acoustic model and Wavenet vocoder achieved a similar score\nof speech quality to vocoded speech.\n"]},
{"authors": ["Osvaldo Simeone"], "title": ["A Brief Introduction to Machine Learning for Engineers"], "date": ["2017-09-08T19:21:26Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1709.02840v2"], "summary": ["  This monograph aims at providing an introduction to key concepts, algorithms,\nand theoretical results in machine learning. The treatment concentrates on\nprobabilistic models for supervised and unsupervised learning problems. It\nintroduces fundamental concepts and algorithms by building on first principles,\nwhile also exposing the reader to more advanced topics with extensive pointers\nto the literature, within a unified notation and mathematical framework. The\nmaterial is organized according to clearly defined categories, such as\ndiscriminative and generative models, frequentist and Bayesian approaches,\nexact and approximate inference, as well as directed and undirected models.\nThis monograph is meant as an entry point for researchers with a background in\nprobability and linear algebra.\n"]},
{"authors": ["Bradley Gram-Hansen", "Yuan Zhou", "Tobias Kohn", "Hongseok Yang", "Frank Wood"], "title": ["Discontinuous Hamiltonian Monte Carlo for Probabilistic Programs"], "date": ["2018-04-07T09:22:56Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03523v1"], "summary": ["  Hamiltonian Monte Carlo (HMC) is the dominant statistical inference algorithm\nused in most popular first-order differentiable probabilistic programming\nlanguages. HMC requires that the joint density be differentiable with respect\nto all latent variables. This complicates expressing some models in such\nlanguages and prohibits others. A recently proposed new integrator for HMC\nyielded a new Discontinuous HMC (DHMC) algorithm that can be used for inference\nin models with joint densities that have discontinuities. In this paper we show\nhow to use DHMC for inference in probabilistic programs. To do this we\nintroduce a sufficient set of language restrictions, a corresponding\nmathematical formalism that ensures that any joint density denoted in such a\nlanguage has a suitably low measure of discontinuous points, and a recipe for\nhow to apply DHMC in the more general probabilistic-programming context. Our\nexperimental findings demonstrate the correctness of this approach.\n"]},
{"authors": ["Iraklis A. Klampanos", "Athanasios Davvetas", "Antonis Koukourikos", "Vangelis Karkaletsis"], "title": ["ANNETT-O: An Ontology for Describing Artificial Neural Network\n  Evaluation, Topology and Training"], "date": ["2018-04-07T07:56:29Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02528v1"], "summary": ["  Deep learning models, while effective and versatile, are becoming\nincreasingly complex, often including multiple overlapping networks of\narbitrary depths, multiple objectives and non-intuitive training methodologies.\nThis makes it increasingly difficult for researchers and practitioners to\ndesign, train and understand them. In this paper we present ANNETT-O, a\nmuch-needed, generic and computer-actionable vocabulary for researchers and\npractitioners to describe their deep learning configurations, training\nprocedures and experiments. The proposed ontology focuses on topological,\ntraining and evaluation aspects of complex deep neural configurations, while\nkeeping peripheral entities more succinct. Knowledge bases implementing\nANNETT-O can support a wide variety of queries, providing relevant insights to\nusers. In addition to a detailed description of the ontology, we demonstrate\nits suitability to the task via a number of hypothetical use-cases of\nincreasing complexity.\n"]},
{"authors": ["Jaegul Choo", "Shixia Liu"], "title": ["Visual Analytics for Explainable Deep Learning"], "date": ["2018-04-07T07:52:04Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02527v1"], "summary": ["  Recently, deep learning has been advancing the state of the art in artificial\nintelligence to a new level, and humans rely on artificial intelligence\ntechniques more than ever. However, even with such unprecedented advancements,\nthe lack of explanation regarding the decisions made by deep learning models\nand absence of control over their internal processes act as major drawbacks in\ncritical decision-making processes, such as precision medicine and law\nenforcement. In response, efforts are being made to make deep learning\ninterpretable and controllable by humans. In this paper, we review visual\nanalytics, information visualization, and machine learning perspectives\nrelevant to this aim, and discuss potential challenges and future research\ndirections.\n"]},
{"authors": ["Ozan \u0130rsoy", "Ethem Alpayd\u0131n"], "title": ["Continuously Constructive Deep Neural Networks"], "date": ["2018-04-07T02:09:16Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02491v1"], "summary": ["  Traditionally, deep learning algorithms update the network weights whereas\nthe network architecture is chosen manually, using a process of trial and\nerror. In this work, we propose two novel approaches that automatically update\nthe network structure while also learning its weights. The novelty of our\napproach lies in our parameterization where the depth, or additional\ncomplexity, is encapsulated continuously in the parameter space through control\nparameters that add additional complexity. We propose two methods: In tunnel\nnetworks, this selection is done at the level of a hidden unit, and in budding\nperceptrons, this is done at the level of a network layer; updating this\ncontrol parameter introduces either another hidden unit or another hidden\nlayer. We show the effectiveness of our methods on the synthetic two-spirals\ndata and on two real data sets of MNIST and MIRFLICKR, where we see that our\nproposed methods, with the same set of hyperparameters, can correctly adjust\nthe network complexity to the task complexity.\n"]},
{"authors": ["Alex Lamb", "Jonathan Binas", "Anirudh Goyal", "Dmitriy Serdyuk", "Sandeep Subramanian", "Ioannis Mitliagkas", "Yoshua Bengio"], "title": ["Fortified Networks: Improving the Robustness of Deep Networks by\n  Modeling the Manifold of Hidden Representations"], "date": ["2018-04-07T00:11:05Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02485v1"], "summary": ["  Deep networks have achieved impressive results across a variety of important\ntasks. However a known weakness is a failure to perform well when evaluated on\ndata which differ from the training distribution, even if these differences are\nvery small, as is the case with adversarial examples. We propose Fortified\nNetworks, a simple transformation of existing networks, which fortifies the\nhidden layers in a deep network by identifying when the hidden states are off\nof the data manifold, and maps these hidden states back to parts of the data\nmanifold where the network performs well. Our principal contribution is to show\nthat fortifying these hidden states improves the robustness of deep networks\nand our experiments (i) demonstrate improved robustness to standard adversarial\nattacks in both black-box and white-box threat models; (ii) suggest that our\nimprovements are not primarily due to the gradient masking problem and (iii)\nshow the advantage of doing this fortification in the hidden layers instead of\nthe input space.\n"]},
{"authors": ["Alessandro Rudi", "Leonard Wossnig", "Carlo Ciliberto", "Andrea Rocchetto", "Massimiliano Pontil", "Simone Severini"], "title": ["Approximating Hamiltonian dynamics with the Nystr\u00f6m method"], "date": ["2018-04-06T23:58:30Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02484v1"], "summary": ["  Simulating the time-evolution of quantum mechanical systems is BQP-hard and\nexpected to be one of the foremost applications of quantum computers. We\nconsider the approximation of Hamiltonian dynamics using subsampling methods\nfrom randomized numerical linear algebra. We propose conditions for the\nefficient approximation of state vectors evolving under a given Hamiltonian. As\nan immediate application, we show that sample based quantum simulation, a type\nof evolution where the Hamiltonian is a density matrix, can be efficiently\nclassically simulated under specific structural conditions. Our main technical\ncontribution is a randomized algorithm for approximating Hermitian matrix\nexponentials. The proof leverages the Nystr\\\"om method to obtain low-rank\napproximations of the Hamiltonian. We envisage that techniques from randomized\nlinear algebra will bring further insights into the power of quantum\ncomputation.\n"]},
{"authors": ["Christopher Chamberland", "Pooya Ronagh"], "title": ["Deep neural decoders for near term fault-tolerant experiments"], "date": ["2018-02-18T20:48:06Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.06441v2"], "summary": ["  Finding efficient decoders for quantum error correcting codes adapted to\nrealistic experimental noise in fault-tolerant devices represents a significant\nchallenge. In this paper we introduce several decoding algorithms complemented\nby deep neural decoders and apply them to analyze several fault-tolerant error\ncorrection protocols such as the surface code as well as Steane and Knill error\ncorrection. Our methods require no knowledge of the underlying noise model\nafflicting the quantum device making them appealing for real-world experiments.\nOur analysis is based on a full circuit-level noise model. It considers both\ndistance-three and five codes, and is performed near the codes pseudo-threshold\nregime. Training deep neural decoders in low noise rate regimes appears to be a\nchallenging machine learning endeavour. We provide a detailed description of\nour neural network architectures and training methodology. We then discuss both\nthe advantages and limitations of deep neural decoders. Lastly, we provide a\nrigorous analysis of the decoding runtime of trained deep neural decoders and\ncompare our methods with anticipated gate times in future quantum devices.\nGiven the broad applications of our decoding schemes, we believe that the\nmethods presented in this paper could have practical applications for near term\nfault-tolerant experiments.\n"]},
{"authors": ["Abhinav Verma", "Vijayaraghavan Murali", "Rishabh Singh", "Pushmeet Kohli", "Swarat Chaudhuri"], "title": ["Programmatically Interpretable Reinforcement Learning"], "date": ["2018-04-06T22:17:18Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02477v1"], "summary": ["  We study the problem of generating interpretable and verifiable policies\nthrough reinforcement learning. Unlike the popular Deep Reinforcement Learning\n(DRL) paradigm, in which the policy is represented by a neural network, the aim\nin Programmatically Interpretable Reinforcement Learning is to find a policy\nthat can be represented in a high-level programming language. Such programmatic\npolicies have the benefits of being more easily interpreted than neural\nnetworks, and being amenable to verification by symbolic methods. We propose a\nnew method, called Neurally Directed Program Search (NDPS), for solving the\nchallenging nonsmooth optimization problem of finding a programmatic policy\nwith maxima reward. NDPS works by first learning a neural policy network using\nDRL, and then performing a local search over programmatic policies that seeks\nto minimize a distance from this neural \"oracle\". We evaluate NDPS on the task\nof learning to drive a simulated car in the TORCS car-racing environment. We\ndemonstrate that NDPS is able to discover human-readable policies that pass\nsome significant performance bars. We also find that a well-designed policy\nlanguage can serve as a regularizer, and result in the discovery of policies\nthat lead to smoother trajectories and are more easily transferred to\nenvironments not encountered during training.\n"]},
{"authors": ["Alex Graves", "Jacob Menick", "Aaron van den Oord"], "title": ["Associative Compression Networks"], "date": ["2018-04-06T22:17:04Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02476v1"], "summary": ["  This paper introduces Associative Compression Networks (ACNs), a new\nframework for variational autoencoding with neural networks. The system differs\nfrom existing variational autoencoders in that the prior distribution used to\nmodel each code is conditioned on a similar code from the dataset. In\ncompression terms this equates to sequentially transmitting the data using an\nordering determined by proximity in latent space. As the prior need only\naccount for local, rather than global variations in the latent space, the\ncoding cost is greatly reduced, leading to rich, informative codes, even when\nautoregressive decoders are used. Experimental results on MNIST, CIFAR-10,\nImageNet and CelebA show that ACNs can yield improved dataset compression\nrelative to order-agnostic generative models, with an upper bound of 73.9 nats\nper image on binarized MNIST. They also demonstrate that ACNs learn high-level\nfeatures such as object class, writing style, pose and facial expression, which\ncan be used to cluster and classify the data, as well as to generate diverse\nand convincing samples.\n"]},
{"authors": ["Thomas Miconi", "Jeff Clune", "Kenneth O. Stanley"], "title": ["Differentiable plasticity: training plastic neural networks with\n  backpropagation"], "date": ["2018-04-06T21:43:13Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02464v1"], "summary": ["  How can we build agents that keep learning from experience, quickly and\nefficiently, after their initial training? Here we take inspiration from the\nmain mechanism of learning in biological brains: synaptic plasticity, carefully\ntuned by evolution to produce efficient lifelong learning. We show that\nplasticity, just like connection weights, can be optimized by gradient descent\nin large (millions of parameters) recurrent networks with Hebbian plastic\nconnections. First, recurrent plastic networks with more than two million\nparameters can be trained to memorize and reconstruct sets of novel,\nhigh-dimensional 1000+ pixels natural images not seen during training.\nCrucially, traditional non-plastic recurrent networks fail to solve this task.\nFurthermore, trained plastic networks can also solve generic meta-learning\ntasks such as the Omniglot task, with competitive results and little parameter\noverhead. Finally, in reinforcement learning settings, plastic networks\noutperform a non-plastic equivalent in a maze exploration task. We conclude\nthat differentiable plasticity may provide a powerful novel approach to the\nlearning-to-learn problem.\n"]},
{"authors": ["Ding Liu", "Shi-Ju Ran", "Peter Wittek", "Cheng Peng", "Raul Bl\u00e1zquez Garc\u00eda", "Gang Su", "Maciej Lewenstein"], "title": ["Machine Learning by Two-Dimensional Hierarchical Tensor Networks: A\n  Quantum Information Theoretic Perspective on Deep Architectures"], "date": ["2017-10-13T08:24:09Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.04833v2"], "summary": ["  The resemblance between the tensor networks (TNs) and machine learning has\ndrawn considerable attention. In particular, TNs and deep learning\narchitectures bear striking similarities suggesting using quantum techniques\nfor machine learning. In this work, we train two-dimensional hierarchical TNs\nto solve image recognition problems, using a training algorithm derived from\nthe multipartite entanglement renormalization ansatz. This approach overcomes\nscalability issues and implies novel mathematical connections among quantum\nmany-body physics, quantum information theory, and machine learning. The\nalgorithm optimally encodes each image class into a TN state, so that the\nlearning tasks as well as the image classes can be characterized by quantum\nproperties of the state including quantum entanglement and fidelity.\nFurthermore, the unitary conditions of the local mappings in our algorithm make\nit possible to realize the machine learning by, e.g., quantum state tomography\ntechniques or quantum computations.\n"]},
{"authors": ["Lior Deutsch"], "title": ["Generating Neural Networks with Neural Networks"], "date": ["2018-01-06T01:27:16Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1801.01952v4"], "summary": ["  Hypernetworks are neural networks that generate weights for another neural\nnetwork. We formulate the hypernetwork training objective as a compromise\nbetween accuracy and diversity, where the diversity takes into account trivial\nsymmetry transformations of the target network. We explain how this simple\nformulation generalizes variational inference. We use multi-layered perceptrons\nto form the mapping from the low dimensional input random vector to the high\ndimensional weight space, and demonstrate how to reduce the number of\nparameters in this mapping by parameter sharing. We perform experiments and\nshow that the generated weights are diverse and lie on a non-trivial manifold.\n"]},
{"authors": ["Dhagash Mehta", "Xiaojun Zhao", "Edgar A. Bernal", "David J. Wales"], "title": ["The Loss Surface of XOR Artificial Neural Networks"], "date": ["2018-04-06T18:11:23Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02411v1"], "summary": ["  Training an artificial neural network involves an optimization process over\nthe landscape defined by the cost (loss) as a function of the network\nparameters. We explore these landscapes using optimisation tools developed for\npotential energy landscapes in molecular science. The number of local minima\nand transition states (saddle points of index one), as well as the ratio of\ntransition states to minima, grow rapidly with the number of nodes in the\nnetwork. There is also a strong dependence on the regularisation parameter,\nwith the landscape becoming more convex (fewer minima) as the regularisation\nterm increases. We demonstrate that in our formulation, stationary points for\nnetworks with $N_h$ hidden nodes, including the minimal network required to fit\nthe XOR data, are also stationary points for networks with $N_{h} +1$ hidden\nnodes when all the weights involving the additional nodes are zero. Hence,\nsmaller networks optimized to train the XOR data are embedded in the landscapes\nof larger networks. Our results clarify certain aspects of the classification\nand sensitivity (to perturbations in the input data) of minima and saddle\npoints for this system, and may provide insight into dropout and network\ncompression.\n"]},
{"authors": ["Kai Sheng Tai", "Vatsal Sharan", "Peter Bailis", "Gregory Valiant"], "title": ["Sketching Linear Classifiers over Data Streams"], "date": ["2017-11-07T06:37:27Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.02305v2"], "summary": ["  We introduce a new sub-linear space sketch---the Weight-Median Sketch---for\nlearning compressed linear classifiers over data streams while supporting the\nefficient recovery of large-magnitude weights in the model. This enables\nmemory-limited execution of several statistical analyses over streams,\nincluding online feature selection, streaming data explanation, relative\ndeltoid detection, and streaming estimation of pointwise mutual information.\nUnlike related sketches that capture the most frequently-occurring features (or\nitems) in a data stream, the Weight-Median Sketch captures the features that\nare most discriminative of one stream (or class) compared to another. The\nWeight-Median Sketch adopts the core data structure used in the Count-Sketch,\nbut, instead of sketching counts, it captures sketched gradient updates to the\nmodel parameters. We provide a theoretical analysis that establishes recovery\nguarantees for batch and online learning, and demonstrate empirical\nimprovements in memory-accuracy trade-offs over alternative memory-budgeted\nmethods, including count-based sketches and feature hashing.\n"]},
{"authors": ["George Tucker", "Surya Bhupatiraju", "Shixiang Gu", "Richard E. Turner", "Zoubin Ghahramani", "Sergey Levine"], "title": ["The Mirage of Action-Dependent Baselines in Reinforcement Learning"], "date": ["2018-02-27T17:16:48Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.10031v2"], "summary": ["  Policy gradient methods are a widely used class of model-free reinforcement\nlearning algorithms where a state-dependent baseline is used to reduce gradient\nestimator variance. Several recent papers extend the baseline to depend on both\nthe state and action and suggest that this significantly reduces variance and\nimproves sample efficiency without introducing bias into the gradient\nestimates. To better understand this development, we decompose the variance of\nthe policy gradient estimator and numerically show that learned\nstate-action-dependent baselines do not in fact reduce variance over a\nstate-dependent baseline in commonly tested benchmark domains. We confirm this\nunexpected result by reviewing the open-source code accompanying these prior\npapers, and show that subtle implementation decisions cause deviations from the\nmethods presented in the papers and explain the source of the previously\nobserved empirical gains. Furthermore, the variance decomposition highlights\nareas for improvement, which we demonstrate by illustrating a simple change to\nthe typical value function parameterization that can significantly improve\nperformance.\n"]},
{"authors": ["Shuai Zheng", "Chris Ding"], "title": ["Minimal Support Vector Machine"], "date": ["2018-04-06T17:44:01Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02370v1"], "summary": ["  Support Vector Machine (SVM) is an efficient classification approach, which\nfinds a hyperplane to separate data from different classes. This hyperplane is\ndetermined by support vectors. In existing SVM formulations, the objective\nfunction uses L2 norm or L1 norm on slack variables. The number of support\nvectors is a measure of generalization errors. In this work, we propose a\nMinimal SVM, which uses L0.5 norm on slack variables. The result model further\nreduces the number of support vectors and increases the classification\nperformance.\n"]},
{"authors": ["Andrew Ilyas", "Logan Engstrom", "Anish Athalye", "Jessy Lin"], "title": ["Query-Efficient Black-box Adversarial Examples (superceded)"], "date": ["2017-12-19T18:58:10Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1712.07113v2"], "summary": ["  Note that this paper is superceded by \"Black-Box Adversarial Attacks with\nLimited Queries and Information.\"\n  Current neural network-based image classifiers are susceptible to adversarial\nexamples, even in the black-box setting, where the attacker is limited to query\naccess without access to gradients. Previous methods --- substitute networks\nand coordinate-based finite-difference methods --- are either unreliable or\nquery-inefficient, making these methods impractical for certain problems.\n  We introduce a new method for reliably generating adversarial examples under\nmore restricted, practical black-box threat models. First, we apply natural\nevolution strategies to perform black-box attacks using two to three orders of\nmagnitude fewer queries than previous methods. Second, we introduce a new\nalgorithm to perform targeted adversarial attacks in the partial-information\nsetting, where the attacker only has access to a limited number of target\nclasses. Using these techniques, we successfully perform the first targeted\nadversarial attack against a commercially deployed machine learning system, the\nGoogle Cloud Vision API, in the partial information setting.\n"]},
{"authors": ["Krzysztof Choromanski", "Mark Rowland", "Vikas Sindhwani", "Richard E. Turner", "Adrian Weller"], "title": ["Structured Evolution with Compact Architectures for Scalable Policy\n  Optimization"], "date": ["2018-04-06T15:25:14Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02395v1"], "summary": ["  We present a new method of blackbox optimization via gradient approximation\nwith the use of structured random orthogonal matrices, providing more accurate\nestimators than baselines and with provable theoretical guarantees. We show\nthat this algorithm can be successfully applied to learn better quality compact\npolicies than those using standard gradient estimation techniques. The compact\npolicies we learn have several advantages over unstructured ones, including\nfaster training algorithms and faster inference. These benefits are important\nwhen the policy is deployed on real hardware with limited resources. Further,\ncompact policies provide more scalable architectures for derivative-free\noptimization (DFO) in high-dimensional spaces. We show that most robotics tasks\nfrom the OpenAI Gym can be solved using neural networks with less than 300\nparameters, with almost linear time complexity of the inference phase, with up\nto 13x fewer parameters relative to the Evolution Strategies (ES) algorithm\nintroduced by Salimans et al. (2017). We do not need heuristics such as fitness\nshaping to learn good quality policies, resulting in a simple and theoretically\nmotivated training mechanism.\n"]},
{"authors": ["Brendan Duke", "Graham W. Taylor"], "title": ["Generalized Hadamard-Product Fusion Operators for Visual Question\n  Answering"], "date": ["2018-03-26T00:30:34Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09374v2"], "summary": ["  We propose a generalized class of multimodal fusion operators for the task of\nvisual question answering (VQA). We identify generalizations of existing\nmultimodal fusion operators based on the Hadamard product, and show that\nspecific non-trivial instantiations of this generalized fusion operator exhibit\nsuperior performance in terms of OpenEnded accuracy on the VQA task. In\nparticular, we introduce Nonlinearity Ensembling, Feature Gating, and\npost-fusion neural network layers as fusion operator components, culminating in\nan absolute percentage point improvement of $1.1\\%$ on the VQA 2.0 test-dev set\nover baseline fusion operators, which use the same features as input. We use\nour findings as evidence that our generalized class of fusion operators could\nlead to the discovery of even superior task-specific operators when used as a\nsearch space in an architecture search over fusion operators.\n"]},
{"authors": ["Konstantin Eckle", "Johannes Schmidt-Hieber"], "title": ["A comparison of deep networks with ReLU activation function and linear\n  spline-type methods"], "date": ["2018-04-06T13:28:15Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02253v1"], "summary": ["  Deep neural networks (DNNs) generate much richer function spaces than shallow\nnetworks. Since the function spaces induced by shallow networks have several\napproximation theoretic drawbacks, this explains, however, not necessarily the\nsuccess of deep networks. In this article we take another route by comparing\nthe expressive power of DNNs with ReLU activation function to piecewise linear\nspline methods. We show that MARS (multivariate adaptive regression splines) is\nimproper learnable by DNNs in the sense that for any given function that can be\nexpressed as a function in MARS with $M$ parameters there exists a multilayer\nneural network with $O(M \\log (M/\\varepsilon))$ parameters that approximates\nthis function up to sup-norm error $\\varepsilon.$ We show a similar result for\nexpansions with respect to the Faber-Schauder system. Based on this, we derive\nrisk comparison inequalities that bound the statistical risk of fitting a\nneural network by the statistical risk of spline-based methods. This shows that\ndeep networks perform better or only slightly worse than the considered spline\nmethods. We provide a constructive proof for the function approximations.\n"]},
{"authors": ["Mehmet Tan", "Ozan F\u0131rat \u00d6zg\u00fcl", "Batuhan Bardak", "I\u015f\u0131ksu Ek\u015fio\u011flu", "Suna Sabuncuo\u011flu"], "title": ["Drug response prediction by ensemble learning and drug-induced gene\n  expression signatures"], "date": ["2018-02-11T19:34:10Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.03800v2"], "summary": ["  Chemotherapeutic response of cancer cells to a given compound is one of the\nmost fundamental information one requires to design anti-cancer drugs. Recent\nadvances in producing large drug screens against cancer cell lines provided an\nopportunity to apply machine learning methods for this purpose. In addition to\ncytotoxicity databases, considerable amount of drug-induced gene expression\ndata has also become publicly available. Following this, several methods that\nexploit omics data were proposed to predict drug activity on cancer cells.\nHowever, due to the complexity of cancer drug mechanisms, none of the existing\nmethods are perfect. One possible direction, therefore, is to combine the\nstrengths of both the methods and the databases for improved performance. We\ndemonstrate that integrating a large number of predictions by the proposed\nmethod improves the performance for this task. The predictors in the ensemble\ndiffer in several aspects such as the method itself, the number of tasks method\nconsiders (multi-task vs. single-task) and the subset of data considered\n(sub-sampling). We show that all these different aspects contribute to the\nsuccess of the final ensemble. In addition, we attempt to use the drug screen\ndata together with two novel signatures produced from the drug-induced gene\nexpression profiles of cancer cell lines. Finally, we evaluate the method\npredictions by in vitro experiments in addition to the tests on data sets.The\npredictions of the methods, the signatures and the software are available from\n\\url{http://mtan.etu.edu.tr/drug-response-prediction/}.\n"]},
{"authors": ["Peilin Zhao", "Yifan Zhang", "Min Wu", "Steven C. H. Hoi", "Mingkui Tan", "Junzhou Huang"], "title": ["Adaptive Cost-sensitive Online Classification"], "date": ["2018-04-06T13:09:55Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02246v1"], "summary": ["  Cost-Sensitive Online Classification has drawn extensive attention in recent\nyears, where the main approach is to directly online optimize two well-known\ncost-sensitive metrics: (i) weighted sum of sensitivity and specificity; (ii)\nweighted misclassification cost. However, previous existing methods only\nconsidered first-order information of data stream. It is insufficient in\npractice, since many recent studies have proved that incorporating second-order\ninformation enhances the prediction performance of classification models. Thus,\nwe propose a family of cost-sensitive online classification algorithms with\nadaptive regularization in this paper. We theoretically analyze the proposed\nalgorithms and empirically validate their effectiveness and properties in\nextensive experiments. Then, for better trade off between the performance and\nefficiency, we further introduce the sketching technique into our algorithms,\nwhich significantly accelerates the computational speed with quite slight\nperformance loss. Finally, we apply our algorithms to tackle several online\nanomaly detection tasks from real world. Promising results prove that the\nproposed algorithms are effective and efficient in solving cost-sensitive\nonline classification problems in various real-world domains.\n"]},
{"authors": ["Adnan Haider", "Philip C. Woodland"], "title": ["Sequence Training of DNN Acoustic Models With Natural Gradient"], "date": ["2018-04-06T11:05:53Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02204v1"], "summary": ["  Deep Neural Network (DNN) acoustic models often use discriminative sequence\ntraining that optimises an objective function that better approximates the word\nerror rate (WER) than frame-based training. Sequence training is normally\nimplemented using Stochastic Gradient Descent (SGD) or Hessian Free (HF)\ntraining. This paper proposes an alternative batch style optimisation framework\nthat employs a Natural Gradient (NG) approach to traverse through the parameter\nspace. By correcting the gradient according to the local curvature of the\nKL-divergence, the NG optimisation process converges more quickly than HF.\nFurthermore, the proposed NG approach can be applied to any sequence\ndiscriminative training criterion. The efficacy of the NG method is shown using\nexperiments on a Multi-Genre Broadcast (MGB) transcription task that\ndemonstrates both the computational efficiency and the accuracy of the\nresulting DNN models.\n"]},
{"authors": ["Yaxing Wang", "Joost van de Weijer", "Luis Herranz"], "title": ["Mix and match networks: encoder-decoder alignment for zero-pair image\n  translation"], "date": ["2018-04-06T10:53:07Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02199v1"], "summary": ["  We address the problem of image translation between domains or modalities for\nwhich no direct paired data is available (i.e. zero-pair translation). We\npropose mix and match networks, based on multiple encoders and decoders aligned\nin such a way that other encoder-decoder pairs can be composed at test time to\nperform unseen image translation tasks between domains or modalities for which\nexplicit paired samples were not seen during training. We study the impact of\nautoencoders, side information and losses in improving the alignment and\ntransferability of trained pairwise translation models to unseen translations.\nWe show our approach is scalable and can perform colorization and style\ntransfer between unseen combinations of domains. We evaluate our system in a\nchallenging cross-modal setting where semantic segmentation is estimated from\ndepth images, without explicit access to any depth-semantic segmentation\ntraining pairs. Our model outperforms baselines based on pix2pix and CycleGAN\nmodels.\n"]},
{"authors": ["Joachim Giesen", "S\u00f6ren Laue"], "title": ["Distributed Convex Optimization with Many Convex Constraints"], "date": ["2016-10-07T12:59:46Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1610.02967v2"], "summary": ["  We address the problem of solving convex optimization problems with many\nconvex constraints in a distributed setting. Our approach is based on an\nextension of the alternating direction method of multipliers (ADMM) that\nrecently gained a lot of attention in the Big Data context. Although it has\nbeen invented decades ago, ADMM so far can be applied only to unconstrained\nproblems and problems with linear equality or inequality constraints. Our\nextension can handle arbitrary inequality constraints directly. It combines the\nability of ADMM to solve convex optimization problems in a distributed setting\nwith the ability of the Augmented Lagrangian method to solve constrained\noptimization problems, and as we show, it inherits the convergence guarantees\nof ADMM and the Augmented Lagrangian method.\n"]},
{"authors": ["I\u00f1igo Casanueva", "Pawe\u0142 Budzianowski", "Pei-Hao Su", "Nikola Mrk\u0161i\u0107", "Tsung-Hsien Wen", "Stefan Ultes", "Lina Rojas-Barahona", "Steve Young", "Milica Ga\u0161i\u0107"], "title": ["A Benchmarking Environment for Reinforcement Learning Based Task\n  Oriented Dialogue Management"], "date": ["2017-11-29T18:51:14Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.11023v2"], "summary": ["  Dialogue assistants are rapidly becoming an indispensable daily aid. To avoid\nthe significant effort needed to hand-craft the required dialogue flow, the\nDialogue Management (DM) module can be cast as a continuous Markov Decision\nProcess (MDP) and trained through Reinforcement Learning (RL). Several RL\nmodels have been investigated over recent years. However, the lack of a common\nbenchmarking framework makes it difficult to perform a fair comparison between\ndifferent models and their capability to generalise to different environments.\nTherefore, this paper proposes a set of challenging simulated environments for\ndialogue model development and evaluation. To provide some baselines, we\ninvestigate a number of representative parametric algorithms, namely deep\nreinforcement learning algorithms - DQN, A2C and Natural Actor-Critic and\ncompare them to a non-parametric model, GP-SARSA. Both the environments and\npolicy models are implemented using the publicly available PyDial toolkit and\nreleased on-line, in order to establish a testbed framework for further\nexperiments and to facilitate experimental reproducibility.\n"]},
{"authors": ["Keisuke Oyamada", "Hirokazu Kameoka", "Takuhiro Kaneko", "Kou Tanaka", "Nobukatsu Hojo", "Hiroyasu Ando"], "title": ["Generative adversarial network-based approach to signal reconstruction\n  from magnitude spectrograms"], "date": ["2018-04-06T09:42:59Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02181v1"], "summary": ["  In this paper, we address the problem of reconstructing a time-domain signal\n(or a phase spectrogram) solely from a magnitude spectrogram. Since magnitude\nspectrograms do not contain phase information, we must restore or infer phase\ninformation to reconstruct a time-domain signal. One widely used approach for\ndealing with the signal reconstruction problem was proposed by Griffin and Lim.\nThis method usually requires many iterations for the signal reconstruction\nprocess and depending on the inputs, it does not always produce high-quality\naudio signals. To overcome these shortcomings, we apply a learning-based\napproach to the signal reconstruction problem by modeling the signal\nreconstruction process using a deep neural network and training it using the\nidea of a generative adversarial network. Experimental evaluations revealed\nthat our method was able to reconstruct signals faster with higher quality than\nthe Griffin-Lim method.\n"]},
{"authors": ["Daniel Krefl", "Stefano Carrazza", "Babak Haghighat", "Jens Kahlen"], "title": ["Riemann-Theta Boltzmann Machine"], "date": ["2017-12-20T17:01:42Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1712.07581v2"], "summary": ["  A general Boltzmann machine with continuous visible and discrete integer\nvalued hidden states is introduced. Under mild assumptions about the connection\nmatrices, the probability density function of the visible units can be solved\nfor analytically, yielding a novel parametric density function involving a\nratio of Riemann-Theta functions. The conditional expectation of a hidden state\nfor given visible states can also be calculated analytically, yielding a\nderivative of the logarithmic Riemann-Theta function. The conditional\nexpectation can be used as activation function in a feedforward neural network,\nthereby increasing the modelling capacity of the network. Both the Boltzmann\nmachine and the derived feedforward neural network can be successfully trained\nvia standard gradient- and non-gradient-based optimization techniques.\n"]},
{"authors": ["Ignasi Clavera", "Anusha Nagabandi", "Ronald S. Fearing", "Pieter Abbeel", "Sergey Levine", "Chelsea Finn"], "title": ["Learning to Adapt: Meta-Learning for Model-Based Control"], "date": ["2018-03-30T05:47:11Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.11347v2"], "summary": ["  Although reinforcement learning methods can achieve impressive results in\nsimulation, the real world presents two major challenges: generating samples is\nexceedingly expensive, and unexpected perturbations can cause proficient but\nnarrowly-learned policies to fail at test time. In this work, we propose to\nlearn how to quickly and effectively adapt online to new situations as well as\nto perturbations. To enable sample-efficient meta-learning, we consider\nlearning online adaptation in the context of model-based reinforcement\nlearning. Our approach trains a global model such that, when combined with\nrecent data, the model can be be rapidly adapted to the local context. Our\nexperiments demonstrate that our approach can enable simulated agents to adapt\ntheir behavior online to novel terrains, to a crippled leg, and in\nhighly-dynamic environments.\n"]},
{"authors": ["Yonghong Tian", "Zeyu Li", "Zhiwei Xu", "Xuying Meng", "Bing Zheng"], "title": ["Peeking the Impact of Points of Interests on Didi"], "date": ["2018-04-06T02:07:03Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04176v1"], "summary": ["  Recently, the online car-hailing service, Didi, has emerged as a leader in\nthe sharing economy. Used by passengers and drivers extensive, it becomes\nincreasingly important for the car-hailing service providers to minimize the\nwaiting time of passengers and optimize the vehicle utilization, thus to\nimprove the overall user experience. Therefore, the supply-demand estimation is\nan indispensable ingredient of an efficient online car-hailing service. To\nimprove the accuracy of the estimation results, we analyze the implicit\nrelationships between the points of Interest (POI) and the supply-demand gap in\nthis paper. The different categories of POIs have positive or negative effects\non the estimation, we propose a POI selection scheme and incorporate it into\nXGBoost [1] to achieve more accurate estimation results. Our experiment\ndemonstrates our method provides more accurate estimation results and more\nstable estimation results than the existing methods.\n"]},
{"authors": ["Luwan Zhang", "Katherine Liao", "Issac Kohane", "Tianxi Cai"], "title": ["Multi-view Banded Spectral Clustering with application to ICD9\n  clustering"], "date": ["2018-04-06T01:02:25Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02097v1"], "summary": ["  Despite recent development in methodology, community detection remains a\nchallenging problem. Existing literature largely focuses on the standard\nsetting where a network is learned using an observed adjacency matrix from a\nsingle data source. Constructing a shared network from multiple data sources is\nmore challenging due to the heterogeneity across populations. Additionally,\nwhen a natural ordering on the nodes of interest arises, no existing method\ntakes such information into account. Motivated by grouping the International\nclassification of diseases, ninth revision, (ICD9) codes to represent\nclinically meaningful phenotypes, we propose a novel spectral clustering method\nthat optimally combines multiple data sources while leveraging the prior\nordering knowledge. The proposed method combines a banding step to encourage a\ndesired moving average structure with a subsequent weighting step to maximize\nconsensus across multiple sources. Its statistical performance is thoroughly\nstudied under a multi-view stochastic block model. We also provide a simple\nrule of choosing weights in practice. The efficacy and robustness of the method\nis fully demonstrated through extensive simulations. Finally, we apply the\nmethod to the ICD9 coding system and yield a very insightful clustering\nstructure by integrating information from a large claim database and two\nhealthcare systems.\n"]},
{"authors": ["Dimitris Berberidis", "Athanasios N. Nikolakopoulos", "Georgios B. Giannakis"], "title": ["Adaptive Diffusions for Scalable Learning over Graphs"], "date": ["2018-04-05T23:41:11Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02081v1"], "summary": ["  Diffusion-based classifiers such as those relying on the Personalized\nPageRank and the Heat kernel, enjoy remarkable classification accuracy at\nmodest computational requirements. Their performance however is affected by the\nextent to which the chosen diffusion captures a typically unknown label\npropagation mechanism, that can be specific to the underlying graph, and\npotentially different for each class. The present work introduces a\ndisciplined, data-efficient approach to learning class-specific diffusion\nfunctions adapted to the underlying network topology. The novel learning\napproach leverages the notion of \"landing probabilities\" of class-specific\nrandom walks, which can be computed efficiently, thereby ensuring scalability\nto large graphs. This is supported by rigorous analysis of the properties of\nthe model as well as the proposed algorithms. Furthermore, a robust version of\nthe classifier facilitates learning even in noisy environments.\n  Classification tests on real networks demonstrate that adapting the diffusion\nfunction to the given graph and observed labels, significantly improves the\nperformance over fixed diffusions; reaching -- and many times surpassing -- the\nclassification accuracy of computationally heavier state-of-the-art competing\nmethods, that rely on node embeddings and deep neural networks.\n"]},
{"authors": ["Rizwan Sadiq", "Mohsin Khan"], "title": ["Analyzing Self-Driving Cars on Twitter"], "date": ["2018-04-05T23:31:44Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04058v1"], "summary": ["  This paper studies users' perception regarding a controversial product,\nnamely self-driving (autonomous) cars. To find people's opinion regarding this\nnew technology, we used an annotated Twitter dataset, and extracted the topics\nin positive and negative tweets using an unsupervised, probabilistic model\nknown as topic modeling. We later used the topics, as well as linguist and\nTwitter specific features to classify the sentiment of the tweets. Regarding\nthe opinions, the result of our analysis shows that people are optimistic and\nexcited about the future technology, but at the same time they find it\ndangerous and not reliable. For the classification task, we found Twitter\nspecific features, such as hashtags as well as linguistic features such as\nemphatic words among top attributes in classifying the sentiment of the tweets.\n"]},
{"authors": ["Xi Ouyang", "Yu Cheng", "Yifan Jiang", "Chun-Liang Li", "Pan Zhou"], "title": ["Pedestrian-Synthesis-GAN: Generating Pedestrian Data in Real Scene and\n  Beyond"], "date": ["2018-04-05T20:22:01Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02047v1"], "summary": ["  State-of-the-art pedestrian detection models have achieved great success in\nmany benchmarks. However, these models require lots of annotation information\nand the labeling process usually takes much time and efforts. In this paper, we\npropose a method to generate labeled pedestrian data and adapt them to support\nthe training of pedestrian detectors. The proposed framework is built on the\nGenerative Adversarial Network (GAN) with multiple discriminators, trying to\nsynthesize realistic pedestrians and learn the background context\nsimultaneously. To handle the pedestrians of different sizes, we adopt the\nSpatial Pyramid Pooling (SPP) layer in the discriminator. We conduct\nexperiments on two benchmarks. The results show that our framework can smoothly\nsynthesize pedestrians on background images of variations and different levels\nof details. To quantitatively evaluate our approach, we add the generated\nsamples into training data of the baseline pedestrian detectors and show the\nsynthetic images are able to improve the detectors' performance.\n"]},
{"authors": ["Francesco Musumeci", "Cristina Rottondi", "Avishek Nag", "Irene Macaluso", "Darko Zibar", "Marco Ruffini", "Massimo Tornatore"], "title": ["A Survey on Application of Machine Learning Techniques in Optical\n  Networks"], "date": ["2018-03-21T15:58:36Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07976v2"], "summary": ["  Today, the amount of data that can be retrieved from communications networks\nis extremely high and diverse (e.g., data regarding users behavior, traffic\ntraces, network alarms, signal quality indicators, etc.). Advanced mathematical\ntools are required to extract useful information from this large set of network\ndata. In particular, Machine Learning (ML) is regarded as a promising\nmethodological area to perform network-data analysis and enable, e.g.,\nautomatized network self-configuration and fault management. In this survey we\nclassify and describe relevant studies dealing with the applications of ML to\noptical communications and networking. Optical networks and system are facing\nan unprecedented growth in terms of complexity due to the introduction of a\nhuge number of adjustable parameters (such as routing configurations,\nmodulation format, symbol rate, coding schemes, etc.), mainly due to the\nadoption of, among the others, coherent transmission/reception technology,\nadvanced digital signal processing and to the presence of nonlinear effects in\noptical fiber systems. Although a good number of research papers have appeared\nin the last years, the application of ML to optical networks is still in its\nearly stage. In this survey we provide an introductory reference for\nresearchers and practitioners interested in this field. To stimulate further\nwork in this area, we conclude the paper proposing new possible research\ndirections.\n"]},
{"authors": ["Cheng Ju", "Antoine Chambaz", "Mark J. van der Laan"], "title": ["Collaborative targeted inference from continuously indexed nuisance\n  parameter estimators"], "date": ["2018-03-31T01:30:36Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00102v2"], "summary": ["  We wish to infer the value of a parameter at a law from which we sample\nindependent observations. The parameter is smooth and we can define two\nvariation-independent features of the law, its $Q$- and $G$-components, such\nthat estimating them consistently at a fast enough product of rates allows to\nbuild a confidence interval (CI) with a given asymptotic level from a plain\ntargeted minimum loss estimator (TMLE). Say that the above product is not fast\nenough and the algorithm for the $G$-component is fine-tuned by a real-valued\n$h$. A plain TMLE with an $h$ chosen by cross-validation would typically not\nyield a CI. We construct a collaborative TMLE (C-TMLE) and show under mild\nconditions that, if there exists an oracle $h$ that makes a bulky remainder\nterm asymptotically Gaussian, then the C-TMLE yields a CI. We illustrate our\nfindings with the inference of the average treatment effect. We conduct a\nsimulation study where the $G$-component is estimated by the LASSO and $h$ is\nthe bound on the coefficients' norms. It sheds light on small sample\nproperties, in the face of low- to high-dimensional baseline covariates, and\npossibly positivity violation.\n"]},
{"authors": ["Sina Dabiri", "Kevin Heaslip"], "title": ["Inferring transportation modes from GPS trajectories using a\n  convolutional neural network"], "date": ["2018-04-05T18:26:12Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02386v1"], "summary": ["  Identifying the distribution of users' transportation modes is an essential\npart of travel demand analysis and transportation planning. With the advent of\nubiquitous GPS-enabled devices (e.g., a smartphone), a cost-effective approach\nfor inferring commuters' mobility mode(s) is to leverage their GPS\ntrajectories. A majority of studies have proposed mode inference models based\non hand-crafted features and traditional machine learning algorithms. However,\nmanual features engender some major drawbacks including vulnerability to\ntraffic and environmental conditions as well as possessing human's bias in\ncreating efficient features. One way to overcome these issues is by utilizing\nConvolutional Neural Network (CNN) schemes that are capable of automatically\ndriving high-level features from the raw input. Accordingly, in this paper, we\ntake advantage of CNN architectures so as to predict travel modes based on only\nraw GPS trajectories, where the modes are labeled as walk, bike, bus, driving,\nand train. Our key contribution is designing the layout of the CNN's input\nlayer in such a way that not only is adaptable with the CNN schemes but\nrepresents fundamental motion characteristics of a moving object including\nspeed, acceleration, jerk, and bearing rate. Furthermore, we ameliorate the\nquality of GPS logs through several data preprocessing steps. Using the clean\ninput layer, a variety of CNN configurations are evaluated to achieve the best\nCNN architecture. The highest accuracy of 84.8% has been achieved through the\nensemble of the best CNN configuration. In this research, we contrast our\nmethodology with traditional machine learning algorithms as well as the seminal\nand most related studies to demonstrate the superiority of our framework.\n"]},
{"authors": ["Susan Athey", "Julie Tibshirani", "Stefan Wager"], "title": ["Generalized Random Forests"], "date": ["2016-10-05T04:42:13Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1610.01271v4"], "summary": ["  We propose generalized random forests, a method for non-parametric\nstatistical estimation based on random forests (Breiman, 2001) that can be used\nto fit any quantity of interest identified as the solution to a set of local\nmoment equations. Following the literature on local maximum likelihood\nestimation, our method considers a weighted set of nearby training examples;\nhowever, instead of using classical kernel weighting functions that are prone\nto a strong curse of dimensionality, we use an adaptive weighting function\nderived from a forest designed to express heterogeneity in the specified\nquantity of interest. We propose a flexible, computationally efficient\nalgorithm for growing generalized random forests, develop a large sample theory\nfor our method showing that our estimates are consistent and asymptotically\nGaussian, and provide an estimator for their asymptotic variance that enables\nvalid confidence intervals. We use our approach to develop new methods for\nthree statistical tasks: non-parametric quantile regression, conditional\naverage partial effect estimation, and heterogeneous treatment effect\nestimation via instrumental variables. A software implementation, grf for R and\nC++, is available from CRAN.\n"]},
{"authors": ["Emmanuel Dufourq", "Bruce A. Bassett"], "title": ["Automated Classification of Text Sentiment"], "date": ["2018-04-05T17:21:48Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01963v1"], "summary": ["  The ability to identify sentiment in text, referred to as sentiment analysis,\nis one which is natural to adult humans. This task is, however, not one which a\ncomputer can perform by default. Identifying sentiments in an automated,\nalgorithmic manner will be a useful capability for business and research in\ntheir search to understand what consumers think about their products or\nservices and to understand human sociology. Here we propose two new Genetic\nAlgorithms (GAs) for the task of automated text sentiment analysis. The GAs\nlearn whether words occurring in a text corpus are either sentiment or\namplifier words, and their corresponding magnitude. Sentiment words, such as\n'horrible', add linearly to the final sentiment. Amplifier words in contrast,\nwhich are typically adjectives/adverbs like 'very', multiply the sentiment of\nthe following word. This increases, decreases or negates the sentiment of the\nfollowing word. The sentiment of the full text is then the sum of these terms.\nThis approach grows both a sentiment and amplifier dictionary which can be\nreused for other purposes and fed into other machine learning algorithms. We\nreport the results of multiple experiments conducted on large Amazon data sets.\nThe results reveal that our proposed approach was able to outperform several\npublic and/or commercial sentiment analysis algorithms.\n"]},
{"authors": ["Mateusz Staniak", "Przemyslaw Biecek"], "title": ["Explanations of model predictions with live and breakDown packages"], "date": ["2018-04-05T17:05:15Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01955v1"], "summary": ["  Complex models are commonly used in predictive modeling. In this paper we\npresent R packages that can be used to explain predictions from complex black\nbox models and attribute parts of these predictions to input features. We\nintroduce two new approaches and corresponding packages for such attribution,\nnamely live and breakDown. We also compare their results with existing\nimplementations of state of the art solutions, namely lime that implements\nLocally Interpretable Model-agnostic Explanations and ShapleyR that implements\nShapley values.\n"]},
{"authors": ["Soheil Kolouri", "Charles E. Martin", "Gustavo K. Rohde"], "title": ["Sliced-Wasserstein Autoencoder: An Embarrassingly Simple Generative\n  Model"], "date": ["2018-04-05T16:45:06Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01947v1"], "summary": ["  In this paper we study generative modeling via autoencoders while using the\nelegant geometric properties of the optimal transport (OT) problem and the\nWasserstein distances. We introduce Sliced-Wasserstein Autoencoders (SWAE),\nwhich are generative models that enable one to shape the distribution of the\nlatent space into any samplable probability distribution without the need for\ntraining an adversarial network or defining a closed-form for the distribution.\nIn short, we regularize the autoencoder loss with the sliced-Wasserstein\ndistance between the distribution of the encoded training samples and a\npredefined samplable distribution. We show that the proposed formulation has an\nefficient numerical solution that provides similar capabilities to Wasserstein\nAutoencoders (WAE) and Variational Autoencoders (VAE), while benefiting from an\nembarrassingly simple implementation.\n"]},
{"authors": ["Manon Kok", "Arno Solin"], "title": ["Scalable Magnetic Field SLAM in 3D Using Gaussian Process Maps"], "date": ["2018-04-05T16:02:38Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01926v1"], "summary": ["  We present a method for scalable and fully 3D magnetic field simultaneous\nlocalisation and mapping (SLAM) using local anomalies in the magnetic field as\na source of position information. These anomalies are due to the presence of\nferromagnetic material in the structure of buildings and in objects such as\nfurniture. We represent the magnetic field map using a Gaussian process model\nand take well-known physical properties of the magnetic field into account. We\nbuild local magnetic field maps using three-dimensional hexagonal block tiling.\nTo make our approach computationally tractable we use reduced-rank Gaussian\nprocess regression in combination with a Rao--Blackwellised particle filter. We\nshow that it is possible to obtain accurate position and orientation estimates\nusing measurements from a smartphone, and that our approach provides a scalable\nmagnetic SLAM algorithm in terms of both computational complexity and map\nstorage.\n"]},
{"authors": ["Baida Hamdan", "Davood Zabihzadeh", "Monsefi Reza"], "title": ["Large Scale Local Online Similarity/Distance Learning Framework based on\n  Passive/Aggressive"], "date": ["2018-04-05T15:11:11Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01900v1"], "summary": ["  Similarity/Distance measures play a key role in many machine learning,\npattern recognition, and data mining algorithms, which leads to the emergence\nof metric learning field. Many metric learning algorithms learn a global\ndistance function from data that satisfy the constraints of the problem.\nHowever, in many real-world datasets that the discrimination power of features\nvaries in the different regions of input space, a global metric is often unable\nto capture the complexity of the task. To address this challenge, local metric\nlearning methods are proposed that learn multiple metrics across the different\nregions of input space. Some advantages of these methods are high flexibility\nand the ability to learn a nonlinear mapping but typically achieves at the\nexpense of higher time requirement and overfitting problem. To overcome these\nchallenges, this research presents an online multiple metric learning\nframework. Each metric in the proposed framework is composed of a global and a\nlocal component learned simultaneously. Adding a global component to a local\nmetric efficiently reduce the problem of overfitting. The proposed framework is\nalso scalable with both sample size and the dimension of input data. To the\nbest of our knowledge, this is the first local online similarity/distance\nlearning framework based on PA (Passive/Aggressive). In addition, for\nscalability with the dimension of input data, DRP (Dual Random Projection) is\nextended for local online learning in the present work. It enables our methods\nto be run efficiently on high-dimensional datasets, while maintains their\npredictive performance. The proposed framework provides a straightforward local\nextension to any global online similarity/distance learning algorithm based on\nPA.\n"]},
{"authors": ["Dmitry Ulyanov", "Andrea Vedaldi", "Victor Lempitsky"], "title": ["Deep Image Prior"], "date": ["2017-11-29T15:50:05Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.10925v3"], "summary": ["  Deep convolutional networks have become a popular tool for image generation\nand restoration. Generally, their excellent performance is imputed to their\nability to learn realistic image priors from a large number of example images.\nIn this paper, we show that, on the contrary, the structure of a generator\nnetwork is sufficient to capture a great deal of low-level image statistics\nprior to any learning. In order to do so, we show that a randomly-initialized\nneural network can be used as a handcrafted prior with excellent results in\nstandard inverse problems such as denoising, super-resolution, and inpainting.\nFurthermore, the same prior can be used to invert deep neural representations\nto diagnose them, and to restore images based on flash-no flash input pairs.\n  Apart from its diverse applications, our approach highlights the inductive\nbias captured by standard generator network architectures. It also bridges the\ngap between two very popular families of image restoration methods:\nlearning-based methods using deep convolutional networks and learning-free\nmethods based on handcrafted image priors such as self-similarity. Code and\nsupplementary material are available at\nhttps://dmitryulyanov.github.io/deep_image_prior .\n"]},
{"authors": ["Ngoc Duy Nguyen", "Saeid Nahavandi", "Thanh Nguyen"], "title": ["A Human Mixed Strategy Approach to Deep Reinforcement Learning"], "date": ["2018-04-05T14:24:42Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01874v1"], "summary": ["  In 2015, Google's DeepMind announced an advancement in creating an autonomous\nagent based on deep reinforcement learning (DRL) that could beat a professional\nplayer in a series of 49 Atari games. However, the current manifestation of DRL\nis still immature, and has significant drawbacks. One of DRL's imperfections is\nits lack of \"exploration\" during the training process, especially when working\nwith high-dimensional problems. In this paper, we propose a mixed strategy\napproach that mimics behaviors of human when interacting with environment, and\ncreate a \"thinking\" agent that allows for more efficient exploration in the DRL\ntraining process. The simulation results based on the Breakout game show that\nour scheme achieves a higher probability of obtaining a maximum score than does\nthe baseline DRL algorithm, i.e., the asynchronous advantage actor-critic\nmethod. The proposed scheme therefore can be applied effectively to solving a\ncomplicated task in a real-world application.\n"]},
{"authors": ["Filip Korzeniowski", "David R. W. Sears", "Gerhard Widmer"], "title": ["A Large-Scale Study of Language Models for Chord Prediction"], "date": ["2018-04-05T13:51:10Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01849v1"], "summary": ["  We conduct a large-scale study of language models for chord prediction.\nSpecifically, we compare N-gram models to various flavours of recurrent neural\nnetworks on a comprehensive dataset comprising all publicly available datasets\nof annotated chords known to us. This large amount of data allows us to\nsystematically explore hyper-parameter settings for the recurrent neural\nnetworks---a crucial step in achieving good results with this model class. Our\nresults show not only a quantitative difference between the models, but also a\nqualitative one: in contrast to static N-gram models, certain RNN\nconfigurations adapt to the songs at test time. This finding constitutes a\nfurther step towards the development of chord recognition systems that are more\naware of local musical context than what was previously possible.\n"]},
{"authors": ["Gilles Louppe", "Kyle Cranmer"], "title": ["Adversarial Variational Optimization of Non-Differentiable Simulators"], "date": ["2017-07-22T07:05:38Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1707.07113v3"], "summary": ["  Complex computer simulators are increasingly used across fields of science as\ngenerative models tying parameters of an underlying theory to experimental\nobservations. Inference in this setup is often difficult, as simulators rarely\nadmit a tractable density or likelihood function. We introduce Adversarial\nVariational Optimization (AVO), a likelihood-free inference algorithm for\nfitting a non-differentiable generative model incorporating ideas from\ngenerative adversarial networks, variational optimization and empirical Bayes.\nWe adapt the training procedure of Wasserstein GANs by replacing the\ndifferentiable generative network with a domain-specific simulator. We solve\nthe resulting non-differentiable minimax problem by minimizing variational\nupper bounds of the two adversarial objectives. Effectively, the procedure\nresults in learning a proposal distribution over simulator parameters, such\nthat the Wasserstein distance between the marginal distribution of the\nsynthetic data and the empirical distribution of observed data is minimized. We\npresent results of the method with simulators producing both discrete and\ncontinuous data.\n"]},
{"authors": ["Yan Wu", "Greg Wayne", "Alex Graves", "Timothy Lillicrap"], "title": ["The Kanerva Machine: A Generative Distributed Memory"], "date": ["2018-04-05T10:07:05Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01756v1"], "summary": ["  We present an end-to-end trained memory system that quickly adapts to new\ndata and generates samples like them. Inspired by Kanerva's sparse distributed\nmemory, it has a robust distributed reading and writing mechanism. The memory\nis analytically tractable, which enables optimal on-line compression via a\nBayesian update-rule. We formulate it as a hierarchical conditional generative\nmodel, where memory provides a rich data-dependent prior distribution.\nConsequently, the top-down memory and bottom-up perception are combined to\nproduce the code representing an observation. Empirically, we demonstrate that\nthe adaptive memory significantly improves generative models trained on both\nthe Omniglot and CIFAR datasets. Compared with the Differentiable Neural\nComputer (DNC) and its variants, our memory model has greater capacity and is\nsignificantly easier to train.\n"]},
{"authors": ["Yu Nishiyama", "Motonobu Kanagawa", "Arthur Gretton", "Kenji Fukumizu"], "title": ["Model-based Kernel Sum Rule: Kernel Bayesian Inference with\n  Probabilistic Models"], "date": ["2014-09-18T02:14:00Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1409.5178v2"], "summary": ["  Kernel Bayesian inference is a powerful nonparametric approach to performing\nBayesian inference in reproducing kernel Hilbert spaces or feature spaces. In\nthis approach, kernel means are estimated instead of probability distributions,\nand these estimates can be used for subsequent probabilistic operations (as for\ninference in graphical models) or in computing the expectations of smooth\nfunctions, for instance. Various algorithms for kernel Bayesian inference have\nbeen obtained by combining basic rules such as the kernel sum rule (KSR),\nkernel chain rule, kernel product rule and kernel Bayes' rule. However, the\ncurrent framework only deals with fully nonparametric inference (i.e., all\nconditional relations are learned nonparametrically), and it does not allow for\nflexible combinations of nonparametric and parametric inference, which are\npractically important. Our contribution is in providing a novel technique to\nrealize such combinations. We introduce a new KSR referred to as the\nmodel-based KSR (Mb-KSR), which employs the sum rule in feature spaces under a\nparametric setting. Incorporating the Mb-KSR into existing kernel Bayesian\nframework provides a richer framework for hybrid (nonparametric and parametric)\nkernel Bayesian inference. As a practical application, we propose a novel\nfiltering algorithm for state space models based on the Mb-KSR, which combines\nthe nonparametric learning of an observation process using kernel mean\nembedding and the additive Gaussian noise model for a state transition process.\nWhile we focus on additive Gaussian noise models in this study, the idea can be\nextended to other noise models, such as the Cauchy and alpha-stable noise\nmodels.\n"]},
{"authors": ["Tuan Anh Le", "Maximilian Igl", "Tom Rainforth", "Tom Jin", "Frank Wood"], "title": ["Auto-Encoding Sequential Monte Carlo"], "date": ["2017-05-29T17:54:11Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1705.10306v2"], "summary": ["  We build on auto-encoding sequential Monte Carlo (AESMC): a method for model\nand proposal learning based on maximizing the lower bound to the log marginal\nlikelihood in a broad family of structured probabilistic models. Our approach\nrelies on the efficiency of sequential Monte Carlo (SMC) for performing\ninference in structured probabilistic models and the flexibility of deep neural\nnetworks to model complex conditional probability distributions. We develop\nadditional theoretical insights and introduce a new training procedure which\nimproves both model and proposal learning. We demonstrate that our approach\nprovides a fast, easy-to-implement and scalable means for simultaneous model\nlearning and proposal adaptation in deep generative models.\n"]},
{"authors": ["Xiaosi Tan", "Weihong Xu", "Yair Be'ery", "Zaichen Zhang", "Xiaohu You", "Chuan Zhang"], "title": ["Improving Massive MIMO Belief Propagation Detector with Deep Neural\n  Network"], "date": ["2018-04-02T10:39:53Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01002v2"], "summary": ["  In this paper, deep neural network (DNN) is utilized to improve the belief\npropagation (BP) detection for massive multiple-input multiple-output (MIMO)\nsystems. A neural network architecture suitable for detection task is firstly\nintroduced by unfolding BP algorithms. DNN MIMO detectors are then proposed\nbased on two modified BP detectors, damped BP and max-sum BP. The correction\nfactors in these algorithms are optimized through deep learning techniques,\naiming at improved detection performance. Numerical results are presented to\ndemonstrate the performance of the DNN detectors in comparison with various BP\nmodifications. The neural network is trained once and can be used for multiple\nonline detections. The results show that, compared to other state-of-the-art\ndetectors, the DNN detectors can achieve lower bit error rate (BER) with\nimproved robustness against various antenna configurations and channel\nconditions at the same level of complexity.\n"]},
{"authors": ["Aditya Grover", "Ramki Gummadi", "Miguel Lazaro-Gredilla", "Dale Schuurmans", "Stefano Ermon"], "title": ["Variational Rejection Sampling"], "date": ["2018-04-05T07:53:41Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01712v1"], "summary": ["  Learning latent variable models with stochastic variational inference is\nchallenging when the approximate posterior is far from the true posterior, due\nto high variance in the gradient estimates. We propose a novel rejection\nsampling step that discards samples from the variational posterior which are\nassigned low likelihoods by the model. Our approach provides an arbitrarily\naccurate approximation of the true posterior at the expense of extra\ncomputation. Using a new gradient estimator for the resulting unnormalized\nproposal distribution, we achieve average improvements of 3.71 nats and 0.21\nnats over state-of-the-art single-sample and multi-sample alternatives\nrespectively for estimating marginal log-likelihoods using sigmoid belief\nnetworks on the MNIST dataset.\n"]},
{"authors": ["Francesco Locatello", "Anant Raj", "Sai Praneeth Karimireddy", "Gunnar R\u00e4tsch", "Bernhard Sch\u00f6lkopf", "Sebastian U. Stich", "Martin Jaggi"], "title": ["Revisiting First-Order Convex Optimization Over Linear Spaces"], "date": ["2018-03-26T12:15:21Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09539v2"], "summary": ["  Two popular examples of first-order optimization methods over linear spaces\nare coordinate descent and matching pursuit algorithms, with their randomized\nvariants. While the former targets the optimization by moving along\ncoordinates, the latter considers a generalized notion of directions.\nExploiting the connection between the two algorithms, we present a unified\nanalysis of both, providing affine invariant sublinear $\\mathcal{O}(1/t)$ rates\non smooth objectives and linear convergence on strongly convex objectives. As a\nbyproduct of our affine invariant analysis of matching pursuit, our rates for\nsteepest coordinate descent are the tightest known. Furthermore, we show the\nfirst accelerated convergence rate $\\mathcal{O}(1/t^2)$ for matching pursuit on\nconvex objectives.\n"]},
{"authors": ["Philippe Thomas", "Hind Bril El Haouzi", "Marie-Christine Suhner", "Andr\u00e9 Thomas", "Emmanuel Zimmermann", "M\u00e9lanie Noyel"], "title": ["Using a Classifier Ensemble for Proactive Quality Monitoring and\n  Control: the impact of the choice of classifiers types, selection criterion,\n  and fusion process"], "date": ["2018-04-05T06:46:19Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01684v1"], "summary": ["  In recent times, the manufacturing processes are faced with many external or\ninternal (the increase of customized product rescheduling , process\nreliability,..) changes. Therefore, monitoring and quality management\nactivities for these manufacturing processes are difficult. Thus, the managers\nneed more proactive approaches to deal with this variability. In this study, a\nproactive quality monitoring and control approach based on classifiers to\npredict defect occurrences and provide optimal values for factors critical to\nthe quality processes is proposed. In a previous work (Noyel et al. 2013), the\nclassification approach had been used in order to improve the quality of a\nlacquering process at a company plant; the results obtained are promising, but\nthe accuracy of the classification model used needs to be improved. One way to\nachieve this is to construct a committee of classifiers (referred to as an\nensemble) to obtain a better predictive model than its constituent models.\nHowever, the selection of the best classification methods and the construction\nof the final ensemble still poses a challenging issue. In this study, we focus\nand analyze the impact of the choice of classifier types on the accuracy of the\nclassifier ensemble; in addition, we explore the effects of the selection\ncriterion and fusion process on the ensemble accuracy as well. Several fusion\nscenarios were tested and compared based on a real-world case. Our results show\nthat using an ensemble classification leads to an increase in the accuracy of\nthe classifier models. Consequently, the monitoring and control of the\nconsidered real-world case can be improved.\n"]},
{"authors": ["Yanan Li", "Haixiang Guo", "Andrew P Paplinski"], "title": ["Semi-Supervised Classification for oil reservoir"], "date": ["2018-04-05T05:41:39Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01675v1"], "summary": ["  This paper addresses the general problem of accurate identification of oil\nreservoirs. Recent improvements in well or borehole logging technology have\nresulted in an explosive amount of data available for processing. The\ntraditional methods of analysis of the logs characteristics by experts require\nsignificant amount of time and money and is no longer practicable. In this\npaper, we use the semi-supervised learning to solve the problem of\never-increasing amount of unlabelled data available for interpretation. The\nexperts are needed to label only a small amount of the log data. The neural\nnetwork classifier is first trained with the initial labelled data. Next,\nbatches of unlabelled data are being classified and the samples with the very\nhigh class probabilities are being used in the next training session,\nbootstrapping the classifier. The process of training, classifying, enhancing\nthe labelled data is repeated iteratively until the stopping criteria are met,\nthat is, no more high probability samples are found. We make an empirical study\non the well data from Jianghan oil field and test the performance of the neural\nnetwork semi-supervised classifier. We compare this method with other\nclassifiers. The comparison results show that our neural network\nsemi-supervised classifier is superior to other classification methods.\n"]},
{"authors": ["Xuan Wang", "Yu Zhang", "Xiang Ren", "Yuhao Zhang", "Marinka Zitnik", "Jingbo Shang", "Curtis Langlotz", "Jiawei Han"], "title": ["Cross-type Biomedical Named Entity Recognition with Deep Multi-Task\n  Learning"], "date": ["2018-01-30T04:44:14Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1801.09851v2"], "summary": ["  Motivation: Biomedical named entity recognition (BioNER) is the most\nfundamental task in biomedical text mining. State-of-the-art BioNER systems\noften require handcrafted features specifically designed for each type of\nbiomedical entities. This feature generation process requires intensive labors\nfrom biomedical and linguistic experts, and makes it difficult to adapt these\nsystems to new biomedical entity types. Although recent studies explored using\nneural network models for BioNER to free experts from manual feature\ngeneration, these models still require substantial human efforts to annotate\nmassive training data.\n  Results: We propose a multi-task learning framework for BioNER that is based\non neural network models to save human efforts. We build a global model by\ncollectively training multiple models that share parameters, each model\ncapturing the characteristics of a different biomedical entity type. In\nexperiments on five BioNER benchmark datasets covering four major biomedical\nentity types, our model outperforms state-of-the-art systems and other neural\nnetwork models by a large margin, even when only limited training data are\navailable. Further analysis shows that the large performance gains come from\nsharing character- and word-level information between different biomedical\nentities. The approach creates new opportunities for text-mining approaches to\nhelp biomedical scientists better exploit knowledge in biomedical literature.\n"]},
{"authors": ["Rong Zhang", "Weiping Li", "Tong Mo"], "title": ["Review of Deep Learning"], "date": ["2018-04-05T02:23:59Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01653v1"], "summary": ["  In recent years, China, the United States and other countries, Google and\nother high-tech companies have increased investment in artificial intelligence.\nDeep learning is one of the current artificial intelligence research's key\nareas. This paper analyzes and summarizes the latest progress and future\nresearch directions of deep learning. Firstly, three basic models of deep\nlearning are outlined, including multilayer perceptrons, convolutional neural\nnetworks, and recurrent neural networks. On this basis, we further analyze the\nemerging new models of convolution neural networks and recurrent neural\nnetworks. This paper then summarizes deep learning's applications in many areas\nof artificial intelligence, including voice, computer vision, natural language\nprocessing and so on. Finally, this paper discusses the existing problems of\ndeep learning and gives the corresponding possible solutions.\n"]},
{"authors": ["Yunlong Feng", "Yiming Ying"], "title": ["Learning with Correntropy-induced Losses for Regression with Mixture of\n  Symmetric Stable Noise"], "date": ["2018-03-01T03:01:54Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.00183v3"], "summary": ["  In recent years, correntropy and its applications in machine learning have\nbeen drawing continuous attention owing to its merits in dealing with\nnon-Gaussian noise and outliers. However, theoretical understanding of\ncorrentropy, especially in the statistical learning context, is still limited.\nIn this study, within the statistical learning framework, we investigate\ncorrentropy based regression in the presence of non-Gaussian noise or outliers.\nTo this purpose, we first introduce mixture of symmetric stable noise, which\ninclude Gaussian noise, Cauchy noise, and the mixture of Gaussian noise as\nspecial cases, to model non-Gaussian noise and outliers. We demonstrate that\nunder the mixture of symmetric stable noise assumption, correntropy based\nregression can learn the conditional mean function or the conditional median\nfunction well without requiring the finite variance assumption of the noise. In\nparticular, we establish learning rates for correntropy based regression\nestimators that are asymptotically of type $\\mathcal{O}(n^{-1})$. We believe\nthat the present study completes our understanding towards correntropy based\nregression from a statistical learning viewpoint, and may also shed some light\non robust statistical learning for regression.\n"]},
{"authors": ["Eduardo Pavez", "Antonio Ortega"], "title": ["Active covariance estimation by random sub-sampling of variables"], "date": ["2018-04-04T22:49:12Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01620v1"], "summary": ["  We study covariance matrix estimation for the case of partially observed\nrandom vectors, where different samples contain different subsets of vector\ncoordinates. Each observation is the product of the variable of interest with a\n$0-1$ Bernoulli random variable. We analyze an unbiased covariance estimator\nunder this model, and derive an error bound that reveals relations between the\nsub-sampling probabilities and the entries of the covariance matrix. We apply\nour analysis in an active learning framework, where the expected number of\nobserved variables is small compared to the dimension of the vector of\ninterest, and propose a design of optimal sub-sampling probabilities and an\nactive covariance matrix estimation algorithm.\n"]},
{"authors": ["Yuansi Chen", "Chi Jin", "Bin Yu"], "title": ["Stability and Convergence Trade-off of Iterative Optimization Algorithms"], "date": ["2018-04-04T22:23:40Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01619v1"], "summary": ["  The overall performance or expected excess risk of an iterative machine\nlearning algorithm can be decomposed into training error and generalization\nerror. While the former is controlled by its convergence analysis, the latter\ncan be tightly handled by algorithmic stability. The machine learning community\nhas a rich history investigating convergence and stability separately. However,\nthe question about the trade-off between these two quantities remains open. In\nthis paper, we show that for any iterative algorithm at any iteration, the\noverall performance is lower bounded by the minimax statistical error over an\nappropriately chosen loss function class. This implies an important trade-off\nbetween convergence and stability of the algorithm -- a faster converging\nalgorithm has to be less stable, and vice versa. As a direct consequence of\nthis fundamental tradeoff, new convergence lower bounds can be derived for\nclasses of algorithms constrained with different stability bounds. In\nparticular, when the loss function is convex (or strongly convex) and smooth,\nwe discuss the stability upper bounds of gradient descent (GD) and stochastic\ngradient descent and their variants with decreasing step sizes. For Nesterov's\naccelerated gradient descent (NAG) and heavy ball method (HB), we provide\nstability upper bounds for the quadratic loss function. Applying existing\nstability upper bounds for the gradient methods in our trade-off framework, we\nobtain lower bounds matching the well-established convergence upper bounds up\nto constants for these algorithms and conjecture similar lower bounds for NAG\nand HB. Finally, we numerically demonstrate the tightness of our stability\nbounds in terms of exponents in the rate and also illustrate via a simulated\nlogistic regression problem that our stability bounds reflect the\ngeneralization errors better than the simple uniform convergence bounds for GD\nand NAG.\n"]},
{"authors": ["Artemy Kolchinsky", "Brendan D. Tracey", "David H. Wolpert"], "title": ["Nonlinear Information Bottleneck"], "date": ["2017-05-06T03:13:21Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1705.02436v5"], "summary": ["  Information bottleneck [IB] is a technique for extracting information in some\n`input' random variable that is relevant for predicting some different 'output'\nrandom variable. IB works by encoding the input in a compressed 'bottleneck\nvariable' from which the output can then be accurately decoded. IB can be\ndifficult to compute in practice, and has been mainly developed for two limited\ncases: (1) discrete random variables with small state spaces, and (2)\ncontinuous random variables that are jointly Gaussian distributed (in which\ncase the encoding and decoding maps are linear). We propose a method to perform\nIB in more general domains. Our approach can be applied to discrete or\ncontinuous inputs and outputs, and allows for nonlinear encoding and decoding\nmaps. The method uses a novel upper bound on the IB objective, derived using a\nnon-parametric estimator of mutual information and a variational approximation.\nWe show how to implement the method using neural networks and gradient-based\noptimization, and demonstrate its performance on the MNIST dataset.\n"]},
{"authors": ["Filippo Maria Bianchi", "Lorenzo Livi", "Alberto Ferrante", "Jelena Milosevic", "Miroslaw Malek"], "title": ["Time series kernel similarities for predicting Paroxysmal Atrial\n  Fibrillation from ECGs"], "date": ["2018-01-21T16:28:23Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1801.06845v2"], "summary": ["  We tackle the problem of classifying Electrocardiography (ECG) signals with\nthe aim of predicting the onset of Paroxysmal Atrial Fibrillation (PAF). Atrial\nfibrillation is the most common type of arrhythmia, but in many cases PAF\nepisodes are asymptomatic. Therefore, in order to help diagnosing PAF, it is\nimportant to design procedures for detecting and, more importantly, predicting\nPAF episodes. We propose a method for predicting PAF events whose first step\nconsists of a feature extraction procedure that represents each ECG as a\nmulti-variate time series. Successively, we design a classification framework\nbased on kernel similarities for multi-variate time series, capable of handling\nmissing data. We consider different approaches to perform classification in the\noriginal space of the multi-variate time series and in an embedding space,\ndefined by the kernel similarity measure. We achieve a classification accuracy\ncomparable with state of the art methods, with the additional advantage of\ndetecting the PAF onset up to 15 minutes in advance.\n"]},
{"authors": ["Massimo Fornasier", "Jan Vyb\u00edral", "Ingrid Daubechies"], "title": ["Identification of Shallow Neural Networks by Fewest Samples"], "date": ["2018-04-04T19:56:40Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01592v1"], "summary": ["  We address the uniform approximation of sums of ridge functions $\\sum_{i=1}^m\ng_i(a_i\\cdot x)$ on ${\\mathbb R}^d$, representing the shallowest form of\nfeed-forward neural network, from a small number of query samples, under mild\nsmoothness assumptions on the functions $g_i$'s and near-orthogonality of the\nridge directions $a_i$'s. The sample points are randomly generated and are\nuniversal, in the sense that the sampled queries on those points will allow the\nproposed recovery algorithms to perform a uniform approximation of any sum of\nridge functions with high-probability. Our general approximation strategy is\ndeveloped as a sequence of algorithms to perform individual sub-tasks. We first\napproximate the span of the ridge directions. Then we use a straightforward\nsubstitution, which reduces the dimensionality of the problem from $d$ to $m$.\nThe core of the construction is then the approximation of ridge directions\nexpressed in terms of rank-$1$ matrices $a_i \\otimes a_i$, realized by\nformulating their individual identification as a suitable nonlinear program,\nmaximizing the spectral norm of certain competitors constrained over the unit\nFrobenius sphere. The final step is then to approximate the functions\n$g_1,\\dots,g_m$ by $\\hat g_1,\\dots,\\hat g_m$. Higher order differentiation, as\nused in our construction, of sums of ridge functions or of their compositions,\nas in deeper neural network, yields a natural connection between neural network\nweight identification and tensor product decomposition identification. In the\ncase of the shallowest feed-forward neural network, we show that second order\ndifferentiation and tensors of order two (i.e., matrices) suffice.\n"]},
{"authors": ["Ramji Venkataramanan", "Oliver Johnson"], "title": ["A strong converse bound for multiple hypothesis testing, with\n  applications to high-dimensional estimation"], "date": ["2017-06-14T11:21:02Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1706.04410v3"], "summary": ["  In statistical inference problems, we wish to obtain lower bounds on the\nminimax risk, that is to bound the performance of any possible estimator. A\nstandard technique to obtain risk lower bounds involves the use of Fano's\ninequality. In an information-theoretic setting, it is known that Fano's\ninequality typically does not give a sharp converse result (error lower bound)\nfor channel coding problems. Moreover, recent work has shown that an argument\nbased on binary hypothesis testing gives tighter results. We adapt this\ntechnique to the statistical setting, and argue that Fano's inequality can\nalways be replaced by this approach to obtain tighter lower bounds that can be\neasily computed and are asymptotically sharp. We illustrate our technique in\nthree applications: density estimation, active learning of a binary classifier,\nand compressed sensing, obtaining tighter risk lower bounds in each case.\n"]},
{"authors": ["Tobias D. Krafft"], "title": ["Qualit\u00e4tsma\u00dfe bin\u00e4rer Klassifikationen im Bereich\n  kriminalprognostischer Instrumente der vierten Generation"], "date": ["2018-04-04T18:27:45Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01557v1"], "summary": ["  This master's thesis discusses an important issue regarding how algorithmic\ndecision making (ADM) is used in crime forecasting. In America forecasting\ntools are widely used by judiciary systems for making decisions about risk\noffenders based on criminal justice for risk offenders. By making use of such\ntools, the judiciary relies on ADM in order to make error free judgement on\noffenders. For this purpose, one of the quality measures for machine learning\ntechniques which is widly used, the $AUC$ (area under curve), is compared to\nand contrasted for results with the $PPV_k$ (positive predictive value).\nKeeping in view the criticality of judgement along with a high dependency on\ntools offering ADM, it is necessary to evaluate risk tools that aid in decision\nmaking based on algorithms. In this methodology, such an evaluation is\nconducted by implementing a common machine learning approach called binary\nclassifier, as it determines the binary outcome of the underlying juristic\nquestion. This thesis showed that the $PPV_k$ (positive predictive value)\ntechnique models the decision of judges much better than the $AUC$. Therefore,\nthis research has investigated whether there exists a classifier for which the\n$PPV_k$ deviates from $AUC$ by a large proportion. It could be shown that the\ndeviation can rise up to 0.75. In order to test this deviation on an already in\nused Classifier, data from the fourth generation risk assement tool COMPAS was\nused. The result were were quite alarming as the two measures derivate from\neach other by 0.48. In this study, the risk assessment evaluation of the\nforecasting tools was successfully conducted, carefully reviewed and examined.\nAdditionally, it is also discussed whether such systems used for the purpose of\nmaking decisions should be socially accepted or not.\n"]},
{"authors": ["Federico Bassetti", "Stefano Gualandi", "Marco Veneroni"], "title": ["On the Computation of Kantorovich-Wasserstein Distances between\n  2D-Histograms by Uncapacitated Minimum Cost Flows"], "date": ["2018-04-02T10:40:48Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00445v2"], "summary": ["  In this work, we present a method to compute the Kantorovich distance, that\nis, the Wasserstein distance of order one, between a pair of two-dimensional\nhistograms. Recent works in Computer Vision and Machine Learning have shown the\nbenefits of measuring Wasserstein distances of order one between histograms\nwith $N$ bins, by solving a classical transportation problem on (very large)\ncomplete bipartite graphs with $N$ nodes and $N^2$ edges. The main contribution\nof our work is to approximate the original transportation problem by an\nuncapacitated min cost flow problem on a reduced flow network of size $O(N)$.\nMore precisely, when the distance among the bin centers is measured with the\n1-norm or the $\\infty$-norm, our approach provides an optimal solution. When\nthe distance amongst bins is measured with the 2-norm: (i) we derive a\nquantitative estimate on the error between optimal and approximate solution;\n(ii) given the error, we construct a reduced flow network of size $O(N)$. We\nnumerically show the benefits of our approach by computing Wasserstein\ndistances of order one on a set of grey scale images used as benchmarks in the\nliterature. We show how our approach scales with the size of the images with\n1-norm, 2-norm and $\\infty$-norm ground distances.\n"]},
{"authors": ["Aravind Srinivas", "Allan Jabri", "Pieter Abbeel", "Sergey Levine", "Chelsea Finn"], "title": ["Universal Planning Networks"], "date": ["2018-04-02T17:51:53Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00645v2"], "summary": ["  A key challenge in complex visuomotor control is learning abstract\nrepresentations that are effective for specifying goals, planning, and\ngeneralization. To this end, we introduce universal planning networks (UPN).\nUPNs embed differentiable planning within a goal-directed policy. This planning\ncomputation unrolls a forward model in a latent space and infers an optimal\naction plan through gradient descent trajectory optimization. The\nplan-by-gradient-descent process and its underlying representations are learned\nend-to-end to directly optimize a supervised imitation learning objective. We\nfind that the representations learned are not only effective for goal-directed\nvisual imitation via gradient-based trajectory optimization, but can also\nprovide a metric for specifying goals using images. The learned representations\ncan be leveraged to specify distance-based rewards to reach new target states\nfor model-free reinforcement learning, resulting in substantially more\neffective learning when solving new tasks described via image-based goals. We\nwere able to achieve successful transfer of visuomotor planning strategies\nacross robots with significantly different morphologies and actuation\ncapabilities.\n"]},
{"authors": ["Trisha Lawrence"], "title": ["Stochastic Dynamic Programming Heuristics for Influence\n  Maximization-Revenue Optimization"], "date": ["2018-02-28T16:26:06Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.10515v2"], "summary": ["  The well-known Influence Maximization (IM) problem has been actively studied\nby researchers over the past decade, with emphasis on marketing and social\nnetworks. Existing research have obtained solutions to the IM problem by\nobtaining the influence spread and utilizing the property of submodularity.\nThis paper is based on a novel approach to the IM problem geared towards\noptimizing clicks and consequently revenue within anOnline Social Network\n(OSN). Our approach diverts from existing approaches by adopting a novel,\ndecision-making perspective through implementing Stochastic Dynamic Programming\n(SDP). Thus, we define a new problem Influence Maximization-Revenue\nOptimization (IM-RO) and propose SDP as a method in which this problem can be\nsolved. The SDP method has lucrative gains for an advertiser in terms of\noptimizing clicks and generating revenue however, one drawback to the method is\nits associated \"curse of dimensionality\" particularly for problems involving a\nlarge state space. Thus, we introduce the Lawrence Degree Heuristic (LDH),\nAdaptive Hill-Climbing (AHC) and Multistage Particle Swarm Optimization (MPSO)\nheuristics as methods which are orders of magnitude faster than the SDP method\nwhilst achieving near-optimal results. Through a comparative analysis on\nvarious synthetic and real-world networks we present the AHC and LDH as\nheuristics well suited to to the IM-RO problem in terms of their accuracy,\nrunning times and scalability under ideal model parameters. In this paper we\npresent a compelling survey on the SDP method as a practical and lucrative\nmethod for spreading information and optimizing revenue within the context of\nOSNs.\n"]},
{"authors": ["Zahra Ahmadi", "Stefan Kramer"], "title": ["Online Multi-Label Classification: A Label Compression Method"], "date": ["2018-04-04T16:18:28Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01491v1"], "summary": ["  Many modern applications deal with multi-label data, such as functional\ncategorizations of genes, image labeling and text categorization.\nClassification of such data with a large number of labels and latent\ndependencies among them is a challenging task, and it becomes even more\nchallenging when the data is received online and in chunks. Many of the current\nmulti-label classification methods require a lot of time and memory, which make\nthem infeasible for practical real-world applications. In this paper, we\npropose a fast linear label space dimension reduction method that transforms\nthe labels into a reduced encoded space and trains models on the obtained\npseudo labels. Additionally, it provides an analytical method to update the\ndecoding matrix which maps the labels into the original space and is used\nduring the test phase. Experimental results show the effectiveness of this\napproach in terms of running times and the prediction performance over\ndifferent measures.\n"]},
{"authors": ["Andrew L. Beam", "Benjamin Kompa", "Inbar Fried", "Nathan P. Palmer", "Xu Shi", "Tianxi Cai", "Isaac S. Kohane"], "title": ["Clinical Concept Embeddings Learned from Massive Sources of Medical Data"], "date": ["2018-04-04T16:02:54Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01486v1"], "summary": ["  Word embeddings have emerged as a popular approach to unsupervised learning\nof word relationships in machine learning and natural language processing. In\nthis article, we benchmark two of the most popular algorithms, GloVe and\nword2vec, to assess their suitability for capturing medical relationships in\nlarge sources of biomedical data. Leaning on recent theoretical insights, we\nprovide a unified view of these algorithms and demonstrate how different\nsources of data can be combined to construct the largest ever set of embeddings\nfor 108,477 medical concepts using an insurance claims database of 60 million\nmembers, 20 million clinical notes, and 1.7 million full text biomedical\njournal articles. We evaluate our approach, called cui2vec, on a set of\nclinically relevant benchmarks and in many instances demonstrate state of the\nart performance relative to previous results. Finally, we provide a\ndownloadable set of pre-trained embeddings for other researchers to use, as\nwell as an online tool for interactive exploration of the cui2vec embeddings.\n"]},
{"authors": ["William Herlands", "Edward McFowland III", "Andrew Gordon Wilson", "Daniel B. Neill"], "title": ["Gaussian Process Subset Scanning for Anomalous Pattern Detection in\n  Non-iid Data"], "date": ["2018-04-04T15:23:16Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01466v1"], "summary": ["  Identifying anomalous patterns in real-world data is essential for\nunderstanding where, when, and how systems deviate from their expected\ndynamics. Yet methods that separately consider the anomalousness of each\nindividual data point have low detection power for subtle, emerging\nirregularities. Additionally, recent detection techniques based on subset\nscanning make strong independence assumptions and suffer degraded performance\nin correlated data. We introduce methods for identifying anomalous patterns in\nnon-iid data by combining Gaussian processes with novel log-likelihood ratio\nstatistic and subset scanning techniques. Our approaches are powerful,\ninterpretable, and can integrate information across multiple data streams. We\nillustrate their performance on numeric simulations and three open source\nspatiotemporal datasets of opioid overdose deaths, 311 calls, and storm\nreports.\n"]},
{"authors": ["Catherine Wong", "Neil Houlsby", "Yifeng Lu", "Andrea Gesmundo"], "title": ["Transfer Automatic Machine Learning"], "date": ["2018-03-07T17:31:02Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02780v2"], "summary": ["  Building effective neural networks requires many design choices. These\ninclude the network topology, optimization procedure, regularization, stability\nmethods, and choice of pre-trained parameters. This design is time consuming\nand requires expert input. Automatic Machine Learning aims automate this\nprocess using hyperparameter optimization. However, automatic model building\nframeworks optimize performance on each task independently, whereas human\nexperts leverage prior knowledge when designing a new network. We propose\nTransfer Automatic Machine Learning, a method to accelerate network design\nusing knowledge of prior tasks. For this, we build upon reinforcement learning\narchitecture design methods to support parallel training on multiple tasks and\ntransfer the search strategy to new tasks. Tested on NLP and Image\nclassification tasks, Transfer Automatic Machine Learning reduces convergence\ntime over single-task methods by almost an order of magnitude on 13 out of 14\ntasks. It achieves better test set accuracy on 10 out of 13 tasks NLP tasks and\nimproves performance on CIFAR-10 image recognition from 95.3% to 97.1%.\n"]},
{"authors": ["Uri Shaham", "Kelly Stanton", "Henry Li", "Boaz Nadler", "Ronen Basri", "Yuval Kluger"], "title": ["SpectralNet: Spectral Clustering using Deep Neural Networks"], "date": ["2018-01-04T23:56:36Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1801.01587v6"], "summary": ["  Spectral clustering is a leading and popular technique in unsupervised data\nanalysis. Two of its major limitations are scalability and generalization of\nthe spectral embedding (i.e., out-of-sample-extension). In this paper we\nintroduce a deep learning approach to spectral clustering that overcomes the\nabove shortcomings. Our network, which we call SpectralNet, learns a map that\nembeds input data points into the eigenspace of their associated graph\nLaplacian matrix and subsequently clusters them. We train SpectralNet using a\nprocedure that involves constrained stochastic optimization. Stochastic\noptimization allows it to scale to large datasets, while the constraints, which\nare implemented using a special-purpose output layer, allow us to keep the\nnetwork output orthogonal. Moreover, the map learned by SpectralNet naturally\ngeneralizes the spectral embedding to unseen data points. To further improve\nthe quality of the clustering, we replace the standard pairwise Gaussian\naffinities with affinities leaned from unlabeled data using a Siamese network.\nAdditional improvement can be achieved by applying the network to code\nrepresentations produced, e.g., by standard autoencoders. Our end-to-end\nlearning procedure is fully unsupervised. In addition, we apply VC dimension\ntheory to derive a lower bound on the size of SpectralNet. State-of-the-art\nclustering results are reported on the Reuters dataset. Our implementation is\npublicly available at https://github.com/kstant0725/SpectralNet .\n"]},
{"authors": ["Michael Blot", "David Picard", "Matthieu Cord"], "title": ["GoSGD: Distributed Optimization for Deep Learning with Gossip Exchange"], "date": ["2018-04-04T12:13:41Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01852v1"], "summary": ["  We address the issue of speeding up the training of convolutional neural\nnetworks by studying a distributed method adapted to stochastic gradient\ndescent. Our parallel optimization setup uses several threads, each applying\nindividual gradient descents on a local variable. We propose a new way of\nsharing information between different threads based on gossip algorithms that\nshow good consensus convergence properties. Our method called GoSGD has the\nadvantage to be fully asynchronous and decentralized.\n"]},
{"authors": ["Kun Xu", "Lingfei Wu", "Zhiguo Wang", "Yansong Feng", "Vadim Sheinin"], "title": ["Graph2Seq: Graph to Sequence Learning with Attention-based Neural\n  Networks"], "date": ["2018-04-03T04:47:22Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00823v2"], "summary": ["  Celebrated \\emph{Sequence to Sequence learning (Seq2Seq)} and its fruitful\nvariants are powerful models to achieve excellent performance on the tasks that\nmap sequences to sequences. However, these are many machine learning tasks with\ninputs naturally represented in a form of graphs, which imposes significant\nchallenges to existing Seq2Seq models for lossless conversion from its graph\nform to the sequence. In this work, we present a general end-to-end approach to\nmap the input graph to a sequence of vectors, and then another attention-based\nLSTM to decode the target sequence from these vectors. Specifically, to address\ninevitable information loss for data conversion, we introduce a novel\ngraph-to-sequence neural network model that follows the encoder-decoder\narchitecture. Our method first uses an improved graph-based neural network to\ngenerate the node and graph embeddings by a novel aggregation strategy to\nincorporate the edge direction information into the node embeddings. We also\npropose an attention based mechanism that aligns node embeddings and decoding\nsequence to better cope with large graphs. Experimental results on bAbI task,\nShortest Path Task, and Natural Language Generation Task demonstrate that our\nmodel achieves the state-of-the-art performance and significantly outperforms\nother baselines. We also show that with the proposed aggregation strategy, our\nproposed model is able to quickly converge to good performance.\n"]},
{"authors": ["Boris Belousov", "Jan Peters"], "title": ["f-Divergence constrained policy improvement"], "date": ["2017-12-29T23:07:26Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1801.00056v2"], "summary": ["  To ensure stability of learning, state-of-the-art generalized policy\niteration algorithms augment the policy improvement step with a trust region\nconstraint bounding the information loss. The size of the trust region is\ncommonly determined by the Kullback-Leibler (KL) divergence, which not only\ncaptures the notion of distance well but also yields closed-form solutions. In\nthis paper, we consider a more general class of f-divergences and derive the\ncorresponding policy update rules. The generic solution is expressed through\nthe derivative of the convex conjugate function to f and includes the KL\nsolution as a special case. Within the class of f-divergences, we further focus\non a one-parameter family of $\\alpha$-divergences to study effects of the\nchoice of divergence on policy improvement. Previously known as well as new\npolicy updates emerge for different values of $\\alpha$. We show that every type\nof policy update comes with a compatible policy evaluation resulting from the\nchosen f-divergence. Interestingly, the mean-squared Bellman error minimization\nis closely related to policy evaluation with the Pearson $\\chi^2$-divergence\npenalty, while the KL divergence results in the soft-max policy update and a\nlog-sum-exp critic. We carry out asymptotic analysis of the solutions for\ndifferent values of $\\alpha$ and demonstrate the effects of using different\ndivergence functions on a multi-armed bandit problem and on common standard\nreinforcement learning problems.\n"]},
{"authors": ["Jos\u00e9 Carlos Aradillas", "Juan Jos\u00e9 Murillo-Fuentes", "Pablo M. Olmos"], "title": ["Boosting Handwriting Text Recognition in Small Databases with Transfer\n  Learning"], "date": ["2018-04-04T11:20:28Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01527v1"], "summary": ["  In this paper we deal with the offline handwriting text recognition (HTR)\nproblem with reduced training datasets. Recent HTR solutions based on\nartificial neural networks exhibit remarkable solutions in referenced\ndatabases. These deep learning neural networks are composed of both\nconvolutional (CNN) and long short-term memory recurrent units (LSTM). In\naddition, connectionist temporal classification (CTC) is the key to avoid\nsegmentation at character level, greatly facilitating the labeling task. One of\nthe main drawbacks of the CNNLSTM-CTC (CLC) solutions is that they need a\nconsiderable part of the text to be transcribed for every type of calligraphy,\ntypically in the order of a few thousands of lines. Furthermore, in some\nscenarios the text to transcribe is not that long, e.g. in the Washington\ndatabase. The CLC typically overfits for this reduced number of training\nsamples. Our proposal is based on the transfer learning (TL) from the\nparameters learned with a bigger database. We first investigate, for a reduced\nand fixed number of training samples, 350 lines, how the learning from a large\ndatabase, the IAM, can be transferred to the learning of the CLC of a reduced\ndatabase, Washington. We focus on which layers of the network could be not\nre-trained. We conclude that the best solution is to re-train the whole CLC\nparameters initialized to the values obtained after the training of the CLC\nfrom the larger database. We also investigate results when the training size is\nfurther reduced. The differences in the CER are more remarkable when training\nwith just 350 lines, a CER of 3.3% is achieved with TL while we have a CER of\n18.2% when training from scratch. As a byproduct, the learning times are quite\nreduced. Similar good results are obtained from the Parzival database when\ntrained with this reduced number of lines and this new approach.\n"]},
{"authors": ["Niharika Gauraha", "Lars Carlsson", "Ola Spjuth"], "title": ["Conformal Prediction in Learning Under Privileged Information Paradigm\n  with Applications in Drug Discovery"], "date": ["2018-03-29T16:21:10Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.11136v2"], "summary": ["  This paper explores conformal prediction in the learning under privileged\ninformation (LUPI) paradigm. We use the SVM+ realization of LUPI in an\ninductive conformal predictor, and apply it to the MNIST benchmark dataset and\nthree datasets in drug discovery. The results show that using privileged\ninformation produces valid models and improves efficiency compared to standard\nSVM, however the improvement varies between the tested datasets and is not\nsubstantial in the drug discovery applications. More importantly, using SVM+ in\na conformal prediction framework enables valid prediction intervals at\nspecified significance levels.\n"]},
{"authors": ["Thomas Krak", "Alexander Erreygers", "Jasper De Bock"], "title": ["An Imprecise Probabilistic Estimator for the Transition Rate Matrix of a\n  Continuous-Time Markov Chain"], "date": ["2018-04-04T10:20:05Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01330v1"], "summary": ["  We consider the problem of estimating the transition rate matrix of a\ncontinuous-time Markov chain from a finite-duration realisation of this\nprocess. We approach this problem in an imprecise probabilistic framework,\nusing a set of prior distributions on the unknown transition rate matrix. The\nresulting estimator is a set of transition rate matrices that, for reasons of\nconjugacy, is easy to find. To determine the hyperparameters for our set of\npriors, we reconsider the problem in discrete time, where we can use the\nwell-known Imprecise Dirichlet Model. In particular, we show how the limit of\nthe resulting discrete-time estimators is a continuous-time estimator. It\ncorresponds to a specific choice of hyperparameters and has an exceptionally\nsimple closed-form expression.\n"]},
{"authors": ["Ming Hou", "Brahim Chaib-draa", "Chao Li", "Qibin Zhao"], "title": ["Generative Adversarial Positive-Unlabelled Learning"], "date": ["2017-11-21T21:40:24Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.08054v2"], "summary": ["  In this work, we consider the task of classifying binary positive-unlabeled\n(PU) data. The existing discriminative learning based PU models attempt to seek\nan optimal reweighting strategy for U data, so that a decent decision boundary\ncan be found. However, given limited P data, the conventional PU models tend to\nsuffer from overfitting when adapted to very flexible deep neural networks. In\ncontrast, we are the first to innovate a totally new paradigm to attack the\nbinary PU task, from perspective of generative learning by leveraging the\npowerful generative adversarial networks (GAN). Our generative\npositive-unlabeled (GenPU) framework incorporates an array of discriminators\nand generators that are endowed with different roles in simultaneously\nproducing positive and negative realistic samples. We provide theoretical\nanalysis to justify that, at equilibrium, GenPU is capable of recovering both\npositive and negative data distributions. Moreover, we show GenPU is\ngeneralizable and closely related to the semi-supervised classification. Given\nrather limited P data, experiments on both synthetic and real-world dataset\ndemonstrate the effectiveness of our proposed framework. With infinite\nrealistic and diverse sample streams generated from GenPU, a very flexible\nclassifier can then be trained using deep neural networks.\n"]},
{"authors": ["Thomas Guyet", "Ren\u00e9 Quiniou"], "title": ["NegPSpan: efficient extraction of negative sequential patterns with\n  embedding constraints"], "date": ["2018-04-04T06:47:32Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01256v1"], "summary": ["  Mining frequent sequential patterns consists in extracting recurrent\nbehaviors, modeled as patterns, in a big sequence dataset. Such patterns inform\nabout which events are frequently observed in sequences, i.e. what does really\nhappen. Sometimes, knowing that some specific event does not happen is more\ninformative than extracting a lot of observed events. Negative sequential\npatterns (NSP) formulate recurrent behaviors by patterns containing both\nobserved events and absent events. Few approaches have been proposed to mine\nsuch NSPs. In addition, the syntax and semantics of NSPs differ in the\ndifferent methods which makes it difficult to compare them. This article\nprovides a unified framework for the formulation of the syntax and the\nsemantics of NSPs. Then, we introduce a new algorithm, NegPSpan, that extracts\nNSPs using a PrefixSpan depth-first scheme and enabling maxgap constraints that\nother approaches do not take into account. The formal framework allows for\nhighlighting the differences between the proposed approach wrt to the methods\nfrom the literature, especially wrt the state of the art approach eNSP.\nIntensive experiments on synthetic and real datasets show that NegPSpan can\nextract meaningful NSPs and that it can process bigger datasets than eNSP\nthanks to significantly lower memory requirements and better computation times.\n"]},
{"authors": ["Trevor Barron", "Oliver Obst", "Heni Ben Amor"], "title": ["Information Maximizing Exploration with a Latent Dynamics Model"], "date": ["2018-04-04T05:04:41Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01238v1"], "summary": ["  All reinforcement learning algorithms must handle the trade-off between\nexploration and exploitation. Many state-of-the-art deep reinforcement learning\nmethods use noise in the action selection, such as Gaussian noise in policy\ngradient methods or $\\epsilon$-greedy in Q-learning. While these methods are\nappealing due to their simplicity, they do not explore the state space in a\nmethodical manner. We present an approach that uses a model to derive reward\nbonuses as a means of intrinsic motivation to improve model-free reinforcement\nlearning. A key insight of our approach is that this dynamics model can be\nlearned in the latent feature space of a value function, representing the\ndynamics of the agent and the environment. This method is both theoretically\ngrounded and computationally advantageous, permitting the efficient use of\nBayesian information-theoretic methods in high-dimensional state spaces. We\nevaluate our method on several continuous control tasks, focusing on improving\nexploration.\n"]},
{"authors": ["Max Simchowitz", "Horia Mania", "Stephen Tu", "Michael I. Jordan", "Benjamin Recht"], "title": ["Learning Without Mixing: Towards A Sharp Analysis of Linear System\n  Identification"], "date": ["2018-02-22T22:48:11Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.08334v3"], "summary": ["  We prove that the ordinary least-squares (OLS) estimator attains nearly\nminimax optimal performance for the identification of linear dynamical systems\nfrom a single observed trajectory. Our upper bound relies on a generalization\nof Mendelson's small-ball method to dependent data, eschewing the use of\nstandard mixing-time arguments. Our lower bounds reveal that these upper bounds\nmatch up to logarithmic factors. In particular, we capture the correct\nsignal-to-noise behavior of the problem, showing that more unstable linear\nsystems are easier to estimate. This behavior is qualitatively different from\narguments which rely on mixing-time calculations that suggest that unstable\nsystems are more difficult to estimate. We generalize our technique to provide\nbounds for a more general class of linear response time-series.\n"]},
{"authors": ["Max Simchowitz", "Ahmed El Alaoui", "Benjamin Recht"], "title": ["Tight Query Complexity Lower Bounds for PCA via Finite Sample Deformed\n  Wigner Law"], "date": ["2018-04-04T03:00:06Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01221v1"], "summary": ["  We prove a \\emph{query complexity} lower bound for approximating the top $r$\ndimensional eigenspace of a matrix. We consider an oracle model where, given a\nsymmetric matrix $\\mathbf{M} \\in \\mathbb{R}^{d \\times d}$, an algorithm\n$\\mathsf{Alg}$ is allowed to make $\\mathsf{T}$ exact queries of the form\n$\\mathsf{w}^{(i)} = \\mathbf{M} \\mathsf{v}^{(i)}$ for $i$ in\n$\\{1,...,\\mathsf{T}\\}$, where $\\mathsf{v}^{(i)}$ is drawn from a distribution\nwhich depends arbitrarily on the past queries and measurements\n$\\{\\mathsf{v}^{(j)},\\mathsf{w}^{(i)}\\}_{1 \\le j \\le i-1}$. We show that for\nevery $\\mathtt{gap} \\in (0,1/2]$, there exists a distribution over matrices\n$\\mathbf{M}$ for which 1) $\\mathrm{gap}_r(\\mathbf{M}) = \\Omega(\\mathtt{gap})$\n(where $\\mathrm{gap}_r(\\mathbf{M})$ is the normalized gap between the $r$ and\n$r+1$-st largest-magnitude eigenvector of $\\mathbf{M}$), and 2) any algorithm\n$\\mathsf{Alg}$ which takes fewer than $\\mathrm{const} \\times \\frac{r \\log\nd}{\\sqrt{\\mathtt{gap}}}$ queries fails (with overwhelming probability) to\nidentity a matrix $\\widehat{\\mathsf{V}} \\in \\mathbb{R}^{d \\times r}$ with\northonormal columns for which $\\langle \\widehat{\\mathsf{V}}, \\mathbf{M}\n\\widehat{\\mathsf{V}}\\rangle \\ge (1 - \\mathrm{const} \\times\n\\mathtt{gap})\\sum_{i=1}^r \\lambda_i(\\mathbf{M})$. Our bound requires only that\n$d$ is a small polynomial in $1/\\mathtt{gap}$ and $r$, and matches the upper\nbounds of Musco and Musco '15. Moreover, it establishes a strict separation\nbetween convex optimization and \\emph{randomized}, \"strict-saddle\" non-convex\noptimization of which PCA is a canonical example: in the former, first-order\nmethods can have dimension-free iteration complexity, whereas in PCA, the\niteration complexity of gradient-based methods must necessarily grow with the\ndimension.\n"]},
{"authors": ["Alexei Botchkarev"], "title": ["Evaluating Hospital Case Cost Prediction Models Using Azure Machine\n  Learning Studio"], "date": ["2018-04-04T02:40:43Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01825v1"], "summary": ["  Ability for accurate hospital case cost modelling and prediction is critical\nfor efficient health care financial management and budgetary planning. A\nvariety of regression machine learning algorithms are known to be effective for\nhealth care cost predictions. The purpose of this experiment was to build an\nAzure Machine Learning Studio tool for rapid assessment of multiple types of\nregression models. The tool offers environment for comparing 14 types of\nregression models in a unified experiment: linear regression, Bayesian linear\nregression, decision forest regression, boosted decision tree regression,\nneural network regression, Poisson regression, Gaussian processes for\nregression, gradient boosted machine, nonlinear least squares regression,\nprojection pursuit regression, random forest regression, robust regression,\nrobust regression with mm-type estimators, support vector regression. The tool\npresents assessment results arranged by model accuracy in a single table using\nfive performance metrics. Evaluation of regression machine learning models for\nperforming hospital case cost prediction demonstrated advantage of robust\nregression model, boosted decision tree regression and decision forest\nregression. The operational tool has been published to the web and openly\navailable for experiments and extensions.\n"]},
{"authors": ["Zheng Xie", "Guannan Liu", "Junjie Wu", "Yong Tan"], "title": ["Social Media Would Not Lie: Prediction of the 2016 Taiwan Election via\n  Online Heterogeneous Data"], "date": ["2018-03-21T16:53:19Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08010v2"], "summary": ["  The prevalence of online media has attracted researchers from various domains\nto explore human behavior and make interesting predictions. In this research,\nwe leverage heterogeneous social media data collected from various online\nplatforms to predict Taiwan's 2016 presidential election. In contrast to most\nexisting research, we take a \"signal\" view of heterogeneous information and\nadopt the Kalman filter to fuse multiple signals into daily vote predictions\nfor the candidates. We also consider events that influenced the election in a\nquantitative manner based on the so-called event study model that originated in\nthe field of financial research. We obtained the following interesting\nfindings. First, public opinions in online media dominate traditional polls in\nTaiwan election prediction in terms of both predictive power and timeliness.\nBut offline polls can still function on alleviating the sample bias of online\nopinions. Second, although online signals converge as election day approaches,\nthe simple Facebook \"Like\" is consistently the strongest indicator of the\nelection result. Third, most influential events have a strong connection to\ncross-strait relations, and the Chou Tzu-yu flag incident followed by the\napology video one day before the election increased the vote share of Tsai\nIng-Wen by 3.66%. This research justifies the predictive power of online media\nin politics and the advantages of information fusion. The combined use of the\nKalman filter and the event study method contributes to the data-driven\npolitical analytics paradigm for both prediction and attribution purposes.\n"]},
{"authors": ["Omid Poursaeed", "Isay Katsman", "Bicheng Gao", "Serge Belongie"], "title": ["Generative Adversarial Perturbations"], "date": ["2017-12-06T18:52:12Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1712.02328v2"], "summary": ["  In this paper, we propose novel generative models for creating adversarial\nexamples, slightly perturbed images resembling natural images but maliciously\ncrafted to fool pre-trained models. We present trainable deep neural networks\nfor transforming images to adversarial perturbations. Our proposed models can\nproduce image-agnostic and image-dependent perturbations for both targeted and\nnon-targeted attacks. We also demonstrate that similar architectures can\nachieve impressive results in fooling classification and semantic segmentation\nmodels, obviating the need for hand-crafting attack methods for each task.\nUsing extensive experiments on challenging high-resolution datasets such as\nImageNet and Cityscapes, we show that our perturbations achieve high fooling\nrates with small perturbation norms. Moreover, our attacks are considerably\nfaster than current iterative methods at inference time.\n"]},
{"authors": ["Aaron Jaech", "Baosen Zhang", "Mari Ostendorf", "Daniel S. Kirschen"], "title": ["Real-Time Prediction of the Duration of Distribution System Outages"], "date": ["2018-04-03T23:10:36Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01189v1"], "summary": ["  This paper addresses the problem of predicting duration of unplanned power\noutages, using historical outage records to train a series of neural network\npredictors. The initial duration prediction is made based on environmental\nfactors, and it is updated based on incoming field reports using natural\nlanguage processing to automatically analyze the text. Experiments using 15\nyears of outage records show good initial results and improved performance\nleveraging text. Case studies show that the language processing identifies\nphrases that point to outage causes and repair steps.\n"]},
{"authors": ["Jialiang Jiang", "Sharon Hewner", "Varun Chandola"], "title": ["Hospital Readmission Prediction - Applying Hierarchical Sparsity Norms\n  for Interpretable Models"], "date": ["2018-04-03T22:56:25Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01188v1"], "summary": ["  Hospital readmissions have become one of the key measures of healthcare\nquality. Preventable readmissions have been identified as one of the primary\ntargets for reducing costs and improving healthcare delivery. However, most\ndata driven studies for understanding readmissions have produced black box\nclassification and predictive models with moderate performance, which precludes\nthem from being used effectively within the decision support systems in the\nhospitals. In this paper we present an application of structured\nsparsity-inducing norms for predicting readmission risk for patients based on\ntheir disease history and demographics. Most existing studies have focused on\nhospital utilization, test results, etc., to assign a readmission label to each\nepisode of hospitalization. However, we focus on assigning a readmission risk\nlabel to a patient based on their disease history. Our emphasis is on\ninterpreting the models to improve the understanding of the readmission\nproblem. To achieve this, we exploit the domain induced hierarchical structure\navailable for the disease codes which are the features for the classification\nalgorithm. We use a tree based sparsity-inducing regularization strategy that\nexplicitly uses the domain hierarchy. The resulting model not only outperforms\nstandard regularization procedures but is also highly sparse and interpretable.\nWe analyze the model and identify several significant factors that have an\neffect on readmission risk. Some of these factors conform to existing beliefs,\ne.g., impact of surgical complications and infections during hospital stay.\nOther factors, such as the impact of mental disorder and substance abuse on\nreadmission, provide empirical evidence for several pre-existing but unverified\nhypotheses. The analysis also reveals previously undiscovered connections such\nas the influence of socioeconomic factors like lack of housing and\nmalnutrition.\n"]},
{"authors": ["Hiroyuki Kasai"], "title": ["Stochastic variance reduced multiplicative update for nonnegative matrix\n  factorization"], "date": ["2017-10-30T06:14:17Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.10781v2"], "summary": ["  Nonnegative matrix factorization (NMF), a dimensionality reduction and factor\nanalysis method, is a special case in which factor matrices have low-rank\nnonnegative constraints. Considering the stochastic learning in NMF, we\nspecifically address the multiplicative update (MU) rule, which is the most\npopular, but which has slow convergence property. This present paper introduces\non the stochastic MU rule a variance-reduced technique of stochastic gradient.\nNumerical comparisons suggest that our proposed algorithms robustly outperform\nstate-of-the-art algorithms across different synthetic and real-world datasets.\n"]},
{"authors": ["Jacob Levy Abitbol", "M\u00e1rton Karsai", "Jean-Philippe Magu\u00e9", "Jean-Pierre Chevrot", "Eric Fleury"], "title": ["Socioeconomic Dependencies of Linguistic Patterns in Twitter: A\n  Multivariate Analysis"], "date": ["2018-04-03T20:18:11Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01155v1"], "summary": ["  Our usage of language is not solely reliant on cognition but is arguably\ndetermined by myriad external factors leading to a global variability of\nlinguistic patterns. This issue, which lies at the core of sociolinguistics and\nis backed by many small-scale studies on face-to-face communication, is\naddressed here by constructing a dataset combining the largest French Twitter\ncorpus to date with detailed socioeconomic maps obtained from national census\nin France. We show how key linguistic variables measured in individual Twitter\nstreams depend on factors like socioeconomic status, location, time, and the\nsocial network of individuals. We found that (i) people of higher socioeconomic\nstatus, active to a greater degree during the daytime, use a more standard\nlanguage; (ii) the southern part of the country is more prone to use more\nstandard language than the northern one, while locally the used variety or\ndialect is determined by the spatial distribution of socioeconomic status; and\n(iii) individuals connected in the social network are closer linguistically\nthan disconnected ones, even after the effects of status homophily have been\nremoved. Our results inform sociolinguistic theory and may inspire novel\nlearning methods for the inference of socioeconomic status of people from the\nway they tweet.\n"]},
{"authors": ["Husheng Li"], "title": ["Analysis on the Nonlinear Dynamics of Deep Neural Networks: Topological\n  Entropy and Chaos"], "date": ["2018-04-03T19:51:20Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03987v1"], "summary": ["  The theoretical explanation for deep neural network (DNN) is still an open\nproblem. In this paper DNN is considered as a discrete-time dynamical system\ndue to its layered structure. The complexity provided by the nonlinearity in\nthe dynamics is analyzed in terms of topological entropy and chaos\ncharacterized by Lyapunov exponents. The properties revealed for the dynamics\nof DNN are applied to analyze the corresponding capabilities of classification\nand generalization.\n"]},
{"authors": ["Sharmistha Dey"], "title": ["Predicting Gross Movie Revenue"], "date": ["2018-04-03T19:44:57Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.03565v1"], "summary": ["  'There is no terror in the bang, only is the anticipation of it' - Alfred\nHitchcock.\n  Yet there is everything in correctly anticipating the bang a movie would make\nin the box-office. Movies make a high profile, billion dollar industry and\nprediction of movie revenue can be very lucrative. Predicted revenues can be\nused for planning both the production and distribution stages. For example,\nprojected gross revenue can be used to plan the remuneration of the actors and\ncrew members as well as other parts of the budget [1].\n  Success or failure of a movie can depend on many factors: star-power, release\ndate, budget, MPAA (Motion Picture Association of America) rating, plot and the\nhighly unpredictable human reactions. The enormity of the number of exogenous\nvariables makes manual revenue prediction process extremely difficult. However,\nin the era of computer and data sciences, volumes of data can be efficiently\nprocessed and modelled. Hence the tough job of predicting gross revenue of a\nmovie can be simplified with the help of modern computing power and the\nhistorical data available as movie databases [2].\n"]},
{"authors": ["Stephane Chretien", "Zhen-Wai Olivier Ho"], "title": ["Feature selection in weakly coherent matrices"], "date": ["2018-04-03T18:26:46Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01119v1"], "summary": ["  A problem of paramount importance in both pure (Restricted Invertibility\nproblem) and applied mathematics (Feature extraction) is the one of selecting a\nsubmatrix of a given matrix, such that this submatrix has its smallest singular\nvalue above a specified level. Such problems can be addressed using\nperturbation analysis. In this paper, we propose a perturbation bound for the\nsmallest singular value of a given matrix after appending a column, under the\nassumption that its initial coherence is not large, and we use this bound to\nderive a fast algorithm for feature extraction.\n"]},
{"authors": ["Yaroslav Ganin", "Tejas Kulkarni", "Igor Babuschkin", "S. M. Ali Eslami", "Oriol Vinyals"], "title": ["Synthesizing Programs for Images using Reinforced Adversarial Learning"], "date": ["2018-04-03T18:25:42Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01118v1"], "summary": ["  Advances in deep generative networks have led to impressive results in recent\nyears. Nevertheless, such models can often waste their capacity on the minutiae\nof datasets, presumably due to weak inductive biases in their decoders. This is\nwhere graphics engines may come in handy since they abstract away low-level\ndetails and represent images as high-level programs. Current methods that\ncombine deep learning and renderers are limited by hand-crafted likelihood or\ndistance functions, a need for large amounts of supervision, or difficulties in\nscaling their inference algorithms to richer datasets. To mitigate these\nissues, we present SPIRAL, an adversarially trained agent that generates a\nprogram which is executed by a graphics engine to interpret and sample images.\nThe goal of this agent is to fool a discriminator network that distinguishes\nbetween real and rendered data, trained with a distributed reinforcement\nlearning setup without any supervision. A surprising finding is that using the\ndiscriminator's output as a reward signal is the key to allow the agent to make\nmeaningful progress at matching the desired output rendering. To the best of\nour knowledge, this is the first demonstration of an end-to-end, unsupervised\nand adversarial inverse graphics agent on challenging real world (MNIST,\nOmniglot, CelebA) and synthetic 3D datasets.\n"]},
{"authors": ["Jayakumar Subramanian", "Aditya Mahajan"], "title": ["Renewal Monte Carlo: Renewal theory based reinforcement learning"], "date": ["2018-04-03T18:18:54Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01116v1"], "summary": ["  In this paper, we present an online reinforcement learning algorithm, called\nRenewal Monte Carlo (RMC), for infinite horizon Markov decision processes with\na designated start state. RMC is a Monte Carlo algorithm and retains the\nadvantages of Monte Carlo methods including low bias, simplicity, and ease of\nimplementation while, at the same time, circumvents their key drawbacks of high\nvariance and delayed (end of episode) updates. The key ideas behind RMC are as\nfollows. First, under any reasonable policy, the reward process is ergodic. So,\nby renewal theory, the performance of a policy is equal to the ratio of\nexpected discounted reward to the expected discounted time over a regenerative\ncycle. Second, by carefully examining the expression for performance gradient,\nwe propose a stochastic approximation algorithm that only requires estimates of\nthe expected discounted reward and discounted time over a regenerative cycle\nand their gradients. We propose two unbiased estimators for evaluating\nperformance gradients---a likelihood ratio based estimator and a simultaneous\nperturbation based estimator---and show that for both estimators, RMC converges\nto a locally optimal policy. We generalize the RMC algorithm to post-decision\nstate models and also present a variant that converges faster to an\napproximately optimal policy. We conclude by presenting numerical experiments\non a randomly generated MDP, event-triggered communication, and inventory\nmanagement.\n"]},
{"authors": ["Daniel Chicharro"], "title": ["Quantifying multivariate redundancy with maximum entropy decompositions\n  of mutual information"], "date": ["2017-08-13T03:29:57Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1708.03845v2"], "summary": ["  Williams and Beer (2010) proposed a nonnegative mutual information\ndecomposition, based on the construction of redundancy lattices, which allows\nseparating the information that a set of variables contains about a target\nvariable into nonnegative components interpretable as the unique information of\nsome variables not provided by others as well as redundant and synergistic\ncomponents. However, the definition of multivariate measures of redundancy that\ncomply with nonnegativity and conform to certain axioms that capture\nconceptually desirable properties of redundancy has proven to be elusive. We\nhere present a procedure to determine nonnegative multivariate redundancy\nmeasures, within the maximum entropy framework. In particular, we generalize\nexisting bivariate maximum entropy measures of redundancy and unique\ninformation, defining measures of the redundant information that a group of\nvariables has about a target, and of the unique redundant information that a\ngroup of variables has about a target that is not redundant with information\nfrom another group. The two key ingredients for this approach are: First, the\nidentification of a type of constraints on entropy maximization that allows\nisolating components of redundancy and unique redundancy by mirroring them to\nsynergy components. Second, the construction of rooted tree-based\ndecompositions of the mutual information, which conform to the axioms of the\nredundancy lattice by the local implementation at each tree node of binary\nunfoldings of the information using hierarchically related maximum entropy\nconstraints. Altogether, the proposed measures quantify the different\nmultivariate redundancy contributions of a nonnegative mutual information\ndecomposition consistent with the redundancy lattice.\n"]},
{"authors": ["Stephane Chretien", "Christophe Guyeux", "Zhen-Wai Olivier HO"], "title": ["Average performance analysis of the stochastic gradient method for\n  online PCA"], "date": ["2018-04-03T17:31:32Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01071v1"], "summary": ["  This paper studies the complexity of the stochastic gradient algorithm for\nPCA when the data are observed in a streaming setting. We also propose an\nonline approach for selecting the learning rate. Simulation experiments confirm\nthe practical relevance of the plain stochastic gradient approach and that\ndrastic improvements can be achieved by learning the learning rate.\n"]},
{"authors": ["Garoe Dorta", "Sara Vicente", "Lourdes Agapito", "Neill D. F. Campbell", "Ivor Simpson"], "title": ["Training VAEs Under Structured Residuals"], "date": ["2018-04-03T16:04:22Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01050v1"], "summary": ["  Variational auto-encoders (VAEs) are a popular and powerful deep generative\nmodel. Previous works on VAEs have assumed a factorised likelihood model,\nwhereby the output uncertainty of each pixel is assumed to be independent. This\napproximation is clearly limited as demonstrated by observing a residual image\nfrom a VAE reconstruction, which often possess a high level of structure. This\npaper demonstrates a novel scheme to incorporate a structured Gaussian\nlikelihood prediction network within the VAE that allows the residual\ncorrelations to be modelled. Our novel architecture, with minimal increase in\ncomplexity, incorporates the covariance matrix prediction within the VAE. We\nalso propose a new mechanism for allowing structured uncertainty on color\nimages. Furthermore, we provide a scheme for effectively training this model,\nand include some suggestions for improving performance in terms of efficiency\nor modelling longer range correlations. The advantage of our approach is\nillustrated on the CelebA face data and the LSUN outdoor churches dataset, with\nsubstantial improvements in terms of samples over traditional VAE and better\nreconstructions.\n"]},
{"authors": ["Haque Ishfaq", "Assaf Hoogi", "Daniel Rubin"], "title": ["TVAE: Triplet-Based Variational Autoencoder using Metric Learning"], "date": ["2018-02-13T00:05:19Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.04403v2"], "summary": ["  Deep metric learning has been demonstrated to be highly effective in learning\nsemantic representation and encoding information that can be used to measure\ndata similarity, by relying on the embedding learned from metric learning. At\nthe same time, variational autoencoder (VAE) has widely been used to\napproximate inference and proved to have a good performance for directed\nprobabilistic models. However, for traditional VAE, the data label or feature\ninformation are intractable. Similarly, traditional representation learning\napproaches fail to represent many salient aspects of the data. In this project,\nwe propose a novel integrated framework to learn latent embedding in VAE by\nincorporating deep metric learning. The features are learned by optimizing a\ntriplet loss on the mean vectors of VAE in conjunction with standard evidence\nlower bound (ELBO) of VAE. This approach, which we call Triplet based\nVariational Autoencoder (TVAE), allows us to capture more fine-grained\ninformation in the latent embedding. Our model is tested on MNIST data set and\nachieves a high triplet accuracy of 95.60% while the traditional VAE (Kingma &\nWelling, 2013) achieves triplet accuracy of 75.08%.\n"]},
{"authors": ["S. T. John", "James Hensman"], "title": ["Large-Scale Cox Process Inference using Variational Fourier Features"], "date": ["2018-04-03T15:00:01Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01016v1"], "summary": ["  Gaussian process modulated Poisson processes provide a flexible framework for\nmodelling spatiotemporal point patterns. So far this had been restricted to one\ndimension, binning to a pre-determined grid, or small data sets of up to a few\nthousand data points. Here we introduce Cox process inference based on Fourier\nfeatures. This sparse representation induces global rather than local\nconstraints on the function space and is computationally efficient. This allows\nus to formulate a grid-free approximation that scales well with the number of\ndata points and the size of the domain. We demonstrate that this allows MCMC\napproximations to the non-Gaussian posterior. We also find that, in practice,\nFourier features have more consistent optimization behavior than previous\napproaches. Our approximate Bayesian method can fit over 100,000 events with\ncomplex spatiotemporal patterns in three dimensions on a single GPU.\n"]},
{"authors": ["Sebastian Ruder", "John Glover", "Afshin Mehrabani", "Parsa Ghaffari"], "title": ["360\u00b0 Stance Detection"], "date": ["2018-04-03T14:17:09Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00982v1"], "summary": ["  The proliferation of fake news and filter bubbles makes it increasingly\ndifficult to form an unbiased, balanced opinion towards a topic. To ameliorate\nthis, we propose 360{\\deg} Stance Detection, a tool that aggregates news with\nmultiple perspectives on a topic. It presents them on a spectrum ranging from\nsupport to opposition, enabling the user to base their opinion on multiple\npieces of diverse evidence.\n"]},
{"authors": ["Nilin Abrahamsen", "Philippe Rigollet"], "title": ["Sparse Gaussian ICA"], "date": ["2018-04-02T06:14:08Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00408v2"], "summary": ["  Independent component analysis (ICA) is a cornerstone of modern data\nanalysis. Its goal is to recover a latent random vector S with independent\ncomponents from samples of X=AS where A is an unknown mixing matrix.\nCritically, all existing methods for ICA rely on and exploit strongly the\nassumption that S is not Gaussian as otherwise A becomes unidentifiable. In\nthis paper, we show that in fact one can handle the case of Gaussian components\nby imposing structure on the matrix A. Specifically, we assume that A is sparse\nand generic in the sense that it is generated from a sparse Bernoulli-Gaussian\nensemble. Under this condition, we give an efficient algorithm to recover the\ncolumns of A given only the covariance matrix of X as input even when S has\nseveral Gaussian components.\n"]},
{"authors": ["Adil Salim", "Pascal Bianchi", "Walid Hachem"], "title": ["A Constant Step Stochastic Douglas-Rachford Algorithm with Application\n  to Non Separable Regularizations"], "date": ["2018-04-03T12:42:07Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00934v1"], "summary": ["  The Douglas Rachford algorithm is an algorithm that converges to a minimizer\nof a sum of two convex functions. The algorithm consists in fixed point\niterations involving computations of the proximity operators of the two\nfunctions separately. The paper investigates a stochastic version of the\nalgorithm where both functions are random and the step size is constant. We\nestablish that the iterates of the algorithm stay close to the set of solution\nwith high probability when the step size is small enough. Application to\nstructured regularization is considered.\n"]},
{"authors": ["Shreyas Patel", "Ashutosh Kakadiya", "Maitrey Mehta", "Raj Derasari", "Rahul Patel", "Ratnik Gandhi"], "title": ["Correlated discrete data generation using adversarial training"], "date": ["2018-04-03T12:10:39Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00925v1"], "summary": ["  Generative Adversarial Networks (GAN) have shown great promise in tasks like\nsynthetic image generation, image inpainting, style transfer, and anomaly\ndetection. However, generating discrete data is a challenge. This work presents\nan adversarial training based correlated discrete data (CDD) generation model.\nIt also details an approach for conditional CDD generation. The results of our\napproach are presented over two datasets; job-seeking candidates skill set\n(private dataset) and MNIST (public dataset). From quantitative and qualitative\nanalysis of these results, we show that our model performs better as it\nleverages inherent correlation in the data, than an existing model that\noverlooks correlation.\n"]},
{"authors": ["Othman Sbai", "Mohamed Elhoseiny", "Antoine Bordes", "Yann LeCun", "Camille Couprie"], "title": ["DeSIGN: Design Inspiration from Generative Networks"], "date": ["2018-04-03T11:54:57Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00921v1"], "summary": ["  Can an algorithm create original and compelling fashion designs to serve as\nan inspirational assistant? To help answer this question, we design and\ninvestigate different image generation models associated with different loss\nfunctions to boost creativity in fashion generation. The dimensions of our\nexplorations include: (i) different Generative Adversarial Networks\narchitectures that start from noise vectors to generate fashion items, (ii) a\nnew loss function that encourages creativity, and (iii) a generation process\nfollowing the key elements of fashion design (disentangling shape and texture\nmakers). A key challenge of this study is the evaluation of generated designs\nand the retrieval of best ones, hence we put together an evaluation protocol\nassociating automatic metrics and human experimental studies that we hope will\nhelp ease future research. We show that our proposed creativity loss yields\nbetter overall appreciation than the one employed in Creative Adversarial\nNetworks. In the end, about 61% of our images are thought to be created by\nhuman designers rather than by a computer while also being considered original\nper our human subject experiments, and our proposed loss scores the highest\ncompared to existing losses in both novelty and likability.\n"]},
{"authors": ["Lauri Juvela", "Bajibabu Bollepalli", "Xin Wang", "Hirokazu Kameoka", "Manu Airaksinen", "Junichi Yamagishi", "Paavo Alku"], "title": ["Speech waveform synthesis from MFCC sequences with generative\n  adversarial networks"], "date": ["2018-04-03T11:43:36Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00920v1"], "summary": ["  This paper proposes a method for generating speech from filterbank mel\nfrequency cepstral coefficients (MFCC), which are widely used in speech\napplications, such as ASR, but are generally considered unusable for speech\nsynthesis. First, we predict fundamental frequency and voicing information from\nMFCCs with an autoregressive recurrent neural net. Second, the spectral\nenvelope information contained in MFCCs is converted to all-pole filters, and a\npitch-synchronous excitation model matched to these filters is trained.\nFinally, we introduce a generative adversarial network -based noise model to\nadd a realistic high-frequency stochastic component to the modeled excitation\nsignal. The results show that high quality speech reconstruction can be\nobtained, given only MFCC information at test time.\n"]},
{"authors": ["Tim R. Davidson", "Luca Falorsi", "Nicola De Cao", "Thomas Kipf", "Jakub M. Tomczak"], "title": ["Hyperspherical Variational Auto-Encoders"], "date": ["2018-04-03T09:57:26Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00891v1"], "summary": ["  The Variational Auto-Encoder (VAE) is one of the most used unsupervised\nmachine learning models. But although the default choice of a Gaussian\ndistribution for both the prior and posterior represents a mathematically\nconvenient distribution often leading to competitive results, we show that this\nparameterization fails to model data with a latent hyperspherical structure. To\naddress this issue we propose using a von Mises-Fisher (vMF) distribution\ninstead, leading to a hyperspherical latent space. Through a series of\nexperiments we show how such a hyperspherical VAE, or $\\mathcal{S}$-VAE, is\nmore suitable for capturing data with a hyperspherical latent structure, while\noutperforming a normal, $\\mathcal{N}$-VAE, in low dimensions on other data\ntypes.\n"]},
{"authors": ["Wei Zhao", "Pengpeng Yang", "Rongrong Ni", "Yao Zhao", "Haorui Wu"], "title": ["Security Consideration For Deep Learning-Based Image Forensics"], "date": ["2018-03-29T17:06:00Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.11157v2"], "summary": ["  Recently, image forensics community has paied attention to the research on\nthe design of effective algorithms based on deep learning technology and facts\nproved that combining the domain knowledge of image forensics and deep learning\nwould achieve more robust and better performance than the traditional schemes.\nInstead of improving it, in this paper, the safety of deep learning based\nmethods in the field of image forensics is taken into account. To the best of\nour knowledge, this is a first work focusing on this topic. Specifically, we\nexperimentally find that the method using deep learning would fail when adding\nthe slight noise into the images (adversarial images). Furthermore, two kinds\nof strategys are proposed to enforce security of deep learning-based method.\nFirstly, an extra penalty term to the loss function is added, which is referred\nto the 2-norm of the gradient of the loss with respect to the input images, and\nthen an novel training method are adopt to train the model by fusing the normal\nand adversarial images. Experimental results show that the proposed algorithm\ncan achieve good performance even in the case of adversarial images and provide\na safety consideration for deep learning-based image forensics\n"]},
{"authors": ["Hongyi Ding", "Mohammad Emtiyaz Khan", "Issei Sato", "Masashi Sugiyama"], "title": ["Bayesian Nonparametric Poisson-Process Allocation for Time-Sequence\n  Modeling"], "date": ["2017-05-19T14:15:13Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1705.07006v5"], "summary": ["  Analyzing the underlying structure of multiple time-sequences provides\ninsights into the understanding of social networks and human activities. In\nthis work, we present the \\emph{Bayesian nonparametric Poisson process\nallocation} (BaNPPA), a latent-function model for time-sequences, which\nautomatically infers the number of latent functions. We model the intensity of\neach sequence as an infinite mixture of latent functions, each of which is\nobtained using a function drawn from a Gaussian process. We show that a\ntechnical challenge for the inference of such mixture models is the\nunidentifiability of the weights of the latent functions. We propose to cope\nwith the issue by regulating the volume of each latent function within a\nvariational inference algorithm. Our algorithm is computationally efficient and\nscales well to large data sets. We demonstrate the usefulness of our proposed\nmodel through experiments on both synthetic and real-world data sets.\n"]},
{"authors": ["Botond Szabo", "Harry van Zanten"], "title": ["Adaptive distributed methods under communication constraints"], "date": ["2018-04-03T08:18:12Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00864v1"], "summary": ["  We study distributed estimation methods under communication constraints in a\ndistributed version of the nonparametric signal-in-white-noise model. We derive\nminimax lower bounds and exhibit methods that attain those bounds. Moreover, we\nshow that adaptive estimation is possible in this setting.\n"]},
{"authors": ["G\u00e9rard Biau", "Erwan Scornet", "Johannes Welbl"], "title": ["Neural Random Forests"], "date": ["2016-04-25T06:43:47Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1604.07143v2"], "summary": ["  Given an ensemble of randomized regression trees, it is possible to\nrestructure them as a collection of multilayered neural networks with\nparticular connection weights. Following this principle, we reformulate the\nrandom forest method of Breiman (2001) into a neural network setting, and in\nturn propose two new hybrid procedures that we call neural random forests. Both\npredictors exploit prior knowledge of regression trees for their architecture,\nhave less parameters to tune than standard networks, and less restrictions on\nthe geometry of the decision boundaries than trees. Consistency results are\nproved, and substantial numerical evidence is provided on both synthetic and\nreal data sets to assess the excellent performance of our methods in a large\nvariety of prediction problems.\n"]},
{"authors": ["Jialin Song", "Ravi Lanka", "Albert Zhao", "Yisong Yue", "Masahiro Ono"], "title": ["Learning to Search via Self-Imitation"], "date": ["2018-04-03T06:52:09Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00846v1"], "summary": ["  We study the problem of learning a good search policy. To do so, we propose\nthe self-imitation learning setting, which builds upon imitation learning in\ntwo ways. First, self-imitation uses feedback provided by retrospective\nanalysis of demonstrated search traces. Second, the policy can learn from its\nown decisions and mistakes without requiring repeated feedback from an external\nexpert. Combined, these two properties allow our approach to iteratively scale\nup to larger problem sizes than the initial problem size for which expert\ndemonstrations were provided. We showcase the effectiveness of our approach on\na synthetic maze solving task and the problem of risk-aware path planning.\n"]},
{"authors": ["Canh Hao Nguyen", "Hiroshi Mamitsuka"], "title": ["Learning on Hypergraphs with Sparsity"], "date": ["2018-04-03T06:16:35Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00836v1"], "summary": ["  Hypergraph is a general way of representing high-order relations on a set of\nobjects. It is a generalization of graph, in which only pairwise relations can\nbe represented. It finds applications in various domains where relationships of\nmore than two objects are observed. On a hypergraph, as a generalization of\ngraph, one wishes to learn a smooth function with respect to its topology. A\nfundamental issue is to find suitable smoothness measures of functions on the\nnodes of a graph/hypergraph. We show a general framework that generalizes\npreviously proposed smoothness measures and also gives rise to new ones. To\naddress the problem of irrelevant or noisy data, we wish to incorporate sparse\nlearning framework into learning on hypergraphs. We propose sparsely smooth\nformulations that learn smooth functions and induce sparsity on hypergraphs at\nboth hyperedge and node levels. We show their properties and sparse support\nrecovery results. We conduct experiments to show that our sparsely smooth\nmodels have benefits to irrelevant and noisy data, and usually give similar or\nimproved performances compared to dense models.\n"]},
{"authors": ["Hangjin Jiang", "Kan Liu", "Yiming Ding"], "title": ["Equitability of Dependence Measure"], "date": ["2015-01-09T10:53:02Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1501.02102v3"], "summary": ["  A measure of dependence is said to be equitable if it gives similar scores to\nequally noisy relationship of different types. In practice, we do not know what\nkind of functional relationship is underlying two given observations, Hence the\nequitability of dependence measure is critical in analysis and by scoring\nrelationships according to an equitable measure one hopes to find important\npatterns of any type of further examination. In this paper, we introduce our\ndefinition of equitability of a dependence measure, which is naturally from\nthis initial description, and Further more power-equitable(weak-equitable) is\nintroduced which is of the most practical meaning in evaluating the equitablity\nof a dependence measure.\n"]},
{"authors": ["Guoqing Chao", "Shiliang Sun", "Jinbo Bi"], "title": ["A Survey on Multi-View Clustering"], "date": ["2017-12-18T04:07:42Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1712.06246v2"], "summary": ["  With advances in information acquisition technologies, multi-view data become\nubiquitous. Multi-view learning has thus become more and more popular in\nmachine learning and data mining fields. Multi-view unsupervised or\nsemi-supervised learning, such as co-training, co-regularization has gained\nconsiderable attention. Although recently, multi-view clustering (MVC) methods\nhave been developed rapidly, there has not been a survey to summarize and\nanalyze the current progress. Therefore, this paper reviews the common\nstrategies for combining multiple views of data and based on this summary we\npropose a novel taxonomy of the MVC approaches. We further discuss the\nrelationships between MVC and multi-view representation, ensemble clustering,\nmulti-task clustering, multi-view supervised and semi-supervised learning.\nSeveral representative real-world applications are elaborated. To promote\nfuture development of MVC, we envision several open problems that may require\nfurther investigation and thorough examination.\n"]},
{"authors": ["Shamak Dutta", "Bryan Tripp", "Graham Taylor"], "title": ["Convolutional Neural Networks Regularized by Correlated Noise"], "date": ["2018-04-03T04:05:00Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00815v1"], "summary": ["  Neurons in the visual cortex are correlated in their variability. The\npresence of correlation impacts cortical processing because noise cannot be\naveraged out over many neurons. In an effort to understand the functional\npurpose of correlated variability, we implement and evaluate correlated noise\nmodels in deep convolutional neural networks. Inspired by the cortex,\ncorrelation is defined as a function of the distance between neurons and their\nselectivity. We show how to sample from high-dimensional correlated\ndistributions while keeping the procedure differentiable, so that\nback-propagation can proceed as usual. The impact of correlated variability is\nevaluated on the classification of occluded and non-occluded images with and\nwithout the presence of other regularization techniques, such as dropout. More\nwork is needed to understand the effects of correlations in various conditions,\nhowever in 10/12 of the cases we studied, the best performance on occluded\nimages was obtained from a model with correlated noise.\n"]},
{"authors": ["Xudong Li", "Mengdi Wang", "Anru Zhang"], "title": ["Estimation of Markov Chain via Rank-constrained Likelihood"], "date": ["2018-04-03T02:28:47Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00795v1"], "summary": ["  This paper studies the recovery and state compression of low-rank Markov\nchains from empirical trajectories. We propose a non-convex estimator based on\nrank-constrained likelihood maximization. Statistical upper bounds are provided\nfor the Kullback-Leiber divergence and the $\\ell_2$ risk between the estimator\nand the true transition matrix. The estimator reveals a compressed state space\nof the Markov chain. We also develop a novel DC (difference of convex function)\nprogramming algorithm to tackle the rank-constrained non-smooth optimization\nproblem. Convergence results are established. Experiments with taxi trip data\nshow that the estimator is able to identify the zoning of Manhattan city.\n"]},
{"authors": ["Ali Shafahi", "W. Ronny Huang", "Mahyar Najibi", "Octavian Suciu", "Christoph Studer", "Tudor Dumitras", "Tom Goldstein"], "title": ["Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks"], "date": ["2018-04-03T02:24:31Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00792v1"], "summary": ["  Data poisoning is a type of adversarial attack on machine learning models\nwherein the attacker adds examples to the training set to manipulate the\nbehavior of the model at test time. This paper explores a broad class of\npoisoning attacks on neural nets. The proposed attacks use \"clean-labels\"; they\ndon't require the attacker to have any control over the labeling of training\ndata. They are also targeted; they control the behavior of the classifier on a\nspecific test instance without noticeably degrading classifier performance on\nother instances.\n  For example, an attacker could add a seemingly innocuous image (that is\nproperly labeled) to a training set for a face recognition engine, and control\nthe identity of a chosen person at test time. Because the attacker does not\nneed to control the labeling function, poisons could be entered into the\ntraining set simply by putting them online and waiting for them to be scraped\nby a data collection bot.\n  We present an optimization-based method for crafting poisons, and show that\njust one single poison image can control classifier behavior when transfer\nlearning is used. For full end-to-end training, we present a \"watermarking\"\nstrategy that makes poisoning reliable using multiple (~50) poisoned training\ninstances. We demonstrate our method by generating poisoned frog images from\nthe CIFAR dataset and using them to manipulate image classifiers.\n"]},
{"authors": ["Chin-Wei Huang", "David Krueger", "Alexandre Lacoste", "Aaron Courville"], "title": ["Neural Autoregressive Flows"], "date": ["2018-04-03T01:41:27Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00779v1"], "summary": ["  Normalizing flows and autoregressive models have been successfully combined\nto produce state-of-the-art results in density estimation, via Masked\nAutoregressive Flows (MAF), and to accelerate state-of-the-art WaveNet-based\nspeech synthesis to 20x faster than real-time, via Inverse Autoregressive Flows\n(IAF). We unify and generalize these approaches, replacing the (conditionally)\naffine univariate transformations of MAF/IAF with a more general class of\ninvertible univariate transformations expressed as monotonic neural networks.\nWe demonstrate that the proposed neural autoregressive flows (NAF) are\nuniversal approximators for continuous probability distributions, and their\ngreater expressivity allows them to better capture multimodal target\ndistributions. Experimentally, NAF yields state-of-the-art performance on a\nsuite of density estimation tasks and outperforms IAF in variational\nautoencoders trained on binarized MNIST.\n"]},
{"authors": ["Hamid Khodabandehlou", "Mohammad Sami Fadali"], "title": ["Training Recurrent Neural Networks as a Constraint Satisfaction Problem"], "date": ["2018-03-20T00:12:26Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07200v4"], "summary": ["  This paper presents a new approach for training artificial neural networks\nusing techniques for solving the constraint satisfaction problem (CSP). The\nquotient gradient system (QGS) is a trajectory based method for solving the\nCSP. This study converts the training set of a neural network into a CSP and\nuses the QGS to find its solutions. The QGS finds the global minimum of the\noptimization problem by tracking trajectories of a nonlinear dynamical system\nand does not stop at a local minimum of the optimization problem. Lyapunov\ntheory is used to prove the asymptotic stability of the solutions with and\nwithout the presence of measurement errors. Numerical examples illustrate the\neffectiveness of the proposed methodology and compare it to a genetic algorithm\nand error backpropagation\n"]},
{"authors": ["Chaochen Wu"], "title": ["Vanlearning: A Machine Learning SaaS Application for People Without\n  Programming Backgrounds"], "date": ["2018-04-03T01:17:16Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01382v1"], "summary": ["  Although we have tons of machine learning tools to analyze data, most of them\nrequire users have some programming backgrounds. Here we introduce a SaaS\napplication which allows users analyze their data without any coding and even\nwithout any knowledge of machine learning. Users can upload, train, predict and\ndownload their data by simply clicks their mouses. Our system uses data\npre-processor and validator to relieve the computational cost of our server.\nThe simple architecture of Vanlearning helps developers can easily maintain and\nextend it.\n"]},
{"authors": ["Joanne C. Wen", "Cecilia S. Lee", "Pearse A. Keane", "Sa Xiao", "Yue Wu", "Ariel Rokem", "Philip P. Chen", "Aaron Y. Lee"], "title": ["Forecasting Future Humphrey Visual Fields Using Deep Learning"], "date": ["2018-04-02T21:05:22Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.04543v1"], "summary": ["  Purpose: To determine if deep learning networks could be trained to forecast\na future 24-2 Humphrey Visual Field (HVF).\n  Participants: All patients who obtained a HVF 24-2 at the University of\nWashington.\n  Methods: All datapoints from consecutive 24-2 HVFs from 1998 to 2018 were\nextracted from a University of Washington database. Ten-fold cross validation\nwith a held out test set was used to develop the three main phases of model\ndevelopment: model architecture selection, dataset combination selection, and\ntime-interval model training with transfer learning, to train a deep learning\nartificial neural network capable of generating a point-wise visual field\nprediction.\n  Results: More than 1.7 million perimetry points were extracted to the\nhundredth decibel from 32,443 24-2 HVFs. The best performing model with 20\nmillion trainable parameters, CascadeNet-5, was selected. The overall MAE for\nthe test set was 2.47 dB (95% CI: 2.45 dB to 2.48 dB). The 100 fully trained\nmodels were able to successfully predict progressive field loss in glaucomatous\neyes up to 5.5 years in the future with a correlation of 0.92 between the MD of\npredicted and actual future HVF (p < 2.2 x 10 -16 ) and an average difference\nof 0.41 dB.\n  Conclusions: Using unfiltered real-world datasets, deep learning networks\nshow an impressive ability to not only learn spatio-temporal HVF changes but\nalso to generate predictions for future HVFs up to 5.5 years, given only a\nsingle HVF.\n"]},
{"authors": ["Ryan J. Urbanowicz", "Melissa Meeker", "William LaCava", "Randal S. Olson", "Jason H. Moore"], "title": ["Relief-Based Feature Selection: Introduction and Review"], "date": ["2017-11-22T18:06:25Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.08421v2"], "summary": ["  Feature selection plays a critical role in biomedical data mining, driven by\nincreasing feature dimensionality in target problems and growing interest in\nadvanced but computationally expensive methodologies able to model complex\nassociations. Specifically, there is a need for feature selection methods that\nare computationally efficient, yet sensitive to complex patterns of\nassociation, e.g. interactions, so that informative features are not mistakenly\neliminated prior to downstream modeling. This paper focuses on Relief-based\nalgorithms (RBAs), a unique family of filter-style feature selection algorithms\nthat have gained appeal by striking an effective balance between these\nobjectives while flexibly adapting to various data characteristics, e.g.\nclassification vs. regression. First, this work broadly examines types of\nfeature selection and defines RBAs within that context. Next, we introduce the\noriginal Relief algorithm and associated concepts, emphasizing the intuition\nbehind how it works, how feature weights generated by the algorithm can be\ninterpreted, and why it is sensitive to feature interactions without evaluating\ncombinations of features. Lastly, we include an expansive review of RBA\nmethodological research beyond Relief and its popular descendant, ReliefF. In\nparticular, we characterize branches of RBA research, and provide comparative\nsummaries of RBA algorithms including contributions, strategies, functionality,\ntime complexity, adaptation to key data characteristics, and software\navailability.\n"]},
{"authors": ["Kibok Lee", "Kimin Lee", "Kyle Min", "Yuting Zhang", "Jinwoo Shin", "Honglak Lee"], "title": ["Hierarchical Novelty Detection for Visual Object Recognition"], "date": ["2018-04-02T20:36:43Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00722v1"], "summary": ["  Deep neural networks have achieved impressive success in large-scale visual\nobject recognition tasks with a predefined set of classes. However, recognizing\nobjects of novel classes unseen during training still remains challenging. The\nproblem of detecting such novel classes has been addressed in the literature,\nbut most prior works have focused on providing simple binary or regressive\ndecisions, e.g., the output would be \"known,\" \"novel,\" or corresponding\nconfidence intervals. In this paper, we study more informative novelty\ndetection schemes based on a hierarchical classification framework. For an\nobject of a novel class, we aim for finding its closest super class in the\nhierarchical taxonomy of known classes. To this end, we propose two different\napproaches termed top-down and flatten methods, and their combination as well.\nThe essential ingredients of our methods are confidence-calibrated classifiers,\ndata relabeling, and the leave-one-out strategy for modeling novel classes\nunder the hierarchical taxonomy. Furthermore, our method can generate a\nhierarchical embedding that leads to improved generalized zero-shot learning\nperformance in combination with other commonly-used semantic embeddings.\n"]},
{"authors": ["Zachary Boyd", "Egil Bae", "Xue-Cheng Tai", "Andrea L. Bertozzi"], "title": ["Simplified Energy Landscape for Modularity Using Total Variation"], "date": ["2017-07-28T15:39:03Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1707.09285v3"], "summary": ["  Networks capture pairwise interactions between entities and are frequently\nused in applications such as social networks, food networks, and protein\ninteraction networks, to name a few. Communities, cohesive groups of nodes,\noften form in these applications, and identifying them gives insight into the\noverall organization of the network. One common quality function used to\nidentify community structure is modularity. In Hu et al. [SIAM J. App. Math.,\n73(6), 2013], it was shown that modularity optimization is equivalent to\nminimizing a particular nonconvex total variation (TV) based functional over a\ndiscrete domain. They solve this problem, assuming the number of communities is\nknown, using a Merriman, Bence, Osher (MBO) scheme.\n  We show that modularity optimization is equivalent to minimizing a convex\nTV-based functional over a discrete domain, again, assuming the number of\ncommunities is known. Furthermore, we show that modularity has no convex\nrelaxation satisfying certain natural conditions. We therefore, find a\nmanageable non-convex approximation using a Ginzburg Landau functional, which\nprovably converges to the correct energy in the limit of a certain parameter.\nWe then derive an MBO algorithm with fewer hand-tuned parameters than in Hu et\nal. and which is 7 times faster at solving the associated diffusion equation\ndue to the fact that the underlying discretization is unconditionally stable.\nOur numerical tests include a hyperspectral video whose associated graph has\n2.9x10^7 edges, which is roughly 37 times larger than was handled in the paper\nof Hu et al.\n"]},
{"authors": ["Anshul Ramachandran", "Ashwin Balakrishna", "Peter Kundzicz", "Anirudh Neti"], "title": ["Predicting Electric Vehicle Charging Station Usage: Using Machine\n  Learning to Estimate Individual Station Statistics from Physical\n  Configurations of Charging Station Networks"], "date": ["2018-04-02T19:41:47Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00714v1"], "summary": ["  Electric vehicles (EVs) have been gaining popularity due to their\nenvironmental friendliness and efficiency. EV charging station networks are\nscalable solutions for supporting increasing numbers of EVs within modern\nelectric grid constraints, yet few tools exist to aid the physical\nconfiguration design of new networks. We use neural networks to predict\nindividual charging station usage statistics from the station's physical\nlocation within a network. We have shown this quickly gives accurate estimates\nof average usage statistics given a proposed configuration, without the need\nfor running many computationally expensive simulations. The trained neural\nnetwork can help EV charging network designers rapidly test various placements\nof charging stations under additional individual constraints in order to find\nan optimal configuration given their design objectives.\n"]},
{"authors": ["Kemal Davaslioglu", "Yalin E. Sagduyu"], "title": ["Generative Adversarial Learning for Spectrum Sensing"], "date": ["2018-04-02T19:23:06Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00709v1"], "summary": ["  A novel approach of training data augmentation and domain adaptation is\npresented to support machine learning applications for cognitive radio. Machine\nlearning provides effective tools to automate cognitive radio functionalities\nby reliably extracting and learning intrinsic spectrum dynamics. However, there\nare two important challenges to overcome, in order to fully utilize the machine\nlearning benefits with cognitive radios. First, machine learning requires\nsignificant amount of truthed data to capture complex channel and emitter\ncharacteristics, and train the underlying algorithm (e.g., a classifier).\nSecond, the training data that has been identified for one spectrum environment\ncannot be used for another one (e.g., after channel and emitter conditions\nchange). To address these challenges, a generative adversarial network (GAN)\nwith deep learning structures is used to 1)~generate additional synthetic\ntraining data to improve classifier accuracy, and 2) adapt training data to\nspectrum dynamics. This approach is applied to spectrum sensing by assuming\nonly limited training data without knowledge of spectrum statistics. Machine\nlearning classifiers are trained with limited, augmented and adapted training\ndata to detect signals. Results show that training data augmentation increases\nthe classifier accuracy significantly and this increase is sustained with\ndomain adaptation as spectrum conditions change.\n"]},
{"authors": ["Eric Zhan", "Stephan Zheng", "Yisong Yue", "Long Sha", "Patrick Lucey"], "title": ["Generative Multi-Agent Behavioral Cloning"], "date": ["2018-03-20T19:19:13Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07612v4"], "summary": ["  We propose and study the problem of generative multi-agent behavioral\ncloning, where the goal is to learn a generative multi-agent policy from\npre-collected demonstration data. Building upon advances in deep generative\nmodels, we present a hierarchical policy framework that can tractably learn\ncomplex mappings from input states to distributions over multi-agent action\nspaces. Our framework is flexible and can incorporate high-level domain\nknowledge into the structure of the underlying deep graphical model. For\ninstance, we can effectively learn low-dimensional structures, such as\nlong-term goals and team coordination, from data. Thus, an additional benefit\nof our hierarchical approach is the ability to plan over multiple time scales\nfor effective long-term planning. We showcase our approach in an application of\nmodeling team offensive play from basketball tracking data. We show how to\ninstantiate our framework to effectively model complex interactions between\nbasketball players and generate realistic multi-agent trajectories of\nbasketball gameplay over long time periods. We validate our approach using both\nquantitative and qualitative evaluations, including a user study comparison\nconducted with professional sports analysts.\n"]},
{"authors": ["Bao Wang", "Xiyang Luo", "Fangbo Zhang", "Baichuan Yuan", "Andrea L. Bertozzi", "P. Jeffrey Brantingham"], "title": ["Graph-Based Deep Modeling and Real Time Forecasting of Sparse\n  Spatio-Temporal Data"], "date": ["2018-04-02T18:23:27Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00684v1"], "summary": ["  We present a generic framework for spatio-temporal (ST) data modeling,\nanalysis, and forecasting, with a special focus on data that is sparse in both\nspace and time. Our multi-scaled framework is a seamless coupling of two major\ncomponents: a self-exciting point process that models the macroscale\nstatistical behaviors of the ST data and a graph structured recurrent neural\nnetwork (GSRNN) to discover the microscale patterns of the ST data on the\ninferred graph. This novel deep neural network (DNN) incorporates the real time\ninteractions of the graph nodes to enable more accurate real time forecasting.\nThe effectiveness of our method is demonstrated on both crime and traffic\nforecasting.\n"]},
{"authors": ["Abubakar Abid", "James Zou"], "title": ["Stochastic EM for Shuffled Linear Regression"], "date": ["2018-04-02T18:13:49Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00681v1"], "summary": ["  We consider the problem of inference in a linear regression model in which\nthe relative ordering of the input features and output labels is not known.\nSuch datasets naturally arise from experiments in which the samples are\nshuffled or permuted during the protocol. In this work, we propose a framework\nthat treats the unknown permutation as a latent variable. We maximize the\nlikelihood of observations using a stochastic expectation-maximization (EM)\napproach. We compare this to the dominant approach in the literature, which\ncorresponds to hard EM in our framework. We show on synthetic data that the\nstochastic EM algorithm we develop has several advantages, including lower\nparameter error, less sensitivity to the choice of initialization, and\nsignificantly better performance on datasets that are only partially shuffled.\nWe conclude by performing two experiments on real datasets that have been\npartially shuffled, in which we show that the stochastic EM algorithm can\nrecover the weights with modest error.\n"]},
{"authors": ["Yeming Wen", "Paul Vicol", "Jimmy Ba", "Dustin Tran", "Roger Grosse"], "title": ["Flipout: Efficient Pseudo-Independent Weight Perturbations on\n  Mini-Batches"], "date": ["2018-03-12T17:25:21Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04386v2"], "summary": ["  Stochastic neural net weights are used in a variety of contexts, including\nregularization, Bayesian neural nets, exploration in reinforcement learning,\nand evolution strategies. Unfortunately, due to the large number of weights,\nall the examples in a mini-batch typically share the same weight perturbation,\nthereby limiting the variance reduction effect of large mini-batches. We\nintroduce flipout, an efficient method for decorrelating the gradients within a\nmini-batch by implicitly sampling pseudo-independent weight perturbations for\neach example. Empirically, flipout achieves the ideal linear variance reduction\nfor fully connected networks, convolutional networks, and RNNs. We find\nsignificant speedups in training neural networks with multiplicative Gaussian\nperturbations. We show that flipout is effective at regularizing LSTMs, and\noutperforms previous methods. Flipout also enables us to vectorize evolution\nstrategies: in our experiments, a single GPU with flipout can handle the same\nthroughput as at least 40 CPU cores using existing methods, equivalent to a\nfactor-of-4 cost reduction on Amazon Web Services.\n"]},
{"authors": ["Dionysios S. Kalogerias", "Warren B. Powell"], "title": ["Recursive Optimization of Convex Risk Measures: Mean-Semideviation\n  Models"], "date": ["2018-04-02T17:27:52Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00636v1"], "summary": ["  We develop and analyze stochastic subgradient methods for optimizing a new,\nversatile, application-friendly and tractable class of convex risk measures,\ntermed here as mean-semideviations. Their construction relies on on the concept\nof a risk regularizer, a one-dimensional nonlinear map with certain properties,\nessentially generalizing the positive part weighting function in the\nmean-upper-semideviation risk measure. After we formally introduce\nmean-semideviations, we study their basic properties, and we present a\nfundamental constructive characterization result, demonstrating their\ngenerality.\n  We then introduce and rigorously analyze the MESSAGEp algorithm, an efficient\nstochastic subgradient procedure for iteratively solving convex\nmean-semideviation risk-averse problems to optimality. The MESSAGEp algorithm\nmay be derived as an application of the T-SCGD algorithm of (Yang et al.,\n2018). However, the generic theoretical framework of (Yang et al., 2018) is too\nnarrow and structurally restrictive, as far as optimization of\nmean-semideviations is concerned, including the classical\nmean-upper-semideviation risk measure. By exploiting problem structure, we\npropose a substantially weaker theoretical framework, under which we establish\npathwise convergence of the MESSAGEp algorithm, under the same strong sense as\nin (Yang et al., 2018). The new framework reveals a fundamental trade-off\nbetween the smoothness of the random position function and that of the\nparticular mean-semideviation risk measure under consideration. Further, we\nexplicitly show that the class of mean-semideviation problems supported under\nour framework is strictly larger than the respective class of problems\nsupported in (Yang et al., 2018). Thus, applicability of compositional\nstochastic optimization is established for a strictly wider spectrum of\nmean-semideviation problems, justifying the purpose of our work.\n"]},
{"authors": ["Vasileios Tzoumas", "Ali Jadbabaie", "George J. Pappas"], "title": ["Resilient Non-Submodular Maximization over Matroid Constraints"], "date": ["2018-04-02T17:26:26Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01013v1"], "summary": ["  Applications in control, robotics, and optimization motivate the design of\nsystems by selecting system elements, such as actuators, sensors, or data,\nsubject to complex design constraints that require the system elements not only\nto be a few in number, but also, to satisfy heterogeneity or\nglobal-interdependency constraints; in particular, matroid constraints.\nHowever, in failure-prone and adversarial environments, sensors get attacked;\nactuators fail; data get deleted. Thence, traditional matroid-constrained\ndesign paradigms become insufficient and, in contrast, resilient\nmatroid-constrained designs against attacks, failures, or deletions become\nimportant. In general, resilient matroid-constrained design problems are\ncomputationally hard. Also, even though they often involve objective functions\nthat are monotone and (possibly) submodular, no scalable approximation\nalgorithms are known for their solution. In this paper, we provide the first\nalgorithm, that achieves the following characteristics: system-wide resiliency,\ni.e., the algorithm is valid for any number of denial-of-service attacks,\ndeletions, or failures; minimal running time, i.e., the algorithm terminates\nwith the same running time as state-of-the-art algorithms for (non-resilient)\nmatroid-constrained optimization; and provable approximation performance, i.e.,\nthe algorithm guarantees for monotone objective functions a solution close to\nthe optimal. We quantify the algorithm's approximation performance using a\nnotion of curvature for monotone (not necessarily submodular) set functions.\nFinally, we support our theoretical analyses with numerical experiments, by\nconsidering a control-aware sensor selection scenario, namely,\nsensing-constrained robot navigation.\n"]},
{"authors": ["Mihai Cucuringu", "Hemant Tyagi"], "title": ["On denoising modulo 1 samples of a function"], "date": ["2017-10-27T15:55:50Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.10210v4"], "summary": ["  Consider an unknown smooth function $f: [0,1] \\rightarrow \\mathbb{R}$, and\nsay we are given $n$ noisy$\\mod 1$ samples of $f$, i.e., $y_i = (f(x_i) +\n\\eta_i)\\mod 1$ for $x_i \\in [0,1]$, where $\\eta_i$ denotes noise. Given the\nsamples $(x_i,y_i)_{i=1}^{n}$ our goal is to recover smooth, robust estimates\nof the clean samples $f(x_i) \\bmod 1$. We formulate a natural approach for\nsolving this problem which works with representations of mod 1 values over the\nunit circle. This amounts to solving a quadratically constrained quadratic\nprogram (QCQP) with non-convex constraints involving points lying on the unit\ncircle. Our proposed approach is based on solving its relaxation which is a\ntrust-region sub-problem, and hence solvable efficiently. We demonstrate its\nrobustness to noise % of our approach via extensive simulations on several\nsynthetic examples, and provide a detailed theoretical analysis.\n"]},
{"authors": ["George Papamakarios", "Iain Murray"], "title": ["Fast $\u03b5$-free Inference of Simulation Models with Bayesian\n  Conditional Density Estimation"], "date": ["2016-05-20T14:34:38Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1605.06376v4"], "summary": ["  Many statistical models can be simulated forwards but have intractable\nlikelihoods. Approximate Bayesian Computation (ABC) methods are used to infer\nproperties of these models from data. Traditionally these methods approximate\nthe posterior over parameters by conditioning on data being inside an\n$\\epsilon$-ball around the observed data, which is only correct in the limit\n$\\epsilon\\!\\rightarrow\\!0$. Monte Carlo methods can then draw samples from the\napproximate posterior to approximate predictions or error bars on parameters.\nThese algorithms critically slow down as $\\epsilon\\!\\rightarrow\\!0$, and in\npractice draw samples from a broader distribution than the posterior. We\npropose a new approach to likelihood-free inference based on Bayesian\nconditional density estimation. Preliminary inferences based on limited\nsimulation data are used to guide later simulations. In some cases, learning an\naccurate parametric representation of the entire true posterior distribution\nrequires fewer model simulations than Monte Carlo ABC methods need to produce a\nsingle sample from an approximate posterior.\n"]},
{"authors": ["Se Eun Oh", "Saikrishna Sunkam", "Nicholas Hopper"], "title": ["p-FP: Extraction, Classification, and Prediction of Website Fingerprints\n  with Deep Learning"], "date": ["2017-11-10T00:56:20Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.03656v2"], "summary": ["  Recent advances in learning Deep Neural Network (DNN) architectures have\nreceived a great deal of attention due to their ability to outperform\nstate-of-the-art classifiers across a wide range of applications, with little\nor no feature engineering. In this paper, we broadly study the applicability of\ndeep learning to website fingerprinting. We show that unsupervised DNNs can be\nused to extract low-dimensional feature vectors that improve the performance of\nstate-of-the-art website fingerprinting attacks. When used as classifiers, we\nshow that they can match or exceed performance of existing attacks across a\nrange of application scenarios, including fingerprinting Tor website traces,\nfingerprinting search engine queries over Tor, defeating fingerprinting\ndefenses, and fingerprinting TLS-encrypted websites. Finally, we show that DNNs\ncan be used to predict the fingerprintability of a website based on its\ncontents, achieving 99% accuracy on a data set of 4500 website downloads.\n"]},
{"authors": ["D. Belomestny", "L. Iosipoi", "N. Zhivotovskiy"], "title": ["Variance reduction via empirical variance minimization: convergence and\n  complexity"], "date": ["2017-12-13T09:09:09Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1712.04667v2"], "summary": ["  In this paper we propose and study a generic variance reduction approach. The\nproposed method is based on minimization of the empirical variance over a\nsuitable class of zero mean control functionals. We discuss several\npossibilities of constructing zero mean control functionals and present the\ncorresponding convergence analysis. Finally, a simulation study showing the\nnumerical efficiency of the proposed approach is presented.\n"]},
{"authors": ["Luiz G. Hafemann", "Robert Sabourin", "Luiz S. Oliveira"], "title": ["Fixed-sized representation learning from Offline Handwritten Signatures\n  of different sizes"], "date": ["2018-04-02T11:07:01Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00448v1"], "summary": ["  Methods for learning feature representations for Offline Handwritten\nSignature Verification have been successfully proposed in recent literature,\nusing Deep Convolutional Neural Networks to learn representations from\nsignature pixels. Such methods reported large performance improvements compared\nto handcrafted feature extractors. However, they also introduced an important\nconstraint: the inputs to the neural networks must have a fixed size, while\nsignatures vary significantly in size between different users. In this paper we\npropose addressing this issue by learning a fixed-sized representation from\nvariable-sized signatures by modifying the network architecture, using Spatial\nPyramid Pooling. We also investigate the impact of the resolution of the images\nused for training, and the impact of adapting (fine-tuning) the representations\nto new operating conditions (different acquisition protocols, such as writing\ninstruments and scan resolution). On the GPDS dataset, we achieve results\ncomparable with the state-of-the-art, while removing the constraint of having a\nmaximum size for the signatures to be processed. We also show that using higher\nresolutions (300 or 600dpi) can improve performance when skilled forgeries from\na subset of users are available for feature learning, but lower resolutions\n(around 100dpi) can be used if only genuine signatures are used. Lastly, we\nshow that fine-tuning can improve performance when the operating conditions\nchange.\n"]},
{"authors": ["Dongwook Lee", "Jaejun Yoo", "Sungho Tak", "Jong Chul Ye"], "title": ["Deep Residual Learning for Accelerated MRI using Magnitude and Phase\n  Networks"], "date": ["2018-04-02T09:08:02Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00432v1"], "summary": ["  Accelerated magnetic resonance (MR) scan acquisition with compressed sensing\n(CS) and parallel imaging is a powerful method to reduce MR imaging scan time.\nHowever, many reconstruction algorithms have high computational costs. To\naddress this, we investigate deep residual learning networks to remove aliasing\nartifacts from artifact corrupted images. The proposed deep residual learning\nnetworks are composed of magnitude and phase networks that are separately\ntrained. If both phase and magnitude information are available, the proposed\nalgorithm can work as an iterative k-space interpolation algorithm using\nframelet representation. When only magnitude data is available, the proposed\napproach works as an image domain post-processing algorithm. Even with strong\ncoherent aliasing artifacts, the proposed network successfully learned and\nremoved the aliasing artifacts, whereas current parallel and CS reconstruction\nmethods were unable to remove these artifacts. Comparisons using single and\nmultiple coil show that the proposed residual network provides good\nreconstruction results with orders of magnitude faster computational time than\nexisting compressed sensing methods. The proposed deep learning framework may\nhave a great potential for accelerated MR reconstruction by generating accurate\nresults immediately.\n"]},
{"authors": ["Fuming Fang", "Junichi Yamagishi", "Isao Echizen", "Jaime Lorenzo-Trueba"], "title": ["High-quality nonparallel voice conversion based on cycle-consistent\n  adversarial network"], "date": ["2018-04-02T07:58:23Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00425v1"], "summary": ["  Although voice conversion (VC) algorithms have achieved remarkable success\nalong with the development of machine learning, superior performance is still\ndifficult to achieve when using nonparallel data. In this paper, we propose\nusing a cycle-consistent adversarial network (CycleGAN) for nonparallel\ndata-based VC training. A CycleGAN is a generative adversarial network (GAN)\noriginally developed for unpaired image-to-image translation. A subjective\nevaluation of inter-gender conversion demonstrated that the proposed method\nsignificantly outperformed a method based on the Merlin open source neural\nnetwork speech synthesis system (a parallel VC system adapted for our setup)\nand a GAN-based parallel VC system. This is the first research to show that the\nperformance of a nonparallel VC method can exceed that of state-of-the-art\nparallel VC methods.\n"]},
{"authors": ["Ke Ding"], "title": ["A Note on Kaldi's PLDA Implementation"], "date": ["2018-04-02T05:44:59Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00403v1"], "summary": ["  Some explanations to Kaldi's PLDA implementation to make formula derivation\neasier to catch.\n"]},
{"authors": ["Shiyu Duan", "Yunmei Chen", "Jose Principe"], "title": ["Learning Multiple Levels of Representations with Kernel Machines"], "date": ["2018-02-11T17:18:28Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.03774v2"], "summary": ["  We propose a connectionist-inspired kernel machine model with three key\nadvantages over traditional kernel machines. First, it is capable of learning\ndistributed and hierarchical representations. Second, its performance is highly\nrobust to the choice of kernel function. Third, the solution space is not\nlimited to the span of images of training data in reproducing kernel Hilbert\nspace (RKHS). Together with the architecture, we propose a greedy learning\nalgorithm that allows the proposed multilayer network to be trained layer-wise\nwithout backpropagation by optimizing the geometric properties of images in\nRKHS. With a single fixed generic kernel for each layer and two layers in\ntotal, our model compares favorably with state-of-the-art multiple kernel\nlearning algorithms using significantly more kernels and popular deep\narchitectures on widely used classification benchmarks.\n"]},
{"authors": ["Anirudh Goyal", "Philemon Brakel", "William Fedus", "Timothy Lillicrap", "Sergey Levine", "Hugo Larochelle", "Yoshua Bengio"], "title": ["Recall Traces: Backtracking Models for Efficient Reinforcement Learning"], "date": ["2018-04-02T03:02:33Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00379v1"], "summary": ["  In many environments only a tiny subset of all states yield high reward. In\nthese cases, few of the interactions with the environment provide a relevant\nlearning signal. Hence, we may want to preferentially train on those\nhigh-reward states and the probable trajectories leading to them. To this end,\nwe advocate for the use of a backtracking model that predicts the preceding\nstates that terminate at a given high-reward state. We can train a model which,\nstarting from a high value state (or one that is estimated to have high value),\npredicts and sample for which the (state, action)-tuples may have led to that\nhigh value state. These traces of (state, action) pairs, which we refer to as\nRecall Traces, sampled from this backtracking model starting from a high value\nstate, are informative as they terminate in good states, and hence we can use\nthese traces to improve a policy. We provide a variational interpretation for\nthis idea and a practical algorithm in which the backtracking model samples\nfrom an approximate posterior distribution over trajectories which lead to\nlarge rewards. Our method improves the sample efficiency of both on- and\noff-policy RL algorithms across several environments and tasks.\n"]},
{"authors": ["Xi-Lin Li"], "title": ["On the Performance of Preconditioned Stochastic Gradient Descent"], "date": ["2018-03-26T01:39:27Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09383v2"], "summary": ["  This paper studies the performance of preconditioned stochastic gradient\ndescent (PSGD), which can be regarded as an enhance stochastic Newton method\nwith the ability to handle gradient noise and non-convexity at the same time.\nWe have improved the implementation of PSGD, unrevealed its relationship to\nequilibrated stochastic gradient descent (ESGD) and feature normalization, and\nprovided a software package (https://github.com/lixilinx/psgd_tf) implemented\nin Tensorflow to compare PSGD with four different preconditioners and\nvariations of stochastic gradient descent (SGD) on a wide range of benchmark\nproblems with commonly used neural network models, e.g., convolutional and\nrecurrent neural networks. Comparison results clearly demonstrate the\nadvantages of PSGD in terms of convergence speeds and generalization\nperformances.\n"]},
{"authors": ["Ruiyi Zhang", "Chunyuan Li", "Changyou Chen", "Lawrence Carin"], "title": ["Learning Structural Weight Uncertainty for Sequential Decision-Making"], "date": ["2017-12-30T04:34:34Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1801.00085v2"], "summary": ["  Learning probability distributions on the weights of neural networks (NNs)\nhas recently proven beneficial in many applications. Bayesian methods, such as\nStein variational gradient descent (SVGD), offer an elegant framework to reason\nabout NN model uncertainty. However, by assuming independent Gaussian priors\nfor the individual NN weights (as often applied), SVGD does not impose prior\nknowledge that there is often structural information (dependence) among\nweights. We propose efficient posterior learning of structural weight\nuncertainty, within an SVGD framework, by employing matrix variate Gaussian\npriors on NN parameters. We further investigate the learned structural\nuncertainty in sequential decision-making problems, including contextual\nbandits and reinforcement learning. Experiments on several synthetic and real\ndatasets indicate the superiority of our model, compared with state-of-the-art\nmethods.\n"]},
{"authors": ["\u0141ukasz Kidzi\u0144ski", "Sharada Prasanna Mohanty", "Carmichael Ong", "Zhewei Huang", "Shuchang Zhou", "Anton Pechenko", "Adam Stelmaszczyk", "Piotr Jarosik", "Mikhail Pavlov", "Sergey Kolesnikov", "Sergey Plis", "Zhibo Chen", "Zhizheng Zhang", "Jiale Chen", "Jun Shi", "Zhuobin Zheng", "Chun Yuan", "Zhihui Lin", "Henryk Michalewski", "Piotr Mi\u0142o\u015b", "B\u0142a\u017cej Osi\u0144ski", "Andrew Melnik", "Malte Schilling", "Helge Ritter", "Sean Carroll", "Jennifer Hicks", "Sergey Levine", "Marcel Salath\u00e9", "Scott Delp"], "title": ["Learning to Run challenge solutions: Adapting reinforcement learning\n  methods for neuromusculoskeletal environments"], "date": ["2018-04-02T00:19:31Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00361v1"], "summary": ["  In the NIPS 2017 Learning to Run challenge, participants were tasked with\nbuilding a controller for a musculoskeletal model to make it run as fast as\npossible through an obstacle course. Top participants were invited to describe\ntheir algorithms. In this work, we present eight solutions that used deep\nreinforcement learning approaches, based on algorithms such as Deep\nDeterministic Policy Gradient, Proximal Policy Optimization, and Trust Region\nPolicy Optimization. Many solutions use similar relaxations and heuristics,\nsuch as reward shaping, frame skipping, discretization of the action space,\nsymmetry, and policy blending. However, each of the eight teams implemented\ndifferent modifications of the known algorithms.\n"]},
{"authors": ["Swami Sankaranarayanan", "Yogesh Balaji", "Arpit Jain", "Ser Nam Lim", "Rama Chellappa"], "title": ["Learning from Synthetic Data: Addressing Domain Shift for Semantic\n  Segmentation"], "date": ["2017-11-19T05:25:24Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.06969v2"], "summary": ["  Visual Domain Adaptation is a problem of immense importance in computer\nvision. Previous approaches showcase the inability of even deep neural networks\nto learn informative representations across domain shift. This problem is more\nsevere for tasks where acquiring hand labeled data is extremely hard and\ntedious. In this work, we focus on adapting the representations learned by\nsegmentation networks across synthetic and real domains. Contrary to previous\napproaches that use a simple adversarial objective or superpixel information to\naid the process, we propose an approach based on Generative Adversarial\nNetworks (GANs) that brings the embeddings closer in the learned feature space.\nTo showcase the generality and scalability of our approach, we show that we can\nachieve state of the art results on two challenging scenarios of synthetic to\nreal domain adaptation. Additional exploratory experiments show that our\napproach: (1) generalizes to unseen domains and (2) results in improved\nalignment of source and target distributions.\n"]},
{"authors": ["Feras A. Saad", "Vikash K. Mansinghka"], "title": ["Temporally-Reweighted Chinese Restaurant Process Mixtures for\n  Clustering, Imputing, and Forecasting Multivariate Time Series"], "date": ["2017-10-18T19:17:43Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.06900v2"], "summary": ["  This article proposes a Bayesian nonparametric method for forecasting,\nimputation, and clustering in sparsely observed, multivariate time series data.\nThe method is appropriate for jointly modeling hundreds of time series with\nwidely varying, non-stationary dynamics. Given a collection of $N$ time series,\nthe Bayesian model first partitions them into independent clusters using a\nChinese restaurant process prior. Within a cluster, all time series are modeled\njointly using a novel \"temporally-reweighted\" extension of the Chinese\nrestaurant process mixture. Markov chain Monte Carlo techniques are used to\nobtain samples from the posterior distribution, which are then used to form\npredictive inferences. We apply the technique to challenging forecasting and\nimputation tasks using seasonal flu data from the US Center for Disease Control\nand Prevention, demonstrating superior forecasting accuracy and competitive\nimputation accuracy as compared to multiple widely used baselines. We further\nshow that the model discovers interpretable clusters in datasets with hundreds\nof time series, using macroeconomic data from the Gapminder Foundation.\n"]},
{"authors": ["N. Benjamin Erichson", "Peng Zeng", "Krithika Manohar", "Steven L. Brunton", "J. Nathan Kutz", "Aleksandr Y. Aravkin"], "title": ["Sparse Principal Component Analysis via Variable Projection"], "date": ["2018-04-01T20:49:56Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00341v1"], "summary": ["  Sparse principal component analysis (SPCA) has emerged as a powerful\ntechnique for modern data analysis. We discuss a robust and scalable algorithm\nfor computing sparse principal component analysis. Specifically, we model SPCA\nas a matrix factorization problem with orthogonality constraints, and develop\nspecialized optimization algorithms that partially minimize a subset of the\nvariables (variable projection). The framework incorporates a wide variety of\nsparsity-inducing regularizers for SPCA. We also extend the variable projection\napproach to robust SPCA, for any robust loss that can be expressed as the\nMoreau envelope of a simple function, with the canonical example of the Huber\nloss. Finally, randomized methods for linear algebra are used to extend the\napproach to the large-scale (big data) setting. The proposed algorithms are\ndemonstrated using both synthetic and real world data.\n"]},
{"authors": ["Aubrey Gress", "Ian Davidson"], "title": ["Probabilistic Formulations of Regression with Mixed Guidance"], "date": ["2018-04-01T20:36:33Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.01575v1"], "summary": ["  Regression problems assume every instance is annotated (labeled) with a real\nvalue, a form of annotation we call \\emph{strong guidance}. In order for these\nannotations to be accurate, they must be the result of a precise experiment or\nmeasurement. However, in some cases additional \\emph{weak guidance} might be\ngiven by imprecise measurements, a domain expert or even crowd sourcing.\nCurrent formulations of regression are unable to use both types of guidance. We\npropose a regression framework that can also incorporate weak guidance based on\nrelative orderings, bounds, neighboring and similarity relations. Consider\nlearning to predict ages from portrait images, these new types of guidance\nallow weaker forms of guidance such as stating a person is in their 20s or two\npeople are similar in age. These types of annotations can be easier to generate\nthan strong guidance. We introduce a probabilistic formulation for these forms\nof weak guidance and show that the resulting optimization problems are convex.\nOur experimental results show the benefits of these formulations on several\ndata sets.\n"]},
{"authors": ["Le Liang", "Hao Ye", "Geoffrey Ye Li"], "title": ["Towards Intelligent Vehicular Networks: A Machine Learning Framework"], "date": ["2018-04-01T20:28:18Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00338v1"], "summary": ["  As wireless networks evolve towards high mobility and providing better\nsupport for connected vehicles, a number of new challenges arise due to the\nresulting high dynamics in vehicular environments and thus motive rethinking of\ntraditional wireless design methodologies. Future intelligent vehicles, which\nare at the heart of high mobility networks, are increasingly equipped with\nmultiple advanced onboard sensors and keep generating large volumes of data.\nMachine learning, as an effective approach to artificial intelligence, can\nprovide a rich set of tools to exploit such data for the benefit of the\nnetworks. In this article, we first identify the distinctive characteristics of\nhigh mobility vehicular networks and motivate the use of machine learning to\naddress the resulting challenges. After a brief introduction of the major\nconcepts of machine learning, we discuss its applications to learn the dynamics\nof vehicular networks and make informed decisions to optimize network\nperformance. In particular, we discuss in greater detail the application of\nreinforcement learning in managing network resources as an alternative to the\nprevalent optimization approach. Finally, some open issues worth further\ninvestigation are highlighted.\n"]},
{"authors": ["Zhili Feng", "Po-Ling Loh"], "title": ["Online learning with graph-structured feedback against adaptive\n  adversaries"], "date": ["2018-04-01T19:56:10Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00335v1"], "summary": ["  We derive upper and lower bounds for the policy regret of $T$-round online\nlearning problems with graph-structured feedback, where the adversary is\nnonoblivious but assumed to have a bounded memory. We obtain upper bounds of\n$\\widetilde O(T^{2/3})$ and $\\widetilde O(T^{3/4})$ for strongly-observable and\nweakly-observable graphs, respectively, based on analyzing a variant of the\nExp3 algorithm. When the adversary is allowed a bounded memory of size 1, we\nshow that a matching lower bound of $\\widetilde\\Omega(T^{2/3})$ is achieved in\nthe case of full-information feedback. We also study the particular loss\nstructure of an oblivious adversary with switching costs, and show that in such\na setting, non-revealing strongly-observable feedback graphs achieve a lower\nbound of $\\widetilde\\Omega(T^{2/3})$, as well.\n"]},
{"authors": ["Bita Darvish Rouhani", "Mohammad Samragh", "Tara Javidi", "Farinaz Koushanfar"], "title": ["CuRTAIL: ChaRacterizing and Thwarting AdversarIal deep Learning"], "date": ["2017-09-08T04:53:51Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1709.02538v3"], "summary": ["  Recent advances in adversarial Deep Learning (DL) have opened up a new and\nlargely unexplored surface for malicious attacks jeopardizing the integrity of\nautonomous DL systems. This paper introduces CuRTAIL, a novel end-to-end\ncomputing framework to characterize and thwart potential adversarial attacks\nand significantly improve the reliability (safety) of a victim DL model. We\nformalize the goal of preventing adversarial attacks as an optimization problem\nto minimize the rarely observed regions in the latent feature space spanned by\na DL network. To solve the aforementioned minimization problem, a set of\ncomplementary but disjoint modular redundancies are trained to validate the\nlegitimacy of the input samples. The proposed countermeasure is unsupervised,\nmeaning that no adversarial sample is leveraged to train modular redundancies.\nThis, in turn, ensures the effectiveness of the defense in the face of generic\nattacks. We evaluate the robustness of our proposed methodology against the\nstate-of-the-art adaptive attacks in a white-box setting considering that the\nadversary knows everything about the victim model and its defenders. Extensive\nevaluations for analyzing MNIST, CIFAR10, and ImageNet data corroborate the\neffectiveness of CuRTAIL framework against adversarial samples. The\ncomputations in each modular redundancy can be performed independently of the\nother redundancy modules. As such, CuRTAIL detection algorithm can be\ncompletely parallelized among multiple hardware settings to achieve maximum\nthroughput. We further provide an open-source Application Programming Interface\n(API) to facilitate the adoption of the proposed framework for various\napplications.\n"]},
{"authors": ["James Lucas", "Richard Zemel", "Roger Grosse"], "title": ["Aggregated Momentum: Stability Through Passive Damping"], "date": ["2018-04-01T17:53:03Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00325v1"], "summary": ["  Momentum is a simple and widely used trick which allows gradient-based\noptimizers to pick up speed in low curvature directions. Its performance\ndepends crucially on a damping coefficient $\\beta$. Large $\\beta$ values can\npotentially deliver much larger speedups, but are prone to oscillations and\ninstability; hence one typically resorts to small values such as 0.5 or 0.9. We\npropose Aggregated Momentum (AggMo), a variant of momentum which combines\nmultiple velocity vectors with different $\\beta$ parameters. AggMo is trivial\nto implement, but significantly dampens oscillations, enabling it to remain\nstable even for aggressive $\\beta$ values such as 0.999. We reinterpret\nNesterov's accelerated gradient descent as a special case of AggMo and provide\ntheoretical convergence bounds for online convex optimization. Empirically, we\nfind that AggMo is a suitable drop-in replacement for other momentum methods,\nand frequently delivers faster convergence.\n"]},
{"authors": ["Fang Su", "Jing-Yan Wang"], "title": ["Domain transfer convolutional attribute embedding"], "date": ["2018-03-26T17:44:45Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09733v2"], "summary": ["  In this paper, we study the problem of transfer learning with the attribute\ndata. In the transfer learning problem, we want to leverage the data of the\nauxiliary and the target domains to build an effective model for the\nclassification problem in the target domain. Meanwhile, the attributes are\nnaturally stable cross different domains. This strongly motives us to learn\neffective domain transfer attribute representations. To this end, we proposed\nto embed the attributes of the data to a common space by using the powerful\nconvolutional neural network (CNN) model. The convolutional representations of\nthe data points are mapped to the corresponding attributes so that they can be\neffective embedding of the attributes. We also represent the data of different\ndomains by a domain-independent CNN, ant a domain-specific CNN, and combine\ntheir outputs with the attribute embedding to build the classification model.\nAn joint learning framework is constructed to minimize the classification\nerrors, the attribute mapping error, the mismatching of the domain-independent\nrepresentations cross different domains, and to encourage the the neighborhood\nsmoothness of representations in the target domain. The minimization problem is\nsolved by an iterative algorithm based on gradient descent. Experiments over\nbenchmark data sets of person re-identification, bankruptcy prediction, and\nspam email detection, show the effectiveness of the proposed method.\n"]},
{"authors": ["Prateek Jain", "Sham M. Kakade", "Rahul Kidambi", "Praneeth Netrapalli", "Aaron Sidford"], "title": ["Parallelizing Stochastic Gradient Descent for Least Squares Regression:\n  mini-batching, averaging, and model misspecification"], "date": ["2016-10-12T16:30:11Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1610.03774v3"], "summary": ["  This work characterizes the benefits of averaging schemes widely used in\nconjunction with stochastic gradient descent (SGD). In particular, this work\nprovides a sharp analysis of: (1) mini-batching, a method of averaging many\nsamples of a stochastic gradient to both reduce the variance of the stochastic\ngradient estimate and for parallelizing SGD and (2) tail-averaging, a method\ninvolving averaging the final few iterates of SGD to decrease the variance in\nSGD's final iterate. This work presents non-asymptotic excess risk bounds for\nthese schemes for the stochastic approximation problem of least squares\nregression.\n  Furthermore, this work establishes a precise problem-dependent extent to\nwhich mini-batch SGD yields provable near-linear parallelization speedups over\nSGD with batch size one. This allows for understanding learning rate versus\nbatch size tradeoffs for the final iterate of an SGD method. These results are\nthen utilized in providing a highly parallelizable SGD method that obtains the\nminimax risk with nearly the same number of serial updates as batch gradient\ndescent, improving significantly over existing SGD methods. A non-asymptotic\nanalysis of communication efficient parallelization schemes such as\nmodel-averaging/parameter mixing methods is then provided.\n  Finally, this work sheds light on some fundamental differences in SGD's\nbehavior when dealing with agnostic noise in the (non-realizable) least squares\nregression problem. In particular, the work shows that the stepsizes that\nensure minimax risk for the agnostic case must be a function of the noise\nproperties.\n  This paper builds on the operator view of analyzing SGD methods, introduced\nby Defossez and Bach (2015), followed by developing a novel analysis in\nbounding these operators to characterize the excess risk. These techniques are\nof broader interest in analyzing computational aspects of stochastic\napproximation.\n"]},
{"authors": ["Cun Mu", "Guang Yang", "Zheng Yan"], "title": ["Revisiting Skip-Gram Negative Sampling Model with Regularization"], "date": ["2018-04-01T15:41:01Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00306v1"], "summary": ["  We revisit skip-gram negative sampling (SGNS), a popular neural-network based\napproach to learning distributed word representation. We first point out the\nambiguity issue undermining the SGNS model, in the sense that the word vectors\ncan be entirely distorted without changing the objective value. To resolve this\nissue, we rectify the SGNS model with quadratic regularization. A theoretical\njustification, which provides a novel insight into quadratic regularization, is\npresented. Preliminary experiments are also conducted on Google's analytical\nreasoning task to support the modified SGNS model.\n"]},
{"authors": ["Ronald Kemker", "Utsav B. Gewali", "Christopher Kanan"], "title": ["EarthMapper: A Tool Box for the Semantic Segmentation of Remote Sensing\n  Imagery"], "date": ["2018-04-01T12:44:20Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00292v1"], "summary": ["  Deep learning continues to push state-of-the-art performance for the semantic\nsegmentation of color (i.e., RGB) imagery; however, the lack of annotated data\nfor many remote sensing sensors (i.e. hyperspectral imagery (HSI)) prevents\nresearchers from taking advantage of this recent success. Since generating\nsensor specific datasets is time intensive and cost prohibitive, remote sensing\nresearchers have embraced deep unsupervised feature extraction. Although these\nmethods have pushed state-of-the-art performance on current HSI benchmarks,\nmany of these tools are not readily accessible to many researchers. In this\nletter, we introduce a software pipeline, which we call EarthMapper, for the\nsemantic segmentation of non-RGB remote sensing imagery. It includes\nself-taught spatial-spectral feature extraction, various standard and deep\nlearning classifiers, and undirected graphical models for post-processing. We\nevaluated EarthMapper on the Indian Pines and Pavia University datasets and\nhave released this code for public use.\n"]},
{"authors": ["Zhikuan Zhao", "Vedran Dunjko", "Jack K. Fitzsimons", "Patrick Rebentrost", "Joseph F. Fitzsimons"], "title": ["A note on state preparation for quantum machine learning"], "date": ["2018-04-01T11:10:00Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00281v1"], "summary": ["  The intersection between the fields of machine learning and quantum\ninformation processing is proving to be a fruitful field for the discovery of\nnew quantum algorithms, which potentially offer an exponential speed-up over\ntheir classical counterparts. However, many such algorithms require the ability\nto produce states proportional to vectors stored in quantum memory. Even given\naccess to quantum databases which store exponentially long vectors, the\nconstruction of which is considered a one-off overhead, it has been argued that\nthe cost of preparing such amplitude-encoded states may offset any exponential\nquantum advantage. Here we argue that specifically in the context of machine\nlearning applications it suffices to prepare a state close to the ideal state\nonly in the $\\infty$-norm, and that this can be achieved with only a constant\nnumber of memory queries.\n"]},
{"authors": ["Zhiting Hu", "Zichao Yang", "Ruslan Salakhutdinov", "Eric P. Xing"], "title": ["On Unifying Deep Generative Models"], "date": ["2017-06-02T04:15:44Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1706.00550v4"], "summary": ["  Deep generative models have achieved impressive success in recent years.\nGenerative Adversarial Networks (GANs) and Variational Autoencoders (VAEs), as\npowerful frameworks for deep generative model learning, have largely been\nconsidered as two distinct paradigms and received extensive independent studies\nrespectively. This paper aims to establish formal connections between GANs and\nVAEs through a new formulation of them. We interpret sample generation in GANs\nas performing posterior inference, and show that GANs and VAEs involve\nminimizing KL divergences of respective posterior and inference distributions\nwith opposite directions, extending the two learning phases of classic\nwake-sleep algorithm, respectively. The unified view provides a powerful tool\nto analyze a diverse set of existing model variants, and enables to transfer\ntechniques across research lines in a principled way. For example, we apply the\nimportance weighting method in VAE literatures for improved GAN learning, and\nenhance VAEs with an adversarial mechanism that leverages generated samples.\nExperiments show generality and effectiveness of the transfered techniques.\n"]},
{"authors": ["Eric F. Lock", "Gen Li"], "title": ["Supervised multiway factorization"], "date": ["2016-09-11T23:12:54Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1609.03228v2"], "summary": ["  We describe a probabilistic PARAFAC/CANDECOMP (CP) factorization for multiway\n(i.e., tensor) data that incorporates auxiliary covariates, SupCP. SupCP\ngeneralizes the supervised singular value decomposition (SupSVD) for\nvector-valued observations, to allow for observations that have the form of a\nmatrix or higher-order array. Such data are increasingly encountered in\nbiomedical research and other fields. We describe a likelihood-based latent\nvariable representation of the CP factorization, in which the latent variables\nare informed by additional covariates. We give conditions for identifiability,\nand develop an EM algorithm for simultaneous estimation of all model\nparameters. SupCP can be used for dimension reduction, capturing latent\nstructures that are more accurate and interpretable due to covariate\nsupervision. Moreover, SupCP specifies a full probability distribution for a\nmultiway data observation with given covariate values, which can be used for\npredictive modeling. We conduct comprehensive simulations to evaluate the SupCP\nalgorithm. We apply it to a facial image database with facial descriptors\n(e.g., smiling / not smiling) as covariates, and to a study of amino acid\nfluorescence. Software is available at https://github.com/lockEF/SupCP .\n"]},
{"authors": ["Baochang Zhang", "Lian Zhuo", "Ze Wang", "Jungong Han", "Xiantong Zhen"], "title": ["The Structure Transfer Machine Theory and Applications"], "date": ["2018-04-01T01:40:10Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00243v1"], "summary": ["  Representation learning is a fundamental but challenging problem, especially\nwhen the distribution of data is unknown. We propose a new representation\nlearning method, termed Structure Transfer Machine (STM), which enables feature\nlearning process to converge at the representation expectation in a\nprobabilistic way. We theoretically show that such an expected value of the\nrepresentation (mean) is achievable if the manifold structure can be\ntransferred from the data space to the feature space. The resulting structure\nregularization term, named manifold loss, is incorporated into the loss\nfunction of the typical deep learning pipeline. The STM architecture is\nconstructed to enforce the learned deep representation to satisfy the intrinsic\nmanifold structure from the data, which results in robust features that suit\nvarious application scenarios, such as digit recognition, image classification\nand object tracking. Compared to state-of-the-art CNN architectures, we achieve\nthe better results on several commonly used benchmarks\\footnote{The source code\nis available. https://github.com/stmstmstm/stm }.\n"]},
{"authors": ["Andreas K\u00f6lsch", "Ashutosh Mishra", "Saurabh Varshneya", "Marcus Liwicki"], "title": ["Recognizing Challenging Handwritten Annotations with Fully Convolutional\n  Networks"], "date": ["2018-04-01T00:56:02Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00236v1"], "summary": ["  This paper introduces a very challenging dataset of historic German documents\nand evaluates Fully Convolutional Neural Network (FCNN) based methods to locate\nhandwritten annotations of any kind in these documents. The handwritten\nannotations can appear in form of underlines and text by using various writing\ninstruments, e.g., the use of pencils makes the data more challenging. We train\nand evaluate various end-to-end semantic segmentation approaches and report the\nresults. The task is to classify the pixels of documents into two classes:\nbackground and handwritten annotation. The best model achieves a mean\nIntersection over Union (IoU) score of 95.6% on the test documents of the\npresented dataset. We also present a comparison of different strategies used\nfor data augmentation and training on our presented dataset. For evaluation, we\nuse the Layout Analysis Evaluator for the ICDAR 2017 Competition on Layout\nAnalysis for Challenging Medieval Manuscripts.\n"]},
{"authors": ["Luke Metz", "Niru Maheswaranathan", "Brian Cheung", "Jascha Sohl-Dickstein"], "title": ["Learning Unsupervised Learning Rules"], "date": ["2018-03-31T22:44:28Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00222v1"], "summary": ["  A major goal of unsupervised learning is to discover data representations\nthat are useful for subsequent tasks, without access to supervised labels\nduring training. Typically, this goal is approached by minimizing a surrogate\nobjective, such as the negative log likelihood of a generative model, with the\nhope that representations useful for subsequent tasks will arise as a side\neffect. In this work, we propose instead to directly target a later desired\ntask by meta-learning an unsupervised learning rule, which leads to\nrepresentations useful for that task. Here, our desired task (meta-objective)\nis the performance of the representation on semi-supervised classification, and\nwe meta-learn an algorithm -- an unsupervised weight update rule -- that\nproduces representations that perform well under this meta-objective.\nAdditionally, we constrain our unsupervised update rule to a be a\nbiologically-motivated, neuron-local function, which enables it to generalize\nto novel neural network architectures. We show that the meta-learned update\nrule produces useful features and sometimes outperforms existing unsupervised\nlearning techniques. We show that the meta-learned unsupervised update rule\ngeneralizes to train networks with different widths, depths, and\nnonlinearities. It also generalizes to train on data with randomly permuted\ninput dimensions and even generalizes from image datasets to a text task.\n"]},
{"authors": ["Lazar Valkov", "Dipak Chaudhari", "Akash Srivastava", "Charles Sutton", "Swarat Chaudhuri"], "title": ["Synthesis of Differentiable Functional Programs for Lifelong Learning"], "date": ["2018-03-31T21:34:50Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00218v1"], "summary": ["  We present a neurosymbolic approach to the lifelong learning of algorithmic\ntasks that mix perception and procedural reasoning. Reusing highlevel concepts\nacross domains and learning complex procedures are two key challenges in\nlifelong learning. We show that a combination of gradientbased learning and\nsymbolic program synthesis can be a more effective response to these challenges\nthan purely neural methods. Concretely, our approach, called HOUDINI,\nrepresents neural networks as strongly typed, end-to-end differentiable\nfunctional programs that use symbolic higher-order combinators to compose a\nlibrary of neural functions. Our learning algorithm consists of: (1) a program\nsynthesizer that performs a type-directed search over programs in this\nlanguage, and decides on the library functions that should be reused and the\narchitectures that should be used to combine them; and (2) a neural module that\ntrains synthesized programs using stochastic gradient descent. We evaluate our\napproach on three algorithmic tasks. Our experiments show that our\ntype-directed search technique is able to significantly prune the search space\nof programs, and that the overall approach transfers high-level concepts more\neffectively than monolithic neural networks as well as traditional transfer\nlearning.\n"]},
{"authors": ["A. Salman Avestimehr", "Seyed Mohammadreza Mousavi Kalan", "Mahdi Soltanolkotabi"], "title": ["Fundamental Resource Trade-offs for Encoded Distributed Optimization"], "date": ["2018-03-31T21:29:33Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00217v1"], "summary": ["  Dealing with the shear size and complexity of today's massive data sets\nrequires computational platforms that can analyze data in a parallelized and\ndistributed fashion. A major bottleneck that arises in such modern distributed\ncomputing environments is that some of the worker nodes may run slow. These\nnodes a.k.a.~stragglers can significantly slow down computation as the slowest\nnode may dictate the overall computational time. A recent computational\nframework, called encoded optimization, creates redundancy in the data to\nmitigate the effect of stragglers. In this paper we develop novel mathematical\nunderstanding for this framework demonstrating its effectiveness in much\nbroader settings than was previously understood. We also analyze the\nconvergence behavior of iterative encoded optimization algorithms, allowing us\nto characterize fundamental trade-offs between convergence rate, size of data\nset, accuracy, computational load (or data redundancy), and straggler\ntoleration in this framework.\n"]},
{"authors": ["Robert M. Gower", "Nicolas Le Roux", "Francis Bach"], "title": ["Tracking the gradients using the Hessian: A new look at variance\n  reducing stochastic methods"], "date": ["2017-10-20T09:31:06Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.07462v3"], "summary": ["  Our goal is to improve variance reducing stochastic methods through better\ncontrol variates. We first propose a modification of SVRG which uses the\nHessian to track gradients over time, rather than to recondition, increasing\nthe correlation of the control variates and leading to faster theoretical\nconvergence close to the optimum. We then propose accurate and computationally\nefficient approximations to the Hessian, both using a diagonal and a low-rank\nmatrix. Finally, we demonstrate the effectiveness of our method on a wide range\nof problems.\n"]},
{"authors": ["P Manisha", "Sujit Gujar"], "title": ["Generative Adversarial Networks (GANs): What it can generate and What it\n  cannot?"], "date": ["2018-03-31T09:01:21Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00140v1"], "summary": ["  Why are Generative Adversarial Networks (GANs) so popular? What is the\npurpose of designing GANs? Can we justify functioning of GANs theoretically?\nHow are the theoretical guarantees? Are there any shortcomings?\n  With the popularity of GANs, the researchers across the globe have been\nperplexed by these questions. In the last year (2017), a plethora of research\npapers attempted to answer the above questions. In this article, we put in our\nbest efforts to compare and contrast different results and put forth a summary\nof theoretical contributions about GANs with focus on image/visual\napplications. Our main aim is to highlight the primary issues related to GANs\nthat each of these papers examine. Besides we provide insight into how each of\nthe discussed articles solve the concerned problems. We expect this summary\npaper to give a bird's eye view to a person wishing to understand the theory\nbehind GANs.\n"]},
{"authors": ["Ahmed Zaki", "Saikat Chatterjee", "Partha P. Mitra", "Lars K. Rasmussen"], "title": ["Locally Convex Sparse Learning over Networks"], "date": ["2018-03-31T07:50:38Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00130v1"], "summary": ["  We consider a distributed learning setup where a sparse signal is estimated\nover a network. Our main interest is to save communication resource for\ninformation exchange over the network and reduce processing time. Each node of\nthe network uses a convex optimization based algorithm that provides a locally\noptimum solution for that node. The nodes exchange their signal estimates over\nthe network in order to refine their local estimates. At a node, the\noptimization algorithm is based on an $\\ell_1$-norm minimization with\nappropriate modifications to promote sparsity as well as to include influence\nof estimates from neighboring nodes. Our expectation is that local estimates in\neach node improve fast and converge, resulting in a limited demand for\ncommunication of estimates between nodes and reducing the processing time. We\nprovide restricted-isometry-property (RIP)-based theoretical analysis on\nestimation quality. In the scenario of clean observation, it is shown that the\nlocal estimates converge to the exact sparse signal under certain technical\nconditions. Simulation results show that the proposed algorithms show\ncompetitive performance compared to a globally optimum distributed LASSO\nalgorithm in the sense of convergence speed and estimation error.\n"]},
{"authors": ["Z. Berkay Celik", "Patrick McDaniel", "Rauf Izmailov", "Nicolas Papernot", "Ryan Sheatsley", "Raquel Alvarez", "Ananthram Swami"], "title": ["Detection under Privileged Information"], "date": ["2016-03-31T15:28:45Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1603.09638v4"], "summary": ["  For well over a quarter century, detection systems have been driven by models\nlearned from input features collected from real or simulated environments. An\nartifact (e.g., network event, potential malware sample, suspicious email) is\ndeemed malicious or non-malicious based on its similarity to the learned model\nat runtime. However, the training of the models has been historically limited\nto only those features available at runtime. In this paper, we consider an\nalternate learning approach that trains models using \"privileged\"\ninformation--features available at training time but not at runtime--to improve\nthe accuracy and resilience of detection systems. In particular, we adapt and\nextend recent advances in knowledge transfer, model influence, and distillation\nto enable the use of forensic or other data unavailable at runtime in a range\nof security domains. An empirical evaluation shows that privileged information\nincreases precision and recall over a system with no privileged information: we\nobserve up to 7.7% relative decrease in detection error for fast-flux bot\ndetection, 8.6% for malware traffic detection, 7.3% for malware classification,\nand 16.9% for face recognition. We explore the limitations and applications of\ndifferent privileged information techniques in detection systems. Such\ntechniques provide a new means for detection systems to learn from data that\nwould otherwise not be available at runtime.\n"]},
{"authors": ["Emilien Dupont"], "title": ["Joint-VAE: Learning Disentangled Joint Continuous and Discrete\n  Representations"], "date": ["2018-03-31T01:37:56Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00104v1"], "summary": ["  We present a framework for learning disentangled and interpretable jointly\ncontinuous and discrete representations in an unsupervised manner. By\naugmenting the continuous latent distribution of variational autoencoders with\na relaxed discrete distribution and controlling the amount of information\nencoded in each latent unit, we show how continuous and categorical factors of\nvariation can be discovered automatically from data. The learned model also\ncontains an inference network which can infer quantities such as angle and\nwidth of objects from image data in a completely unsupervised manner. Our\nexperiments show that the framework disentangles continuous and discrete\ngenerative factors on various datasets, including disentangling digit type from\nstroke thickness, angle and width on MNIST, chair type from azimuth and width\non the Chairs dataset and age from azimuth on CelebA.\n"]},
{"authors": ["Alexey Kurakin", "Ian Goodfellow", "Samy Bengio", "Yinpeng Dong", "Fangzhou Liao", "Ming Liang", "Tianyu Pang", "Jun Zhu", "Xiaolin Hu", "Cihang Xie", "Jianyu Wang", "Zhishuai Zhang", "Zhou Ren", "Alan Yuille", "Sangxia Huang", "Yao Zhao", "Yuzhe Zhao", "Zhonglin Han", "Junjiajia Long", "Yerkebulan Berdibekov", "Takuya Akiba", "Seiya Tokui", "Motoki Abe"], "title": ["Adversarial Attacks and Defences Competition"], "date": ["2018-03-31T00:52:20Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00097v1"], "summary": ["  To accelerate research on adversarial examples and robustness of machine\nlearning classifiers, Google Brain organized a NIPS 2017 competition that\nencouraged researchers to develop new methods to generate adversarial examples\nas well as to develop new ways to defend against them. In this chapter, we\ndescribe the structure and organization of the competition and the solutions\ndeveloped by several of the top-placing teams.\n"]},
{"authors": ["Hiroaki Sasaki", "Takafumi Kanamori", "Aapo Hyv\u00e4rinen", "Gang Niu", "Masashi Sugiyama"], "title": ["Mode-Seeking Clustering and Density Ridge Estimation via Direct\n  Estimation of Density-Derivative-Ratios"], "date": ["2017-07-06T09:57:08Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1707.01711v3"], "summary": ["  Modes and ridges of the probability density function behind observed data are\nuseful geometric features. Mode-seeking clustering assigns cluster labels by\nassociating data samples with the nearest modes, and estimation of density\nridges enables us to find lower-dimensional structures hidden in data. A key\ntechnical challenge both in mode-seeking clustering and density ridge\nestimation is accurate estimation of the ratios of the first- and second-order\ndensity derivatives to the density. A naive approach takes a three-step\napproach of first estimating the data density, then computing its derivatives,\nand finally taking their ratios. However, this three-step approach can be\nunreliable because a good density estimator does not necessarily mean a good\ndensity derivative estimator, and division by the estimated density could\nsignificantly magnify the estimation error. To cope with these problems, we\npropose a novel estimator for the \\emph{density-derivative-ratios}. The\nproposed estimator does not involve density estimation, but rather\n\\emph{directly} approximates the ratios of density derivatives of any order.\nMoreover, we establish a convergence rate of the proposed estimator. Based on\nthe proposed estimator, novel methods both for mode-seeking clustering and\ndensity ridge estimation are developed, and the respective convergence rates to\nthe mode and ridge of the underlying density are also established. Finally, we\nexperimentally demonstrate that the developed methods significantly outperform\nexisting methods, particularly for relatively high-dimensional data.\n"]},
{"authors": ["Uri Shaham", "James Garritano", "Yutaro Yamada", "Ethan Weinberger", "Alex Cloninger", "Xiuyuan Cheng", "Kelly Stanton", "Yuval Kluger"], "title": ["Defending against Adversarial Images using Basis Functions\n  Transformations"], "date": ["2018-03-28T20:27:58Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10840v2"], "summary": ["  We study the effectiveness of various approaches that defend against\nadversarial attacks on deep networks via manipulations based on basis function\nrepresentations of images. Specifically, we experiment with low-pass filtering,\nPCA, JPEG compression, low resolution wavelet approximation, and\nsoft-thresholding. We evaluate these defense techniques using three types of\npopular attacks in black, gray and white-box settings. Our results show JPEG\ncompression tends to outperform the other tested defenses in most of the\nsettings considered, in addition to soft-thresholding, which performs well in\nspecific cases, and yields a more mild decrease in accuracy on benign examples.\nIn addition, we also mathematically derive a novel white-box attack in which\nthe adversarial perturbation is composed only of terms corresponding a to\npre-determined subset of the basis functions, of which a \"low frequency attack\"\nis a special case.\n"]},
{"authors": ["Edward Raff", "Jared Sylvester", "Charles Nicholas"], "title": ["Engineering a Simplified 0-Bit Consistent Weighted Sampling"], "date": ["2018-03-30T22:12:44Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00069v1"], "summary": ["  The Min-Hashing approach to sketching has become an important tool in data\nanalysis, search, and classification. To apply it to real-valued datasets, the\nICWS algorithm has become a seminal approach that is widely used, and provides\nstate-of-the-art performance for this problem space. However, ICWS suffers a\ncomputational burden as the sketch size K increases. We develop a new\nSimplified approach to the ICWS algorithm, that enables us to obtain over 20x\nspeedups compared to the standard algorithm. The veracity of our approach is\ndemonstrated empirically on multiple datasets, showing that our new Simplified\nCWS obtains the same quality of results while being an order of magnitude\nfaster.\n"]},
{"authors": ["Shujian Yu", "Jose C. Principe"], "title": ["Understanding Autoencoders with Information Theoretic Concepts"], "date": ["2018-03-30T21:13:34Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00057v1"], "summary": ["  Despite their great success in practical applications, there is still a lack\nof theoretical and systematic methods to analyze deep neural networks. In this\npaper, we illustrate an advanced information theoretic methodology to\nunderstand the dynamics of learning and the design of autoencoders, a special\ntype of deep learning architectures that resembles a communication channel. By\ngeneralizing the information plane to any cost function, and inspecting the\nroles and dynamics of different layers using layer-wise information quantities,\nwe emphasize the role that mutual information plays in quantifying learning\nfrom data. We further propose and also experimentally validate, for mean square\nerror training, two hypotheses regarding the layer-wise flow of information and\nintrinsic dimensionality of the bottleneck layer, using respectively the data\nprocessing inequality and the identification of a bifurcation point in the\ninformation plane that is controlled by the given data. Our observations have\ndirect impact on the optimal design of autoencoders, the design of alternative\nfeedforward training methods, and even in the problem of generalization.\n"]},
{"authors": ["Xishuang Dong", "Hsiang-Huang Wu", "Yuzhong Yan", "Lijun Qian"], "title": ["Hierarchical Transfer Convolutional Neural Networks for Image\n  Classification"], "date": ["2018-03-30T18:19:32Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00021v1"], "summary": ["  In this paper, we address the issue of how to enhance the generalization\nperformance of convolutional neural networks (CNN) in the early learning stage\nfor image classification. This is motivated by real-time applications that\nrequire the generalization performance of CNN to be satisfactory within limited\ntraining time. In order to achieve this, a novel hierarchical transfer CNN\nframework is proposed. It consists of a group of shallow CNNs and a cloud CNN,\nwhere the shallow CNNs are trained firstly and then the first layers of the\ntrained shallow CNNs are used to initialize the first layer of the cloud CNN.\nThis method will boost the generalization performance of the cloud CNN\nsignificantly, especially during the early stage of training. Experiments using\nCIFAR-10 and ImageNet datasets are performed to examine the proposed method.\nResults demonstrate the improvement of testing accuracy is 12% on average and\nas much as 20% for the CIFAR-10 case while 5% testing accuracy improvement for\nthe ImageNet case during the early stage of learning. It is also shown that\nuniversal improvements of testing accuracy are obtained across different\nsettings of dropout and number of shallow CNNs.\n"]},
{"authors": ["Minh Tang"], "title": ["The eigenvalues of stochastic blockmodel graphs"], "date": ["2018-03-30T17:43:16Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.11551v1"], "summary": ["  We derive the limiting distribution for the largest eigenvalues of the\nadjacency matrix for a stochastic blockmodel graph when the number of vertices\ntends to infinity. We show that, in the limit, these eigenvalues are jointly\nmultivariate normal with bounded covariances. Our result extends the classic\nresult of F\\\"{u}redi and Koml\\'{o}s on the fluctuation of the largest\neigenvalue for Erd\\H{o}s-R\\'{e}nyi graphs.\n"]},
{"authors": ["Cheng Zhou", "Fang Han", "Xinsheng Zhang", "Han Liu"], "title": ["An Extreme-Value Approach for Testing the Equality of Large U-Statistic\n  Based Correlation Matrices"], "date": ["2015-02-11T07:54:25Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1502.03211v2"], "summary": ["  There has been an increasing interest in testing the equality of large\nPearson's correlation matrices. However, in many applications it is more\nimportant to test the equality of large rank-based correlation matrices since\nthey are more robust to outliers and nonlinearity. Unlike the Pearson's case,\ntesting the equality of large rank-based statistics has not been well explored\nand requires us to develop new methods and theory. In this paper, we provide a\nframework for testing the equality of two large U-statistic based correlation\nmatrices, which include the rank-based correlation matrices as special cases.\nOur approach exploits extreme value statistics and the Jackknife estimator for\nuncertainty assessment and is valid under a fully nonparametric model.\nTheoretically, we develop a theory for testing the equality of U-statistic\nbased correlation matrices. We then apply this theory to study the problem of\ntesting large Kendall's tau correlation matrices and demonstrate its\noptimality. For proving this optimality, a novel construction of least\nfavourable distributions is developed for the correlation matrix comparison.\n"]},
{"authors": ["Lizhe Sun", "Adrian Barbu"], "title": ["Online Regression with Model Selection"], "date": ["2018-03-30T15:52:10Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.11521v1"], "summary": ["  Online learning algorithms have a wide variety of applications in large scale\nmachine learning problems due to their low computational and memory\nrequirements. However, standard online learning methods still suffer some\nissues such as lower convergence rates and limited capability to select\nfeatures or to recover the true features. In this paper, we present a novel\nframework for online learning based on running averages and introduce a series\nof online versions of some popular existing offline algorithms such as Adaptive\nLasso, Elastic Net and Feature Selection with Annealing. We prove the\nequivalence between our online methods and their offline counterparts and give\ntheoretical feature selection and convergence guarantees for some of them. In\ncontrast to the existing online methods, the proposed methods can extract model\nwith any desired sparsity level at any time. Numerical experiments indicate\nthat our new methods enjoy high feature selection accuracy and a fast\nconvergence rate, compared with standard stochastic algorithms and offline\nlearning algorithms. We also present some applications to large datasets where\nagain the proposed framework shows competitive results compared to popular\nonline and offline algorithms.\n"]},
{"authors": ["Tabish Rashid", "Mikayel Samvelyan", "Christian Schroeder de Witt", "Gregory Farquhar", "Jakob Foerster", "Shimon Whiteson"], "title": ["QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent\n  Reinforcement Learning"], "date": ["2018-03-30T14:23:39Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.11485v1"], "summary": ["  In many real-world settings, a team of agents must coordinate their behaviour\nwhile acting in a decentralised way. At the same time, it is often possible to\ntrain the agents in a centralised fashion in a simulated or laboratory setting,\nwhere global state information is available and communication constraints are\nlifted. Learning joint action-values conditioned on extra state information is\nan attractive way to exploit centralised learning, but the best strategy for\nthen extracting decentralised policies is unclear. Our solution is QMIX, a\nnovel value-based method that can train decentralised policies in a centralised\nend-to-end fashion. QMIX employs a network that estimates joint action-values\nas a complex non-linear combination of per-agent values that condition only on\nlocal observations. We structurally enforce that the joint-action value is\nmonotonic in the per-agent values, which allows tractable maximisation of the\njoint action-value in off-policy learning, and guarantees consistency between\nthe centralised and decentralised policies. We evaluate QMIX on a challenging\nset of StarCraft II micromanagement tasks, and show that QMIX significantly\noutperforms existing value-based multi-agent reinforcement learning methods.\n"]},
{"authors": ["Shashank Singh", "Bharath K. Sriperumbudur", "Barnab\u00e1s P\u00f3czos"], "title": ["Minimax Estimation of Quadratic Fourier Functionals"], "date": ["2018-03-30T13:41:42Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.11451v1"], "summary": ["  We study estimation of (semi-)inner products between two nonparametric\nprobability distributions, given IID samples from each distribution. These\nproducts include relatively well-studied classical $\\mathcal{L}^2$ and Sobolev\ninner products, as well as those induced by translation-invariant reproducing\nkernels, for which we believe our results are the first. We first propose\nestimators for these quantities, and the induced (semi)norms and\n(pseudo)metrics. We then prove non-asymptotic upper bounds on their mean\nsquared error, in terms of weights both of the inner product and of the two\ndistributions, in the Fourier basis. Finally, we prove minimax lower bounds\nthat imply rate-optimality of the proposed estimators over Fourier ellipsoids.\n"]},
{"authors": ["Amnon Drory", "Shai Avidan", "Raja Giryes"], "title": ["On the Resistance of Neural Nets to Label Noise"], "date": ["2018-03-30T11:06:43Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.11410v1"], "summary": ["  We investigate the behavior of convolutional neural networks (CNN) in the\npresence of label noise. We show empirically that CNN prediction for a given\ntest sample depends on the labels of the training samples in its local\nneighborhood. This is similar to the way that the K-nearest neighbors (K-NN)\nclassifier works. With this understanding, we derive an analytical expression\nfor the expected accuracy of a K-NN, and hence a CNN, classifier for any level\nof noise. In particular, we show that K-NN, and CNN, are resistant to label\nnoise that is randomly spread across the training set, but are very sensitive\nto label noise that is concentrated. Experiments on real datasets validate our\nanalytical expression by showing that they match the empirical results for\nvarying degrees of label noise.\n"]},
{"authors": ["Antoine Marot", "Sami Tazi", "Benjamin Donnot", "Patrick Panciatici"], "title": ["Guided Machine Learning for power grid segmentation"], "date": ["2017-11-13T10:44:01Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.09715v3"], "summary": ["  The segmentation of large scale power grids into zones is crucial for control\nroom operators when managing the grid complexity near real time. In this paper\nwe propose a new method in two steps which is able to automatically do this\nsegmentation, while taking into account the real time context, in order to help\nthem handle shifting dynamics. Our method relies on a \"guided\" machine learning\napproach. As a first step, we define and compute a task specific \"Influence\nGraph\" in a guided manner. We indeed simulate on a grid state chosen\ninterventions, representative of our task of interest (managing active power\nflows in our case). For visualization and interpretation, we then build a\nhigher representation of the grid relevant to this task by applying the graph\ncommunity detection algorithm \\textit{Infomap} on this Influence Graph. To\nillustrate our method and demonstrate its practical interest, we apply it on\ncommonly used systems, the IEEE-14 and IEEE-118. We show promising and original\ninterpretable results, especially on the previously well studied RTS-96 system\nfor grid segmentation. We eventually share initial investigation and results on\na large-scale system, the French power grid, whose segmentation had a\nsurprising resemblance with RTE's historical partitioning.\n"]},
{"authors": ["Guanbin Li", "Yizhou Yu"], "title": ["Contrast-Oriented Deep Neural Networks for Salient Object Detection"], "date": ["2018-03-30T09:51:04Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.11395v1"], "summary": ["  Deep convolutional neural networks have become a key element in the recent\nbreakthrough of salient object detection. However, existing CNN-based methods\nare based on either patch-wise (region-wise) training and inference or fully\nconvolutional networks. Methods in the former category are generally\ntime-consuming due to severe storage and computational redundancies among\noverlapping patches. To overcome this deficiency, methods in the second\ncategory attempt to directly map a raw input image to a predicted dense\nsaliency map in a single network forward pass. Though being very efficient, it\nis arduous for these methods to detect salient objects of different scales or\nsalient regions with weak semantic information. In this paper, we develop\nhybrid contrast-oriented deep neural networks to overcome the aforementioned\nlimitations. Each of our deep networks is composed of two complementary\ncomponents, including a fully convolutional stream for dense prediction and a\nsegment-level spatial pooling stream for sparse saliency inference. We further\npropose an attentional module that learns weight maps for fusing the two\nsaliency predictions from these two streams. A tailored alternate scheme is\ndesigned to train these deep networks by fine-tuning pre-trained baseline\nmodels. Finally, a customized fully connected CRF model incorporating a salient\ncontour feature embedding can be optionally applied as a post-processing step\nto improve spatial coherence and contour positioning in the fused result from\nthese two streams. Extensive experiments on six benchmark datasets demonstrate\nthat our proposed model can significantly outperform the state of the art in\nterms of all popular evaluation metrics.\n"]},
{"authors": ["Taco S. Cohen", "Mario Geiger", "Maurice Weiler"], "title": ["Intertwiners between Induced Representations (with Applications to the\n  Theory of Equivariant Neural Networks)"], "date": ["2018-03-28T17:30:26Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10743v2"], "summary": ["  Group equivariant and steerable convolutional neural networks (regular and\nsteerable G-CNNs) have recently emerged as a very effective model class for\nlearning from signal data such as 2D and 3D images, video, and other data where\nsymmetries are present. In geometrical terms, regular G-CNNs represent data in\nterms of scalar fields (\"feature channels\"), whereas the steerable G-CNN can\nalso use vector or tensor fields (\"capsules\") to represent data. In algebraic\nterms, the feature spaces in regular G-CNNs transform according to a regular\nrepresentation of the group G, whereas the feature spaces in Steerable G-CNNs\ntransform according to the more general induced representations of G. In order\nto make the network equivariant, each layer in a G-CNN is required to\nintertwine between the induced representations associated with its input and\noutput space.\n  In this paper we present a general mathematical framework for G-CNNs on\nhomogeneous spaces like Euclidean space or the sphere. We show, using\nelementary methods, that the layers of an equivariant network are convolutional\nif and only if the input and output feature spaces transform according to an\ninduced representation. This result, which follows from G.W. Mackey's abstract\ntheory on induced representations, establishes G-CNNs as a universal class of\nequivariant network architectures, and generalizes the important recent work of\nKondor & Trivedi on the intertwiners between regular representations.\n"]},
{"authors": ["Qi Meng", "Wei Chen", "Shuxin Zheng", "Qiwei Ye", "Tie-Yan Liu"], "title": ["Optimizing Neural Networks in the Equivalence Class Space"], "date": ["2018-02-11T08:57:08Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.03713v2"], "summary": ["  It has been widely observed that many activation functions and pooling\nmethods of neural network models have (positive-) rescaling-invariant property,\nincluding ReLU, PReLU, max-pooling, and average pooling, which makes\nfully-connected neural networks (FNNs) and convolutional neural networks (CNNs)\ninvariant to (positive) rescaling operation across layers. This may cause\nunneglectable problems with their optimization: (1) different NN models could\nbe equivalent, but their gradients can be very different from each other; (2)\nit can be proven that the loss functions may have many spurious critical points\nin the redundant weight space. To tackle these problems, in this paper, we\nfirst characterize the rescaling-invariant properties of NN models using\nequivalence classes and prove that the dimension of the equivalence class space\nis significantly smaller than the dimension of the original weight space. Then\nwe represent the loss function in the compact equivalence class space and\ndevelop novel algorithms that conduct optimization of the NN models directly in\nthe equivalence class space. We call these algorithms Equivalence Class\nOptimization (abbreviated as EC-Opt) algorithms. Moreover, we design efficient\ntricks to compute the gradients in the equivalence class, which almost have no\nextra computational complexity as compared to standard back-propagation (BP).\nWe conducted experimental study to demonstrate the effectiveness of our\nproposed new optimization algorithms. In particular, we show that by using the\nidea of EC-Opt, we can significantly improve the accuracy of the learned model\n(for both FNN and CNN), as compared to using conventional stochastic gradient\ndescent algorithms.\n"]},
{"authors": ["Nicholas Guttenberg", "Ryota Kanai"], "title": ["Learning to generate classifiers"], "date": ["2018-03-30T07:43:35Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.11373v1"], "summary": ["  We train a network to generate mappings between training sets and\nclassification policies (a 'classifier generator') by conditioning on the\nentire training set via an attentional mechanism. The network is directly\noptimized for test set performance on an training set of related tasks, which\nis then transferred to unseen 'test' tasks. We use this to optimize for\nperformance in the low-data and unsupervised learning regimes, and obtain\nsignificantly better performance in the 10-50 datapoint regime than support\nvector classifiers, random forests, XGBoost, and k-nearest neighbors on a range\nof small datasets.\n"]},
{"authors": ["Daiki Tanaka", "Daiki Ikami", "Toshihiko Yamasaki", "Kiyoharu Aizawa"], "title": ["Joint Optimization Framework for Learning with Noisy Labels"], "date": ["2018-03-30T06:53:40Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.11364v1"], "summary": ["  Deep neural networks (DNNs) trained on large-scale datasets have exhibited\nsignificant performance in image classification. Many large-scale datasets are\ncollected from websites, however they tend to contain inaccurate labels that\nare termed as noisy labels. Training on such noisy labeled datasets causes\nperformance degradation because DNNs easily overfit to noisy labels. To\novercome this problem, we propose a joint optimization framework of learning\nDNN parameters and estimating true labels. Our framework can correct labels\nduring training by alternating update of network parameters and labels. We\nconduct experiments on the noisy CIFAR-10 datasets and the Clothing1M dataset.\nThe results indicate that our approach significantly outperforms other\nstate-of-the-art methods.\n"]},
{"authors": ["Xingwei Cao", "Xuyang Zhao", "Qibin Zhao"], "title": ["Tensorizing Generative Adversarial Nets"], "date": ["2017-10-30T05:05:02Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.10772v2"], "summary": ["  Generative Adversarial Network (GAN) and its variants exhibit\nstate-of-the-art performance in the class of generative models. To capture\nhigher-dimensional distributions, the common learning procedure requires high\ncomputational complexity and a large number of parameters. The problem of\nemploying such massive framework arises when deploying it on a platform with\nlimited computational power such as mobile phones. In this paper, we present a\nnew generative adversarial framework by representing each layer as a tensor\nstructure connected by multilinear operations, aiming to reduce the number of\nmodel parameters by a large factor while preserving the generative performance\nand sample quality. To learn the model, we employ an efficient algorithm which\nalternatively optimizes both discriminator and generator. Experimental outcomes\ndemonstrate that our model can achieve high compression rate for model\nparameters up to $35$ times when compared to the original GAN for MNIST\ndataset.\n"]},
{"authors": ["Xin Guo", "Johnny Hong", "Tianyi Lin", "Nan Yang"], "title": ["Relaxed Wasserstein with Applications to GANs"], "date": ["2017-05-19T19:51:34Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1705.07164v3"], "summary": ["  We propose a novel class of statistical divergences called \\textit{Relaxed\nWasserstein} (RW) divergence. RW divergence generalizes Wasserstein divergence\nand is parametrized by a class of strictly convex and differentiable functions.\nWe establish for RW divergence several probabilistic properties, which are\ncritical for the success of Wasserstein divergence. In particular, we show that\nRW divergence is dominated by Total Variation (TV) and Wasserstein-$L^2$\ndivergence, and that RW divergence has continuity, differentiability and\nduality representation. Finally, we provide a nonasymptotic moment estimate and\na concentration inequality for RW divergence.\n  Our experiments on the image generation task demonstrate that RW divergence\nis a suitable choice for GANs. Indeed, the performance of RWGANs with\nKullback-Leibler (KL) divergence is very competitive with other\nstate-of-the-art GANs approaches. Furthermore, RWGANs possess better\nconvergence properties than the existing WGANs with competitive inception\nscores. To the best of our knowledge, our new conceptual framework is the first\nto not only provide the flexibility in designing effective GANs scheme, but\nalso the possibility in studying different losses under a unified mathematical\nframework.\n"]},
{"authors": ["Andrew V. Knyazev"], "title": ["On spectral partitioning of signed graphs"], "date": ["2017-01-05T17:31:16Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1701.01394v2"], "summary": ["  We argue that the standard graph Laplacian is preferable for spectral\npartitioning of signed graphs compared to the signed Laplacian. Simple examples\ndemonstrate that partitioning based on signs of components of the leading\neigenvectors of the signed Laplacian may be meaningless, in contrast to\npartitioning based on the Fiedler vector of the standard graph Laplacian for\nsigned graphs. We observe that negative eigenvalues are beneficial for spectral\npartitioning of signed graphs, making the Fiedler vector easier to compute.\n"]},
{"authors": ["Adam Gustafson", "Matthew Hirn", "Kitty Mohammed", "Hariharan Narayanan", "Jason Xu"], "title": ["Structural Risk Minimization for $C^{1,1}(\\mathbb{R}^d)$ Regression"], "date": ["2018-03-29T00:19:45Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10884v2"], "summary": ["  One means of fitting functions to high-dimensional data is by providing\nsmoothness constraints. Recently, the following smooth function approximation\nproblem was proposed: given a finite set $E \\subset \\mathbb{R}^d$ and a\nfunction $f: E \\rightarrow \\mathbb{R}$, interpolate the given information with\na function $\\widehat{f} \\in \\dot{C}^{1, 1}(\\mathbb{R}^d)$ (the class of\nfirst-order differentiable functions with Lipschitz gradients) such that\n$\\widehat{f}(a) = f(a)$ for all $a \\in E$, and the value of\n$\\mathrm{Lip}(\\nabla \\widehat{f})$ is minimal. An algorithm is provided that\nconstructs such an approximating function $\\widehat{f}$ and estimates the\noptimal Lipschitz constant $\\mathrm{Lip}(\\nabla \\widehat{f})$ in the noiseless\nsetting.\n  We address statistical aspects of reconstructing the approximating function\n$\\widehat{f}$ from a closely-related class $C^{1, 1}(\\mathbb{R}^d)$ given\nsamples from noisy data. We observe independent and identically distributed\nsamples $y(a) = f(a) + \\xi(a)$ for $a \\in E$, where $\\xi(a)$ is a noise term\nand the set $E \\subset \\mathbb{R}^d$ is fixed and known. We obtain uniform\nbounds relating the empirical risk and true risk over the class\n$\\mathcal{F}_{\\widetilde{M}} = \\{f \\in C^{1, 1}(\\mathbb{R}^d) \\mid\n\\mathrm{Lip}(\\nabla f) \\leq \\widetilde{M}\\}$, where the quantity\n$\\widetilde{M}$ grows with the number of samples at a rate governed by the\nmetric entropy of the class $C^{1, 1}(\\mathbb{R}^d)$. Finally, we provide an\nimplementation using Vaidya's algorithm, supporting our results via numerical\nexperiments on simulated data.\n"]},
{"authors": ["Biyi Fang", "Diego Klabjan"], "title": ["A Stochastic Large-scale Machine Learning Algorithm for Distributed\n  Features and Observations"], "date": ["2018-03-29T23:26:00Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.11287v1"], "summary": ["  As the size of modern data sets exceeds the disk and memory capacities of a\nsingle computer, machine learning practitioners have resorted to parallel and\ndistributed computing. Given that optimization is one of the pillars of machine\nlearning and predictive modeling, distributed optimization methods have\nrecently garnered ample attention, in particular when either observations or\nfeatures are distributed, but not both. We propose a general stochastic\nalgorithm where observations, features, and gradient components can be sampled\nin a double distributed setting, i.e., with both features and observations\ndistributed. Very technical analyses establish convergence properties of the\nalgorithm under different conditions on the learning rate (diminishing to zero\nor constant). Computational experiments in Spark demonstrate a superior\nperformance of our algorithm versus a benchmark in early iterations of the\nalgorithm, which is due to the stochastic components of the algorithm.\n"]},
{"authors": ["Matteo Manica", "Joris Cadow", "Roland Mathis", "Mar\u00eda Rodr\u00edguez Mart\u00ednez"], "title": ["PIMKL: Pathway Induced Multiple Kernel Learning"], "date": ["2018-03-29T22:28:51Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.11274v1"], "summary": ["  Reliable identification of molecular biomarkers is essential for accurate\npatient stratification. While state-of-the-art machine learning approaches for\nsample classification continue to push boundaries in terms of performance, most\nof these methods are not able to integrate different data types and lack\ngeneralization power limiting their application in a clinical setting.\nFurthermore, many methods behave as black boxes, therefore we have very little\nunderstanding about the mechanisms that lead to the prediction provided. While\nopaqueness concerning machine behaviour might not be a problem in deterministic\ndomains, in health care, providing explanations about the molecular factors and\nphenotypes that are driving the classification is crucial to build trust in the\nperformance of the predictive system. We propose Pathway Induced Multiple\nKernel Learning (PIMKL), a novel methodology to classify samples reliably that\ncan, at the same time, provide a pathway-based molecular fingerprint of the\nsignature that underlies the classification. PIMKL exploits prior knowledge in\nthe form of molecular interaction networks and annotated gene sets, by\noptimizing a mixture of pathway-induced kernels using a Multiple Kernel\nLearning algorithm (MKL), an approach that has demonstrated excellent\nperformance in different machine learning applications. After optimizing the\ncombination of kernels for prediction of a specific phenotype, the model\nprovides a stable molecular signature that can be interpreted in the light of\nthe ingested prior knowledge and that can be used in transfer learning tasks.\n"]},
{"authors": ["Patrick Schratz", "Jannes Muenchow", "Eugenia Iturritxa", "Jakob Richter", "Alexander Brenning"], "title": ["Performance evaluation and hyperparameter tuning of statistical and\n  machine-learning models using spatial data"], "date": ["2018-03-29T21:48:11Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.11266v1"], "summary": ["  Machine-learning algorithms have gained popularity in recent years in the\nfield of ecological modeling due to their promising results in predictive\nperformance of classification problems. While the application of such\nalgorithms has been highly simplified in the last years due to their\nwell-documented integration in commonly used statistical programming languages\nsuch as R, there are several practical challenges in the field of ecological\nmodeling related to unbiased performance estimation, optimization of algorithms\nusing hyperparameter tuning and spatial autocorrelation. We address these\nissues in the comparison of several widely used machine-learning algorithms\nsuch as Boosted Regression Trees (BRT), k-Nearest Neighbor (WKNN), Random\nForest (RF) and Support Vector Machine (SVM) to traditional parametric\nalgorithms such as logistic regression (GLM) and semi-parametric ones like\ngeneralized additive models (GAM). Different nested cross-validation methods\nincluding hyperparameter tuning methods are used to evaluate model performances\nwith the aim to receive bias-reduced performance estimates. As a case study the\nspatial distribution of forest disease Diplodia sapinea in the Basque Country\nin Spain is investigated using common environmental variables such as\ntemperature, precipitation, soil or lithology as predictors. Results show that\nGAM and RF (mean AUROC estimates 0.708 and 0.699) outperform all other methods\nin predictive accuracy. The effect of hyperparameter tuning saturates at around\n50 iterations for this data set. The AUROC differences between the bias-reduced\n(spatial cross-validation) and overoptimistic (non-spatial cross-validation)\nperformance estimates of the GAM and RF are 0.167 (24%) and 0.213 (30%),\nrespectively. It is recommended to also use spatial partitioning for\ncross-validation hyperparameter tuning of spatial data.\n"]},
{"authors": ["Adnan Haider"], "title": ["A Common Framework for Natural Gradient and Taylor based Optimisation\n  using Manifold Theory"], "date": ["2018-03-26T18:54:36Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09791v2"], "summary": ["  This technical report constructs a theoretical framework to relate standard\nTaylor approximation based optimisation methods with Natural Gradient (NG), a\nmethod which is Fisher efficient with probabilistic models. Such a framework\nwill be shown to also provide mathematical justification to combine higher\norder methods with the method of NG.\n"]},
{"authors": ["Joris M. Mooij", "Sara Magliacane", "Tom Claassen"], "title": ["Joint Causal Inference from Multiple Contexts"], "date": ["2016-11-30T20:50:33Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1611.10351v3"], "summary": ["  The gold standard for discovering causal relations is by means of\nexperimentation. Over the last decades, alternative methods have been proposed\nthat can infer causal relations between variables from certain statistical\npatterns in purely observational data. We introduce Joint Causal Inference\n(JCI), a novel approach to causal discovery from multiple data sets that\nelegantly unifies both approaches. JCI is a causal modeling approach rather\nthan a specific algorithm, and it can be used in combination with any causal\ndiscovery algorithm that can take into account certain background knowledge.\nThe main idea is to reduce causal discovery from multiple datasets originating\nfrom different contexts (e.g., different experimental conditions) to causal\ndiscovery from a single pooled dataset by adding a set of auxiliary context\nvariables. JCI offers the following features: it deals with several different\ntypes of interventions in a unified fashion, it can learn intervention targets,\nit pools data across different datasets which improves the statistical power of\nindependence tests, and by exploiting differences in distribution between\ncontexts it improves on the accuracy and identifiability of the predicted\ncausal relations. We evaluate the approach on flow cytometry data.\n"]},
{"authors": ["Dmitrii Ostrovskii", "Zaid Harchaoui"], "title": ["Efficient First-Order Algorithms for Adaptive Signal Denoising"], "date": ["2018-03-29T21:11:48Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.11262v1"], "summary": ["  We consider the problem of discrete-time signal denoising, focusing on a\nspecific family of non-linear convolution-type estimators. Each such estimator\nis associated with a time-invariant filter which is obtained adaptively, by\nsolving a certain convex optimization problem. Adaptive convolution-type\nestimators were demonstrated to have favorable statistical properties. However,\nthe question of their computational complexity remains largely unexplored, and\nin fact we are not aware of any publicly available implementation of these\nestimators. Our first contribution is an efficient implementation of these\nestimators via some known first-order proximal algorithms. Our second\ncontribution is a computational complexity analysis of the proposed procedures,\nwhich takes into account their statistical nature and the related notion of\nstatistical accuracy. The proposed procedures and their analysis are\nillustrated on a simulated data benchmark.\n"]},
{"authors": ["Kush R. Varshney"], "title": ["How an Electrical Engineer Became an Artificial Intelligence Researcher,\n  a Multiphase Active Contours Analysis"], "date": ["2018-03-29T21:11:32Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.11261v1"], "summary": ["  This essay examines how what is considered to be artificial intelligence (AI)\nhas changed over time and come to intersect with the expertise of the author.\nInitially, AI developed on a separate trajectory, both topically and\ninstitutionally, from pattern recognition, neural information processing,\ndecision and control systems, and allied topics by focusing on symbolic systems\nwithin computer science departments rather than on continuous systems in\nelectrical engineering departments. The separate evolutions continued\nthroughout the author's lifetime, with some crossover in reinforcement learning\nand graphical models, but were shocked into converging by the virality of deep\nlearning, thus making an electrical engineer into an AI researcher. Now that\nthis convergence has happened, opportunity exists to pursue an agenda that\ncombines learning and reasoning bridged by interpretable machine learning\nmodels.\n"]},
{"authors": ["Anqi Wu", "Mikio C. Aoi", "Jonathan W. Pillow"], "title": ["Exploiting gradients and Hessians in Bayesian optimization and Bayesian\n  quadrature"], "date": ["2017-03-31T21:13:08Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1704.00060v2"], "summary": ["  An exciting branch of machine learning research focuses on methods for\nlearning, optimizing, and integrating unknown functions that are difficult or\ncostly to evaluate. A popular Bayesian approach to this problem uses a Gaussian\nprocess (GP) to construct a posterior distribution over the function of\ninterest given a set of observed measurements, and selects new points to\nevaluate using the statistics of this posterior. Here we extend these methods\nto exploit derivative information from the unknown function. We describe\nmethods for Bayesian optimization (BO) and Bayesian quadrature (BQ) in settings\nwhere first and second derivatives may be evaluated along with the function\nitself. We perform sampling-based inference in order to incorporate uncertainty\nover hyperparameters, and show that both hyperparameter and function\nuncertainty decrease much more rapidly when using derivative information.\nMoreover, we introduce techniques for overcoming ill-conditioning issues that\nhave plagued earlier methods for gradient-enhanced Gaussian processes and\nkriging. We illustrate the efficacy of these methods using applications to real\nand simulated Bayesian optimization and quadrature problems, and show that\nexploting derivatives can provide substantial gains over standard methods.\n"]},
{"authors": ["Feipeng Zhao", "Martin Renqiang Min", "Chen Shen", "Amit Chakraborty"], "title": ["Convolutional Neural Knowledge Graph Learning"], "date": ["2017-10-23T20:39:40Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.08502v2"], "summary": ["  Previous models for learning entity and relationship embeddings of knowledge\ngraphs such as TransE, TransH, and TransR aim to explore new links based on\nlearned representations. However, these models interpret relationships as\nsimple translations on entity embeddings. In this paper, we try to learn more\ncomplex connections between entities and relationships. In particular, we use a\nConvolutional Neural Network (CNN) to learn entity and relationship\nrepresentations in knowledge graphs. In our model, we treat entities and\nrelationships as one-dimensional numerical sequences with the same length.\nAfter that, we combine each triplet of head, relationship, and tail together as\na matrix with height 3. CNN is applied to the triplets to get confidence\nscores. Positive and manually corrupted negative triplets are used to train the\nembeddings and the CNN model simultaneously. Experimental results on public\nbenchmark datasets show that the proposed model outperforms state-of-the-art\nmodels on exploring unseen relationships, which proves that CNN is effective to\nlearn complex interactive patterns between entities and relationships.\n"]},
{"authors": ["Tianbing Xu", "Qiang Liu", "Jian Peng"], "title": ["Stochastic Variance Reduction for Policy Gradient Estimation"], "date": ["2017-10-17T00:05:06Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.06034v4"], "summary": ["  Recent advances in policy gradient methods and deep learning have\ndemonstrated their applicability for complex reinforcement learning problems.\nHowever, the variance of the performance gradient estimates obtained from the\nsimulation is often excessive, leading to poor sample efficiency. In this\npaper, we apply the stochastic variance reduced gradient descent (SVRG) to\nmodel-free policy gradient to significantly improve the sample-efficiency. The\nSVRG estimation is incorporated into a trust-region Newton conjugate gradient\nframework for the policy optimization. On several Mujoco tasks, our method\nachieves significantly better performance compared to the state-of-the-art\nmodel-free policy gradient methods in robotic continuous control such as trust\nregion policy optimization (TRPO)\n"]},
{"authors": ["Javier S. Turek", "Alexander Huth"], "title": ["Efficient, sparse representation of manifold distance matrices for\n  classical scaling"], "date": ["2017-05-30T23:18:18Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1705.10887v2"], "summary": ["  Geodesic distance matrices can reveal shape properties that are largely\ninvariant to non-rigid deformations, and thus are often used to analyze and\nrepresent 3-D shapes. However, these matrices grow quadratically with the\nnumber of points. Thus for large point sets it is common to use a low-rank\napproximation to the distance matrix, which fits in memory and can be\nefficiently analyzed using methods such as multidimensional scaling (MDS). In\nthis paper we present a novel sparse method for efficiently representing\ngeodesic distance matrices using biharmonic interpolation. This method exploits\nknowledge of the data manifold to learn a sparse interpolation operator that\napproximates distances using a subset of points. We show that our method is 2x\nfaster and uses 20x less memory than current leading methods for solving MDS on\nlarge point sets, with similar quality. This enables analyses of large point\nsets that were previously infeasible.\n"]},
{"authors": ["Zhize Li", "Tianyi Zhang", "Jian Li"], "title": ["Stochastic Gradient Hamiltonian Monte Carlo with Variance Reduction for\n  Bayesian Inference"], "date": ["2018-03-29T17:06:26Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.11159v1"], "summary": ["  Gradient-based Monte Carlo sampling algorithms, like Langevin dynamics and\nHamiltonian Monte Carlo, are important methods for Bayesian inference. In\nlarge-scale settings, full-gradients are not affordable and thus stochastic\ngradients evaluated on mini-batches are used as a replacement. In order to\nreduce the high variance of noisy stochastic gradients, [Dubey et al., 2016]\napplied the standard variance reduction technique on stochastic gradient\nLangevin dynamics and obtained both theoretical and experimental improvements.\nIn this paper, we apply the variance reduction tricks on Hamiltonian Monte\nCarlo and achieve better theoretical convergence results compared with the\nvariance-reduced Langevin dynamics. Moreover, we apply the symmetric splitting\nscheme in our variance-reduced Hamiltonian Monte Carlo algorithms to further\nimprove the theoretical results. The experimental results are also consistent\nwith the theoretical results. As our experiment shows, variance-reduced\nHamiltonian Monte Carlo demonstrates better performance than variance-reduced\nLangevin dynamics in Bayesian regression and classification tasks on real-world\ndatasets.\n"]},
{"authors": ["Jingwei Zhuo", "Chang Liu", "Jiaxin Shi", "Jun Zhu", "Ning Chen", "Bo Zhang"], "title": ["Message Passing Stein Variational Gradient Descent"], "date": ["2017-11-13T05:39:25Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.04425v2"], "summary": ["  Stein variational gradient descent (SVGD) is a remarkable recent Bayesian\ninference method, which has stronger approximating ability than traditional\nvariational inference methods, and is more effective than Monte Carlo methods\nwith the same particle size. However, we observed that SVGD still manifests\nparticle degeneracy as the dimension increases: particles tend to collapse on\nlocal modes. We take an initial step towards understanding this phenomenon by\nanalyzing the repulsive force and find that there exists a negative correlation\nbetween the repulsive force and the dimensionality which should be blamed for\nthis phenomenon. We also propose Message Passing SVGD (MP-SVGD) to solve this\nproblem. By leveraging the conditional independence structure of probabilistic\ngraphical models (PGMs), MP-SVGD converts the original high dimensional global\ninference problem into a set of local ones over the Markov blanket with lower\ndimensions. Experimental results show its advantages of exploring structural\ninformation over SVGD and particle efficiency and approximation flexibility\nover other inference methods on graphical models.\n"]},
{"authors": ["Kun Ho Kim", "Oisin Mac Aodha", "Pietro Perona"], "title": ["Context Embedding Networks"], "date": ["2017-09-22T18:46:40Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.01691v3"], "summary": ["  Low dimensional embeddings that capture the main variations of interest in\ncollections of data are important for many applications. One way to construct\nthese embeddings is to acquire estimates of similarity from the crowd. However,\nsimilarity is a multi-dimensional concept that varies from individual to\nindividual. Existing models for learning embeddings from the crowd typically\nmake simplifying assumptions such as all individuals estimate similarity using\nthe same criteria, the list of criteria is known in advance, or that the crowd\nworkers are not influenced by the data that they see. To overcome these\nlimitations we introduce Context Embedding Networks (CENs). In addition to\nlearning interpretable embeddings from images, CENs also model worker biases\nfor different attributes along with the visual context i.e. the visual\nattributes highlighted by a set of images. Experiments on two noisy crowd\nannotated datasets show that modeling both worker bias and visual context\nresults in more interpretable embeddings compared to existing approaches.\n"]},
{"authors": ["Afonso S. Bandeira", "Amelia Perry", "Alexander S. Wein"], "title": ["Notes on computational-to-statistical gaps: predictions using\n  statistical physics"], "date": ["2018-03-29T16:10:04Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.11132v1"], "summary": ["  In these notes we describe heuristics to predict computational-to-statistical\ngaps in certain statistical problems. These are regimes in which the underlying\nstatistical problem is information-theoretically possible although no efficient\nalgorithm exists, rendering the problem essentially unsolvable for large\ninstances. The methods we describe here are based on mature, albeit\nnon-rigorous, tools from statistical physics.\n  These notes are based on a lecture series given by the authors at the Courant\nInstitute of Mathematical Sciences in New York City, on May 16th, 2017.\n"]},
{"authors": ["Xiaoyuan Liang", "Xunsheng Du", "Guiling Wang", "Zhu Han"], "title": ["Deep Reinforcement Learning for Traffic Light Control in Vehicular\n  Networks"], "date": ["2018-03-29T15:24:28Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.11115v1"], "summary": ["  Existing inefficient traffic light control causes numerous problems, such as\nlong delay and waste of energy. To improve efficiency, taking real-time traffic\ninformation as an input and dynamically adjusting the traffic light duration\naccordingly is a must. In terms of how to dynamically adjust traffic signals'\nduration, existing works either split the traffic signal into equal duration or\nextract limited traffic information from the real data. In this paper, we study\nhow to decide the traffic signals' duration based on the collected data from\ndifferent sensors and vehicular networks. We propose a deep reinforcement\nlearning model to control the traffic light. In the model, we quantify the\ncomplex traffic scenario as states by collecting data and dividing the whole\nintersection into small grids. The timing changes of a traffic light are the\nactions, which are modeled as a high-dimension Markov decision process. The\nreward is the cumulative waiting time difference between two cycles. To solve\nthe model, a convolutional neural network is employed to map the states to\nrewards. The proposed model is composed of several components to improve the\nperformance, such as dueling network, target network, double Q-learning\nnetwork, and prioritized experience replay. We evaluate our model via\nsimulation in the Simulation of Urban MObility (SUMO) in a vehicular network,\nand the simulation results show the efficiency of our model in controlling\ntraffic lights.\n"]},
{"authors": ["Gabrielle Ras", "Marcel van Gerven", "Pim Haselager"], "title": ["Explanation Methods in Deep Learning: Users, Values, Concerns and\n  Challenges"], "date": ["2018-03-20T16:44:47Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07517v2"], "summary": ["  Issues regarding explainable AI involve four components: users, laws &\nregulations, explanations and algorithms. Together these components provide a\ncontext in which explanation methods can be evaluated regarding their adequacy.\nThe goal of this chapter is to bridge the gap between expert users and lay\nusers. Different kinds of users are identified and their concerns revealed,\nrelevant statements from the General Data Protection Regulation are analyzed in\nthe context of Deep Neural Networks (DNNs), a taxonomy for the classification\nof existing explanation methods is introduced, and finally, the various classes\nof explanation methods are analyzed to verify if user concerns are justified.\nOverall, it is clear that (visual) explanations can be given about various\naspects of the influence of the input on the output. However, it is noted that\nexplanation methods or interfaces for lay users are missing and we speculate\nwhich criteria these methods / interfaces should satisfy. Finally it is noted\nthat two important concerns are difficult to address with explanation methods:\nthe concern about bias in datasets that leads to biased DNNs, as well as the\nsuspicion about unfair outcomes.\n"]},
{"authors": ["Toon Van Craenendonck", "Sebastijan Duman\u010di\u0107", "Elia Van Wolputte", "Hendrik Blockeel"], "title": ["COBRAS: Fast, Iterative, Active Clustering with Pairwise Constraints"], "date": ["2018-03-29T13:52:59Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.11060v1"], "summary": ["  Constraint-based clustering algorithms exploit background knowledge to\nconstruct clusterings that are aligned with the interests of a particular user.\nThis background knowledge is often obtained by allowing the clustering system\nto pose pairwise queries to the user: should these two elements be in the same\ncluster or not? Active clustering methods aim to minimize the number of queries\nneeded to obtain a good clustering by querying the most informative pairs\nfirst. Ideally, a user should be able to answer a couple of these queries,\ninspect the resulting clustering, and repeat these two steps until a\nsatisfactory result is obtained. We present COBRAS, an approach to active\nclustering with pairwise constraints that is suited for such an interactive\nclustering process. A core concept in COBRAS is that of a super-instance: a\nlocal region in the data in which all instances are assumed to belong to the\nsame cluster. COBRAS constructs such super-instances in a top-down manner to\nproduce high-quality results early on in the clustering process, and keeps\nrefining these super-instances as more pairwise queries are given to get more\ndetailed clusterings later on. We experimentally demonstrate that COBRAS\nproduces good clusterings at fast run times, making it an excellent candidate\nfor the iterative clustering scenario outlined above.\n"]},
{"authors": ["Wilson Ye Chen", "Lester Mackey", "Jackson Gorham", "Fran\u00e7ois-Xavier Briol", "Chris J. Oates"], "title": ["Stein Points"], "date": ["2018-03-27T16:12:33Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10161v2"], "summary": ["  An important task in computational statistics and machine learning is to\napproximate a posterior distribution $p(x)$ with an empirical measure supported\non a set of representative points $\\{x_i\\}_{i=1}^n$. This paper focuses on\nmethods where the selection of points is essentially deterministic, with an\nemphasis on achieving accurate approximation when $n$ is small. To this end, we\npresent `Stein Points'. The idea is to exploit either a greedy or a conditional\ngradient method to iteratively minimise a kernel Stein discrepancy between the\nempirical measure and $p(x)$. Our empirical results demonstrate that Stein\nPoints enable accurate approximation of the posterior at modest computational\ncost. In addition, theoretical results are provided to establish convergence of\nthe method.\n"]},
{"authors": ["Jose Casadiego", "Dimitra Maoutsa", "Marc Timme"], "title": ["Inferring network connectivity from event timing patterns"], "date": ["2018-03-27T09:15:04Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09974v2"], "summary": ["  Reconstructing network connectivity from the collective dynamics of a system\ntypically requires access to its complete continuous-time evolution although\nthese are often experimentally inaccessible. Here we propose a theory for\nrevealing physical connectivity of networked systems only from the event time\nseries their intrinsic collective dynamics generate. Representing the patterns\nof event timings in an event space spanned by inter-event and cross-event\nintervals, we reveal which other units directly influence the inter-event times\nof any given unit. For illustration, we linearize an event space mapping\nconstructed from the spiking patterns in model neural circuits to reveal the\npresence or absence of synapses between any pair of neurons as well as whether\nthe coupling acts in an inhibiting or activating (excitatory) manner. The\nproposed model-independent reconstruction theory is scalable to larger networks\nand may thus play an important role in the reconstruction of networks from\nbiology to social science and engineering.\n"]},
{"authors": ["Luzie Helfmann", "Johannes von Lindheim", "Mattes Mollenhauer", "Ralf Banisch"], "title": ["On Hyperparameter Search in Cluster Ensembles"], "date": ["2018-03-29T11:11:10Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.11008v1"], "summary": ["  Quality assessments of models in unsupervised learning and clustering\nverification in particular have been a long-standing problem in the machine\nlearning research. The lack of robust and universally applicable cluster\nvalidity scores often makes the algorithm selection and hyperparameter\nevaluation a tough guess. In this paper, we show that cluster ensemble\naggregation techniques such as consensus clustering may be used to evaluate\nclusterings and their hyperparameter configurations. We use normalized mutual\ninformation to compare individual objects of a clustering ensemble to the\nconstructed consensus of the whole ensemble and show, that the resulting score\ncan serve as an overall quality measure for clustering problems. This method is\ncapable of highlighting the standout clustering and hyperparameter\nconfiguration in the ensemble even in the case of a distorted consensus. We\napply this very general framework to various data sets and give possible\ndirections for future research.\n"]},
{"authors": ["Ruth Fong", "Andrea Vedaldi"], "title": ["Net2Vec: Quantifying and Explaining how Concepts are Encoded by Filters\n  in Deep Neural Networks"], "date": ["2018-01-10T17:01:36Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1801.03454v2"], "summary": ["  In an effort to understand the meaning of the intermediate representations\ncaptured by deep networks, recent papers have tried to associate specific\nsemantic concepts to individual neural network filter responses, where\ninteresting correlations are often found, largely by focusing on extremal\nfilter responses. In this paper, we show that this approach can favor\neasy-to-interpret cases that are not necessarily representative of the average\nbehavior of a representation.\n  A more realistic but harder-to-study hypothesis is that semantic\nrepresentations are distributed, and thus filters must be studied in\nconjunction. In order to investigate this idea while enabling systematic\nvisualization and quantification of multiple filter responses, we introduce the\nNet2Vec framework, in which semantic concepts are mapped to vectorial\nembeddings based on corresponding filter responses. By studying such\nembeddings, we are able to show that 1., in most cases, multiple filters are\nrequired to code for a concept, that 2., often filters are not concept specific\nand help encode multiple concepts, and that 3., compared to single filter\nactivations, filter embeddings are able to better characterize the meaning of a\nrepresentation and its relationship to other concepts.\n"]},
{"authors": ["Sima Sharifirad", "Azra Nazari", "Mehdi Ghatee"], "title": ["Modified SMOTE Using Mutual Information and Different Sorts of Entropies"], "date": ["2018-03-29T10:41:19Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.11002v1"], "summary": ["  SMOTE is one of the oversampling techniques for balancing the datasets and it\nis considered as a pre-processing step in learning algorithms. In this paper,\nfour new enhanced SMOTE are proposed that include an improved version of KNN in\nwhich the attribute weights are defined by mutual information firstly and then\nthey are replaced by maximum entropy, Renyi entropy and Tsallis entropy. These\nfour pre-processing methods are combined with 1NN and J48 classifiers and their\nperformance are compared with the previous methods on 11 imbalanced datasets\nfrom KEEL repository. The results show that these pre-processing methods\nimproves the accuracy compared with the previous stablished works. In addition,\nas a case study, the first pre-processing method is applied on transportation\ndata of Tehran-Bazargan Highway in Iran with IR equal to 36.\n"]},
{"authors": ["Viet Hung Tran"], "title": ["Copula Variational Bayes inference via information geometry"], "date": ["2018-03-29T10:10:35Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10998v1"], "summary": ["  Variational Bayes (VB), also known as independent mean-field approximation,\nhas become a popular method for Bayesian network inference in recent years. Its\napplication is vast, e.g. in neural network, compressed sensing, clustering,\netc. to name just a few. In this paper, the independence constraint in VB will\nbe relaxed to a conditional constraint class, called copula in statistics.\nSince a joint probability distribution always belongs to a copula class, the\nnovel copula VB (CVB) approximation is a generalized form of VB. Via\ninformation geometry, we will see that CVB algorithm iteratively projects the\noriginal joint distribution to a copula constraint space until it reaches a\nlocal minimum Kullback-Leibler (KL) divergence. By this way, all mean-field\napproximations, e.g. iterative VB, Expectation-Maximization (EM), Iterated\nConditional Mode (ICM) and k-means algorithms, are special cases of CVB\napproximation.\n  For a generic Bayesian network, an augmented hierarchy form of CVB will also\nbe designed. While mean-field algorithms can only return a locally optimal\napproximation for a correlated network, the augmented CVB network, which is an\noptimally weighted average of a mixture of simpler network structures, can\npotentially achieve the globally optimal approximation for the first time. Via\nsimulations of Gaussian mixture clustering, the classification's accuracy of\nCVB will be shown to be far superior to that of state-of-the-art VB, EM and\nk-means algorithms.\n"]},
{"authors": ["Hyeongki Kim"], "title": ["Dihedral angle prediction using generative adversarial networks"], "date": ["2018-03-29T10:02:14Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10996v1"], "summary": ["  Several dihedral angles prediction methods were developed for protein\nstructure prediction and their other applications. However, distribution of\npredicted angles would not be similar to that of real angles. To address this\nwe employed generative adversarial networks (GAN). Generative adversarial\nnetworks are composed of two adversarially trained networks: a discriminator\nand a generator. A discriminator distinguishes samples from a dataset and\ngenerated samples while a generator generates realistic samples. Although the\ndiscriminator of GANs is trained to estimate density, GAN model is intractable.\nOn the other hand, noise-contrastive estimation (NCE) was introduced to\nestimate a normalization constant of an unnormalized statistical model and thus\nthe density function. In this thesis, we introduce noise-contrastive estimation\ngenerative adversarial networks (NCE-GAN) which enables explicit density\nestimation of a GAN model. And a new loss for the generator is proposed. We\nalso propose residue-wise variants of auxiliary classifier GAN (AC-GAN) and\nSemi-supervised GAN to handle sequence information in a window. In our\nexperiment, the conditional generative adversarial network (C-GAN), AC-GAN and\nSemi-supervised GAN were compared. And experiments done with improved\nconditions were invested. We identified a phenomenon of AC-GAN that\ndistribution of its predicted angles is composed of unusual clusters. The\ndistribution of the predicted angles of Semi-supervised GAN was most similar to\nthe Ramachandran plot. We found that adding the output of the NCE as an\nadditional input of the discriminator is helpful to stabilize the training of\nthe GANs and to capture the detailed structures. Adding regression loss and\nusing predicted angles by regression loss only model could improve the\nconditional generation performance of the C-GAN and AC-GAN.\n"]},
{"authors": ["Richard Kenway"], "title": ["Protection against Cloning for Deep Learning"], "date": ["2018-03-29T10:02:09Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10995v1"], "summary": ["  The susceptibility of deep learning to adversarial attack can be understood\nin the framework of the Renormalisation Group (RG) and the vulnerability of a\nspecific network may be diagnosed provided the weights in each layer are known.\nAn adversary with access to the inputs and outputs could train a second network\nto clone these weights and, having identified a weakness, use them to compute\nthe perturbation of the input data which exploits it. However, the RG framework\nalso provides a means to poison the outputs of the network imperceptibly,\nwithout affecting their legitimate use, so as to prevent such cloning of its\nweights and thereby foil the generation of adversarial data.\n"]},
{"authors": ["Vah\u00e9 Asvatourian", "Cl\u00e9lia Coutzac", "Nathalie Chaput", "Caroline Robert", "Stefan Michiels", "Emilie Lanoy"], "title": ["Estimating causal effects of time-dependent exposures on a binary\n  endpoint in a high-dimensional setting"], "date": ["2018-03-28T11:34:41Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10535v2"], "summary": ["  Recently, the intervention calculus when the DAG is absent (IDA) method was\ndeveloped to estimate lower bounds of causal effects from observational\nhigh-dimensional data. Originally it was introduced to assess the effect of\nbaseline biomarkers which do not vary over time. However, in many clinical\nsettings, measurements of biomarkers are repeated at fixed time points during\ntreatment exposure and, therefore, this method need to be extended. The purpose\nof this paper is then to extend the first step of the IDA, the Peter Clarks\n(PC)-algorithm, to a time-dependent exposure in the context of a binary\noutcome. We generalised the PC-algorithm for taking into account the\nchronological order of repeated measurements of the exposure and propose to\napply the IDA with our new version, the chronologically ordered PC-algorithm\n(COPC-algorithm). A simulation study has been performed before applying the\nmethod for estimating causal effects of time-dependent immunological biomarkers\non toxicity, death and progression in patients with metastatic melanoma. The\nsimulation study showed that the completed partially directed acyclic graphs\n(CPDAGs) obtained using COPC-algorithm were structurally closer to the true\nCPDAG than CPDAGs obtained using PC-algorithm. Also, causal effects were more\naccurate when they were estimated based on CPDAGs obtained using\nCOPC-algorithm. Moreover, CPDAGs obtained by COPC-algorithm allowed removing\nnon-chronologic arrows with a variable measured at a time t pointing to a\nvariable measured at a time t' where t'< t. Bidirected edges were less present\nin CPDAGs obtained with the COPC-algorithm, supporting the fact that there was\nless variability in causal effects estimated from these CPDAGs. The\nCOPC-algorithm provided CPDAGs that keep the chronological structure present in\nthe data, thus allowed to estimate lower bounds of the causal effect of\ntime-dependent biomarkers.\n"]},
{"authors": ["Barbara Barabasz", "Andrew Anderson", "David Gregg"], "title": ["Improving accuracy of Winograd convolution for DNNs"], "date": ["2018-03-29T09:48:02Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10986v1"], "summary": ["  Modern deep neural networks (DNNs) spend a large amount of their execution\ntime computing convolutions. Winograd's minimal algorithm for small\nconvolutions can greatly reduce the number of arithmetic operations. However, a\nlarge reduction in floating point (FP) operations in these algorithms can\nresult in significantly reduced FP accuracy of the result. In this paper we\npropose several methods for reducing the FP error of these algorithms. Minimal\nconvolution algorithms depend on the selection of several numeric\n\\textit{points} that have a large impact on the accuracy of the result. Some\npoints are known to be better than others, but there is no systematic method\nselecting points for small convolutions. We show that there are a relatively\nsmall number of important cases for DNN convolution, that can be searched\nempirically. We compared both standard and modified versions of the Winograd\nalgorithm. Further, we demonstrate that both the ordering and value of the\npoints is important, and we propose a canonical evaluation ordering that both\nreduces FP error and the size of the search space based on Huffman coding. We\nfind that good point selections depend on the values of the points themselves\nand on symmetries between different points. We show that sets of points with\nsymmetric groups give better results. In addition, we explore other methods to\nreduce FP error, including mixed-precision convolution, and pairwise addition\nacross DNN channels. Using our methods we can significantly reduce FP error for\na given Winograd convolution block size, which allows larger block sizes and\nreduced computation.\n"]},
{"authors": ["Jalal Fadili", "J\u00e9r\u00f4me Malick", "Gabriel Peyr\u00e9"], "title": ["Sensitivity Analysis for Mirror-Stratifiable Convex Functions"], "date": ["2017-07-11T09:35:14Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1707.03194v2"], "summary": ["  This paper provides a set of sensitivity analysis and activity identification\nresults for a class of convex functions with a strong geometric structure, that\nwe coined \"mirror-stratifiable\". These functions are such that there is a\nbijection between a primal and a dual stratification of the space into\npartitioning sets, called strata. This pairing is crucial to track the strata\nthat are identifiable by solutions of parametrized optimization problems or by\niterates of optimization algorithms. This class of functions encompasses all\nregularizers routinely used in signal and image processing, machine learning,\nand statistics. We show that this \"mirror-stratifiable\" structure enjoys a nice\nsensitivity theory, allowing us to study stability of solutions of optimization\nproblems to small perturbations, as well as activity identification of\nfirst-order proximal splitting-type algorithms. Existing results in the\nliterature typically assume that, under a non-degeneracy condition, the active\nset associated to a minimizer is stable to small perturbations and is\nidentified in finite time by optimization schemes. In contrast, our results do\nnot require any non-degeneracy assumption: in consequence, the optimal active\nset is not necessarily stable anymore, but we are able to track precisely the\nset of identifiable strata.We show that these results have crucial implications\nwhen solving challenging ill-posed inverse problems via regularization, a\ntypical scenario where the non-degeneracy condition is not fulfilled. Our\ntheoretical results, illustrated by numerical simulations, allow to\ncharacterize the instability behaviour of the regularized solutions, by\nlocating the set of all low-dimensional strata that can be potentially\nidentified by these solutions.\n"]},
{"authors": ["Aditya Grover", "Aaron Zweig", "Stefano Ermon"], "title": ["Graphite: Iterative Generative Modeling of Graphs"], "date": ["2018-03-28T08:37:25Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10459v2"], "summary": ["  Graphs are a fundamental abstraction for modeling relational data. However,\ngraphs are discrete and combinatorial in nature, and learning representations\nsuitable for machine learning tasks poses statistical and computational\nchallenges. In this work, we propose Graphite an algorithmic framework for\nunsupervised learning of representations over nodes in a graph using deep\nlatent variable generative models. Our model is based on variational\nautoencoders (VAE), and differs from existing VAE frameworks for data\nmodalities such as images, speech, and text in the use of graph neural networks\nfor parameterizing both the generative model (i.e., decoder) and inference\nmodel (i.e., encoder). The use of graph neural networks directly incorporates\ninductive biases due to the spatial, local structure of graphs directly in the\ngenerative model. Moreover, we draw novel connections between graph neural\nnetworks and approximate inference via kernel embeddings of distributions. We\ndemonstrate empirically that Graphite outperforms state-of-the-art approaches\nfor the tasks of density estimation, link prediction, and node classification\non synthetic and benchmark datasets.\n"]},
{"authors": ["Yanning Shen", "Panagiotis A. Traganitis", "Georgios B. Giannakis"], "title": ["Nonlinear Dimensionality Reduction on Graphs"], "date": ["2018-01-29T08:11:04Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1801.09390v2"], "summary": ["  In this era of data deluge, many signal processing and machine learning tasks\nare faced with high-dimensional datasets, including images, videos, as well as\ntime series generated from social, commercial and brain network interactions.\nTheir efficient processing calls for dimensionality reduction techniques\ncapable of properly compressing the data while preserving task-related\ncharacteristics, going beyond pairwise data correlations. The present paper\nputs forth a nonlinear dimensionality reduction framework that accounts for\ndata lying on known graphs. The novel framework encompasses most of the\nexisting dimensionality reduction methods, but it is also capable of capturing\nand preserving possibly nonlinear correlations that are ignored by linear\nmethods. Furthermore, it can take into account information from multiple\ngraphs. The proposed algorithms were tested on synthetic as well as real\ndatasets to corroborate their effectiveness.\n"]},
{"authors": ["Aditya Grover", "Todor Markov", "Peter Attia", "Norman Jin", "Nicholas Perkins", "Bryan Cheong", "Michael Chen", "Zi Yang", "Stephen Harris", "William Chueh", "Stefano Ermon"], "title": ["Best arm identification in multi-armed bandits with delayed feedback"], "date": ["2018-03-29T06:46:38Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10937v1"], "summary": ["  We propose a generalization of the best arm identification problem in\nstochastic multi-armed bandits (MAB) to the setting where every pull of an arm\nis associated with delayed feedback. The delay in feedback increases the\neffective sample complexity of standard algorithms, but can be offset if we\nhave access to partial feedback received before a pull is completed. We propose\na general framework to model the relationship between partial and delayed\nfeedback, and as a special case we introduce efficient algorithms for settings\nwhere the partial feedback are biased or unbiased estimators of the delayed\nfeedback. Additionally, we propose a novel extension of the algorithms to the\nparallel MAB setting where an agent can control a batch of arms. Our\nexperiments in real-world settings, involving policy search and hyperparameter\noptimization in computational sustainability domains for fast charging of\nbatteries and wildlife corridor construction, demonstrate that exploiting the\nstructure of partial feedback can lead to significant improvements over\nbaselines in both sequential and parallel MAB.\n"]},
{"authors": ["Amir Hossein Akhavan Rahnama", "Mehdi Toloo", "Nezer Jacob Zaidenberg"], "title": ["An LP-based hyperparameter optimization model for language modeling"], "date": ["2018-03-29T05:15:36Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10927v1"], "summary": ["  In order to find hyperparameters for a machine learning model, algorithms\nsuch as grid search or random search are used over the space of possible values\nof the models hyperparameters. These search algorithms opt the solution that\nminimizes a specific cost function. In language models, perplexity is one of\nthe most popular cost functions. In this study, we propose a fractional\nnonlinear programming model that finds the optimal perplexity value. The\nspecial structure of the model allows us to approximate it by a linear\nprogramming model that can be solved using the well-known simplex algorithm. To\nthe best of our knowledge, this is the first attempt to use optimization\ntechniques to find perplexity values in the language modeling literature. We\napply our model to find hyperparameters of a language model and compare it to\nthe grid search algorithm. Furthermore, we illustrating that it results in\nlower perplexity values. We perform this experiment on a real-world dataset\nfrom SwiftKey to validate our proposed approach.\n"]},
{"authors": ["Ilya Soloveychik", "Vahid Tarokh"], "title": ["Region Detection in Markov Random Fields: Gaussian Case"], "date": ["2018-02-12T00:21:32Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.03848v8"], "summary": ["  We consider the problem of model selection in Gaussian Markov fields in the\nsample deficient scenario. The benchmark information-theoretic results in the\ncase of d-regular graphs require the number of samples to be at least\nproportional to the logarithm of the number of vertices to allow consistent\ngraph recovery. When the number of samples is less than this amount, reliable\ndetection of all edges is impossible. In many applications, it is more\nimportant to learn the distribution of the edge (coupling) parameters over the\nnetwork than the specific locations of the edges. Assuming that the entire\ngraph can be partitioned into a number of spatial regions with similar edge\nparameters and reasonably regular boundaries, we develop new\ninformation-theoretic sample complexity bounds and show that a bounded number\nof samples can be sufficient to consistently recover these regions. Finally, we\nintroduce and analyze an efficient region growing algorithm capable of\nrecovering the regions with high accuracy. We show that it is consistent and\ndemonstrate its performance benefits in synthetic simulations.\n"]},
{"authors": ["Di Wang", "Marco Gaboardi", "Jinhui Xu"], "title": ["Efficient Empirical Risk Minimization with Smooth Loss Functions in\n  Non-interactive Local Differential Privacy"], "date": ["2018-02-12T14:52:24Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.04085v2"], "summary": ["  In this paper, we study the Empirical Risk Minimization problem in the\nnon-interactive local model of differential privacy. We first show that if the\nERM loss function is $(\\infty, T)$-smooth, then we can avoid a dependence of\nthe sample complexity, to achieve error $\\alpha$, on the exponential of the\ndimensionality $p$ with base $1/\\alpha$ ({\\em i.e.,} $\\alpha^{-p}$), which\nanswers a question in \\cite{smith2017interaction}. Our approach is based on\nBernstein polynomial approximation. Then, we propose player-efficient\nalgorithms with $1$-bit communication complexity and $O(1)$ computation cost\nfor each player. The error bound is asymptotically the same as the original\none. Also with additional assumptions we show a server efficient algorithm with\npolynomial running time. At last, we propose (efficient) non-interactive\nlocally differential private algorithms, based on different types of polynomial\napproximations, for learning the set of k-way marginal queries and the set of\nsmooth queries.\n"]},
{"authors": ["Yudong Chen", "Yuejie Chi"], "title": ["Harnessing Structures in Big Data via Guaranteed Low-Rank Matrix\n  Estimation"], "date": ["2018-02-23T05:41:37Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.08397v2"], "summary": ["  Low-rank modeling plays a pivotal role in signal processing and machine\nlearning, with applications ranging from collaborative filtering, video\nsurveillance, medical imaging, to dimensionality reduction and adaptive\nfiltering. Many modern high-dimensional data and interactions thereof can be\nmodeled as lying approximately in a low-dimensional subspace or manifold,\npossibly with additional structures, and its proper exploitations lead to\nsignificant reduction of costs in sensing, computation and storage. In recent\nyears, there is a plethora of progress in understanding how to exploit low-rank\nstructures using computationally efficient procedures in a provable manner,\nincluding both convex and nonconvex approaches. On one side, convex relaxations\nsuch as nuclear norm minimization often lead to statistically optimal\nprocedures for estimating low-rank matrices, where first-order methods are\ndeveloped to address the computational challenges; on the other side, there is\nemerging evidence that properly designed nonconvex procedures, such as\nprojected gradient descent, often provide globally optimal solutions with a\nmuch lower computational cost in many problems. This survey article will\nprovide a unified overview of these recent advances on low-rank matrix\nestimation from incomplete measurements. Attention is paid to rigorous\ncharacterization of the performance of these algorithms, and to problems where\nthe low-rank matrix have additional structural properties that require new\nalgorithmic designs and theoretical analysis.\n"]},
{"authors": ["Kostas Hatalis", "Shalinee Kishore", "Katya Scheinberg", "Alberto Lamadrid"], "title": ["An Empirical Analysis of Constrained Support Vector Quantile Regression\n  for Nonparametric Probabilistic Forecasting of Wind Power"], "date": ["2018-03-29T01:05:54Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10888v1"], "summary": ["  Uncertainty analysis in the form of probabilistic forecasting can provide\nsignificant improvements in decision-making processes in the smart power grid\nfor better integrating renewable energies such as wind. Whereas point\nforecasting provides a single expected value, probabilistic forecasts provide\nmore information in the form of quantiles, prediction intervals, or full\npredictive densities. This paper analyzes the effectiveness of an approach for\nnonparametric probabilistic forecasting of wind power that combines support\nvector machines and nonlinear quantile regression with non-crossing\nconstraints. A numerical case study is conducted using publicly available wind\ndata from the Global Energy Forecasting Competition 2014. Multiple quantiles\nare estimated to form 20%, 40%, 60% and 80% prediction intervals which are\nevaluated using the pinball loss function and reliability measures. Three\nbenchmark models are used for comparison where results demonstrate the proposed\napproach leads to significantly better performance while preventing the problem\nof overlapping quantile estimates.\n"]},
{"authors": ["Deirdre Quillen", "Eric Jang", "Ofir Nachum", "Chelsea Finn", "Julian Ibarz", "Sergey Levine"], "title": ["Deep Reinforcement Learning for Vision-Based Robotic Grasping: A\n  Simulated Comparative Evaluation of Off-Policy Methods"], "date": ["2018-02-28T05:11:38Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.10264v2"], "summary": ["  In this paper, we explore deep reinforcement learning algorithms for\nvision-based robotic grasping. Model-free deep reinforcement learning (RL) has\nbeen successfully applied to a range of challenging environments, but the\nproliferation of algorithms makes it difficult to discern which particular\napproach would be best suited for a rich, diverse task like grasping. To answer\nthis question, we propose a simulated benchmark for robotic grasping that\nemphasizes off-policy learning and generalization to unseen objects. Off-policy\nlearning enables utilization of grasping data over a wide variety of objects,\nand diversity is important to enable the method to generalize to new objects\nthat were not seen during training. We evaluate the benchmark tasks against a\nvariety of Q-function estimation methods, a method previously proposed for\nrobotic grasping with deep neural network models, and a novel approach based on\na combination of Monte Carlo return estimation and an off-policy correction.\nOur results indicate that several simple methods provide a surprisingly strong\ncompetitor to popular algorithms such as double Q-learning, and our analysis of\nstability sheds light on the relative tradeoffs between the algorithms.\n"]},
{"authors": ["Alain Durmus", "Szymon Majewski", "B\u0142a\u017cej Miasojedow"], "title": ["Analysis of Langevin Monte Carlo via convex optimization"], "date": ["2018-02-26T07:50:57Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.09188v2"], "summary": ["  In this paper, we provide new insights on the Unadjusted Langevin Algorithm.\nWe show that this method can be formulated as a first order optimization\nalgorithm of an objective functional defined on the Wasserstein space of order\n$2$. Using this interpretation and techniques borrowed from convex\noptimization, we give a non-asymptotic analysis of this method to sample from\nlogconcave smooth target distribution on $\\mathbb{R}^d$. Based on this\ninterpretation, we propose two new methods for sampling from a non-smooth\ntarget distribution, which we analyze as well. Besides, these new algorithms\nare natural extensions of the Stochastic Gradient Langevin Dynamics (SGLD)\nalgorithm, which is a popular extension of the Unadjusted Langevin Algorithm.\nSimilar to SGLD, they only rely on approximations of the gradient of the target\nlog density and can be used for large-scale Bayesian inference.\n"]},
{"authors": ["C. Soizea", "R. Ghanem", "C. Safta", "X. Huan", "Z. P. Vane", "J. Oefelein", "G. Lacaz", "H. N. Najm", "Q. Tang", "X. Chen"], "title": ["Entropy-based closure for probabilistic learning on manifolds"], "date": ["2018-03-21T22:46:31Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08161v2"], "summary": ["  In a recent paper, the authors proposed a general methodology for\nprobabilistic learning on manifolds. The method was used to generate numerical\nsamples that are statistically consistent with an existing dataset construed as\na realization from a non-Gaussian random vector. The manifold structure is\nlearned using diffusion manifolds and the statistical sample generation is\naccomplished using a projected Ito stochastic differential equation. This\nprobabilistic learning approach has been extended to polynomial chaos\nrepresentation of databases on manifolds and to probabilistic nonconvex\nconstrained optimization with a fixed budget of function evaluations. The\nmethodology introduces an isotropic-diffusion kernel with hyperparameter\n{\\epsilon}. Currently, {\\epsilon} is more or less arbitrarily chosen. In this\npaper, we propose a selection criterion for identifying an optimal value of\n{\\epsilon}, based on a maximum entropy argument. The result is a comprehensive,\nclosed, probabilistic model for characterizing data sets with hidden\nconstraints. This entropy argument ensures that out of all possible models,\nthis is the one that is the most uncertain beyond any specified constraints,\nwhich is selected. Applications are presented for several databases.\n"]},
{"authors": ["Jack Harmer", "Linus Gissl\u00e9n", "Henrik Holst", "Joakim Bergdahl", "Tom Olsson", "Kristoffer Sj\u00f6\u00f6", "Magnus Nordin"], "title": ["Imitation Learning with Concurrent Actions in 3D Games"], "date": ["2018-03-14T16:59:17Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05402v3"], "summary": ["  In this work we describe a novel deep reinforcement learning neural network\narchitecture that allows multiple actions to be selected at every time-step.\nMulti-action policies allows complex behaviors to be learnt that are otherwise\nhard to achieve when using single action selection techniques. This work\ndescribes an algorithm that uses both imitation learning (IL) and temporal\ndifference (TD) reinforcement learning (RL) to provide a 4x improvement in\ntraining time and 2.5x improvement in performance over single action selection\nTD RL. We demonstrate the capabilities of this network using a complex in-house\n3D game. Mimicking the behavior of the expert teacher significantly improves\nworld state exploration and allows the agents vision system to be trained more\nrapidly than TD RL alone. This initial training technique kick-starts TD\nlearning and the agent quickly learns to surpass the capabilities of the\nexpert.\n"]},
{"authors": ["Yu Cheng", "Rong Ge"], "title": ["Non-Convex Matrix Completion Against a Semi-Random Adversary"], "date": ["2018-03-28T20:46:27Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10846v1"], "summary": ["  Matrix completion is a well-studied problem with many machine learning\napplications. In practice, the problem is often solved by non-convex\noptimization algorithms. However, the current theoretical analysis for\nnon-convex algorithms relies heavily on the assumption that every entry is\nobserved with exactly the same probability $p$, which is not realistic in\npractice.\n  In this paper, we investigate a more realistic semi-random model, where the\nprobability of observing each entry is at least $p$. Even with this mild\nsemi-random perturbation, we can construct counter-examples where existing\nnon-convex algorithms get stuck in bad local optima.\n  In light of the negative results, we propose a pre-processing step that tries\nto re-weight the semi-random input, so that it becomes \"similar\" to a random\ninput. We give a nearly-linear time algorithm for this problem, and show that\nafter our pre-processing, all the local minima of the non-convex objective can\nbe used to approximately recover the underlying ground-truth matrix.\n"]},
{"authors": ["Nikolaos Passalis", "Anastasios Tefas"], "title": ["Probabilistic Knowledge Transfer for Deep Representation Learning"], "date": ["2018-03-28T20:14:08Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10837v1"], "summary": ["  Knowledge Transfer (KT) techniques tackle the problem of transferring the\nknowledge from a large and complex neural network into a smaller and faster\none. However, existing KT methods are tailored towards classification tasks and\nthey cannot be used efficiently for other representation learning tasks. In\nthis paper a novel knowledge transfer technique, that is capable of training a\nstudent model that maintains the same amount of mutual information between the\nlearned representation and a set of (possible unknown) labels as the teacher\nmodel, is proposed. Apart from outperforming existing KT techniques, the\nproposed method allows for overcoming several limitations of existing methods\nproviding new insight into KT as well as novel KT applications, ranging from\nknowledge transfer from handcrafted feature extractors to {cross-modal} KT from\nthe textual modality into the representation extracted from the visual modality\nof the data.\n"]},
{"authors": ["Lu Zhang", "Yongkai Wu", "Xintao Wu"], "title": ["Achieving non-discrimination in prediction"], "date": ["2017-02-28T21:20:19Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1703.00060v2"], "summary": ["  Discrimination-aware classification is receiving an increasing attention in\ndata science fields. The pre-process methods for constructing a\ndiscrimination-free classifier first remove discrimination from the training\ndata, and then learn the classifier from the cleaned data. However, they lack a\ntheoretical guarantee for the potential discrimination when the classifier is\ndeployed for prediction. In this paper, we fill this gap by mathematically\nbounding the probability of the discrimination in prediction being within a\ngiven interval in terms of the training data and classifier. We adopt the\ncausal model for modeling the data generation mechanism, and formally defining\ndiscrimination in population, in a dataset, and in prediction. We obtain two\nimportant theoretical results: (1) the discrimination in prediction can still\nexist even if the discrimination in the training data is completely removed;\nand (2) not all pre-process methods can ensure non-discrimination in prediction\neven though they can achieve non-discrimination in the modified training data.\nBased on the results, we develop a two-phase framework for constructing a\ndiscrimination-free classifier with a theoretical guarantee. The experiments\ndemonstrate the theoretical results and show the effectiveness of our two-phase\nframework.\n"]},
{"authors": ["Zhe Li", "Chong Wang", "Mei Han", "Yuan Xue", "Wei Wei", "Li-Jia Li", "Li Fei-Fei"], "title": ["Thoracic Disease Identification and Localization with Limited\n  Supervision"], "date": ["2017-11-17T01:52:56Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.06373v4"], "summary": ["  Accurate identification and localization of abnormalities from radiology\nimages play an integral part in clinical diagnosis and treatment planning.\nBuilding a highly accurate prediction model for these tasks usually requires a\nlarge number of images manually annotated with labels and finding sites of\nabnormalities. In reality, however, such annotated data are expensive to\nacquire, especially the ones with location annotations. We need methods that\ncan work well with only a small amount of location annotations. To address this\nchallenge, we present a unified approach that simultaneously performs disease\nidentification and localization through the same underlying model for all\nimages. We demonstrate that our approach can effectively leverage both class\ninformation as well as limited location annotation, and significantly\noutperforms the comparative reference baseline in both classification and\nlocalization tasks.\n"]},
{"authors": ["Louis-\u00c9mile Robitaille", "Audrey Durand", "Marc-Andr\u00e9 Gardner", "Christian Gagn\u00e9", "Paul De Koninck", "Flavie Lavoie-Cardinal"], "title": ["Learning to Become an Expert: Deep Networks Applied To Super-Resolution\n  Microscopy"], "date": ["2018-03-28T19:01:45Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10806v1"], "summary": ["  With super-resolution optical microscopy, it is now possible to observe\nmolecular interactions in living cells. The obtained images have a very high\nspatial precision but their overall quality can vary a lot depending on the\nstructure of interest and the imaging parameters. Moreover, evaluating this\nquality is often difficult for non-expert users. In this work, we tackle the\nproblem of learning the quality function of super- resolution images from\nscores provided by experts. More specifically, we are proposing a system based\non a deep neural network that can provide a quantitative quality measure of a\nSTED image of neuronal structures given as input. We conduct a user study in\norder to evaluate the quality of the predictions of the neural network against\nthose of a human expert. Results show the potential while highlighting some of\nthe limits of the proposed approach.\n"]},
{"authors": ["Hanie Sedghi", "Ashish Sabharwal"], "title": ["Knowledge Completion for Generics using Guided Tensor Factorization"], "date": ["2016-12-12T19:53:04Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1612.03871v3"], "summary": ["  Given a knowledge base or KB containing (noisy) facts about common nouns or\ngenerics, such as \"all trees produce oxygen\" or \"some animals live in forests\",\nwe consider the problem of inferring additional such facts at a precision\nsimilar to that of the starting KB. Such KBs capture general knowledge about\nthe world, and are crucial for various applications such as question answering.\nDifferent from commonly studied named entity KBs such as Freebase, generics KBs\ninvolve quantification, have more complex underlying regularities, tend to be\nmore incomplete, and violate the commonly used locally closed world assumption\n(LCWA). We show that existing KB completion methods struggle with this new\ntask, and present the first approach that is successful. Our results\ndemonstrate that external information, such as relation schemas and entity\ntaxonomies, if used appropriately, can be a surprisingly powerful tool in this\nsetting. First, our simple yet effective knowledge guided tensor factorization\napproach achieves state-of-the-art results on two generics KBs (80% precise)\nfor science, doubling their size at 74%-86% precision. Second, our novel\ntaxonomy guided, submodular, active learning method for collecting annotations\nabout rare entities (e.g., oriole, a bird) is 6x more effective at inferring\nfurther new facts about them than multiple active learning baselines.\n"]},
{"authors": ["Jelena Stojanovic", "Djordje Gligorijevic", "Zoran Obradovic"], "title": ["Modeling Customer Engagement from Partial Observations"], "date": ["2018-03-28T18:49:07Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10799v1"], "summary": ["  It is of high interest for a company to identify customers expected to bring\nthe largest profit in the upcoming period. Knowing as much as possible about\neach customer is crucial for such predictions. However, their demographic data,\npreferences, and other information that might be useful for building loyalty\nprograms is often missing. Additionally, modeling relations among different\ncustomers as a network can be beneficial for predictions at an individual\nlevel, as similar customers tend to have similar purchasing patterns. We\naddress this problem by proposing a robust framework for structured regression\non deficient data in evolving networks with a supervised representation\nlearning based on neural features embedding. The new method is compared to\nseveral unstructured and structured alternatives for predicting customer\nbehavior (e.g. purchasing frequency and customer ticket) on user networks\ngenerated from customer databases of two companies from different industries.\nThe obtained results show $4\\%$ to $130\\%$ improvement in accuracy over\nalternatives when all customer information is known. Additionally, the\nrobustness of our method is demonstrated when up to $80\\%$ of demographic\ninformation was missing where it was up to several folds more accurate as\ncompared to alternatives that are either ignoring cases with missing values or\nlearn their feature representation in an unsupervised manner.\n"]},
{"authors": ["Nicolas Loizou", "Peter Richt\u00e1rik"], "title": ["Momentum and Stochastic Momentum for Stochastic Gradient, Newton,\n  Proximal Point and Subspace Descent Methods"], "date": ["2017-12-27T20:40:24Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1712.09677v2"], "summary": ["  In this paper we study several classes of stochastic optimization algorithms\nenriched with heavy ball momentum. Among the methods studied are: stochastic\ngradient descent, stochastic Newton, stochastic proximal point and stochastic\ndual subspace ascent. This is the first time momentum variants of several of\nthese methods are studied. We choose to perform our analysis in a setting in\nwhich all of the above methods are equivalent. We prove global nonassymptotic\nlinear convergence rates for all methods and various measures of success,\nincluding primal function values, primal iterates (in L2 sense), and dual\nfunction values. We also show that the primal iterates converge at an\naccelerated linear rate in the L1 sense. This is the first time a linear rate\nis shown for the stochastic heavy ball method (i.e., stochastic gradient\ndescent method with momentum). Under somewhat weaker conditions, we establish a\nsublinear convergence rate for Cesaro averages of primal iterates. Moreover, we\npropose a novel concept, which we call stochastic momentum, aimed at decreasing\nthe cost of performing the momentum step. We prove linear convergence of\nseveral stochastic methods with stochastic momentum, and show that in some\nsparse data regimes and for sufficiently small momentum parameters, these\nmethods enjoy better overall complexity than methods with deterministic\nmomentum. Finally, we perform extensive numerical testing on artificial and\nreal datasets, including data coming from average consensus problems.\n"]},
{"authors": ["Greg Wayne", "Chia-Chun Hung", "David Amos", "Mehdi Mirza", "Arun Ahuja", "Agnieszka Grabska-Barwinska", "Jack Rae", "Piotr Mirowski", "Joel Z. Leibo", "Adam Santoro", "Mevlana Gemici", "Malcolm Reynolds", "Tim Harley", "Josh Abramson", "Shakir Mohamed", "Danilo Rezende", "David Saxton", "Adam Cain", "Chloe Hillier", "David Silver", "Koray Kavukcuoglu", "Matt Botvinick", "Demis Hassabis", "Timothy Lillicrap"], "title": ["Unsupervised Predictive Memory in a Goal-Directed Agent"], "date": ["2018-03-28T17:54:01Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10760v1"], "summary": ["  Animals execute goal-directed behaviours despite the limited range and scope\nof their sensors. To cope, they explore environments and store memories\nmaintaining estimates of important information that is not presently available.\nRecently, progress has been made with artificial intelligence (AI) agents that\nlearn to perform tasks from sensory input, even at a human level, by merging\nreinforcement learning (RL) algorithms with deep neural networks, and the\nexcitement surrounding these results has led to the pursuit of related ideas as\nexplanations of non-human animal learning. However, we demonstrate that\ncontemporary RL algorithms struggle to solve simple tasks when enough\ninformation is concealed from the sensors of the agent, a property called\n\"partial observability\". An obvious requirement for handling partially observed\ntasks is access to extensive memory, but we show memory is not enough; it is\ncritical that the right information be stored in the right format. We develop a\nmodel, the Memory, RL, and Inference Network (MERLIN), in which memory\nformation is guided by a process of predictive modeling. MERLIN facilitates the\nsolution of tasks in 3D virtual reality environments for which partial\nobservability is severe and memories must be maintained over long durations.\nOur model demonstrates a single learning agent architecture that can solve\ncanonical behavioural tasks in psychology and neurobiology without strong\nsimplifying assumptions about the dimensionality of sensory input or the\nduration of experiences.\n"]},
{"authors": ["Sven Schmit", "Carlos Riquelme"], "title": ["Human Interaction with Recommendation Systems"], "date": ["2017-03-01T22:28:42Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1703.00535v3"], "summary": ["  Many recommendation algorithms rely on user data to generate recommendations.\nHowever, these recommendations also affect the data obtained from future users.\nThis work aims to understand the effects of this dynamic interaction. We\npropose a simple model where users with heterogeneous preferences arrive over\ntime. Based on this model, we prove that naive estimators, i.e. those which\nignore this feedback loop, are not consistent. We show that consistent\nestimators are efficient in the presence of myopic agents. Our results are\nvalidated using extensive simulations.\n"]},
{"authors": ["Charles Gadd", "Sara Wade", "Akeel Shah", "Dimitris Grammatopoulos"], "title": ["Pseudo-marginal Bayesian inference for supervised Gaussian process\n  latent variable models"], "date": ["2018-03-28T17:31:12Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10746v1"], "summary": ["  We introduce a Bayesian framework for inference with a supervised version of\nthe Gaussian process latent variable model. The framework overcomes the high\ncorrelations between latent variables and hyperparameters by using an unbiased\npseudo estimate for the marginal likelihood that approximately integrates over\nthe latent variables. This is used to construct a Markov Chain to explore the\nposterior of the hyperparameters. We demonstrate the procedure on simulated and\nreal examples, showing its ability to capture uncertainty and multimodality of\nthe hyperparameters and improved uncertainty quantification in predictions when\ncompared with variational inference.\n"]},
{"authors": ["David Friedlander"], "title": ["Pattern Analysis with Layered Self-Organizing Maps"], "date": ["2018-03-23T22:07:52Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08996v2"], "summary": ["  This paper defines a new learning architecture, Layered Self-Organizing Maps\n(LSOMs), that uses the SOM and supervised-SOM learning algorithms. The\narchitecture is validated with the MNIST database of hand-written digit images.\nLSOMs are similar to convolutional neural nets (covnets) in the way they sample\ndata, but different in the way they represent features and learn. LSOMs analyze\n(or generate) image patches with maps of exemplars determined by the SOM\nlearning algorithm rather than feature maps from filter-banks learned via\nbackprop.\n  LSOMs provide an alternative to features derived from covnets. Multi-layer\nLSOMs are trained bottom-up, without the use of backprop and therefore may be\nof interest as a model of the visual cortex. The results show organization at\nmultiple levels. The algorithm appears to be resource efficient in learning,\nclassifying and generating images. Although LSOMs can be used for\nclassification, their validation accuracy for these exploratory runs was well\nbelow the state of the art. The goal of this article is to define the\narchitecture and display the structures resulting from its application to the\nMNIST images.\n"]},
{"authors": ["Spencer Chang", "Timothy Cohen", "Bryan Ostdiek"], "title": ["What is the Machine Learning?"], "date": ["2017-09-28T18:00:00Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1709.10106v2"], "summary": ["  Applications of machine learning tools to problems of physical interest are\noften criticized for producing sensitivity at the expense of transparency. To\naddress this concern, we explore a data planing procedure for identifying\ncombinations of variables -- aided by physical intuition -- that can\ndiscriminate signal from background. Weights are introduced to smooth away the\nfeatures in a given variable(s). New networks are then trained on this modified\ndata. Observed decreases in sensitivity diagnose the variable's discriminating\npower. Planing also allows the investigation of the linear versus non-linear\nnature of the boundaries between signal and background. We demonstrate the\nefficacy of this approach using a toy example, followed by an application to an\nidealized heavy resonance scenario at the Large Hadron Collider. By unpacking\nthe information being utilized by these algorithms, this method puts in context\nwhat it means for a machine to learn.\n"]},
{"authors": ["Timothy Cohen", "Marat Freytsis", "Bryan Ostdiek"], "title": ["(Machine) Learning to Do More with Less"], "date": ["2017-06-28T19:28:52Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1706.09451v3"], "summary": ["  Determining the best method for training a machine learning algorithm is\ncritical to maximizing its ability to classify data. In this paper, we compare\nthe standard \"fully supervised\" approach (that relies on knowledge of\nevent-by-event truth-level labels) with a recent proposal that instead utilizes\nclass ratios as the only discriminating information provided during training.\nThis so-called \"weakly supervised\" technique has access to less information\nthan the fully supervised method and yet is still able to yield impressive\ndiscriminating power. In addition, weak supervision seems particularly well\nsuited to particle physics since quantum mechanics is incompatible with the\nnotion of mapping an individual event onto any single Feynman diagram. We\nexamine the technique in detail -- both analytically and numerically -- with a\nfocus on the robustness to issues of mischaracterizing the training samples.\nWeakly supervised networks turn out to be remarkably insensitive to systematic\nmismodeling. Furthermore, we demonstrate that the event level outputs for\nweakly versus fully supervised networks are probing different kinematics, even\nthough the numerical quality metrics are essentially identical. This implies\nthat it should be possible to improve the overall classification ability by\ncombining the output from the two types of networks. For concreteness, we apply\nthis technology to a signature of beyond the Standard Model physics to\ndemonstrate that all these impressive features continue to hold in a scenario\nof relevance to the LHC.\n"]},
{"authors": ["Jelena Stojanovic", "Milos Jovanovic", "Djordje Gligorijevic", "Zoran Obradovic"], "title": ["Semi-supervised learning for structured regression on partially observed\n  attributed graphs"], "date": ["2018-03-28T16:16:14Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10705v1"], "summary": ["  Conditional probabilistic graphical models provide a powerful framework for\nstructured regression in spatio-temporal datasets with complex correlation\npatterns. However, in real-life applications a large fraction of observations\nis often missing, which can severely limit the representational power of these\nmodels. In this paper we propose a Marginalized Gaussian Conditional Random\nFields (m-GCRF) structured regression model for dealing with missing labels in\npartially observed temporal attributed graphs. This method is aimed at learning\nwith both labeled and unlabeled parts and effectively predicting future values\nin a graph. The method is even capable of learning from nodes for which the\nresponse variable is never observed in history, which poses problems for many\nstate-of-the-art models that can handle missing data. The proposed model is\ncharacterized for various missingness mechanisms on 500 synthetic graphs. The\nbenefits of the new method are also demonstrated on a challenging application\nfor predicting precipitation based on partial observations of climate variables\nin a temporal graph that spans the entire continental US. We also show that the\nmethod can be useful for optimizing the costs of data collection in climate\napplications via active reduction of the number of weather stations to\nconsider. In experiments on these real-world and synthetic datasets we show\nthat the proposed model is consistently more accurate than alternative\nsemi-supervised structured models, as well as models that either use imputation\nto deal with missing values or simply ignore them altogether.\n"]},
{"authors": ["Djordje Gligorijevic", "Jelena Stojanovic", "Zoran Obradovic"], "title": ["Improving confidence while predicting trends in temporal disease\n  networks"], "date": ["2018-03-28T15:53:39Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.11462v1"], "summary": ["  For highly sensitive real-world predictive analytic applications such as\nhealthcare and medicine, having good prediction accuracy alone is often not\nenough. These kinds of applications require a decision making process which\nuses uncertainty estimation as input whenever possible. Quality of uncertainty\nestimation is a subject of over or under confident prediction, which is often\nnot addressed in many models. In this paper we show several extensions to the\nGaussian Conditional Random Fields model, which aim to provide higher quality\nuncertainty estimation. These extensions are applied to the temporal disease\ngraph built from the State Inpatient Database (SID) of California, acquired\nfrom the HCUP. Our experiments demonstrate benefits of using graph information\nin modeling temporal disease properties as well as improvements in uncertainty\nestimation provided by given extensions of the Gaussian Conditional Random\nFields method.\n"]},
{"authors": ["Konrad Zolna", "Devansh Arpit", "Dendi Suhubdy", "Yoshua Bengio"], "title": ["Fraternal Dropout"], "date": ["2017-10-31T19:32:45Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.00066v4"], "summary": ["  Recurrent neural networks (RNNs) are important class of architectures among\nneural networks useful for language modeling and sequential prediction.\nHowever, optimizing RNNs is known to be harder compared to feed-forward neural\nnetworks. A number of techniques have been proposed in literature to address\nthis problem. In this paper we propose a simple technique called fraternal\ndropout that takes advantage of dropout to achieve this goal. Specifically, we\npropose to train two identical copies of an RNN (that share parameters) with\ndifferent dropout masks while minimizing the difference between their\n(pre-softmax) predictions. In this way our regularization encourages the\nrepresentations of RNNs to be invariant to dropout mask, thus being robust. We\nshow that our regularization term is upper bounded by the expectation-linear\ndropout objective which has been shown to address the gap due to the difference\nbetween the train and inference phases of dropout. We evaluate our model and\nachieve state-of-the-art results in sequence modeling tasks on two benchmark\ndatasets - Penn Treebank and Wikitext-2. We also show that our approach leads\nto performance improvement by a significant margin in image captioning\n(Microsoft COCO) and semi-supervised (CIFAR-10) tasks.\n"]},
{"authors": ["Constantin Grigo", "Phaedon-Stelios Koutsourelakis"], "title": ["Bayesian model and dimension reduction for uncertainty propagation:\n  applications in random media"], "date": ["2017-11-07T14:19:24Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.02475v2"], "summary": ["  Well-established methods for the solution of stochastic partial differential\nequations (SPDEs) typically struggle in problems with high-dimensional\ninputs/outputs. Such difficulties are only amplified in large-scale\napplications where even a few tens of full-order model runs are impracticable.\nWhile dimensionality reduction can alleviate some of these issues, it is not\nknown which and how many features of the (high-dimensional) input are actually\npredictive of the (high-dimensional) output. In this paper, we advocate a\nBayesian formulation that is capable of performing simultaneous dimension and\nmodel-order reduction. It consists of a component that encodes the\nhigh-dimensional input into a low-dimensional set of feature functions by\nemploying sparsity-enforcing priors and a decoding component that makes use of\nthe solution of a coarse-grained model in order to reconstruct that of the\nfull-order model. Both components are represented with latent variables in a\nprobabilistic graphical model and are simultaneously trained using Stochastic\nVariational Inference methods. The model is capable of quantifying the\npredictive uncertainty due to the information loss that unavoidably takes place\nin any model-order/dimension reduction as well as the uncertainty arising from\nfinite-sized training datasets. We demonstrate its capabilities in the context\nof random media where fine-scale fluctuations can give rise to random inputs\nwith tens of thousands of variables. With a few tens of full-order model\nsimulations, the proposed model is capable of identifying salient physical\nfeatures and produce sharp predictions under different boundary conditions of\nthe full output which itself consists of thousands of components.\n"]},
{"authors": ["Bernardo P\u00e9rez Orozco", "Gabriele Abbati", "Stephen Roberts"], "title": ["MOrdReD: Memory-based Ordinal Regression Deep Neural Networks for Time\n  Series Forecasting"], "date": ["2018-03-26T16:36:37Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09704v2"], "summary": ["  Time series forecasting is ubiquitous in the modern world. Applications range\nfrom health care to astronomy, include climate modelling, financial trading and\nmonitoring of critical engineering equipment. To offer value over this range of\nactivities we must have models that not only provide accurate forecasts but\nthat also quantify and adjust their uncertainty over time. Furthermore, such\nmodels must allow for multimodal, non-Gaussian behaviour that arises regularly\nin applied settings. In this work, we propose a novel, end-to-end deep learning\nmethod for time series forecasting. Crucially, our model allows the principled\nassessment of predictive uncertainty as well as providing rich information\nregarding multiple modes of future data values. Our approach not only provides\nan excellent predictive forecast, shadowing true future values, but also allows\nus to infer valuable information, such as the predictive distribution of the\noccurrence of critical events of interest, accurately and reliably even over\nlong time horizons. We find the method outperforms other state-of-the-art\nalgorithms, such as Gaussian Processes.\n"]},
{"authors": ["Yucen Luo", "Jun Zhu", "Mengxi Li", "Yong Ren", "Bo Zhang"], "title": ["Smooth Neighbors on Teacher Graphs for Semi-supervised Learning"], "date": ["2017-11-01T09:10:07Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.00258v2"], "summary": ["  The recently proposed self-ensembling methods have achieved promising results\nin deep semi-supervised learning, which penalize inconsistent predictions of\nunlabeled data under different perturbations. However, they only consider\nadding perturbations to each single data point, while ignoring the connections\nbetween data samples. In this paper, we propose a novel method, called Smooth\nNeighbors on Teacher Graphs (SNTG). In SNTG, a graph is constructed based on\nthe predictions of the teacher model, i.e., the implicit self-ensemble of\nmodels. Then the graph serves as a similarity measure with respect to which the\nrepresentations of \"similar\" neighboring points are learned to be smooth on the\nlow-dimensional manifold. We achieve state-of-the-art results on\nsemi-supervised learning benchmarks. The error rates are 9.89%, 3.99% for\nCIFAR-10 with 4000 labels, SVHN with 500 labels, respectively. In particular,\nthe improvements are significant when the labels are fewer. For the\nnon-augmented MNIST with only 20 labels, the error rate is reduced from\nprevious 4.81% to 1.36%. Our method also shows robustness to noisy labels.\n"]},
{"authors": ["Krishnan Kumaran", "Dimitri Papageorgiou", "Yutong Chang", "Minhan Li", "Martin Tak\u00e1\u010d"], "title": ["Active Metric Learning for Supervised Classification"], "date": ["2018-03-28T14:36:37Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10647v1"], "summary": ["  Clustering and classification critically rely on distance metrics that\nprovide meaningful comparisons between data points. We present mixed-integer\noptimization approaches to find optimal distance metrics that generalize the\nMahalanobis metric extensively studied in the literature. Additionally, we\ngeneralize and improve upon leading methods by removing reliance on\npre-designated \"target neighbors,\" \"triplets,\" and \"similarity pairs.\" Another\nsalient feature of our method is its ability to enable active learning by\nrecommending precise regions to sample after an optimal metric is computed to\nimprove classification performance. This targeted acquisition can significantly\nreduce computational burden by ensuring training data completeness,\nrepresentativeness, and economy. We demonstrate classification and\ncomputational performance of the algorithms through several simple and\nintuitive examples, followed by results on real image and medical datasets.\n"]},
{"authors": ["Finn Macleod"], "title": ["Unreasonable Effectivness of Deep Learning"], "date": ["2018-03-28T14:29:30Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10768v1"], "summary": ["  We show how well known rules of back propagation arise from a weighted\ncombination of finite automata. By redefining a finite automata as a predictor\nwe combine the set of all $k$-state finite automata using a weighted majority\nalgorithm. This aggregated prediction algorithm can be simplified using\nsymmetry, and we prove the equivalence of an algorithm that does this. We\ndemonstrate that this algorithm is equivalent to a form of a back propagation\nacting in a completely connected $k$-node neural network. Thus the use of the\nweighted majority algorithm allows a bound on the general performance of deep\nlearning approaches to prediction via known results from online statistics. The\npresented framework opens more detailed questions about network topology; it is\na bridge to the well studied techniques of semigroup theory and applying these\ntechniques to answer what specific network topologies are capable of\npredicting. This informs both the design of artificial networks and the\nexploration of neuroscience models.\n"]},
{"authors": ["Hasan Abasi", "Nader H. Bshouty"], "title": ["On Learning Graphs with Edge-Detecting Queries"], "date": ["2018-03-28T14:20:17Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10639v1"], "summary": ["  We consider the problem of learning a general graph $G=(V,E)$ using\nedge-detecting queries, where the number of vertices $|V|=n$ is given to the\nlearner. The information theoretic lower bound gives $m\\log n$ for the number\nof queries, where $m=|E|$ is the number of edges. In case the number of edges\n$m$ is also given to the learner, Angluin-Chen's Las Vegas algorithm\n\\cite{AC08} runs in $4$ rounds and detects the edges in $O(m\\log n)$ queries.\nIn the other harder case where the number of edges $m$ is unknown, their\nalgorithm runs in $5$ rounds and asks $O(m\\log n+\\sqrt{m}\\log^2 n)$ queries.\nThere have been two open problems: \\emph{(i)} can the number of queries be\nreduced to $O(m\\log n)$ in the second case, and, \\emph{(ii)} can the number of\nrounds be reduced without substantially increasing the number of queries (in\nboth cases). For the first open problem (when $m$ is unknown) we give two\nalgorithms. The first is an $O(1)$-round Las Vegas algorithm that asks $m\\log\nn+\\sqrt{m}(\\log^{[k]}n)\\log n$ queries for any constant $k$ where\n$\\log^{[k]}n=\\log \\stackrel{k}{\\cdots} \\log n$. The second is an\n$O(\\log^*n)$-round Las Vegas algorithm that asks $O(m\\log n)$ queries. This\nsolves the first open problem for any practical $n$, for example,\n$n<2^{65536}$. We also show that no deterministic algorithm can solve this\nproblem in a constant number of rounds. To solve the second problem we study\nthe case when $m$ is known. We first show that any non-adaptive Monte Carlo\nalgorithm (one-round) must ask at least $\\Omega(m^2\\log n)$ queries, and any\ntwo-round Las Vegas algorithm must ask at least $m^{4/3-o(1)}\\log n$ queries on\naverage. We then give two two-round Monte Carlo algorithms, the first asks\n$O(m^{4/3}\\log n)$ queries for any $n$ and $m$, and the second asks $O(m\\log\nn)$ queries when $n>2^m$. Finally, we give a $3$-round Monte Carlo algorithm\nthat asks $O(m\\log n)$ queries for any $n$ and $m$.\n"]},
{"authors": ["Alexander Shekhovtsov", "Boris Flach", "Michal Busta"], "title": ["Feed-forward Uncertainty Propagation in Belief and Neural Networks"], "date": ["2018-03-28T13:26:47Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10590v1"], "summary": ["  We propose a feed-forward inference method applicable to belief and neural\nnetworks. In a belief network, the method estimates an approximate factorized\nposterior of all hidden units given the input. In neural networks the method\npropagates uncertainty of the input through all the layers. In neural networks\nwith injected noise, the method analytically takes into account uncertainties\nresulting from this noise. Such feed-forward analytic propagation is\ndifferentiable in parameters and can be trained end-to-end. Compared to\nstandard NN, which can be viewed as propagating only the means, we propagate\nthe mean and variance. The method can be useful in all scenarios that require\nknowledge of the neuron statistics, e.g. when dealing with uncertain inputs,\nconsidering sigmoid activations as probabilities of Bernoulli units, training\nthe models regularized by injected noise (dropout) or estimating activation\nstatistics over the dataset (as needed for normalization methods). In the\nexperiments we show the possible utility of the method in all these tasks as\nwell as its current limitations.\n"]},
{"authors": ["Tobias Pl\u00f6tz", "Anne S. Wannenwetsch", "Stefan Roth"], "title": ["Stochastic Variational Inference with Gradient Linearization"], "date": ["2018-03-28T13:22:57Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10586v1"], "summary": ["  Variational inference has experienced a recent surge in popularity owing to\nstochastic approaches, which have yielded practical tools for a wide range of\nmodel classes. A key benefit is that stochastic variational inference obviates\nthe tedious process of deriving analytical expressions for closed-form variable\nupdates. Instead, one simply needs to derive the gradient of the log-posterior,\nwhich is often much easier. Yet for certain model classes, the log-posterior\nitself is difficult to optimize using standard gradient techniques. One such\nexample are random field models, where optimization based on gradient\nlinearization has proven popular, since it speeds up convergence significantly\nand can avoid poor local optima. In this paper we propose stochastic\nvariational inference with gradient linearization (SVIGL). It is similarly\nconvenient as standard stochastic variational inference - all that is required\nis a local linearization of the energy gradient. Its benefit over stochastic\nvariational inference with conventional gradient methods is a clear improvement\nin convergence speed, while yielding comparable or even better variational\napproximations in terms of KL divergence. We demonstrate the benefits of SVIGL\nin three applications: Optical flow estimation, Poisson-Gaussian denoising, and\n3D surface reconstruction.\n"]},
{"authors": ["Paul Rolland", "Jonathan Scarlett", "Ilija Bogunovic", "Volkan Cevher"], "title": ["High-Dimensional Bayesian Optimization via Additive Models with\n  Overlapping Groups"], "date": ["2018-02-20T09:42:03Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.07028v2"], "summary": ["  Bayesian optimization (BO) is a popular technique for sequential black-box\nfunction optimization, with applications including parameter tuning, robotics,\nenvironmental monitoring, and more. One of the most important challenges in BO\nis the development of algorithms that scale to high dimensions, which remains a\nkey open problem despite recent progress. In this paper, we consider the\napproach of Kandasamy et al. (2015), in which the high-dimensional function\ndecomposes as a sum of lower-dimensional functions on subsets of the underlying\nvariables. In particular, we significantly generalize this approach by lifting\nthe assumption that the subsets are disjoint, and consider additive models with\narbitrary overlap among the subsets. By representing the dependencies via a\ngraph, we deduce an efficient message passing algorithm for optimizing the\nacquisition function. In addition, we provide an algorithm for learning the\ngraph from samples based on Gibbs sampling. We empirically demonstrate the\neffectiveness of our methods on both synthetic and real-world data.\n"]},
{"authors": ["Alexander Shekhovtsov", "Boris Flach"], "title": ["Normalization of Neural Networks using Analytic Variance Propagation"], "date": ["2018-03-28T12:37:27Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10560v1"], "summary": ["  We address the problem of estimating statistics of hidden units in a neural\nnetwork using a method of analytic moment propagation. These statistics are\nuseful for approximate whitening of the inputs in front of saturating\nnon-linearities such as a sigmoid function. This is important for\ninitialization of training and for reducing the accumulated scale and bias\ndependencies (compensating covariate shift), which presumably eases the\nlearning. In batch normalization, which is currently a very widely applied\ntechnique, sample estimates of statistics of hidden units over a batch are\nused. The proposed estimation uses an analytic propagation of mean and variance\nof the training set through the network. The result depends on the network\nstructure and its current weights but not on the specific batch input. The\nestimates are suitable for initialization and normalization, efficient to\ncompute and independent of the batch size. The experimental verification well\nsupports these claims. However, the method does not share the generalization\nproperties of BN, to which our experiments give some additional insight.\n"]},
{"authors": ["Luciana Ferrer", "Mitchell McLaren"], "title": ["Joint PLDA for Simultaneous Modeling of Two Factors"], "date": ["2018-03-28T12:11:56Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10554v1"], "summary": ["  Probabilistic linear discriminant analysis (PLDA) is a method used for\nbiometric problems like speaker or face recognition that models the variability\nof the samples using two latent variables, one that depends on the class of the\nsample and another one that is assumed independent across samples and models\nthe within-class variability. In this work, we propose a generalization of PLDA\nthat enables joint modeling of two sample-dependent factors: the class of\ninterest and a nuisance condition. The approach does not change the basic form\nof PLDA but rather modifies the training procedure to consider the dependency\nacross samples of the latent variable that models within-class variability.\nWhile the identity of the nuisance condition is needed during training, it is\nnot needed during testing since we propose a scoring procedure that\nmarginalizes over the corresponding latent variable. We show results on a\nmultilingual speaker-verification task, where the language spoken is considered\na nuisance condition. We show that the proposed joint PLDA approach leads to\nsignificant performance gains in this task for two different datasets, in\nparticular when the training data contains mostly or only monolingual speakers.\n"]},
{"authors": ["Uri Alon", "Meital Zilberstein", "Omer Levy", "Eran Yahav"], "title": ["code2vec: Learning Distributed Representations of Code"], "date": ["2018-03-26T09:05:30Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09473v2"], "summary": ["  We present a neural model for representing snippets of code as continuous\ndistributed vectors. The main idea is to represent code as a collection of\npaths in its abstract syntax tree, and aggregate these paths, in a smart and\nscalable way, into a single fixed-length $\\textit{code vector}$, which can be\nused to predict semantic properties of the snippet.\n  We demonstrate the effectiveness of our approach by using it to predict a\nmethod's name from the vector representation of its body. We evaluate our\napproach by training a model on a dataset of $14$M methods. We show that code\nvectors trained on this dataset can predict method names from files that were\ncompletely unobserved during training. Furthermore, we show that our model\nlearns useful method name vectors that capture semantic similarities,\ncombinations, and analogies.\n  Comparing previous techniques over the same data set, our approach obtains a\nrelative improvement of over $75\\%$, being the first to successfully predict\nmethod names based on a large, cross-project, corpus.\n"]},
{"authors": ["Zhikuan Zhao", "Jack K. Fitzsimons", "Michael A. Osborne", "Stephen J. Roberts", "Joseph F. Fitzsimons"], "title": ["Quantum algorithms for training Gaussian Processes"], "date": ["2018-03-28T10:53:37Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10520v1"], "summary": ["  Gaussian processes (GPs) are important models in supervised machine learning.\nTraining in Gaussian processes refers to selecting the covariance functions and\nthe associated parameters in order to improve the outcome of predictions, the\ncore of which amounts to evaluating the logarithm of the marginal likelihood\n(LML) of a given model. LML gives a concrete measure of the quality of\nprediction that a GP model is expected to achieve. The classical computation of\nLML typically carries a polynomial time overhead with respect to the input\nsize. We propose a quantum algorithm that computes the logarithm of the\ndeterminant of a Hermitian matrix, which runs in logarithmic time for sparse\nmatrices. This is applied in conjunction with a variant of the quantum linear\nsystem algorithm that allows for logarithmic time computation of the form\n$\\mathbf{y}^TA^{-1}\\mathbf{y}$, where $\\mathbf{y}$ is a dense vector and $A$ is\nthe covariance matrix. We hence show that quantum computing can be used to\nestimate the LML of a GP with exponentially improved efficiency under certain\nconditions.\n"]},
{"authors": ["Eunhee Kang", "Jaejun Yoo", "Jong Chul Ye"], "title": ["Deep Convolutional Framelet Denosing for Low-Dose CT via Wavelet\n  Residual Network"], "date": ["2017-07-31T16:17:31Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1707.09938v3"], "summary": ["  Model based iterative reconstruction (MBIR) algorithms for low-dose X-ray CT\nare computationally expensive. To address this problem, we recently proposed a\ndeep convolutional neural network (CNN) for low-dose X-ray CT and won the\nsecond place in 2016 AAPM Low-Dose CT Grand Challenge. However, some of the\ntexture were not fully recovered. To address this problem, here we propose a\nnovel framelet-based denoising algorithm using wavelet residual network which\nsynergistically combines the expressive power of deep learning and the\nperformance guarantee from the framelet-based denoising algorithms. The new\nalgorithms were inspired by the recent interpretation of the deep convolutional\nneural network (CNN) as a cascaded convolution framelet signal representation.\nExtensive experimental results confirm that the proposed networks have\nsignificantly improved performance and preserves the detail texture of the\noriginal images.\n"]},
{"authors": ["Boussad Addad", "Jerome Kodjabachian", "Christophe Meyer"], "title": ["Clipping free attacks against artificial neural networks"], "date": ["2018-03-26T08:39:15Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09468v2"], "summary": ["  During the last years, a remarkable breakthrough has been made in AI domain\nthanks to artificial deep neural networks that achieved a great success in many\nmachine learning tasks in computer vision, natural language processing, speech\nrecognition, malware detection and so on. However, they are highly vulnerable\nto easily crafted adversarial examples. Many investigations have pointed out\nthis fact and different approaches have been proposed to generate attacks while\nadding a limited perturbation to the original data. The most robust known\nmethod so far is the so called C&W attack [1]. Nonetheless, a countermeasure\nknown as feature squeezing coupled with ensemble defense showed that most of\nthese attacks can be destroyed [6]. In this paper, we present a new method we\ncall Centered Initial Attack (CIA) whose advantage is twofold : first, it\ninsures by construction the maximum perturbation to be smaller than a threshold\nfixed beforehand, without the clipping process that degrades the quality of\nattacks. Second, it is robust against recently introduced defenses such as\nfeature squeezing, JPEG encoding and even against a voting ensemble of\ndefenses. While its application is not limited to images, we illustrate this\nusing five of the current best classifiers on ImageNet dataset among which two\nare adversarialy retrained on purpose to be robust against attacks. With a\nfixed maximum perturbation of only 1.5% on any pixel, around 80% of attacks\n(targeted) fool the voting ensemble defense and nearly 100% when the\nperturbation is only 6%. While this shows how it is difficult to defend against\nCIA attacks, the last section of the paper gives some guidelines to limit their\nimpact.\n"]},
{"authors": ["Yoseob Han", "Jong Chul Ye"], "title": ["Framing U-Net via Deep Convolutional Framelets: Application to\n  Sparse-view CT"], "date": ["2017-08-28T14:31:50Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1708.08333v3"], "summary": ["  X-ray computed tomography (CT) using sparse projection views is a recent\napproach to reduce the radiation dose. However, due to the insufficient\nprojection views, an analytic reconstruction approach using the filtered back\nprojection (FBP) produces severe streaking artifacts. Recently, deep learning\napproaches using large receptive field neural networks such as U-Net have\ndemonstrated impressive performance for sparse- view CT reconstruction.\nHowever, theoretical justification is still lacking. Inspired by the recent\ntheory of deep convolutional framelets, the main goal of this paper is,\ntherefore, to reveal the limitation of U-Net and propose new multi-resolution\ndeep learning schemes. In particular, we show that the alternative U- Net\nvariants such as dual frame and the tight frame U-Nets satisfy the so-called\nframe condition which make them better for effective recovery of high frequency\nedges in sparse view- CT. Using extensive experiments with real patient data\nset, we demonstrate that the new network architectures provide better\nreconstruction performance.\n"]},
{"authors": ["Kristina Preuer", "Philipp Renz", "Thomas Unterthiner", "Sepp Hochreiter", "G\u00fcnter Klambauer"], "title": ["Fr\u00e9chet ChemblNet Distance: A metric for generative models for\n  molecules"], "date": ["2018-03-26T11:36:24Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09518v2"], "summary": ["  The new wave of successful generative models in machine learning has\nincreased the interest in deep learning driven de novo drug design. However,\nassessing the performance of such generative models is notoriously difficult.\nMetrics that are typically used to assess the performance of such generative\nmodels are the percentage of chemically valid molecules or the similarity to\nreal molecules in terms of particular descriptors, such as the partition\ncoefficient (logP) or druglikeness. However, method comparison is difficult\nbecause of the inconsistent use of evaluation metrics, the necessity for\nmultiple metrics, and the fact that some of these measures can easily be\ntricked by simple rule-based systems. We propose a novel distance measure\nbetween two sets of molecules, called Fr\\'echet ChemblNet distance (FCD), that\ncan be used as an evaluation metric for generative models. The FCD is similar\nto a recently established performance metric for comparing image generation\nmethods, the Fr\\'echet Inception Distance (FID). Whereas the FID uses one of\nthe hidden layers of InceptionNet, the FCD utilizes the penultimate layer of a\ndeep neural network called \"ChemblNet\", which was trained to predict drug\nactivities. Thus, the FCD metric takes into account chemically and biologically\nrelevant information about molecules, and also measures the diversity of the\nset via the distribution of generated molecules. The FCD's advantage over\nprevious metrics is that it can detect if generated molecules are a) diverse\nand have similar b) chemical and c) biological properties as real molecules. We\nfurther provide an easy-to-use implementation that only requires the SMILES\nrepresentation of the generated molecules as input to calculate the FCD.\nImplementations are available at: https://www.github.com/bioinf-jku/FCD\n"]},
{"authors": ["Lingjiao Chen", "Hongyi Wang", "Zachary Charles", "Dimitris Papailiopoulos"], "title": ["DRACO: Robust Distributed Training via Redundant Gradients"], "date": ["2018-03-27T03:34:25Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09877v2"], "summary": ["  Distributed model training is vulnerable to worst-case system failures and\nadversarial compute nodes, i.e., nodes that use malicious updates to corrupt\nthe global model stored at a parameter server (PS). To tolerate node failures\nand adversarial attacks, recent work suggests using variants of the geometric\nmedian to aggregate distributed updates at the PS, in place of bulk averaging.\nAlthough median-based update rules are robust to adversarial nodes, their\ncomputational cost can be prohibitive in large-scale settings and their\nconvergence guarantees often require relatively strong assumptions.\n  In this work, we present DRACO, a scalable framework for robust distributed\ntraining that uses ideas from coding theory. In DRACO, each compute node\nevaluates redundant gradients that are then used by the parameter server to\neliminate the effects of adversarial updates. We present problem-independent\nrobustness guarantees for DRACO and show that the model it produces is\nidentical to the one trained in the adversary-free setup. We provide extensive\nexperiments on real datasets and distributed setups across a variety of\nlarge-scale models, where we show that DRACO is several times to orders of\nmagnitude faster than median-based approaches.\n"]},
{"authors": ["Yuval Dagan", "Koby Crammer"], "title": ["A Better Resource Allocation Algorithm with Semi-Bandit Feedback"], "date": ["2018-03-28T05:05:24Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10415v1"], "summary": ["  We study a sequential resource allocation problem between a fixed number of\narms. On each iteration the algorithm distributes a resource among the arms in\norder to maximize the expected success rate. Allocating more of the resource to\na given arm increases the probability that it succeeds, yet with a cut-off. We\nfollow Lattimore et al. (2014) and assume that the probability increases\nlinearly until it equals one, after which allocating more of the resource is\nwasteful. These cut-off values are fixed and unknown to the learner. We present\nan algorithm for this problem and prove a regret upper bound of $O(\\log n)$\nimproving over the best known bound of $O(\\log^2 n)$. Lower bounds we prove\nshow that our upper bound is tight. Simulations demonstrate the superiority of\nour algorithm.\n"]},
{"authors": ["Kun He", "Fatih Cakir", "Sarah Adel Bargal", "Stan Sclaroff"], "title": ["Hashing as Tie-Aware Learning to Rank"], "date": ["2017-05-23T23:42:46Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1705.08562v3"], "summary": ["  Hashing, or learning binary embeddings of data, is frequently used in nearest\nneighbor retrieval. In this paper, we develop learning to rank formulations for\nhashing, aimed at directly optimizing ranking-based evaluation metrics such as\nAverage Precision (AP) and Normalized Discounted Cumulative Gain (NDCG). We\nfirst observe that the integer-valued Hamming distance often leads to tied\nrankings, and propose to use tie-aware versions of AP and NDCG to evaluate\nhashing for retrieval. Then, to optimize tie-aware ranking metrics, we derive\ntheir continuous relaxations, and perform gradient-based optimization with deep\nneural networks. Our results establish the new state-of-the-art for image\nretrieval by Hamming ranking in common benchmarks.\n"]},
{"authors": ["Sambit Ghadai", "Aditya Balu", "Adarsh Krishnamurthy", "Soumik Sarkar"], "title": ["Learning and Visualizing Localized Geometric Features Using 3D-CNN: An\n  Application to Manufacturability Analysis of Drilled Holes"], "date": ["2017-11-13T21:05:39Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.04851v3"], "summary": ["  3D Convolutional Neural Networks (3D-CNN) have been used for object\nrecognition based on the voxelized shape of an object. However, interpreting\nthe decision making process of these 3D-CNNs is still an infeasible task. In\nthis paper, we present a unique 3D-CNN based Gradient-weighted Class Activation\nMapping method (3D-GradCAM) for visual explanations of the distinct local\ngeometric features of interest within an object. To enable efficient learning\nof 3D geometries, we augment the voxel data with surface normals of the object\nboundary. We then train a 3D-CNN with this augmented data and identify the\nlocal features critical for decision-making using 3D GradCAM. An application of\nthis feature identification framework is to recognize difficult-to-manufacture\ndrilled hole features in a complex CAD geometry. The framework can be extended\nto identify difficult-to-manufacture features at multiple spatial scales\nleading to a real-time design for manufacturability decision support system.\n"]},
{"authors": ["Takeshi Inagaki"], "title": ["Supervising Unsupervised Learning with Evolutionary Algorithm in Deep\n  Neural Network"], "date": ["2018-03-28T03:20:18Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10397v1"], "summary": ["  A method to control results of gradient descent unsupervised learning in a\ndeep neural network by using evolutionary algorithm is proposed. To process\ncrossover of unsupervisedly trained models, the algorithm evaluates pointwise\nfitness of individual nodes in neural network. Labeled training data is\nrandomly sampled and breeding process selects nodes by calculating degree of\ntheir consistency on different sets of sampled data. This method supervises\nunsupervised training by evolutionary process. We also introduce modified\nRestricted Boltzmann Machine which contains repulsive force among nodes in a\nneural network and it contributes to isolate network nodes each other to avoid\naccidental degeneration of nodes by evolutionary process. These new methods are\napplied to document classification problem and it results better accuracy than\na traditional fully supervised classifier implemented with linear regression\nalgorithm.\n"]},
{"authors": ["Faris B. Mismar", "Brian L. Evans"], "title": ["Deep Q-Learning for Self-Organizing Networks Fault Management and Radio\n  Performance Improvement"], "date": ["2017-07-10T02:29:17Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1707.02329v3"], "summary": ["  We propose a method to improve the radio link performance in a wireless\nnetwork using a deep Q-Learning based algorithm. In this paper, we use this\nreinforcement learning model to allow the wireless network cluster to self-heal\nby performing certain fault management actions which improves the radio link\nperformance of this wireless network. The main contributions of this paper are:\n1) introduce a radio performance tuning algorithm that self-organizing networks\ncan implement in a polynomial runtime, 2) employ deep reinforcement learning to\nperform fault management, and 3) show that this fault management method can\nimprove the radio link performance in a realistic network setup. Simulation\nresults show that an optimal action sequence to clear alarms is feasible even\nagainst the randomness of the network faults and user movements.\n"]},
{"authors": ["Yasuo Tabei", "Yoshihiro Yamanishi", "Rasmus Pagh"], "title": ["Scalable Alignment Kernels via Space-Efficient Feature Maps"], "date": ["2018-02-18T14:16:28Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.06382v5"], "summary": ["  String kernels are attractive data analysis tools for analyzing string data.\nAmong them, alignment kernels are known for their high prediction accuracies in\nstring classifications when tested in combination with SVMs in various\napplications. However, alignment kernels have a crucial drawback in that they\nscale poorly due to their quadratic computation complexity in the number of\ninput strings, which limits large-scale applications in practice. We present\nthe first approximation named ESP+SFM for alignment kernels by leveraging a\nmetric embedding named edit-sensitive parsing (ESP) and space-efficient feature\nmaps (SFM) for random Fourier features (RFF) for large-scale string analyses.\nInput strings are projected into vectors of RFF by leveraging ESP and SFM.\nThen, SVMs are trained on the projected vectors, which enables to significantly\nimprove the scalability of alignment kernels while preserving their prediction\naccuracies. We experimentally test ESP+ SFM on its ability to learn SVMs for\nlarge-scale string classifications with various massive string data, and we\ndemonstrate the superior performance of ESP+SFM with respect to prediction\naccuracy, scalability and computation efficiency.\n"]},
{"authors": ["Niangjun Chen", "Gautam Goel", "Adam Wierman"], "title": ["Smoothed Online Convex Optimization in High Dimensions via Online\n  Balanced Descent"], "date": ["2018-03-28T00:39:33Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10366v1"], "summary": ["  We study Smoothed Online Convex Optimization, a version of online convex\noptimization where the learner incurs a penalty for changing her actions\nbetween rounds. Given a known $\\Omega(\\sqrt{d})$ lower bound on the competitive\nratio of any online algorithm, where $d$ is the dimension of the action space,\nwe ask under what conditions this bound can be beaten. We introduce a novel\nalgorithmic framework for this problem, Online Balanced Descent (OBD), which\nworks by iteratively projecting the previous point onto a carefully chosen\nlevel set of the current cost function so as to balance the switching costs and\nhitting costs. We demonstrate the generality of the OBD framework by showing\nhow, with different choices of \"balance,\" OBD can improve upon state-of-the-art\nperformance guarantees for both competitive ratio and regret; in particular,\nOBD is the first algorithm to achieve a dimension-free competitive ratio, $3 +\nO(1/\\alpha)$, for locally polyhedral costs, where $\\alpha$ measures the\n\"steepness\" of the costs. We also prove bounds on the dynamic regret of OBD\nwhen the balance is performed in the dual space that are dimension-free and\nimply that OBD has sublinear static regret.\n"]},
{"authors": ["Max Kochurov", "Timur Garipov", "Dmitry Podoprikhin", "Dmitry Molchanov", "Arsenii Ashukha", "Dmitry Vetrov"], "title": ["Bayesian Incremental Learning for Deep Neural Networks"], "date": ["2018-02-20T21:11:17Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.07329v3"], "summary": ["  In industrial machine learning pipelines, data often arrive in parts.\nParticularly in the case of deep neural networks, it may be too expensive to\ntrain the model from scratch each time, so one would rather use a previously\nlearned model and the new data to improve performance. However, deep neural\nnetworks are prone to getting stuck in a suboptimal solution when trained on\nonly new data as compared to the full dataset. Our work focuses on a continuous\nlearning setup where the task is always the same and new parts of data arrive\nsequentially. We apply a Bayesian approach to update the posterior\napproximation with each new piece of data and find this method to outperform\nthe traditional approach in our experiments.\n"]},
{"authors": ["Andrew E. Bruno", "Patrick Charbonneau", "Janet Newman", "Edward H. Snell", "David R. So", "Vincent Vanhoucke", "Shawn Williams", "Julie Wilson"], "title": ["Classification of crystallization outcomes using deep convolutional\n  neural networks"], "date": ["2018-03-27T22:03:20Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10342v1"], "summary": ["  The Machine Recognition of Crystallization Outcomes (MARCO) initiative has\nassembled roughly half a million annotated images of macromolecular\ncrystallization experiments from various sources and setups. Here,\nstate-of-the-art machine learning algorithms are trained and tested on\ndifferent parts of this data set. We find that more than 94% of the test images\ncan be correctly labeled, irrespective of their experimental origin. Because\ncrystal recognition is key to high-density screening and the systematic\nanalysis of crystallization experiments, this approach opens the door to both\nindustrial and fundamental research applications.\n"]},
{"authors": ["Qunwei Li", "Bhavya Kailkhura", "Ryan Goldhahn", "Priyadip Ray", "Pramod K. Varshney"], "title": ["Robust Decentralized Learning Using ADMM with Unreliable Agents"], "date": ["2017-10-14T21:44:32Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.05241v2"], "summary": ["  Many machine learning problems can be formulated as consensus optimization\nproblems which can be solved efficiently via a cooperative multi-agent system.\nHowever, the agents in the system can be unreliable due to a variety of\nreasons: noise, faults and attacks. Thus, providing falsified data leads the\noptimization process in a wrong direction, and degrades the performance of\ndistributed machine learning algorithms. This paper considers the problem of\ndecentralized learning using ADMM in the presence of unreliable agents. First,\nwe rigorously analyze the effect of falsified updates (in ADMM learning\niterations) on the convergence behavior of multi-agent system. We show that the\nalgorithm linearly converges to a neighborhood of the optimal solution under\ncertain conditions and characterize the neighborhood size analytically. Next,\nwe provide guidelines for network structure design to achieve a faster\nconvergence. We also provide necessary conditions on the falsified updates for\nexact convergence to the optimal solution. Finally, to mitigate the influence\nof unreliable agents, we propose a robust variant of ADMM and show its\nresilience to unreliable agents.\n"]},
{"authors": ["Doris Xin", "Litian Ma", "Shuchen Song", "Aditya Parameswaran"], "title": ["How Developers Iterate on Machine Learning Workflows -- A Survey of the\n  Applied Machine Learning Literature"], "date": ["2018-03-27T20:38:05Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10311v1"], "summary": ["  Machine learning workflow development is anecdotally regarded to be an\niterative process of trial-and-error with humans-in-the-loop. However, we are\nnot aware of quantitative evidence corroborating this popular belief. A\nquantitative characterization of iteration can serve as a benchmark for machine\nlearning workflow development in practice, and can aid the development of\nhuman-in-the-loop machine learning systems. To this end, we conduct a\nsmall-scale survey of the applied machine learning literature from five\ndistinct application domains. We collect and distill statistics on the role of\niteration within machine learning workflow development, and report preliminary\ntrends and insights from our investigation, as a starting point towards this\nbenchmark. Based on our findings, we finally describe desiderata for effective\nand versatile human-in-the-loop machine learning systems that can cater to\nusers in diverse domains.\n"]},
{"authors": ["Jia Chen", "Gang Wang", "Yanning Shen", "Georgios B. Giannakis"], "title": ["Canonical Correlation Analysis of Datasets with a Common Source Graph"], "date": ["2018-03-27T20:36:26Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10309v1"], "summary": ["  Canonical correlation analysis (CCA) is a powerful technique for discovering\nwhether or not hidden sources are commonly present in two (or more) datasets.\nIts well-appreciated merits include dimensionality reduction, clustering,\nclassification, feature selection, and data fusion. The standard CCA however,\ndoes not exploit the geometry of the common sources, which may be available\nfrom the given data or can be deduced from (cross-) correlations. In this\npaper, this extra information provided by the common sources generating the\ndata is encoded in a graph, and is invoked as a graph regularizer. This leads\nto a novel graph-regularized CCA approach, that is termed graph (g) CCA. The\nnovel gCCA accounts for the graph-induced knowledge of common sources, while\nminimizing the distance between the wanted canonical variables. Tailored for\ndiverse practical settings where the number of data is smaller than the data\nvector dimensions, the dual formulation of gCCA is also developed. One such\nsetting includes kernels that are incorporated to account for nonlinear data\ndependencies. The resultant graph-kernel (gk) CCA is also obtained in closed\nform. Finally, corroborating image classification tests over several real\ndatasets are presented to showcase the merits of the novel linear, dual, and\nkernel approaches relative to competing alternatives.\n"]},
{"authors": ["Elizaveta Rebrova", "Gustavo Chavez", "Yang Liu", "Pieter Ghysels", "Xiaoye Sherry Li"], "title": ["A Study of Clustering Techniques and Hierarchical Matrix Formats for\n  Kernel Ridge Regression"], "date": ["2018-03-27T19:04:52Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10274v1"], "summary": ["  We present memory-efficient and scalable algorithms for kernel methods used\nin machine learning. Using hierarchical matrix approximations for the kernel\nmatrix the memory requirements, the number of floating point operations, and\nthe execution time are drastically reduced compared to standard dense linear\nalgebra routines. We consider both the general $\\mathcal{H}$ matrix\nhierarchical format as well as Hierarchically Semi-Separable (HSS) matrices.\nFurthermore, we investigate the impact of several preprocessing and clustering\ntechniques on the hierarchical matrix compression. Effective clustering of the\ninput leads to a ten-fold increase in efficiency of the compression. The\nalgorithms are implemented using the STRUMPACK solver library. These results\nconfirm that --- with correct tuning of the hyperparameters --- classification\nusing kernel ridge regression with the compressed matrix does not lose\nprediction accuracy compared to the exact --- not compressed --- kernel matrix\nand that our approach can be extended to $\\mathcal{O}(1M)$ datasets, for which\ncomputation with the full kernel matrix becomes prohibitively expensive. We\npresent numerical experiments in a distributed memory environment up to 1,024\nprocessors of the NERSC's Cori supercomputer using well-known datasets to the\nmachine learning community that range from dimension 8 up to 784.\n"]},
{"authors": ["Yin Lou", "Jacob Bien", "Rich Caruana", "Johannes Gehrke"], "title": ["Sparse Partially Linear Additive Models"], "date": ["2014-07-17T16:27:36Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1407.4729v3"], "summary": ["  The generalized partially linear additive model (GPLAM) is a flexible and\ninterpretable approach to building predictive models. It combines features in\nan additive manner, allowing each to have either a linear or nonlinear effect\non the response. However, the choice of which features to treat as linear or\nnonlinear is typically assumed known. Thus, to make a GPLAM a viable approach\nin situations in which little is known $a~priori$ about the features, one must\novercome two primary model selection challenges: deciding which features to\ninclude in the model and determining which of these features to treat\nnonlinearly. We introduce the sparse partially linear additive model (SPLAM),\nwhich combines model fitting and $both$ of these model selection challenges\ninto a single convex optimization problem. SPLAM provides a bridge between the\nlasso and sparse additive models. Through a statistical oracle inequality and\nthorough simulation, we demonstrate that SPLAM can outperform other methods\nacross a broad spectrum of statistical regimes, including the high-dimensional\n($p\\gg N$) setting. We develop efficient algorithms that are applied to real\ndata sets with half a million samples and over 45,000 features with excellent\npredictive performance.\n"]},
{"authors": ["Cynthia Dwork", "Vitaly Feldman"], "title": ["Privacy-preserving Prediction"], "date": ["2018-03-27T18:40:05Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10266v1"], "summary": ["  Ensuring differential privacy of models learned from sensitive user data is\nan important goal that has been studied extensively in recent years. It is now\nknown that for some basic learning problems, especially those involving\nhigh-dimensional data, producing an accurate private model requires much more\ndata than learning without privacy. At the same time, in many applications it\nis not necessary to expose the model itself. Instead users may be allowed to\nquery the prediction model on their inputs only through an appropriate\ninterface. Here we formulate the problem of ensuring privacy of individual\npredictions and investigate the overheads required to achieve it in several\nstandard models of classification and regression.\n  We first describe a simple baseline approach based on training several models\non disjoint subsets of data and using standard private aggregation techniques\nto predict. We show that this approach has nearly optimal sample complexity for\n(realizable) PAC learning of any class of Boolean functions. At the same time,\nwithout strong assumptions on the data distribution, the aggregation step\nintroduces a substantial overhead. We demonstrate that this overhead can be\navoided for the well-studied class of thresholds on a line and for a number of\nstandard settings of convex regression. The analysis of our algorithm for\nlearning thresholds relies crucially on strong generalization guarantees that\nwe establish for all differentially private prediction algorithms.\n"]},
{"authors": ["Alican Nalci", "Igor Fedorov", "Maher Al-Shoukairi", "Thomas T. Liu", "Bhaskar D. Rao"], "title": ["Rectified Gaussian Scale Mixtures and the Sparse Non-Negative Least\n  Squares Problem"], "date": ["2016-01-22T23:47:36Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1601.06207v6"], "summary": ["  In this paper, we develop a Bayesian evidence maximization framework to solve\nthe sparse non-negative least squares (S-NNLS) problem. We introduce a family\nof probability densities referred to as the Rectified Gaussian Scale Mixture\n(R- GSM) to model the sparsity enforcing prior distribution for the solution.\nThe R-GSM prior encompasses a variety of heavy-tailed densities such as the\nrectified Laplacian and rectified Student- t distributions with a proper choice\nof the mixing density. We utilize the hierarchical representation induced by\nthe R-GSM prior and develop an evidence maximization framework based on the\nExpectation-Maximization (EM) algorithm. Using the EM based method, we estimate\nthe hyper-parameters and obtain a point estimate for the solution. We refer to\nthe proposed method as rectified sparse Bayesian learning (R-SBL). We provide\nfour R- SBL variants that offer a range of options for computational complexity\nand the quality of the E-step computation. These methods include the Markov\nchain Monte Carlo EM, linear minimum mean-square-error estimation, approximate\nmessage passing and a diagonal approximation. Using numerical experiments, we\nshow that the proposed R-SBL method outperforms existing S-NNLS solvers in\nterms of both signal and support recovery performance, and is also very robust\nagainst the structure of the design matrix.\n"]},
{"authors": ["Bryan Lim", "Mihaela van der Schaar"], "title": ["Disease-Atlas: Navigating Disease Trajectories with Deep Learning"], "date": ["2018-03-27T18:03:02Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10254v1"], "summary": ["  Joint models for longitudinal and time-to-event data are commonly used in\nlongitudinal studies to forecast disease trajectories over time. While there\nare many advantages to joint modeling, the standard forms suffer from\nlimitations that arise from a fixed model specification, and computational\ndifficulties when applied to high-dimensional datasets. In this paper, we\npropose a deep learning approach to address these limitations, enhancing\nexisting methods with the inherent flexibility and scalability of deep neural\nnetworks, while retaining the benefits of joint modeling. Using longitudinal\ndata from two real-world medical datasets, we demonstrate improvements in\nperformance and scalability, as well as robustness in the presence of\nirregularly sampled data.\n"]},
{"authors": ["Minshuo Chen", "Lin Yang", "Mengdi Wang", "Tuo Zhao"], "title": ["Dimensionality Reduction for Stationary Time Series via Stochastic\n  Nonconvex Optimization"], "date": ["2018-03-06T17:38:03Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02312v2"], "summary": ["  Stochastic optimization naturally arises in machine learning. Efficient\nalgorithms with provable guarantees, however, are still largely missing, when\nthe objective function is nonconvex and the data points are dependent. This\npaper studies this fundamental challenge through a streaming PCA problem for\nstationary time series data. Specifically, our goal is to estimate the\nprinciple component of time series data with respect to the covariance matrix\nof the stationary distribution. Computationally, we propose a variant of Oja's\nalgorithm combined with downsampling to control the bias of the stochastic\ngradient caused by the data dependency. Theoretically, we quantify the\nuncertainty of our proposed stochastic algorithm based on diffusion\napproximations. This allows us to prove the global convergence in terms of the\ncontinuous time limiting solution trajectory and further implies near optimal\nsample complexity. Numerical experiments are provided to support our analysis.\n"]},
{"authors": ["Casey Kneale", "Steven D. Brown"], "title": ["Band Target Entropy Minimization and Target Partial Least Squares for\n  Spectral Recovery and Calibration"], "date": ["2018-02-11T23:21:38Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.03839v2"], "summary": ["  The resolution and calibration of pure spectra of minority components in\nmeasurements of chemical mixtures without prior knowledge of the mixture is a\nchallenging problem. In this work, a combination of band target entropy\nminimization (BTEM) and target partial least squares (T-PLS) was used to obtain\nestimates for single pure component spectra and to calibrate those estimates in\na true, one-at-a-time fashion. This approach allows for minor components to be\ntargeted and their relative amounts estimated in the presence of other varying\ncomponents in spectral data. The use of T-PLS estimation is an improvement to\nthe BTEM method because it overcomes the need to identify all of the pure\ncomponents prior to estimation. Estimated amounts from this combination were\nfound to be similar to those obtained from a standard method, multivariate\ncurve resolution-alternating least squares (MCR-ALS), on a simple, three\ncomponent mixture dataset. Studies from two experimental datasets demonstrate\nwhere the combination of BTEM and T-PLS could model the pure component spectra\nand obtain concentration profiles of minor components but MCR-ALS could not.\n"]},
{"authors": ["Daniele Calandriello", "Alessandro Lazaric", "Michal Valko"], "title": ["Distributed Adaptive Sampling for Kernel Matrix Approximation"], "date": ["2018-03-27T16:39:00Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10172v1"], "summary": ["  Most kernel-based methods, such as kernel or Gaussian process regression,\nkernel PCA, ICA, or $k$-means clustering, do not scale to large datasets,\nbecause constructing and storing the kernel matrix $\\mathbf{K}_n$ requires at\nleast $\\mathcal{O}(n^2)$ time and space for $n$ samples. Recent works show that\nsampling points with replacement according to their ridge leverage scores (RLS)\ngenerates small dictionaries of relevant points with strong spectral\napproximation guarantees for $\\mathbf{K}_n$. The drawback of RLS-based methods\nis that computing exact RLS requires constructing and storing the whole kernel\nmatrix. In this paper, we introduce SQUEAK, a new algorithm for kernel\napproximation based on RLS sampling that sequentially processes the dataset,\nstoring a dictionary which creates accurate kernel matrix approximations with a\nnumber of points that only depends on the effective dimension $d_{eff}(\\gamma)$\nof the dataset. Moreover since all the RLS estimations are efficiently\nperformed using only the small dictionary, SQUEAK is the first RLS sampling\nalgorithm that never constructs the whole matrix $\\mathbf{K}_n$, runs in linear\ntime $\\widetilde{\\mathcal{O}}(nd_{eff}(\\gamma)^3)$ w.r.t. $n$, and requires\nonly a single pass over the dataset. We also propose a parallel and distributed\nversion of SQUEAK that linearly scales across multiple machines, achieving\nsimilar accuracy in as little as\n$\\widetilde{\\mathcal{O}}(\\log(n)d_{eff}(\\gamma)^3)$ time.\n"]},
{"authors": ["Roxana Istrate", "Adelmo Cristiano Innocenza Malossi", "Costas Bekas", "Dimitrios Nikolopoulos"], "title": ["Incremental Training of Deep Convolutional Neural Networks"], "date": ["2018-03-27T16:05:34Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10232v1"], "summary": ["  We propose an incremental training method that partitions the original\nnetwork into sub-networks, which are then gradually incorporated in the running\nnetwork during the training process. To allow for a smooth dynamic growth of\nthe network, we introduce a look-ahead initialization that outperforms the\nrandom initialization. We demonstrate that our incremental approach reaches the\nreference network baseline accuracy. Additionally, it allows to identify\nsmaller partitions of the original state-of-the-art network, that deliver the\nsame final accuracy, by using only a fraction of the global number of\nparameters. This allows for a potential speedup of the training time of several\nfactors. We report training results on CIFAR-10 for ResNet and VGGNet.\n"]},
{"authors": ["Keuntaek Lee", "Kamil Saigol", "Evangelos Theodorou"], "title": ["Safe end-to-end imitation learning for model predictive control"], "date": ["2018-03-27T15:47:29Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10231v1"], "summary": ["  We propose the use of Bayesian networks, which provide both a mean value and\nan uncertainty estimate as output, to enhance the safety of learned control\npolicies under circumstances in which a test-time input differs significantly\nfrom the training set. Our algorithm combines reinforcement learning and\nend-to-end imitation learning to simultaneously learn a control policy as well\nas a threshold over the predictive uncertainty of the learned model, with no\nhand-tuning required. Corrective action, such as a return of control to the\nmodel predictive controller or human expert, is taken when the uncertainty\nthreshold is exceeded. We validate our method on fully-observable and\nvision-based partially-observable systems using cart-pole and autonomous\ndriving simulations using deep convolutional Bayesian neural networks. We\ndemonstrate that our method is robust to uncertainty resulting from varying\nsystem dynamics as well as from partial state observability.\n"]},
{"authors": ["Chen Zeno", "Itay Golan", "Elad Hoffer", "Daniel Soudry"], "title": ["Bayesian Gradient Descent: Online Variational Bayes Learning with\n  Increased Robustness to Catastrophic Forgetting and Weight Pruning"], "date": ["2018-03-27T15:11:08Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10123v1"], "summary": ["  We suggest a novel approach for the estimation of the posterior distribution\nof the weights of a neural network, using an online version of the variational\nBayes method. Having a confidence measure of the weights allows to combat\nseveral shortcomings of neural networks, such as their parameter redundancy,\nand their notorious vulnerability to the change of input distribution\n(\"catastrophic forgetting\"). Specifically, We show that this approach helps\nalleviate the catastrophic forgetting phenomenon - even without the knowledge\nof when the tasks are been switched. Furthermore, it improves the robustness of\nthe network to weight pruning - even without re-training.\n"]},
{"authors": ["Bradley S. Price", "Ben Sherwood"], "title": ["A Cluster Elastic Net for Multivariate Regression"], "date": ["2017-07-12T03:50:38Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1707.03530v2"], "summary": ["  We propose a method for estimating coefficients in multivariate regression\nwhen there is a clustering structure to the response variables. The proposed\nmethod includes a fusion penalty, to shrink the difference in fitted values\nfrom responses in the same cluster, and an L1 penalty for simultaneous variable\nselection and estimation. The method can be used when the grouping structure of\nthe response variables is known or unknown. When the clustering structure is\nunknown the method will simultaneously estimate the clusters of the response\nand the regression coefficients. Theoretical results are presented for the\npenalized least squares case, including asymptotic results allowing for p >> n.\nWe extend our method to the setting where the responses are binomial variables.\nWe propose a coordinate descent algorithm for both the normal and binomial\nlikelihood, which can easily be extended to other generalized linear model\n(GLM) settings. Simulations and data examples from business operations and\ngenomics are presented to show the merits of both the least squares and\nbinomial methods.\n"]},
{"authors": ["Sylvestre-Alvise Rebuffi", "Hakan Bilen", "Andrea Vedaldi"], "title": ["Efficient parametrization of multi-domain deep neural networks"], "date": ["2018-03-27T13:55:56Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10082v1"], "summary": ["  A practical limitation of deep neural networks is their high degree of\nspecialization to a single task and visual domain. Recently, inspired by the\nsuccesses of transfer learning, several authors have proposed to learn instead\nuniversal, fixed feature extractors that, used as the first stage of any deep\nnetwork, work well for several tasks and domains simultaneously. Nevertheless,\nsuch universal features are still somewhat inferior to specialized networks.\n  To overcome this limitation, in this paper we propose to consider instead\nuniversal parametric families of neural networks, which still contain\nspecialized problem-specific models, but differing only by a small number of\nparameters. We study different designs for such parametrizations, including\nseries and parallel residual adapters, joint adapter compression, and parameter\nallocations, and empirically identify the ones that yield the highest\ncompression. We show that, in order to maximize performance, it is necessary to\nadapt both shallow and deep layers of a deep network, but the required changes\nare very small. We also show that these universal parametrization are very\neffective for transfer learning, where they outperform traditional fine-tuning\ntechniques.\n"]},
{"authors": ["Jack W Rae", "Chris Dyer", "Peter Dayan", "Timothy P Lillicrap"], "title": ["Fast Parametric Learning with Activation Memorization"], "date": ["2018-03-27T12:53:24Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10049v1"], "summary": ["  Neural networks trained with backpropagation often struggle to identify\nclasses that have been observed a small number of times. In applications where\nmost class labels are rare, such as language modelling, this can become a\nperformance bottleneck. One potential remedy is to augment the network with a\nfast-learning non-parametric model which stores recent activations and class\nlabels into an external memory. We explore a simplified architecture where we\ntreat a subset of the model parameters as fast memory stores. This can help\nretain information over longer time intervals than a traditional memory, and\ndoes not require additional space or compute. In the case of image\nclassification, we display faster binding of novel classes on an Omniglot image\ncurriculum task. We also show improved performance for word-based language\nmodels on news reports (GigaWord), books (Project Gutenberg) and Wikipedia\narticles (WikiText-103) --- the latter achieving a state-of-the-art perplexity\nof 29.2.\n"]},
{"authors": ["Michele Scipioni", "Maria F. Santarelli", "Luigi Landini", "Ciprian Catana", "Douglas N. Greve", "Julie C. Price", "Stefano Pedemonte"], "title": ["Kinetic Compressive Sensing"], "date": ["2018-03-27T12:46:57Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10045v1"], "summary": ["  Parametric images provide insight into the spatial distribution of\nphysiological parameters, but they are often extremely noisy, due to low SNR of\ntomographic data. Direct estimation from projections allows accurate noise\nmodeling, improving the results of post-reconstruction fitting. We propose a\nmethod, which we name kinetic compressive sensing (KCS), based on a\nhierarchical Bayesian model and on a novel reconstruction algorithm, that\nencodes sparsity of kinetic parameters. Parametric maps are reconstructed by\nmaximizing the joint probability, with an Iterated Conditional Modes (ICM)\napproach, alternating the optimization of activity time series (OS-MAP-OSL),\nand kinetic parameters (MAP-LM). We evaluated the proposed algorithm on a\nsimulated dynamic phantom: a bias/variance study confirmed how direct estimates\ncan improve the quality of parametric maps over a post-reconstruction fitting,\nand showed how the novel sparsity prior can further reduce their variance,\nwithout affecting bias. Real FDG PET human brain data (Siemens mMR, 40min)\nimages were also processed. Results enforced how the proposed KCS-regularized\ndirect method can produce spatially coherent images and parametric maps, with\nlower spatial noise and better tissue contrast. A GPU-based open source\nimplementation of the algorithm is provided.\n"]},
{"authors": ["Emilio Rafael Balda", "Arash Behboodi", "Rudolph Mathar"], "title": ["On Generation of Adversarial Examples using Convex Programming"], "date": ["2018-03-09T17:24:45Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03607v2"], "summary": ["  It has been observed that deep learning architectures tend to make erroneous\ndecisions with high reliability for particularly designed adversarial\ninstances. In this work, we show that the perturbation analysis of these\narchitectures provides a framework for generating adversarial instances by\nconvex programming which, for classification tasks, is able to recover variants\nof existing non-adaptive adversarial methods. The proposed framework can be\nused for the design of adversarial noise under various desirable constraints\nand different types of networks. Moreover, this framework is capable of\nexplaining various existing adversarial methods and can be used to derive new\nalgorithms as well. Furthermore, we make use of these results to obtain novel\nalgorithms. Experiments show the competitive performance of the obtained\nsolutions, in terms of fooling ratio, when benchmarked with well-known\nadversarial methods.\n"]},
{"authors": ["Matthias S. Treder"], "title": ["Cross-validation in high-dimensional spaces: a lifeline for\n  least-squares models and multi-class LDA"], "date": ["2018-03-27T11:20:10Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10016v1"], "summary": ["  Least-squares models such as linear regression and Linear Discriminant\nAnalysis (LDA) are amongst the most popular statistical learning techniques.\nHowever, since their computation time increases cubically with the number of\nfeatures, they are inefficient in high-dimensional neuroimaging datasets.\nFortunately, for k-fold cross-validation, an analytical approach has been\ndeveloped that yields the exact cross-validated predictions in least-squares\nmodels without explicitly training the model. Its computation time grows with\nthe number of test samples. Here, this approach is systematically investigated\nin the context of cross-validation and permutation testing. LDA is used\nexemplarily but results hold for all other least-squares methods. Furthermore,\na non-trivial extension to multi-class LDA is formally derived. The analytical\napproach is evaluated using complexity calculations, simulations, and\npermutation testing of an EEG/MEG dataset. Depending on the ratio between\nfeatures and samples, the analytical approach is up to 10,000x faster than the\nstandard approach (retraining the model on each training set). This allows for\na fast cross-validation of least-squares models and multi-class LDA in\nhigh-dimensional data, with obvious applications in multi-dimensional datasets,\nRepresentational Similarity Analysis, and permutation testing.\n"]},
{"authors": ["Pierre Dellenbach", "Aur\u00e9lien Bellet", "Jan Ramon"], "title": ["Hiding in the Crowd: A Massively Distributed Algorithm for Private\n  Averaging with Malicious Adversaries"], "date": ["2018-03-27T09:35:29Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09984v1"], "summary": ["  The amount of personal data collected in our everyday interactions with\nconnected devices offers great opportunities for innovative services fueled by\nmachine learning, as well as raises serious concerns for the privacy of\nindividuals. In this paper, we propose a massively distributed protocol for a\nlarge set of users to privately compute averages over their joint data, which\ncan then be used to learn predictive models. Our protocol can find a solution\nof arbitrary accuracy, does not rely on a third party and preserves the privacy\nof users throughout the execution in both the honest-but-curious and malicious\nadversary models. Specifically, we prove that the information observed by the\nadversary (the set of maliciours users) does not significantly reduce the\nuncertainty in its prediction of private values compared to its prior belief.\nThe level of privacy protection depends on a quantity related to the Laplacian\nmatrix of the network graph and generally improves with the size of the graph.\nFurthermore, we design a verification procedure which offers protection against\nmalicious users joining the service with the goal of manipulating the outcome\nof the algorithm.\n"]},
{"authors": ["Stephan Bongers", "Joris M. Mooij"], "title": ["From Random Differential Equations to Structural Causal Models: the\n  stochastic case"], "date": ["2018-03-23T13:20:56Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08784v2"], "summary": ["  Random Differential Equations provide a natural extension of Ordinary\nDifferential Equations to the stochastic setting. We show how, and under which\nconditions, every equilibrium state of a Random Differential Equation (RDE) can\nbe described by a Structural Causal Model (SCM), while pertaining the causal\nsemantics. This provides an SCM that captures the stochastic and causal\nbehavior of the RDE, which can model both cycles and confounders. This enables\nthe study of the equilibrium states of the RDE by applying the theory and\nstatistical tools available for SCMs, for example, marginalizations and Markov\nproperties, as we illustrate by means of an example. Our work thus provides a\ndirect connection between two fields that so far have been developing in\nisolation.\n"]},
{"authors": ["Roberto Maestre", "Juan Duque", "Alberto Rubio", "Juan Ar\u00e9valo"], "title": ["Reinforcement Learning for Fair Dynamic Pricing"], "date": ["2018-03-27T09:00:48Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09967v1"], "summary": ["  Unfair pricing policies have been shown to be one of the most negative\nperceptions customers can have concerning pricing, and may result in long-term\nlosses for a company. Despite the fact that dynamic pricing models help\ncompanies maximize revenue, fairness and equality should be taken into account\nin order to avoid unfair price differences between groups of customers. This\npaper shows how to solve dynamic pricing by using Reinforcement Learning (RL)\ntechniques so that prices are maximized while keeping a balance between revenue\nand fairness. We demonstrate that RL provides two main features to support\nfairness in dynamic pricing: on the one hand, RL is able to learn from recent\nexperience, adapting the pricing policy to complex market environments; on the\nother hand, it provides a trade-off between short and long-term objectives,\nhence integrating fairness into the model's core. Considering these two\nfeatures, we propose the application of RL for revenue optimization, with the\nadditional integration of fairness as part of the learning procedure by using\nJain's index as a metric. Results in a simulated environment show a significant\nimprovement in fairness while at the same time maintaining optimisation of\nrevenue.\n"]},
{"authors": ["Andy Zeng", "Shuran Song", "Stefan Welker", "Johnny Lee", "Alberto Rodriguez", "Thomas Funkhouser"], "title": ["Learning Synergies between Pushing and Grasping with Self-supervised\n  Deep Reinforcement Learning"], "date": ["2018-03-27T08:31:28Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09956v1"], "summary": ["  Skilled robotic manipulation benefits from complex synergies between\nnon-prehensile (e.g. pushing) and prehensile (e.g. grasping) actions: pushing\ncan help rearrange cluttered objects to make space for arms and fingers;\nlikewise, grasping can help displace objects to make pushing movements more\nprecise and collision-free. In this work, we demonstrate that it is possible to\ndiscover and learn these synergies from scratch through model-free deep\nreinforcement learning. Our method involves training two fully convolutional\nnetworks that map from visual observations to actions: one infers the utility\nof pushes for a dense pixel-wise sampling of end effector orientations and\nlocations, while the other does the same for grasping. Both networks are\ntrained jointly in a Q-learning framework and are entirely self-supervised by\ntrial and error, where rewards are provided from successful grasps. In this\nway, our policy learns pushing motions that enable future grasps, while\nlearning grasps that can leverage past pushes. During picking experiments in\nboth simulation and real-world scenarios, we find that our system quickly\nlearns complex behaviors amid challenging cases of clutter, and achieves better\ngrasping success rates and picking efficiencies than baseline alternatives\nafter only a few hours of training. We further demonstrate that our method is\ncapable of generalizing to novel objects. Qualitative results (videos), code,\npre-trained models, and simulation environments are available at\nhttp://vpg.cs.princeton.edu\n"]},
{"authors": ["Toru Nakashika", "Shinji Takaki", "Junichi Yamagishi"], "title": ["Complex-Valued Restricted Boltzmann Machine for Direct Speech\n  Parameterization from Complex Spectra"], "date": ["2018-03-27T08:07:20Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09946v1"], "summary": ["  This paper describes a novel energy-based probabilistic distribution that\nrepresents complex-valued data and explains how to apply it to direct feature\nextraction from complex-valued spectra. The proposed model, the complex-valued\nrestricted Boltzmann machine (CRBM), is designed to deal with complex-valued\nvisible units as an extension of the well-known restricted Boltzmann machine\n(RBM). Like the RBM, the CRBM learns the relationships between visible and\nhidden units without having connections between units in the same layer, which\ndramatically improves training efficiency by using Gibbs sampling or\ncontrastive divergence (CD). Another important characteristic is that the CRBM\nalso has connections between real and imaginary parts of each of the\ncomplex-valued visible units that help represent the data distribution in the\ncomplex domain. In speech signal processing, classification and generation\nfeatures are often based on amplitude spectra (e.g., MFCC, cepstra, and\nmel-cepstra) even if they are calculated from complex spectra, and they ignore\nphase information. In contrast, the proposed feature extractor using the CRBM\ndirectly encodes the complex spectra (or another complex-valued representation\nof the complex spectra) into binary-valued latent features (hidden units).\nSince the visible-hidden connections are undirected, we can also recover\n(decode) the complex spectra from the latent features directly. Our speech\ncoding experiments demonstrated that the CRBM outperformed other speech coding\nmethods, such as methods using the conventional RBM, the mel-log spectrum\napproximate (MLSA) decoder, etc.\n"]},
{"authors": ["Tanvi Verma", "Pradeep Varakantham", "Hoong Chuin Lau"], "title": ["Entropy Controlled Non-Stationarity for Improving Performance of\n  Independent Learners in Anonymous MARL Settings"], "date": ["2018-03-27T07:10:20Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09928v1"], "summary": ["  With the advent of sequential matching (of supply and demand) systems (uber,\nLyft, Grab for taxis; ubereats, deliveroo, etc for food; amazon prime, lazada\netc. for groceries) across many online and offline services, individuals (taxi\ndrivers, delivery boys, delivery van drivers, etc.) earn more by being at the\n\"right\" place at the \"right\" time. We focus on learning techniques for\nproviding guidance (on right locations to be at right times) to individuals in\nthe presence of other \"learning\" individuals. Interactions between indivduals\nare anonymous, i.e, the outcome of an interaction (competing for demand) is\nindependent of the identity of the agents and therefore we refer to these as\nAnonymous MARL settings.\n  Existing research of relevance is on independent learning using Reinforcement\nLearning (RL) or on Multi-Agent Reinforcement Learning (MARL). The number of\nindividuals in aggregation systems is extremely large and individuals have\ntheir own selfish interest (of maximising revenue). Therefore, traditional MARL\napproaches are either not scalable or assumptions of common objective or action\ncoordination are not viable. In this paper, we focus on improving performance\nof independent reinforcement learners, specifically the popular Deep Q-Networks\n(DQN) and Advantage Actor Critic (A2C) approaches by exploiting anonymity.\nSpecifically, we control non-stationarity introduced by other agents using\nentropy of agent density distribution. We demonstrate a significant improvement\nin revenue for individuals and for all agents together with our learners on a\ngeneric experimental set up for aggregation systems and a real world taxi\ndataset.\n"]},
{"authors": ["Fei Wang", "Xilun Wu", "Gregory Essertel", "James Decker", "Tiark Rompf"], "title": ["Demystifying Differentiable Programming: Shift/Reset the Penultimate\n  Backpropagator"], "date": ["2018-03-27T04:43:12Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10228v1"], "summary": ["  Deep learning has seen tremendous success over the past decade in computer\nvision, machine translation, and gameplay. This success rests in crucial ways\non gradient-descent optimization and the ability to learn parameters of a\nneural network by backpropagating observed errors. However, neural network\narchitectures are growing increasingly sophisticated and diverse, which\nmotivates an emerging quest for even more general forms of differentiable\nprogramming, where arbitrary parameterized computations can be trained by\ngradient descent. In this paper, we take a fresh look at automatic\ndifferentiation (AD) techniques, and especially aim to demystify the\nreverse-mode form of AD that generalizes backpropagation in neural networks.\n  We uncover a tight connection between reverse-mode AD and delimited\ncontinuations, which permits implementing reverse-mode AD purely via operator\noverloading and without any auxiliary data structures. We further show how this\nformulation of AD can be fruitfully combined with multi-stage programming\n(staging), leading to a highly efficient implementation that combines the\nperformance benefits of deep learning frameworks based on explicit reified\ncomputation graphs (e.g., TensorFlow) with the expressiveness of pure library\napproaches (e.g., PyTorch).\n"]},
{"authors": ["Ashley D. Edwards", "Laura Downs", "James C. Davidson"], "title": ["Forward-Backward Reinforcement Learning"], "date": ["2018-03-27T04:33:08Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.10227v1"], "summary": ["  Goals for reinforcement learning problems are typically defined through\nhand-specified rewards. To design such problems, developers of learning\nalgorithms must inherently be aware of what the task goals are, yet we often\nrequire agents to discover them on their own without any supervision beyond\nthese sparse rewards. While much of the power of reinforcement learning derives\nfrom the concept that agents can learn with little guidance, this requirement\ngreatly burdens the training process. If we relax this one restriction and\nendow the agent with knowledge of the reward function, and in particular of the\ngoal, we can leverage backwards induction to accelerate training. To achieve\nthis, we propose training a model to learn to take imagined reversal steps from\nknown goal states. Rather than training an agent exclusively to determine how\nto reach a goal while moving forwards in time, our approach travels backwards\nto jointly predict how we got there. We evaluate our work in Gridworld and\nTowers of Hanoi and empirically demonstrate that it yields better performance\nthan standard DDQN.\n"]},
{"authors": ["Jie Liu", "Hao Zheng"], "title": ["MLE-induced Likelihood for Markov Random Fields"], "date": ["2018-03-27T04:05:44Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09887v1"], "summary": ["  Due to the intractable partition function, the exact likelihood function for\na Markov random field (MRF), in many situations, can only be approximated.\nMajor approximation approaches include pseudolikelihood and Laplace\napproximation. In this paper, we propose a novel way of approximating the\nlikelihood function through first approximating the marginal likelihood\nfunctions of individual parameters and then reconstructing the joint likelihood\nfunction from these marginal likelihood functions. For approximating the\nmarginal likelihood functions, we derive a particular likelihood function from\na modified scenario of coin tossing which is useful for capturing how one\nparameter interacts with the remaining parameters in the likelihood function.\nFor reconstructing the joint likelihood function, we use an appropriate copula\nto link up these marginal likelihood functions. Numerical investigation\nsuggests the superior performance of our approach. Especially as the size of\nthe MRF increases, both the numerical performance and the computational cost of\nour approach remain consistently satisfactory, whereas Laplace approximation\ndeteriorates and pseudolikelihood becomes computationally unbearable.\n"]},
{"authors": ["Yash Sharma", "Pin-Yu Chen"], "title": ["Attacking the Madry Defense Model with $L_1$-based Adversarial Examples"], "date": ["2017-10-30T00:57:34Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.10733v3"], "summary": ["  The Madry Lab recently hosted a competition designed to test the robustness\nof their adversarially trained MNIST model. Attacks were constrained to perturb\neach pixel of the input image by a scaled maximal $L_\\infty$ distortion\n$\\epsilon$ = 0.3. This discourages the use of attacks which are not optimized\non the $L_\\infty$ distortion metric. Our experimental results demonstrate that\nby relaxing the $L_\\infty$ constraint of the competition, the elastic-net\nattack to deep neural networks (EAD) can generate transferable adversarial\nexamples which, despite their high average $L_\\infty$ distortion, have minimal\nvisual distortion. These results call into question the use of $L_\\infty$ as a\nsole measure for visual distortion, and further demonstrate the power of EAD at\ngenerating robust adversarial examples.\n"]},
{"authors": ["Yash Sharma", "Pin-Yu Chen"], "title": ["Bypassing Feature Squeezing by Increasing Adversary Strength"], "date": ["2018-03-27T03:08:39Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09868v1"], "summary": ["  Feature Squeezing is a recently proposed defense method which reduces the\nsearch space available to an adversary by coalescing samples that correspond to\nmany different feature vectors in the original space into a single sample. It\nhas been shown that feature squeezing defenses can be combined in a joint\ndetection framework to achieve high detection rates against state-of-the-art\nattacks. However, we demonstrate on the MNIST and CIFAR-10 datasets that by\nincreasing the adversary strength of said state-of-the-art attacks, one can\nbypass the detection framework with adversarial examples of minimal visual\ndistortion. These results suggest for proposed defenses to validate against\nstronger attack configurations.\n"]},
{"authors": ["Senuri Wijenayake", "Timothy Graham", "Peter Christen"], "title": ["A Decision Tree Approach to Predicting Recidivism in Domestic Violence"], "date": ["2018-03-27T03:03:26Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09862v1"], "summary": ["  Domestic violence (DV) is a global social and public health issue that is\nhighly gendered. Being able to accurately predict DV recidivism, i.e.,\nre-offending of a previously convicted offender, can speed up and improve risk\nassessment procedures for police and front-line agencies, better protect\nvictims of DV, and potentially prevent future re-occurrences of DV. Previous\nwork in DV recidivism has employed different classification techniques,\nincluding decision tree (DT) induction and logistic regression, where the main\nfocus was on achieving high prediction accuracy. As a result, even the diagrams\nof trained DTs were often too difficult to interpret due to their size and\ncomplexity, making decision-making challenging. Given there is often a\ntrade-off between model accuracy and interpretability, in this work our aim is\nto employ DT induction to obtain both interpretable trees as well as high\nprediction accuracy. Specifically, we implement and evaluate different\napproaches to deal with class imbalance as well as feature selection. Compared\nto previous work in DV recidivism prediction that employed logistic regression,\nour approach can achieve comparable area under the ROC curve results by using\nonly 3 of 11 available features and generating understandable decision trees\nthat contain only 4 leaf nodes.\n"]},
{"authors": ["Leslie N. Smith"], "title": ["A disciplined approach to neural network hyper-parameters: Part 1 --\n  learning rate, batch size, momentum, and weight decay"], "date": ["2018-03-26T20:05:59Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09820v1"], "summary": ["  Although deep learning has produced dazzling successes for applications of\nimage, speech, and video processing in the past few years, most trainings are\nwith suboptimal hyper-parameters, requiring unnecessarily long training times.\nSetting the hyper-parameters remains a black art that requires years of\nexperience to acquire. This report proposes several efficient ways to set the\nhyper-parameters that significantly reduce training time and improves\nperformance. Specifically, this report shows how to examine the training\nvalidation/test loss function for subtle clues of underfitting and overfitting\nand suggests guidelines for moving toward the optimal balance point. Then it\ndiscusses how to increase/decrease the learning rate/momentum to speed up\ntraining. Our experiments show that it is crucial to balance every manner of\nregularization for each dataset and architecture. Weight decay is used as a\nsample regularizer to show how its optimal value is tightly coupled with the\nlearning rates and momentums.\n"]},
{"authors": ["Jason Poulos"], "title": ["Counterfactual time-series prediction with encoder-decoder networks"], "date": ["2017-12-10T16:00:18Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1712.03553v3"], "summary": ["  This paper proposes an alternative to the synthetic control method (SCM) for\nestimating the effect of a policy intervention on an outcome over time.\nEncoder-decoder recurrent neural networks (RNNs) are used to predict\ncounterfactual time-series of treated unit outcomes using only the outcomes of\ncontrol units as inputs. Unlike SCM, the proposed method does not rely on\npre-intervention covariates, allows for nonconvex combinations of control\nunits, and can handle multiple treated units. In empirical and simulated data\napplications, RNN-based models outperform SCM in terms of predictive accuracy\nwhile using much less information to produce counterfactual predictions.\n"]},
{"authors": ["In\u00eas Almeida", "Jo\u00e3o Xavier"], "title": ["DJAM: distributed Jacobi asynchronous method for learning personal\n  models"], "date": ["2018-03-26T17:53:56Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09737v1"], "summary": ["  Processing data collected by a network of agents often boils down to solving\nan optimization problem. The distributed nature of these problems calls for\nmethods that are, themselves, distributed. While most collaborative learning\nproblems require agents to reach a common (or consensus) model, there are\nsituations in which the consensus solution may not be optimal. For instance,\nagents may want to reach a compromise between agreeing with their neighbors and\nminimizing a personal loss function. We present DJAM, a Jacobi-like distributed\nalgorithm for learning personalized models. This method is\nimplementation-friendly: it has no hyperparameters that need tuning, it is\nasynchronous, and its updates only require single-neighbor interactions. We\nprove that DJAM converges with probability one to the solution, provided that\nthe personal loss functions are strongly convex and have Lipschitz gradient. We\nthen give evidence that DJAM is on par with state-of-the-art methods: our\nmethod reaches a solution with error similar to the error of a carefully tuned\nADMM in about the same number of single-neighbor interactions.\n"]},
{"authors": ["Brent Schlotfeldt", "Vasileios Tzoumas", "Dinesh Thakur", "George J. Pappas"], "title": ["Resilient Active Information Gathering with Mobile Robots"], "date": ["2018-03-26T17:41:05Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09730v1"], "summary": ["  Applications in robotics, such as multi-robot target tracking, involve the\nexecution of information acquisition tasks by teams of mobile robots. However,\nin failure-prone or adversarial environments, robots get attacked, their\ncommunication channels get jammed, and their sensors fail, resulting in the\nwithdrawal of robots from the collective task, and, subsequently, the inability\nof the remaining active robots to coordinate with each other. As a result,\ntraditional design paradigms become insufficient and, in contrast, resilient\ndesigns against system-wide failures and attacks become important. In general,\nresilient design problems are hard, and even though they often involve\nobjective functions that are monotone and (possibly) submodular, scalable\napproximation algorithms for their solution have been hitherto unknown. In this\npaper, we provide the first algorithm, enabling the following capabilities:\nminimal communication, i.e., the algorithm is executed by the robots based only\non minimal communication between them, system-wide resiliency, i.e., the\nalgorithm is valid for any number of denial-of-service attacks and failures,\nand provable approximation performance, i.e., the algorithm ensures for all\nmonotone and (possibly) submodular objective functions a solution that is\nfinitely close to the optimal. We support our theoretical analyses with\nsimulated and real-world experiments, by considering an active information\nacquisition application scenario, namely, multi-robot target tracking.\n"]},
{"authors": ["Yoon Kim", "Sam Wiseman", "Andrew C. Miller", "David Sontag", "Alexander M. Rush"], "title": ["Semi-Amortized Variational Autoencoders"], "date": ["2018-02-07T18:06:42Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.02550v4"], "summary": ["  Amortized variational inference (AVI) replaces instance-specific local\ninference with a global inference network. While AVI has enabled efficient\ntraining of deep generative models such as variational autoencoders (VAE),\nrecent empirical work suggests that inference networks can produce suboptimal\nvariational parameters. We propose a hybrid approach, to use AVI to initialize\nthe variational parameters and run stochastic variational inference (SVI) to\nrefine them. Crucially, the local SVI procedure is itself differentiable, so\nthe inference network and generative model can be trained end-to-end with\ngradient-based optimization. This semi-amortized approach enables the use of\nrich generative models without experiencing the posterior-collapse phenomenon\ncommon in training VAEs for problems like text generation. Experiments show\nthis approach outperforms strong autoregressive and variational baselines on\nstandard text and image datasets.\n"]},
{"authors": ["Olivier Deiss", "Siddharth Biswal", "Jing Jin", "Haoqi Sun", "M. Brandon Westover", "Jimeng Sun"], "title": ["HAMLET: Interpretable Human And Machine co-LEarning Technique"], "date": ["2018-03-26T16:29:03Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09702v1"], "summary": ["  Efficient label acquisition processes are key to obtaining robust\nclassifiers. However, data labeling is often challenging and subject to high\nlevels of label noise. This can arise even when classification targets are well\ndefined, if instances to be labeled are more difficult than the prototypes used\nto define the class, leading to disagreements among the expert community.\n  Here, we enable efficient training of deep neural networks. From\nlow-confidence labels, we iteratively improve their quality by simultaneous\nlearning of machines and experts. We call it Human And Machine co-LEarning\nTechnique (HAMLET). Throughout the process, experts become more consistent,\nwhile the algorithm provides them with explainable feedback for confirmation.\nHAMLET uses a neural embedding function and a memory module filled with diverse\nreference embeddings from different classes. Its output includes classification\nlabels and highly relevant reference embeddings as explanation.\n  We took the study of brain monitoring at intensive care unit (ICU) as an\napplication of HAMLET on continuous electroencephalography (cEEG) data.\nAlthough cEEG monitoring yields large volumes of data, labeling costs and\ndifficulty make it hard to build a classifier. Additionally, while experts\nagree on the labels of clear-cut examples of cEEG patterns, labeling many\nreal-world cEEG data can be extremely challenging. Thus, a large minority of\nsequences might be mislabeled. HAMLET has shown significant performance gain\nagainst deep learning and other baselines, increasing accuracy from 7.03% to\n68.75% on challenging inputs. Besides improved performance, clinical experts\nconfirmed the interpretability of those reference embeddings in helping\nexplaining the classification results by HAMLET.\n"]},
{"authors": ["Cem Eteke", "Hayati Havlucu", "Nisa \u0130rem K\u0131rba\u00e7", "Mehmet Cengiz Onba\u015fl\u0131", "Aykut Co\u015fkun", "Terry Eskenazi", "O\u011fuzhan \u00d6zcan", "Bar\u0131\u015f Akg\u00fcn"], "title": ["Flow From Motion: A Deep Learning Approach"], "date": ["2018-03-26T16:12:48Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09689v1"], "summary": ["  Wearable devices have the potential to enhance sports performance, yet they\nare not fulfilling this promise. Our previous studies with 6 professional\ntennis coaches and 20 players indicate that this could be due the lack of\npsychological or mental state feedback, which the coaches claim to provide.\nTowards this end, we propose to detect the flow state, mental state of optimal\nperformance, using wearables data to be later used in training. We performed a\nstudy with a professional tennis coach and two players. The coach provided\nlabels about the players' flow state while each player had a wearable device on\ntheir racket holding wrist. We trained multiple models using the wearables data\nand the coach labels. Our deep neural network models achieved around 98%\ntesting accuracy for a variety of conditions. This suggests that the flow state\nor what coaches recognize as flow, can be detected using wearables data in\ntennis which is a novel result. The implication for the HCI community is that\nhaving access to such information would allow for design of novel hardware and\ninteraction paradigms that would be helpful in professional athlete training.\n"]},
{"authors": ["Sebastian Schulze", "Owain Evans"], "title": ["Active Reinforcement Learning with Monte-Carlo Tree Search"], "date": ["2018-03-13T16:35:25Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04926v3"], "summary": ["  Active Reinforcement Learning (ARL) is a twist on RL where the agent observes\nreward information only if it pays a cost. This subtle change makes exploration\nsubstantially more challenging. Powerful principles in RL like optimism,\nThompson sampling, and random exploration do not help with ARL. We relate ARL\nin tabular environments to Bayes-Adaptive MDPs. We provide an ARL algorithm\nusing Monte-Carlo Tree Search that is asymptotically Bayes optimal.\nExperimentally, this algorithm is near-optimal on small Bandit problems and\nMDPs. On larger MDPs it outperforms a Q-learner augmented with specialised\nheuristics for ARL. By analysing exploration behaviour in detail, we uncover\nobstacles to scaling up simulation-based algorithms for ARL.\n"]},
{"authors": ["Sixue Gong", "Vishnu Naresh Boddeti", "Anil K. Jain"], "title": ["On the Intrinsic Dimensionality of Face Representation"], "date": ["2018-03-26T15:38:27Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09672v1"], "summary": ["  The two underlying factors that determine the efficacy of face\nrepresentations are, the embedding function to represent a face image and the\ndimensionality of the representation, e.g. the number of features. While the\ndesign of the embedding function has been well studied, relatively little is\nknown about the compactness of such representations. For instance, what is the\nminimal number of degrees of freedom or intrinsic dimensionality of a given\nface representation? Can we find a mapping from the ambient representation to\nthis minimal intrinsic space that retains it's full utility? This paper\naddresses both of these questions. Given a face representation, (1) we leverage\nintrinsic geodesic distances induced by a neighborhood graph to empirically\nestimate it's intrinsic dimensionality, (2) develop a neural network based\nnon-linear mapping that transforms the ambient representation to the minimal\nintrinsic space of that dimensionality, and (3) validate the veracity of the\nmapping through face matching in the intrinsic space. Experiments on benchmark\nface datasets (LFW, IJB-A, IJB-B, PCSO and CASIA) indicate that, (1) the\nintrinsic dimensionality of deep neural network representation is significantly\nlower than the dimensionality of the ambient features. For instance, Facenet's\n128-d representation has an intrinsic dimensionality in the range of 9-12, and\n(2) the neural network based mapping is able to provide face representations of\nsignificantly lower dimensionality while being as discriminative (TAR @ 0.1%\nFAR of 84.67%, 90.40% at 10 and 20 dimensions, respectively vs 95.50% at 128\nambient dimension on the LFW dataset) as the corresponding ambient\nrepresentation.\n"]},
{"authors": ["Giovanni Mariani", "Florian Scheidegger", "Roxana Istrate", "Costas Bekas", "Cristiano Malossi"], "title": ["BAGAN: Data Augmentation with Balancing GAN"], "date": ["2018-03-26T15:20:56Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09655v1"], "summary": ["  Image classification datasets are often imbalanced, characteristic that\nnegatively affects the accuracy of deeplearning classifiers. In this work we\npropose balancing GANs (BAGANs) as an augmentation tool to restore balance in\nimbalanced datasets. This is challenging because the few minority-class images\nmay not be enough to train a GAN. We overcome this issue by including during\ntraining all available images of majority and minority classes. The generative\nmodel learns useful features from majority classes and uses these to generate\nimages for minority classes. We apply class-conditioning in the latent space to\ndrive the generation process towards a target class. Additionally, we couple\nGANs with autoencoding techniques to reduce the risk of collapsing toward the\ngeneration of few foolish examples. We compare the proposed methodology with\nstate-of-the-art GANs and demonstrate that BAGAN generates images of superior\nquality when trained with an imbalanced dataset.\n"]},
{"authors": ["Pei-Hsuan Lu", "Pin-Yu Chen", "Chia-Mu Yu"], "title": ["On the Limitation of Local Intrinsic Dimensionality for Characterizing\n  the Subspaces of Adversarial Examples"], "date": ["2018-03-26T14:56:28Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09638v1"], "summary": ["  Understanding and characterizing the subspaces of adversarial examples aid in\nstudying the robustness of deep neural networks (DNNs) to adversarial\nperturbations. Very recently, Ma et al. (ICLR 2018) proposed to use local\nintrinsic dimensionality (LID) in layer-wise hidden representations of DNNs to\nstudy adversarial subspaces. It was demonstrated that LID can be used to\ncharacterize the adversarial subspaces associated with different attack\nmethods, e.g., the Carlini and Wagner's (C&W) attack and the fast gradient sign\nattack.\n  In this paper, we use MNIST and CIFAR-10 to conduct two new sets of\nexperiments that are absent in existing LID analysis and report the limitation\nof LID in characterizing the corresponding adversarial subspaces, which are (i)\noblivious attacks and LID analysis using adversarial examples with different\nconfidence levels; and (ii) black-box transfer attacks. For (i), we find that\nthe performance of LID is very sensitive to the confidence parameter deployed\nby an attack, and the LID learned from ensembles of adversarial examples with\nvarying confidence levels surprisingly gives poor performance. For (ii), we\nfind that when adversarial examples are crafted from another DNN model, LID is\nineffective in characterizing their adversarial subspaces. These two findings\ntogether suggest the limited capability of LID in characterizing the subspaces\nof adversarial examples.\n"]},
{"authors": ["Yoav Kaempfer", "Lior Wolf"], "title": ["Learning the Multiple Traveling Salesmen Problem with Permutation\n  Invariant Pooling Networks"], "date": ["2018-03-26T14:29:42Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09621v1"], "summary": ["  While there are optimal TSP solvers as well as recent learning-based\napproaches, the generalization of the TSP to the multiple Traveling Salesmen\nProblem is much less studied. Here, we design a neural network solution that\ntreats the salesmen, the cities, and the depot as three different sets of\nvarying cardinalities. Coupled with a normalization algorithm, a dedicated\nloss, and a search method, our solution is shown in two benchmarks to\noutperform all the meta-heuristics of the leading solver in the field.\n"]},
{"authors": ["Nils Reimers", "Iryna Gurevych"], "title": ["Why Comparing Single Performance Scores Does Not Allow to Draw\n  Conclusions About Machine Learning Approaches"], "date": ["2018-03-26T13:35:14Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09578v1"], "summary": ["  Developing state-of-the-art approaches for specific tasks is a major driving\nforce in our research community. Depending on the prestige of the task,\npublishing it can come along with a lot of visibility. The question arises how\nreliable are our evaluation methodologies to compare approaches?\n  One common methodology to identify the state-of-the-art is to partition data\ninto a train, a development and a test set. Researchers can train and tune\ntheir approach on some part of the dataset and then select the model that\nworked best on the development set for a final evaluation on unseen test data.\nTest scores from different approaches are compared, and performance differences\nare tested for statistical significance.\n  In this publication, we show that there is a high risk that a statistical\nsignificance in this type of evaluation is not due to a superior learning\napproach. Instead, there is a high risk that the difference is due to chance.\nFor example for the CoNLL 2003 NER dataset we observed in up to 26% of the\ncases type I errors (false positives) with a threshold of p < 0.05, i.e.,\nfalsely concluding a statistically significant difference between two identical\napproaches.\n  We prove that this evaluation setup is unsuitable to compare learning\napproaches. We formalize alternative evaluation setups based on score\ndistributions.\n"]},
{"authors": ["Gil Keren", "Nicholas Cummins", "Bj\u00f6rn Schuller"], "title": ["Calibrated Prediction Intervals for Neural Network Regressors"], "date": ["2018-03-26T12:35:12Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09546v1"], "summary": ["  Ongoing developments in neural network models are continually advancing the\nstate-of-the-art in terms of system accuracy. However, the predicted labels\nshould not be regarded as the only core output; also important is a well\ncalibrated estimate of the prediction uncertainty. Such estimates and their\ncalibration is critical in relation to robust handling of out of distribution\nevents not observed in training data. Despite their obvious aforementioned\nadvantage in relation to accuracy, contemporary neural networks can, generally,\nbe regarded as poorly calibrated and as such do not produce reliable output\nprobability estimates. Further, while post-processing calibration solutions can\nbe found in the relevant literature, these tend to be for systems performing\nclassification. In this regard, we herein present a method for acquiring\ncalibrated predictions intervals for neural network regressors by posing the\nregression task as a multi-class classification problem and applying one of\nthree proposed calibration methods on the classifiers' output. Testing our\nmethod on two exemplar tasks - speaker age prediction and signal-to-noise ratio\nestimation - indicates both the suitability of the classification-based\nregression models and that post-processing by our proposed empirical\ncalibration or temperature scaling methods yields well calibrated prediction\nintervals. The code for computing calibrated predicted intervals is publicly\navailable.\n"]},
{"authors": ["Jean-Baptiste Escudi\u00e9", "Alaa Saade", "Alice Coucke", "Marc Lelarge"], "title": ["Deep Representation for Patient Visits from Electronic Health Records"], "date": ["2018-03-26T12:02:48Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09533v1"], "summary": ["  We show how to learn low-dimensional representations (embeddings) of patient\nvisits from the corresponding electronic health record (EHR) where\nInternational Classification of Diseases (ICD) diagnosis codes are removed. We\nexpect that these embeddings will be useful for the construction of predictive\nstatistical models anticipated to drive personalized medicine and improve\nhealthcare quality. These embeddings are learned using a deep neural network\ntrained to predict ICD diagnosis categories. We show that our embeddings\ncapture relevant clinical informations and can be used directly as input to\nstandard machine learning algorithms like multi-output classifiers for ICD code\nprediction. We also show that important medical informations correspond to\nparticular directions in our embedding space.\n"]},
{"authors": ["Eran Malach", "Shai Shalev-Shwartz"], "title": ["A Provably Correct Algorithm for Deep Learning that Actually Works"], "date": ["2018-03-26T11:48:14Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09522v1"], "summary": ["  We describe a layer-by-layer algorithm for training deep convolutional\nnetworks, where each step involves gradient updates for a two layer network\nfollowed by a simple clustering algorithm. Our algorithm stems from a deep\ngenerative model that generates mages level by level, where lower resolution\nimages correspond to latent semantic classes. We analyze the convergence rate\nof our algorithm assuming that the data is indeed generated according to this\nmodel (as well as additional assumptions). While we do not pretend to claim\nthat the assumptions are realistic for natural images, we do believe that they\ncapture some true properties of real data. Furthermore, we show that our\nalgorithm actually works in practice (on the CIFAR dataset), achieving results\nin the same ballpark as that of vanilla convolutional neural networks that are\nbeing trained by stochastic gradient descent. Finally, our proof techniques may\nbe of independent interest.\n"]},
{"authors": ["Omiros Papaspiliopoulos", "Gareth O. Roberts", "Giacomo Zanella"], "title": ["Scalable inference for crossed random effects models"], "date": ["2018-03-26T08:15:54Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09460v1"], "summary": ["  We analyze the complexity of Gibbs samplers for inference in crossed random\neffect models used in modern analysis of variance. We demonstrate that for\ncertain designs the plain vanilla Gibbs sampler is not scalable, in the sense\nthat its complexity is worse than proportional to the number of parameters and\ndata. We thus propose a simple modification leading to a collapsed Gibbs\nsampler that is provably scalable. Although our theory requires some\nbalancedness assumptions on the data designs, we demonstrate in simulated and\nreal datasets that the rates it predicts match remarkably the correct rates in\ncases where the assumptions are violated. We also show that the collapsed Gibbs\nsampler, extended to sample further unknown hyperparameters, outperforms\nsignificantly alternative state of the art algorithms.\n"]},
{"authors": ["Huangjie Zheng", "Jiangchao Yao", "Ya Zhang", "Ivor W. Tsang"], "title": ["Degeneration in VAE: in the Light of Fisher Information Loss"], "date": ["2018-02-19T15:45:36Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.06677v2"], "summary": ["  Variational Autoencoder (VAE) is one of the most popular generative models,\nand enormous advances have been explored in recent years. Due to the increasing\ncomplexity of the raw data and the model architecture, deep networks are needed\nin VAE models while few works discuss their impacts. According to our\nobservation, VAE does not always benefit from deeper architecture: 1) Deeper\nencoder makes VAE learn more comprehensible latent representations, while\nresults in blurry reconstruction samples; 2) Deeper decoder ensures more\nhigh-quality generations, while the latent representations become abstruse; 3)\nWhen encoder and decoder both go deeper, abstruse latent representation occurs\nwith blurry reconstruction samples at same time. In this paper, we deduce a\nFisher information measure for the corresponding analysis. With such measure,\nwe demonstrate that information loss is ineluctable in feed-forward networks\nand causes the previous three types of degeneration, especially when the\nnetwork goes deeper. We also demonstrate that skip connections benefit the\npreservation of information amount, thus propose a VAE enhanced by skip\nconnections, named SCVAE. In the experiments, SCVAE is shown to mitigate the\ninformation loss and to achieve a promising performance in both encoding and\ndecoding tasks. Moreover, SCVAE can be adaptive to other state-of-the-art\nvariants of VAE for further amelioration.\n"]},
{"authors": ["Siddique Latif", "Rajib Rana", "Junaid Qadir", "Julien Epps"], "title": ["Variational Autoencoders for Learning Latent Representations of Speech\n  Emotion: A Preliminary Study"], "date": ["2017-12-23T03:54:00Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1712.08708v2"], "summary": ["  Learning the latent representation of data in unsupervised fashion is a very\ninteresting process that provides relevant features for enhancing the\nperformance of a classifier. For speech emotion recognition tasks, generating\neffective features is crucial. Currently, handcrafted features are mostly used\nfor speech emotion recognition, however, features learned automatically using\ndeep learning have shown strong success in many problems, especially in image\nprocessing. In particular, deep generative models such as Variational\nAutoencoders (VAEs) have gained enormous success for generating features for\nnatural images. Inspired by this, we propose VAEs for deriving the latent\nrepresentation of speech signals and use this representation to classify\nemotions. To the best of our knowledge, we are the first to propose VAEs for\nspeech emotion classification. Evaluations on the IEMOCAP dataset demonstrate\nthat features learned by VAEs can produce state-of-the-art results for speech\nemotion classification.\n"]},
{"authors": ["Francisco J. R. Ruiz", "Michalis K. Titsias", "Adji B. Dieng", "David M. Blei"], "title": ["Augment and Reduce: Stochastic Inference for Large Categorical\n  Distributions"], "date": ["2018-02-12T18:04:06Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.04220v2"], "summary": ["  Categorical distributions are ubiquitous in machine learning, e.g., in\nclassification, language models, and recommendation systems. They are also at\nthe core of discrete choice models. However, when the number of possible\noutcomes is very large, using categorical distributions becomes computationally\nexpensive, as the complexity scales linearly with the number of outcomes. To\naddress this problem, we propose augment and reduce (A&R), a method to\nalleviate the computational complexity. A&R uses two ideas: latent variable\naugmentation and stochastic variational inference. It maximizes a lower bound\non the marginal likelihood of the data. Unlike existing methods which are\nspecific to softmax, A&R is more general and is amenable to other categorical\nmodels, such as multinomial probit. On several large-scale classification\nproblems, we show that A&R provides a tighter bound on the marginal likelihood\nand has better predictive performance than existing approaches.\n"]},
{"authors": ["Michael Teti", "Elan Barenholtz", "Shawn Martin", "William Hahn"], "title": ["A Systematic Comparison of Deep Learning Architectures in an Autonomous\n  Vehicle"], "date": ["2018-03-26T01:58:07Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09386v1"], "summary": ["  Self-driving technology is advancing rapidly, largely due to recent\ndevelopments in deep learning algorithms. To date, however, there has been no\nsystematic comparison of how different deep learning architectures perform at\nsuch tasks, or an attempt to determine a correlation between classification\nperformance and performance in an actual vehicle. Here, we introduce the first\ncontrolled comparison of seven contemporary deep-learning architectures in an\nend-to-end autonomous driving task. We use a simple and affordable platform\nconsisting of of an off-the-shelf, remotely operated vehicle, a GPU equipped\ncomputer and an indoor foam-rubber racetrack. We compare a fully-connected\nnetwork, a 2-layer CNN, AlexNet, VGG-16, Inception-V3, ResNet-26, and LSTM and\nreport the number of laps they are able to successfully complete without\ncrashing while traversing an indoor racetrack under identical testing\nconditions. Based on these tests, AlexNet completed the most laps without\ncrashing out of all networks, and ResNet-26 is the most 'efficient'\narchitecture examined, with respect to the number of laps completed relative to\nthe number of parameters. We also observe whether spatial, color, or temporal\nfeatures - or some combination - are more important for such tasks. Finally, we\nshow that validation loss/accuracy is not sufficiently indicative of the\nmodel's performance even when employed in a real vehicle with a simple task,\nemphasizing the need for greater accessibility to research platforms within the\nself-driving community.\n"]},
{"authors": ["David M. Blei", "Alp Kucukelbir", "Jon D. McAuliffe"], "title": ["Variational Inference: A Review for Statisticians"], "date": ["2016-01-04T21:28:04Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1601.00670v8"], "summary": ["  One of the core problems of modern statistics is to approximate\ndifficult-to-compute probability densities. This problem is especially\nimportant in Bayesian statistics, which frames all inference about unknown\nquantities as a calculation involving the posterior density. In this paper, we\nreview variational inference (VI), a method from machine learning that\napproximates probability densities through optimization. VI has been used in\nmany applications and tends to be faster than classical methods, such as Markov\nchain Monte Carlo sampling. The idea behind VI is to first posit a family of\ndensities and then to find the member of that family which is close to the\ntarget. Closeness is measured by Kullback-Leibler divergence. We review the\nideas behind mean-field variational inference, discuss the special case of VI\napplied to exponential family models, present a full example with a Bayesian\nmixture of Gaussians, and derive a variant that uses stochastic optimization to\nscale up to massive data. We discuss modern research in VI and highlight\nimportant open problems. VI is powerful, but it is not yet well understood. Our\nhope in writing this paper is to catalyze statistical research on this class of\nalgorithms.\n"]},
{"authors": ["Tianbing Xu"], "title": ["Variational Inference for Policy Gradient"], "date": ["2018-02-21T22:18:20Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.07833v2"], "summary": ["  Inspired by the seminal work on Stein Variational Inference and Stein\nVariational Policy Gradient, we derived a method to generate samples from the\nposterior variational parameter distribution by \\textit{explicitly} minimizing\nthe KL divergence to match the target distribution in an amortize fashion.\nConsequently, we applied this varational inference technique into vanilla\npolicy gradient, TRPO and PPO with Bayesian Neural Network parameterizations\nfor reinforcement learning problems.\n"]},
{"authors": ["Vasileios Tzoumas", "Ali Jadbabaie", "George J. Pappas"], "title": ["Resilient Monotone Sequential Maximization"], "date": ["2018-03-21T15:00:33Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07954v3"], "summary": ["  Applications in machine learning, optimization, and control require the\nsequential selection of a few system elements, such as sensors, data, or\nactuators, to optimize the system performance across multiple time steps.\nHowever, in failure-prone and adversarial environments, sensors get attacked,\ndata get deleted, and actuators fail. Thence, traditional sequential design\nparadigms become insufficient and, in contrast, resilient sequential designs\nthat adapt against system-wide attacks, deletions, or failures become\nimportant. In general, resilient sequential design problems are computationally\nhard. Also, even though they often involve objective functions that are\nmonotone and (possibly) submodular, no scalable approximation algorithms are\nknown for their solution. In this paper, we provide the first scalable\nalgorithm, that achieves the following characteristics: system-wide resiliency,\ni.e., the algorithm is valid for any number of denial-of-service attacks,\ndeletions, or failures; adaptiveness, i.e., at each time step, the algorithm\nselects system elements based on the history of inflicted attacks, deletions,\nor failures; and provable approximation performance, i.e., the algorithm\nguarantees for monotone objective functions a solution close to the optimal. We\nquantify the algorithm's approximation performance using a notion of curvature\nfor monotone (not necessarily submodular) set functions. Finally, we support\nour theoretical analyses with simulated experiments, by considering a\ncontrol-aware sensor scheduling scenario, namely, sensing-constrained robot\nnavigation.\n"]},
{"authors": ["Praneeth Narayanamurthy", "Namrata Vaswani"], "title": ["Nearly Optimal Robust Subspace Tracking"], "date": ["2017-12-17T06:14:58Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1712.06061v3"], "summary": ["  In this work, we study the robust subspace tracking (RST) problem and obtain\none of the first two provable guarantees for it. The goal of RST is to track\nsequentially arriving data vectors that lie in a slowly changing\nlow-dimensional subspace, while being robust to corruption by additive sparse\noutliers. It can also be interpreted as a dynamic (time-varying) extension of\nrobust PCA (RPCA), with the minor difference that RST also requires a short\ntracking delay. We develop a recursive projected compressive sensing algorithm\nthat we call Nearly Optimal RST via ReProCS (ReProCS-NORST) because its\ntracking delay is nearly optimal. We prove that NORST solves both the RST and\nthe dynamic RPCA problems under weakened standard RPCA assumptions, two simple\nextra assumptions (slow subspace change and most outlier magnitudes lower\nbounded), and a few minor assumptions.\n  Our guarantee shows that NORST enjoys a near optimal tracking delay of $O(r\n\\log n \\log(1/\\epsilon))$. Its required delay between subspace change times is\nthe same, and its memory complexity is $n$ times this value. Thus both these\nare also nearly optimal. Here $n$ is the ambient space dimension, $r$ is the\nsubspaces' dimension, and $\\epsilon$ is the tracking accuracy. NORST also has\nthe best outlier tolerance compared with all previous RPCA or RST methods, both\ntheoretically and empirically (including for real videos), without requiring\nany model on how the outlier support is generated. This is possible because of\nthe extra assumptions it uses.\n"]},
{"authors": ["Chi Jin", "Lydia T. Liu", "Rong Ge", "Michael I. Jordan"], "title": ["Minimizing Nonconvex Population Risk from Rough Empirical Risk"], "date": ["2018-03-25T22:18:04Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09357v1"], "summary": ["  Population risk---the expectation of the loss over the sampling\nmechanism---is always of primary interest in machine learning. However,\nlearning algorithms only have access to empirical risk, which is the average\nloss over training examples. Although the two risks are typically guaranteed to\nbe pointwise close, for applications with nonconvex nonsmooth losses (such as\nmodern deep networks), the effects of sampling can transform a well-behaved\npopulation risk into an empirical risk with a landscape that is problematic for\noptimization. The empirical risk can be nonsmooth, and it may have many\nadditional local minima.\n  This paper considers a general optimization framework which aims to find\napproximate local minima of a smooth nonconvex function $F$ (population risk)\ngiven only access to the function value of another function $f$ (empirical\nrisk), which is pointwise close to $F$ (i.e., $\\|F-f\\|_{\\infty} \\le \\nu$). We\npropose a simple algorithm based on stochastic gradient descent (SGD) on a\nsmoothed version of $f$ which is guaranteed to find an $\\epsilon$-second-order\nstationary point if $\\nu \\le O(\\epsilon^{1.5}/d)$, thus escaping all saddle\npoints of $F$ and all the additional local minima introduced by $f$. We also\nprovide an almost matching lower bound showing that our SGD-based approach\nachieves the optimal trade-off between $\\nu$ and $\\epsilon$, as well as the\noptimal dependence on problem dimension $d$, among all algorithms making a\npolynomial number of queries. As a concrete example, we show that our results\ncan be directly used to give sample complexities for learning a ReLU unit,\nwhose empirical risk is nonsmooth.\n"]},
{"authors": ["Thodoris Lykouris", "Vahab Mirrokni", "Renato Paes Leme"], "title": ["Stochastic bandits robust to adversarial corruptions"], "date": ["2018-03-25T21:48:53Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09353v1"], "summary": ["  We introduce a new model of stochastic bandits with adversarial corruptions\nwhich aims to capture settings where most of the input follows a stochastic\npattern but some fraction of it can be adversarially changed to trick the\nalgorithm, e.g., click fraud, fake reviews and email spam. The goal of this\nmodel is to encourage the design of bandit algorithms that (i) work well in\nmixed adversarial and stochastic models, and (ii) whose performance\ndeteriorates gracefully as we move from fully stochastic to fully adversarial\nmodels.\n  In our model, the rewards for all arms are initially drawn from a\ndistribution and are then altered by an adaptive adversary. We provide a simple\nalgorithm whose performance gracefully degrades with the total corruption the\nadversary injected in the data, measured by the sum across rounds of the\nbiggest alteration the adversary made in the data in that round; this total\ncorruption is denoted by $C$. Our algorithm provides a guarantee that retains\nthe optimal guarantee (up to a logarithmic term) if the input is stochastic and\nwhose performance degrades linearly to the amount of corruption $C$, while\ncrucially being agnostic to it. We also provide a lower bound showing that this\nlinear degradation is necessary if the algorithm achieves optimal performance\nin the stochastic setting (the lower bound works even for a known amount of\ncorruption, a special case in which our algorithm achieves optimal performance\nwithout the extra logarithm).\n"]},
{"authors": ["Dylan J. Foster", "Satyen Kale", "Haipeng Luo", "Mehryar Mohri", "Karthik Sridharan"], "title": ["Logistic Regression: The Importance of Being Improper"], "date": ["2018-03-25T21:37:08Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09349v1"], "summary": ["  Learning linear predictors with the logistic loss---both in stochastic and\nonline settings---is a fundamental task in learning and statistics, with direct\nconnections to classification and boosting. Existing \"fast rates\" for this\nsetting exhibit exponential dependence on the predictor norm, and Hazan et al.\n(2014) showed that this is unfortunately unimprovable. Starting with the simple\nobservation that the logistic loss is 1-mixable, we design a new efficient\nimproper learning algorithm for online logistic regression that circumvents the\naforementioned lower bound with a regret bound exhibiting a doubly-exponential\nimprovement in dependence on the predictor norm. This provides a positive\nresolution to a variant of the COLT 2012 open problem of McMahan and Streeter\n(2012) when improper learning is allowed. This improvement is obtained both in\nthe online setting and, with some extra work, in the batch statistical setting\nwith high probability. We also show that the improved dependency on predictor\nnorm is also near-optimal.\n  Leveraging this improved dependency on the predictor norm yields the\nfollowing applications: (a) we give algorithms for online bandit multiclass\nlearning with the logistic loss with an $\\tilde{O}(\\sqrt{n})$ relative mistake\nbound across essentially all parameter ranges, thus providing a solution to the\nCOLT 2009 open problem of Abernethy and Rakhlin (2009), and (b) we give an\nadaptive algorithm for online multiclass boosting with optimal sample\ncomplexity, thus partially resolving an open problem of Beygelzimer et al.\n(2015) and Jung et al. (2017). Finally, we give information-theoretic bounds on\nthe optimal rates for improper logistic regression with general function\nclasses, thereby characterizing the extent to which our improvement for linear\nclasses extends to other parameteric and even nonparametric settings.\n"]},
{"authors": ["Jiong Zhang", "Qi Lei", "Inderjit S. Dhillon"], "title": ["Stabilizing Gradients for Deep Neural Networks via Efficient SVD\n  Parameterization"], "date": ["2018-03-25T20:12:18Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09327v1"], "summary": ["  Vanishing and exploding gradients are two of the main obstacles in training\ndeep neural networks, especially in capturing long range dependencies in\nrecurrent neural networks~(RNNs). In this paper, we present an efficient\nparametrization of the transition matrix of an RNN that allows us to stabilize\nthe gradients that arise in its training. Specifically, we parameterize the\ntransition matrix by its singular value decomposition(SVD), which allows us to\nexplicitly track and control its singular values. We attain efficiency by using\ntools that are common in numerical linear algebra, namely Householder\nreflectors for representing the orthogonal matrices that arise in the SVD. By\nexplicitly controlling the singular values, our proposed Spectral-RNN method\nallows us to easily solve the exploding gradient problem and we observe that it\nempirically solves the vanishing gradient issue to a large extent. We note that\nthe SVD parameterization can be used for any rectangular weight matrix, hence\nit can be easily extended to any deep neural network, such as a multi-layer\nperceptron. Theoretically, we demonstrate that our parameterization does not\nlose any expressive power, and show how it controls generalization of RNN for\nthe classification task. %, and show how it potentially makes the optimization\nprocess easier. Our extensive experimental results also demonstrate that the\nproposed framework converges faster, and has good generalization, especially in\ncapturing long range dependencies, as shown on the synthetic addition and copy\ntasks, as well as on MNIST and Penn Tree Bank data sets.\n"]},
{"authors": ["Dustin G. Mixon", "Soledad Villar"], "title": ["SUNLayer: Stable denoising with generative networks"], "date": ["2018-03-25T19:33:04Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09319v1"], "summary": ["  It has been experimentally established that deep neural networks can be used\nto produce good generative models for real world data. It has also been\nestablished that such generative models can be exploited to solve classical\ninverse problems like compressed sensing and super resolution. In this work we\nfocus on the classical signal processing problem of image denoising. We propose\na theoretical setting that uses spherical harmonics to identify what\nmathematical properties of the activation functions will allow signal denoising\nwith local methods.\n"]},
{"authors": ["Shaowu Pan", "Karthik Duraisamy"], "title": ["Data-driven Discovery of Closure Models"], "date": ["2018-03-25T19:24:52Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09318v1"], "summary": ["  Derivation of reduced order representations of dynamical systems requires the\nmodeling of the truncated dynamics on the retained dynamics. In its most\ngeneral form, this so-called closure model has to account for memory effects.\nIn this work, we present a framework of operator inference to extract the\ngoverning dynamics of closure from data in a compact, non-Markovian form. We\nemploy sparse polynomial regression and artificial neural networks to extract\nthe underlying operator. For a special class of non-linear systems,\nobservability of the closure in terms of the resolved dynamics is analyzed and\ntheoretical results are presented on the compactness of the memory. The\nproposed framework is evaluated on examples consisting of linear to nonlinear\nsystems with and without chaotic dynamics, with an emphasis on predictive\nperformance on unseen data.\n"]},
{"authors": ["Mehdi S. M. Sajjadi", "Raviteja Vemulapalli", "Matthew Brown"], "title": ["Frame-Recurrent Video Super-Resolution"], "date": ["2018-01-14T17:53:53Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1801.04590v4"], "summary": ["  Recent advances in video super-resolution have shown that convolutional\nneural networks combined with motion compensation are able to merge information\nfrom multiple low-resolution (LR) frames to generate high-quality images.\nCurrent state-of-the-art methods process a batch of LR frames to generate a\nsingle high-resolution (HR) frame and run this scheme in a sliding window\nfashion over the entire video, effectively treating the problem as a large\nnumber of separate multi-frame super-resolution tasks. This approach has two\nmain weaknesses: 1) Each input frame is processed and warped multiple times,\nincreasing the computational cost, and 2) each output frame is estimated\nindependently conditioned on the input frames, limiting the system's ability to\nproduce temporally consistent results.\n  In this work, we propose an end-to-end trainable frame-recurrent video\nsuper-resolution framework that uses the previously inferred HR estimate to\nsuper-resolve the subsequent frame. This naturally encourages temporally\nconsistent results and reduces the computational cost by warping only one image\nin each step. Furthermore, due to its recurrent nature, the proposed method has\nthe ability to assimilate a large number of previous frames without increased\ncomputational demands. Extensive evaluations and comparisons with previous\nmethods validate the strengths of our approach and demonstrate that the\nproposed framework is able to significantly outperform the current state of the\nart.\n"]},
{"authors": ["Abdullah Al-Dujaili", "Alex Huang", "Erik Hemberg", "Una-May O'Reilly"], "title": ["Adversarial Deep Learning for Robust Detection of Binary Encoded Malware"], "date": ["2018-01-09T14:32:30Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1801.02950v3"], "summary": ["  Malware is constantly adapting in order to avoid detection. Model based\nmalware detectors, such as SVM and neural networks, are vulnerable to so-called\nadversarial examples which are modest changes to detectable malware that allows\nthe resulting malware to evade detection. Continuous-valued methods that are\nrobust to adversarial examples of images have been developed using saddle-point\noptimization formulations. We are inspired by them to develop similar methods\nfor the discrete, e.g. binary, domain which characterizes the features of\nmalware. A specific extra challenge of malware is that the adversarial examples\nmust be generated in a way that preserves their malicious functionality. We\nintroduce methods capable of generating functionally preserved adversarial\nmalware examples in the binary domain. Using the saddle-point formulation, we\nincorporate the adversarial examples into the training of models that are\nrobust to them. We evaluate the effectiveness of the methods and others in the\nliterature on a set of Portable Execution~(PE) files. Comparison prompts our\nintroduction of an online measure computed during training to assess general\nexpectation of robustness.\n"]},
{"authors": ["Hangjin Jiang", "Yiming Ding"], "title": ["Dependence Measure for non-additive model"], "date": ["2013-10-06T09:36:55Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1310.1562v5"], "summary": ["  We proposed a new statistical dependency measure called Copula Dependency\nCoefficient(CDC) for two sets of variables based on copula. It is robust to\noutliers, easy to implement, powerful and appropriate to high-dimensional\nvariables. These properties are important in many applications. Experimental\nresults show that CDC can detect the dependence between variables in both\nadditive and non-additive models.\n"]},
{"authors": ["Avigail Stekel", "Merav Chkroun", "Amos Azaria"], "title": ["Goldbach's Function Approximation Using Deep Learning"], "date": ["2018-03-25T12:09:43Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09237v1"], "summary": ["  Goldbach conjecture is one of the most famous open mathematical problems. It\nstates that every even number, bigger than two, can be presented as a sum of 2\nprime numbers. % In this work we present a deep learning based model that\npredicts the number of Goldbach partitions for a given even number.\nSurprisingly, our model outperforms all state-of-the-art analytically derived\nestimations for the number of couples, while not requiring prime factorization\nof the given number. We believe that building a model that can accurately\npredict the number of couples brings us one step closer to solving one of the\nworld most famous open problems. To the best of our knowledge, this is the\nfirst attempt to consider machine learning based data-driven methods to\napproximate open mathematical problems in the field of number theory, and hope\nthat this work will encourage such attempts.\n"]},
{"authors": ["Or Sharir", "Ronen Tamari", "Nadav Cohen", "Amnon Shashua"], "title": ["Tensorial Mixture Models"], "date": ["2016-10-13T16:43:32Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1610.04167v5"], "summary": ["  Casting neural networks in generative frameworks is a highly sought-after\nendeavor these days. Contemporary methods, such as Generative Adversarial\nNetworks, capture some of the generative capabilities, but not all. In\nparticular, they lack the ability of tractable marginalization, and thus are\nnot suitable for many tasks. Other methods, based on arithmetic circuits and\nsum-product networks, do allow tractable marginalization, but their performance\nis challenged by the need to learn the structure of a circuit. Building on the\ntractability of arithmetic circuits, we leverage concepts from tensor analysis,\nand derive a family of generative models we call Tensorial Mixture Models\n(TMMs). TMMs assume a simple convolutional network structure, and in addition,\nlend themselves to theoretical analyses that allow comprehensive understanding\nof the relation between their structure and their expressive properties. We\nthus obtain a generative model that is tractable on one hand, and on the other\nhand, allows effective representation of rich distributions in an easily\ncontrolled manner. These two capabilities are brought together in the task of\nclassification under missing data, where TMMs deliver state of the art\naccuracies with seamless implementation and design.\n"]},
{"authors": ["Vinith Misra", "Sumit Bhatia"], "title": ["Bernoulli Embeddings for Graphs"], "date": ["2018-03-25T07:19:47Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09211v1"], "summary": ["  Just as semantic hashing can accelerate information retrieval, binary valued\nembeddings can significantly reduce latency in the retrieval of graphical data.\nWe introduce a simple but effective model for learning such binary vectors for\nnodes in a graph. By imagining the embeddings as independent coin flips of\nvarying bias, continuous optimization techniques can be applied to the\napproximate expected loss. Embeddings optimized in this fashion consistently\noutperform the quantization of both spectral graph embeddings and various\nlearned real-valued embeddings, on both ranking and pre-ranking tasks for a\nvariety of datasets.\n"]},
{"authors": ["Joel Ruben Antony Moniz", "Christopher Beckham", "Simon Rajotte", "Sina Honari", "Christopher Pal"], "title": ["Unsupervised Depth Estimation, 3D Face Rotation and Replacement"], "date": ["2018-03-25T05:07:11Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09202v1"], "summary": ["  We present an unsupervised approach for learning to estimate three\ndimensional (3D) facial structure from a single image while also predicting 3D\nviewpoint transformations that match a desired pose and facial geometry. We\nachieve this by inferring the depth of facial key-points in an input image in\nan unsupervised way. We show how it is possible to use these depths as\nintermediate computations within a new backpropable loss to predict the\nparameters of a 3D affine transformation matrix that maps inferred 3D\nkey-points of an input face to corresponding 2D key-points on a desired target\nfacial geometry or pose. Our resulting approach can therefore be used to infer\nplausible 3D transformations from one face pose to another, allowing faces to\nbe frontalized, trans- formed into 3D models or even warped to another pose and\nfacial geometry. Lastly, we identify certain shortcomings with our formulation,\nand explore adversarial image translation techniques as a post-processing step.\nCorrespondingly, we explore several adversarial image transformation methods\nwhich allow us to re-synthesize complete head shots for faces re-targeted to\ndifferent poses as well as repair images resulting from face replacements\nacross identities.\n"]},
{"authors": ["Jean-Gabriel Young", "Laurent H\u00e9bert-Dufresne", "Edward Laurence", "Charles Murphy", "Guillaume St-Onge", "Patrick Desrosiers"], "title": ["Network archaeology: phase transition in the recoverability of network\n  history"], "date": ["2018-03-25T02:09:10Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09191v1"], "summary": ["  Network growth processes can be understood as generative models of the\nstructure and history of complex networks. This point of view naturally leads\nto the problem of network archaeology: Reconstructing all the past states of a\nnetwork from its structure---a difficult permutation inference problem. In this\npaper, we introduce a Bayesian formulation of network archaeology, with a\ngeneralization of preferential attachment as our generative mechanism. We\ndevelop a sequential importance sampling algorithm to evaluate the posterior\naverages of this model, as well as an efficient heuristic that uncovers the\nhistory of a network in linear time. We use these methods to identify and\ncharacterize a phase transition in the quality of the reconstructed history,\nwhen they are applied to artificial networks generated by the model itself.\nDespite the existence of a no-recovery phase, we find that non-trivial\ninference is possible in a large portion of the parameter space as well as on\nempirical data.\n"]},
{"authors": ["Sicheng Zhao", "Bichen Wu", "Joseph Gonzalez", "Sanjit A. Seshia", "Kurt Keutzer"], "title": ["Unsupervised Domain Adaptation: from Simulation Engine to the RealWorld"], "date": ["2018-03-24T23:34:06Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09180v1"], "summary": ["  Large-scale labeled training datasets have enabled deep neural networks to\nexcel on a wide range of benchmark vision tasks. However, in many applications\nit is prohibitively expensive or time-consuming to obtain large quantities of\nlabeled data. To cope with limited labeled training data, many have attempted\nto directly apply models trained on a large-scale labeled source domain to\nanother sparsely labeled target domain. Unfortunately, direct transfer across\ndomains often performs poorly due to domain shift and dataset bias. Domain\nadaptation is the machine learning paradigm that aims to learn a model from a\nsource domain that can perform well on a different (but related) target domain.\nIn this paper, we summarize and compare the latest unsupervised domain\nadaptation methods in computer vision applications. We classify the non-deep\napproaches into sample re-weighting and intermediate subspace transformation\ncategories, while the deep strategy includes discrepancy-based methods,\nadversarial generative models, adversarial discriminative models and\nreconstruction-based methods. We also discuss some potential directions.\n"]},
{"authors": ["Kahkashan Afrin", "Gurudev Illangovan", "Sanjay S. Srivatsa", "Satish T. S. Bukkapatnam"], "title": ["Balanced Random Survival Forests for Extremely Unbalanced, Right\n  Censored Data"], "date": ["2018-03-24T22:58:41Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09177v1"], "summary": ["  Accuracies of survival models for life expectancy prediction as well as\nlifesaving critical-care applications are significantly compromised due to the\nsparsity of samples and extreme imbalance between the survival and mortality\nclasses in addition to the invalidity of the popular proportional hazard\nassumption. An imbalance in data results in an underestimation (overestimation)\nof the hazard of the mortality (survival) classes. Balanced random survival\nforests (BRSF) model, based on training random survival forests with balanced\ndata generated from a synthetic minority sampling scheme is presented to\naddress this gap. Theoretical findings on the improvement of survival\nprediction after balancing are corroborated using extensive empirical\nevaluations. Benchmarking studies consider five data sets of different levels\nof class imbalance from public repositories and an imbalanced survival data set\nof 267 ST-elevated myocardial infarction (STEMI) patients collected over a\nperiod of one year at Heart, Artery, and Vein Center of Fresno, CA.\nInvestigations suggest BRSF provides a better discriminatory strength between\nthe censored and the mortality classes and improves survival prediction of the\nminority. BRSF outperformed both optimized Cox (without and with balancing) and\nRSF with a 55% reduction (averaged over all 6 data sets) in prediction error\nover the next best alternative.\n"]},
{"authors": ["Tegjyot Singh Sethi", "Mehmed Kantardzic", "Joung Woo Ryu"], "title": ["Security Theater: On the Vulnerability of Classifiers to Exploratory\n  Attacks"], "date": ["2018-03-24T21:10:00Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09163v1"], "summary": ["  The increasing scale and sophistication of cyberattacks has led to the\nadoption of machine learning based classification techniques, at the core of\ncybersecurity systems. These techniques promise scale and accuracy, which\ntraditional rule or signature based methods cannot. However, classifiers\noperating in adversarial domains are vulnerable to evasion attacks by an\nadversary, who is capable of learning the behavior of the system by employing\nintelligently crafted probes. Classification accuracy in such domains provides\na false sense of security, as detection can easily be evaded by carefully\nperturbing the input samples. In this paper, a generic data driven framework is\npresented, to analyze the vulnerability of classification systems to black box\nprobing based attacks. The framework uses an exploration exploitation based\nstrategy, to understand an adversary's point of view of the attack defense\ncycle. The adversary assumes a black box model of the defender's classifier and\ncan launch indiscriminate attacks on it, without information of the defender's\nmodel type, training data or the domain of application. Experimental evaluation\non 10 real world datasets demonstrates that even models having high perceived\naccuracy (>90%), by a defender, can be effectively circumvented with a high\nevasion rate (>95%, on average). The detailed attack algorithms, adversarial\nmodel and empirical evaluation, serve.\n"]},
{"authors": ["Tegjyot Singh Sethi", "Mehmed Kantardzic", "Lingyu Lyua", "Jiashun Chen"], "title": ["A Dynamic-Adversarial Mining Approach to the Security of Machine\n  Learning"], "date": ["2018-03-24T20:55:20Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09162v1"], "summary": ["  Operating in a dynamic real world environment requires a forward thinking and\nadversarial aware design for classifiers, beyond fitting the model to the\ntraining data. In such scenarios, it is necessary to make classifiers - a)\nharder to evade, b) easier to detect changes in the data distribution over\ntime, and c) be able to retrain and recover from model degradation. While most\nworks in the security of machine learning has concentrated on the evasion\nresistance (a) problem, there is little work in the areas of reacting to\nattacks (b and c). Additionally, while streaming data research concentrates on\nthe ability to react to changes to the data distribution, they often take an\nadversarial agnostic view of the security problem. This makes them vulnerable\nto adversarial activity, which is aimed towards evading the concept drift\ndetection mechanism itself. In this paper, we analyze the security of machine\nlearning, from a dynamic and adversarial aware perspective. The existing\ntechniques of Restrictive one class classifier models, Complex learning models\nand Randomization based ensembles, are shown to be myopic as they approach\nsecurity as a static task. These methodologies are ill suited for a dynamic\nenvironment, as they leak excessive information to an adversary, who can\nsubsequently launch attacks which are indistinguishable from the benign data.\nBased on empirical vulnerability analysis against a sophisticated adversary, a\nnovel feature importance hiding approach for classifier design, is proposed.\nThe proposed design ensures that future attacks on classifiers can be detected\nand recovered from. The proposed work presents motivation, by serving as a\nblueprint, for future work in the area of Dynamic-Adversarial mining, which\ncombines lessons learned from Streaming data mining, Adversarial learning and\nCybersecurity.\n"]},
{"authors": ["Tegjyot Singh Sethi", "Mehmed Kantardzic"], "title": ["Handling Adversarial Concept Drift in Streaming Data"], "date": ["2018-03-24T20:30:50Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09160v1"], "summary": ["  Classifiers operating in a dynamic, real world environment, are vulnerable to\nadversarial activity, which causes the data distribution to change over time.\nThese changes are traditionally referred to as concept drift, and several\napproaches have been developed in literature to deal with the problem of drift\nhandling and detection. However, most concept drift handling techniques,\napproach it as a domain independent task, to make them applicable to a wide\ngamut of reactive systems. These techniques were developed from an adversarial\nagnostic perspective, where they are naive and assume that drift is a benign\nchange, which can be fixed by updating the model. However, this is not the case\nwhen an active adversary is trying to evade the deployed classification system.\nIn such an environment, the properties of concept drift are unique, as the\ndrift is intended to degrade the system and at the same time designed to avoid\ndetection by traditional concept drift detection techniques. This special\ncategory of drift is termed as adversarial drift, and this paper analyzes its\ncharacteristics and impact, in a streaming environment. A novel framework for\ndealing with adversarial concept drift is proposed, called the Predict-Detect\nstreaming framework. Experimental evaluation of the framework, on generated\nadversarial drifting data streams, demonstrates that this framework is able to\nprovide reliable unsupervised indication of drift, and is able to recover from\ndrifts swiftly. While traditional partially labeled concept drift detection\nmethodologies fail to detect adversarial drifts, the proposed framework is able\nto detect such drifts and operates with <6% labeled data, on average. Also, the\nframework provides benefits for active learning over imbalanced data streams,\nby innately providing for feature space honeypots, where minority class\nadversarial samples may be captured.\n"]},
{"authors": ["Edward McFowland III", "Sriram Somanchi", "Daniel B. Neill"], "title": ["Efficient Discovery of Heterogeneous Treatment Effects in Randomized\n  Experiments via Anomalous Pattern Detection"], "date": ["2018-03-24T20:21:06Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09159v1"], "summary": ["  The randomized experiment is an important tool for inferring the causal\nimpact of an intervention. The recent literature on statistical learning\nmethods for heterogeneous treatment effects demonstrates the utility of\nestimating the marginal conditional average treatment effect (MCATE), i.e., the\naverage treatment effect for a subpopulation of respondents who share a\nparticular subset of covariates. However, each proposed method makes its own\nset of restrictive assumptions about the intervention's effects, the underlying\ndata generating processes, and which subpopulations (MCATEs) to explicitly\nestimate. Moreover, the majority of the literature provides no mechanism to\nidentify which subpopulations are the most affected--beyond manual\ninspection--and provides little guarantee on the correctness of the identified\nsubpopulations. Therefore, we propose Treatment Effect Subset Scan (TESS), a\nnew method for discovering which subpopulation in a randomized experiment is\nmost significantly affected by a treatment. We frame this challenge as a\npattern detection problem where we maximize a nonparametric scan statistic\n(measurement of distributional divergence) over subpopulations, while being\nparsimonious in which specific subpopulations to evaluate. Furthermore, we\nidentify the subpopulation which experiences the largest distributional change\nas a result of the intervention, while making minimal assumptions about the\nintervention's effects or the underlying data generating process. In addition\nto the algorithm, we demonstrate that the asymptotic Type I and II error can be\ncontrolled, and provide sufficient conditions for detection consistency---i.e.,\nexact identification of the affected subpopulation. Finally, we validate the\nefficacy of the method by discovering heterogeneous treatment effects in\nsimulations and in real-world data from a well-known program evaluation study.\n"]},
{"authors": ["Anna Silnova", "Niko Brummer", "Daniel Garcia-Romero", "David Snyder", "Lukas Burget"], "title": ["Fast variational Bayes for heavy-tailed PLDA applied to i-vectors and\n  x-vectors"], "date": ["2018-03-24T19:19:32Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09153v1"], "summary": ["  The standard state-of-the-art backend for text-independent speaker\nrecognizers that use i-vectors or x-vectors, is Gaussian PLDA (G-PLDA),\nassisted by a Gaussianization step involving length normalization. G-PLDA can\nbe trained with both generative or discriminative methods. It has long been\nknown that heavy-tailed PLDA (HT-PLDA), applied without length normalization,\ngives similar accuracy, but at considerable extra computational cost. We have\nrecently introduced a fast scoring algorithm for a discriminatively trained\nHT-PLDA backend. This paper extends that work by introducing a fast,\nvariational Bayes, generative training algorithm. We compare old and new\nbackends, with and without length-normalization, with i-vectors and x-vectors,\non SRE'10, SRE'16 and SITW.\n"]},
{"authors": ["Hugh Salimbeni", "Stefanos Eleftheriadis", "James Hensman"], "title": ["Natural Gradients in Practice: Non-Conjugate Variational Inference in\n  Gaussian Process Models"], "date": ["2018-03-24T19:11:43Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09151v1"], "summary": ["  The natural gradient method has been used effectively in conjugate Gaussian\nprocess models, but the non-conjugate case has been largely unexplored. We\nexamine how natural gradients can be used in non-conjugate stochastic settings,\ntogether with hyperparameter learning. We conclude that the natural gradient\ncan significantly improve performance in terms of wall-clock time. For\nill-conditioned posteriors the benefit of the natural gradient method is\nespecially pronounced, and we demonstrate a practical setting where ordinary\ngradients are unusable. We show how natural gradients can be computed\nefficiently and automatically in any parameterization, using automatic\ndifferentiation. Our code is integrated into the GPflow package.\n"]},
{"authors": ["Nicholas Polson", "Veronika Rockova"], "title": ["Posterior Concentration for Sparse Deep Learning"], "date": ["2018-03-24T17:51:15Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09138v1"], "summary": ["  Spike-and-Slab Deep Learning (SS-DL) is a fully Bayesian alternative to\nDropout for improving generalizability of deep ReLU networks. This new type of\nregularization enables provable recovery of smooth input-output maps with\nunknown levels of smoothness. Indeed, we show that the posterior distribution\nconcentrates at the near minimax rate for $\\alpha$-H\\\"older smooth maps,\nperforming as well as if we knew the smoothness level $\\alpha$ ahead of time.\nOur result sheds light on architecture design for deep neural networks, namely\nthe choice of depth, width and sparsity level. These network attributes\ntypically depend on unknown smoothness in order to be optimal. We obviate this\nconstraint with the fully Bayes construction. As an aside, we show that SS-DL\ndoes not overfit in the sense that the posterior concentrates on smaller\nnetworks with fewer (up to the optimal number of) nodes and links. Our results\nprovide new theoretical justifications for deep ReLU networks from a Bayesian\npoint of view.\n"]},
{"authors": ["Frank Webb", "Amir Karami", "Vanessa Kitzie"], "title": ["Characterizing Diseases and disorders in Gay Users' tweets"], "date": ["2018-03-24T17:27:37Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09134v1"], "summary": ["  A lack of information exists about the health issues of lesbian, gay,\nbisexual, transgender, and queer (LGBTQ) people who are often excluded from\nnational demographic assessments, health studies, and clinical trials. As a\nresult, medical experts and researchers lack a holistic understanding of the\nhealth disparities facing these populations. Fortunately, publicly available\nsocial media data such as Twitter data can be utilized to support the decisions\nof public health policy makers and managers with respect to LGBTQ people. This\nresearch employs a computational approach to collect tweets from gay users on\nhealth-related topics and model these topics. To determine the nature of\nhealth-related information shared by men who have sex with men on Twitter, we\ncollected thousands of tweets from 177 active users. We sampled these tweets\nusing a framework that can be applied to other LGBTQ sub-populations in future\nresearch. We found 11 diseases in 7 categories based on ICD 10 that are in line\nwith the published studies and official reports.\n"]},
{"authors": ["Matthew Collins", "Amir Karami"], "title": ["Social Media Analysis For Organizations: Us Northeastern Public And\n  State Libraries Case Study"], "date": ["2018-03-24T17:23:41Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09133v1"], "summary": ["  Social networking sites such as Twitter have provided a great opportunity for\norganizations such as public libraries to disseminate information for public\nrelations purposes. However, there is a need to analyze vast amounts of social\nmedia data. This study presents a computational approach to explore the content\nof tweets posted by nine public libraries in the northeastern United States of\nAmerica. In December 2017, this study extracted more than 19,000 tweets from\nthe Twitter accounts of seven state libraries and two urban public libraries.\nComputational methods were applied to collect the tweets and discover\nmeaningful themes. This paper shows how the libraries have used Twitter to\nrepresent their services and provides a starting point for different\norganizations to evaluate the themes of their public tweets.\n"]},
{"authors": ["Kriste Krstovski", "David M. Blei"], "title": ["Equation Embeddings"], "date": ["2018-03-24T15:04:17Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09123v1"], "summary": ["  We present an unsupervised approach for discovering semantic representations\nof mathematical equations. Equations are challenging to analyze because each is\nunique, or nearly unique. Our method, which we call equation embeddings, finds\ngood representations of equations by using the representations of their\nsurrounding words. We used equation embeddings to analyze four collections of\nscientific articles from the arXiv, covering four computer science domains\n(NLP, IR, AI, and ML) and $\\sim$98.5k equations. Quantitatively, we found that\nequation embeddings provide better models when compared to existing word\nembedding approaches. Qualitatively, we found that equation embeddings provide\ncoherent semantic representations of equations and can capture semantic\nsimilarity to other equations and to words.\n"]},
{"authors": ["Chris Larson", "Josef Spjut", "Ross Knepper", "Robert Shepherd"], "title": ["A Deformable Interface for Human Touch Recognition using Stretchable\n  Carbon Nanotube Dielectric Elastomer Sensors and Deep Neural Networks"], "date": ["2017-06-08T12:20:44Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1706.02542v3"], "summary": ["  User interfaces provide an interactive window between physical and virtual\nenvironments. A new concept in the field of human-computer interaction is a\nsoft user interface; a compliant surface that facilitates touch interaction\nthrough deformation. Despite the potential of these interfaces, they currently\nlack a signal processing framework that can efficiently extract information\nfrom their deformation. Here we present OrbTouch, a device that uses\nstatistical learning algorithms, based on convolutional neural networks, to map\ndeformations from human touch to categorical labels (i.e., gestures) and touch\nlocation using stretchable capacitor signals as inputs. We demonstrate this\napproach by using the device to control the popular game Tetris. OrbTouch\nprovides a modular, robust framework to interpret deformation in soft media,\nlaying a foundation for new modes of human computer interaction through shape\nchanging solids.\n"]},
{"authors": ["Mariano Chouza", "Stephen Roberts", "Stefan Zohren"], "title": ["Gradient descent in Gaussian random fields as a toy model for\n  high-dimensional optimisation in deep learning"], "date": ["2018-03-24T14:22:36Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09119v1"], "summary": ["  In this paper we model the loss function of high-dimensional optimization\nproblems by a Gaussian random field, or equivalently a Gaussian process. Our\naim is to study gradient descent in such loss functions or energy landscapes\nand compare it to results obtained from real high-dimensional optimization\nproblems such as encountered in deep learning. In particular, we analyze the\ndistribution of the improved loss function after a step of gradient descent,\nprovide analytic expressions for the moments as well as prove asymptotic\nnormality as the dimension of the parameter space becomes large. Moreover, we\ncompare this with the expectation of the global minimum of the landscape\nobtained by means of the Euler characteristic of excursion sets. Besides\ncomplementing our analytical findings with numerical results from simulated\nGaussian random fields, we also compare it to loss functions obtained from\noptimisation problems on synthetic and real data sets by proposing a \"black\nbox\" random field toy-model for a deep neural network loss function.\n"]},
{"authors": ["Yuhan Liu", "Xiao Zhang", "Maciej Lewenstein", "Shi-Ju Ran"], "title": ["Learning architectures based on quantum entanglement: a simple matrix\n  product state algorithm for image recognition"], "date": ["2018-03-24T13:48:33Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09111v1"], "summary": ["  It is a fundamental, but still elusive question whether methods based on\nquantum mechanics, in particular on quantum entanglement, can be used for\nclassical information processing and machine learning. Even partial answer to\nthis question would bring important insights to both fields of both machine\nlearning and quantum mechanics. In this work, we implement simple numerical\nexperiments, related to pattern/images classification, in which we represent\nthe classifiers by quantum matrix product states (MPS). Classical machine\nlearning algorithm is then applied to these quantum states. We explicitly show\nhow quantum features (i.e., single-site and bipartite entanglement) can emerge\nin such represented images; entanglement characterizes here the importance of\ndata, and this information can be practically used to improve the learning\nprocedures. Thanks to the low demands on the dimensions and number of the\nunitary matrices, necessary to construct the MPS, we expect such numerical\nexperiments could open new paths in classical machine learning, and shed at\nsame time lights on generic quantum simulations/computations.\n"]},
{"authors": ["Mathijs Pieters", "Marco Wiering"], "title": ["Comparing Generative Adversarial Network Techniques for Image Creation\n  and Modification"], "date": ["2018-03-24T11:19:07Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09093v1"], "summary": ["  Generative adversarial networks (GANs) have demonstrated to be successful at\ngenerating realistic real-world images. In this paper we compare various GAN\ntechniques, both supervised and unsupervised. The effects on training stability\nof different objective functions are compared. We add an encoder to the\nnetwork, making it possible to encode images to the latent space of the GAN.\nThe generator, discriminator and encoder are parameterized by deep\nconvolutional neural networks. For the discriminator network we experimented\nwith using the novel Capsule Network, a state-of-the-art technique for\ndetecting global features in images. Experiments are performed using a digit\nand face dataset, with various visualizations illustrating the results. The\nresults show that using the encoder network it is possible to reconstruct\nimages. With the conditional GAN we can alter visual attributes of generated or\nencoded images. The experiments with the Capsule Network as discriminator\nresult in generated images of a lower quality, compared to a standard\nconvolutional neural network.\n"]},
{"authors": ["Tim Tsz-Kit Lau", "Jinshan Zeng", "Baoyuan Wu", "Yuan Yao"], "title": ["A Proximal Block Coordinate Descent Algorithm for Deep Neural Network\n  Training"], "date": ["2018-03-24T09:17:27Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09082v1"], "summary": ["  Training deep neural networks (DNNs) efficiently is a challenge due to the\nassociated highly nonconvex optimization. The backpropagation (backprop)\nalgorithm has long been the most widely used algorithm for gradient computation\nof parameters of DNNs and is used along with gradient descent-type algorithms\nfor this optimization task. Recent work have shown the efficiency of block\ncoordinate descent (BCD) type methods empirically for training DNNs. In view of\nthis, we propose a novel algorithm based on the BCD method for training DNNs\nand provide its global convergence results built upon the powerful framework of\nthe Kurdyka-Lojasiewicz (KL) property. Numerical experiments on standard\ndatasets demonstrate its competitive efficiency against standard optimizers\nwith backprop.\n"]},
{"authors": ["Lei Sang", "Min Xu", "Shengsheng Qian", "Xindong Wu"], "title": ["AAANE: Attention-based Adversarial Autoencoder for Multi-scale Network\n  Embedding"], "date": ["2018-03-24T09:15:05Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09080v1"], "summary": ["  Network embedding represents nodes in a continuous vector space and preserves\nstructure information from the Network. Existing methods usually adopt a\n\"one-size-fits-all\" approach when concerning multi-scale structure information,\nsuch as first- and second-order proximity of nodes, ignoring the fact that\ndifferent scales play different roles in the embedding learning. In this paper,\nwe propose an Attention-based Adversarial Autoencoder Network Embedding(AAANE)\nframework, which promotes the collaboration of different scales and lets them\nvote for robust representations. The proposed AAANE consists of two components:\n1) Attention-based autoencoder effectively capture the highly non-linear\nnetwork structure, which can de-emphasize irrelevant scales during training. 2)\nAn adversarial regularization guides the autoencoder learn robust\nrepresentations by matching the posterior distribution of the latent embeddings\nto given prior distribution. This is the first attempt to introduce attention\nmechanisms to multi-scale network embedding. Experimental results on real-world\nnetworks show that our learned attention parameters are different for every\nnetwork and the proposed approach outperforms existing state-of-the-art\napproaches for network embedding.\n"]},
{"authors": ["Sheila Alemany", "Jonathan Beltran", "Adrian Perez", "Sam Ganzfried"], "title": ["Predicting Hurricane Trajectories using a Recurrent Neural Network"], "date": ["2018-02-01T08:17:58Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.02548v2"], "summary": ["  Hurricanes are cyclones circulating about a defined center whose closed wind\nspeeds exceed 75 mph originating over tropical and subtropical waters. At\nlandfall, hurricanes can result in severe disasters. The accuracy of predicting\ntheir trajectory paths is critical to reduce economic loss and save human\nlives. Given the complexity and nonlinearity of weather data, a recurrent\nneural network (RNN) could be beneficial in modeling hurricane behavior. We\npropose the application of a fully connected RNN to predict the trajectory of\nhurricanes. We employed the RNN over a fine grid to reduce typical truncation\nerrors. We utilized their latitude, longitude, wind speed, and pressure\npublicly provided by the National Hurricane Center (NOAA) to predict the\ntrajectory of a hurricane at 6-hour intervals.\n"]},
{"authors": ["Chulhee Yun", "Suvrit Sra", "Ali Jadbabaie"], "title": ["Global optimality conditions for deep neural networks"], "date": ["2017-07-08T14:04:37Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1707.02444v3"], "summary": ["  We study the error landscape of deep linear and nonlinear neural networks\nwith the squared error loss. Minimizing the loss of a deep linear neural\nnetwork is a nonconvex problem, and despite recent progress, our understanding\nof this loss surface is still incomplete. For deep linear networks, we present\nnecessary and sufficient conditions for a critical point of the risk function\nto be a global minimum. Surprisingly, our conditions provide an efficiently\ncheckable test for global optimality, while such tests are typically\nintractable in nonconvex optimization. We further extend these results to deep\nnonlinear neural networks and prove similar sufficient conditions for global\noptimality, albeit in a more limited function space setting.\n"]},
{"authors": ["Mengye Ren", "Wenyuan Zeng", "Bin Yang", "Raquel Urtasun"], "title": ["Learning to Reweight Examples for Robust Deep Learning"], "date": ["2018-03-24T03:41:59Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09050v1"], "summary": ["  Deep neural networks have been shown to be very powerful modeling tools for\nmany supervised learning tasks involving complex input patterns. However, they\ncan also easily overfit to training set biases and label noises. In addition to\nvarious regularizers, example reweighting algorithms are popular solutions to\nthese problems, but they require careful tuning of additional hyperparameters,\nsuch as example mining schedules and regularization hyperparameters. In\ncontrast to past reweighting methods, which typically consist of functions of\nthe cost value of each example, in this work we propose a novel meta-learning\nalgorithm that learns to assign weights to training examples based on their\ngradient directions. To determine the example weights, our method performs a\nmeta gradient descent step on the current mini-batch example weights (which are\ninitialized from zero) to minimize the loss on a clean unbiased validation set.\nOur proposed method can be easily implemented on any type of deep network, does\nnot require any additional hyperparameter tuning, and achieves impressive\nperformance on class imbalance and corrupted label problems where only a small\namount of clean validation data is available.\n"]},
{"authors": ["Jonathan Mei", "Jose' M. F. Moura"], "title": ["SILVar: Single Index Latent Variable Models"], "date": ["2017-05-09T20:46:19Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1705.03536v3"], "summary": ["  A semi-parametric, non-linear regression model in the presence of latent\nvariables is introduced. These latent variables can correspond to unmodeled\nphenomena or unmeasured agents in a complex networked system. This new\nformulation allows joint estimation of certain non-linearities in the system,\nthe direct interactions between measured variables, and the effects of\nunmodeled elements on the observed system. The particular form of the model\nadopted is justified, and learning is posed as a regularized empirical risk\nminimization. This leads to classes of structured convex optimization problems\nwith a \"sparse plus low-rank\" flavor. Relations between the proposed model and\nseveral common model paradigms, such as those of Robust Principal Component\nAnalysis (PCA) and Vector Autoregression (VAR), are established. Particularly\nin the VAR setting, the low-rank contributions can come from broad trends\nexhibited in the time series. Details of the algorithm for learning the model\nare presented. Experiments demonstrate the performance of the model and the\nestimation algorithm on simulated and real data.\n"]},
{"authors": ["Chenxi Liu", "Barret Zoph", "Maxim Neumann", "Jonathon Shlens", "Wei Hua", "Li-Jia Li", "Li Fei-Fei", "Alan Yuille", "Jonathan Huang", "Kevin Murphy"], "title": ["Progressive Neural Architecture Search"], "date": ["2017-12-02T06:23:16Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1712.00559v2"], "summary": ["  We propose a new method for learning the structure of convolutional neural\nnetworks (CNNs) that is more efficient than recent state-of-the-art methods\nbased on reinforcement learning and evolutionary algorithms. Our approach uses\na sequential model-based optimization (SMBO) strategy, in which we search for\nstructures in order of increasing complexity, while simultaneously learning a\nsurrogate model to guide the search through structure space. Direct comparison\nunder the same search space shows that our method is up to 5 times more\nefficient than the RL method of Zoph et al. (2018) in terms of number of models\nevaluated, and 8 times faster in terms of total compute. The structures we\ndiscover in this way achieve state of the art classification accuracies on\nCIFAR-10 and ImageNet.\n"]},
{"authors": ["Abraham Nunes", "Alexander Rudiuk"], "title": ["The Importance of Constraint Smoothness for Parameter Estimation in\n  Computational Cognitive Modeling"], "date": ["2018-03-24T00:25:20Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09018v1"], "summary": ["  Psychiatric neuroscience is increasingly aware of the need to define\npsychopathology in terms of abnormal neural computation. The central tool in\nthis endeavour is the fitting of computational models to behavioural data. The\nmost prominent example of this procedure is fitting reinforcement learning (RL)\nmodels to decision-making data collected from mentally ill and healthy subject\npopulations. These models are generative models of the decision-making data\nthemselves, and the parameters we seek to infer can be psychologically and\nneurobiologically meaningful. Currently, the gold standard approach to this\ninference procedure involves Monte-Carlo sampling, which is robust but\ncomputationally intensive---rendering additional procedures, such as\ncross-validation, impractical. Searching for point estimates of model\nparameters using optimization procedures remains a popular and interesting\noption. On a novel testbed simulating parameter estimation from a common RL\ntask, we investigated the effects of smooth vs. boundary constraints on\nparameter estimation using interior point and deterministic direct search\nalgorithms for optimization. Ultimately, we show that the use of boundary\nconstraints can lead to substantial truncation effects. Our results discourage\nthe use of boundary constraints for these applications.\n"]},
{"authors": ["Craig Sherstan", "Marlos C. Machado", "Patrick M. Pilarski"], "title": ["Accelerating Learning in Constructive Predictive Frameworks with the\n  Successor Representation"], "date": ["2018-03-23T22:40:22Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.09001v1"], "summary": ["  Here we propose using the successor representation (SR) to accelerate\nlearning in a constructive knowledge system based on general value functions\n(GVFs). In real-world settings like robotics for unstructured and dynamic\nenvironments, it is infeasible to model all meaningful aspects of a system and\nits environment by hand due to both complexity and size. Instead, robots must\nbe capable of learning and adapting to changes in their environment and task,\nincrementally constructing models from their own experience. GVFs, taken from\nthe field of reinforcement learning (RL), are a way of modeling the world as\npredictive questions. One approach to such models proposes a massive network of\ninterconnected and interdependent GVFs, which are incrementally added over\ntime. It is reasonable to expect that new, incrementally added predictions can\nbe learned more swiftly if the learning process leverages knowledge gained from\npast experience. The SR provides such a means of separating the dynamics of the\nworld from the prediction targets and thus capturing regularities that can be\nreused across multiple GVFs. As a primary contribution of this work, we show\nthat using SR-based predictions can improve sample efficiency and learning\nspeed in a continual learning setting where new predictions are incrementally\nadded and learned over time. We analyze our approach in a grid-world and then\ndemonstrate its potential on data from a physical robot arm.\n"]},
{"authors": ["Valentin G. Stanev", "Filip L. Iliev", "Scott Hansen", "Velimir V. Vesselinov", "Boian S. Alexandrov"], "title": ["Identification of release sources in advection-diffusion system by\n  machine learning combined with Green function inverse method"], "date": ["2016-12-12T22:05:10Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1612.03948v3"], "summary": ["  The identification of sources of advection-diffusion transport is based\nusually on solving complex ill-posed inverse models against the available\nstate- variable data records. However, if there are several sources with\ndifferent locations and strengths, the data records represent mixtures rather\nthan the separate influences of the original sources. Importantly, the number\nof these original release sources is typically unknown, which hinders\nreliability of the classical inverse-model analyses. To address this challenge,\nwe present here a novel hybrid method for identification of the unknown number\nof release sources. Our hybrid method, called HNMF, couples unsupervised\nlearning based on Nonnegative Matrix Factorization (NMF) and inverse-analysis\nGreen functions method. HNMF synergistically performs decomposition of the\nrecorded mixtures, finds the number of the unknown sources and uses the Green\nfunction of advection-diffusion equation to identify their characteristics. In\nthe paper, we introduce the method and demonstrate that it is capable of\nidentifying the advection velocity and dispersivity of the medium as well as\nthe unknown number, locations, and properties of various sets of synthetic\nrelease sources with different space and time dependencies, based only on the\nrecorded data. HNMF can be applied directly to any problem controlled by a\npartial-differential parabolic equation where mixtures of an unknown number of\nsources are measured at multiple locations.\n"]},
{"authors": ["Amir Barati Farimani", "Joseph Gomes", "Rishi Sharma", "Franklin L. Lee", "Vijay S. Pande"], "title": ["Deep Learning Phase Segregation"], "date": ["2018-03-23T21:59:01Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08993v1"], "summary": ["  Phase segregation, the process by which the components of a binary mixture\nspontaneously separate, is a key process in the evolution and design of many\nchemical, mechanical, and biological systems. In this work, we present a\ndata-driven approach for the learning, modeling, and prediction of phase\nsegregation. A direct mapping between an initially dispersed, immiscible binary\nfluid and the equilibrium concentration field is learned by conditional\ngenerative convolutional neural networks. Concentration field predictions by\nthe deep learning model conserve phase fraction, correctly predict phase\ntransition, and reproduce area, perimeter, and total free energy distributions\nup to 98% accuracy.\n"]},
{"authors": ["Filip L. Iliev", "Valentin G. Stanev", "Velimir V. Vesselinov", "Boian S. Alexandrov"], "title": ["Nonnegative Matrix Factorization for identification of unknown number of\n  sources emitting delayed signals"], "date": ["2016-12-12T22:21:41Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1612.03950v2"], "summary": ["  Factor analysis is broadly used as a powerful unsupervised machine learning\ntool for reconstruction of hidden features in recorded mixtures of signals. In\nthe case of a linear approximation, the mixtures can be decomposed by a variety\nof model-free Blind Source Separation (BSS) algorithms. Most of the available\nBSS algorithms consider an instantaneous mixing of signals, while the case when\nthe mixtures are linear combinations of signals with delays is less explored.\nEspecially difficult is the case when the number of sources of the signals with\ndelays is unknown and has to be determined from the data as well. To address\nthis problem, in this paper, we present a new method based on Nonnegative\nMatrix Factorization (NMF) that is capable of identifying: (a) the unknown\nnumber of the sources, (b) the delays and speed of propagation of the signals,\nand (c) the locations of the sources. Our method can be used to decompose\nrecords of mixtures of signals with delays emitted by an unknown number of\nsources in a nondispersive medium, based only on recorded data. This is the\ncase, for example, when electromagnetic signals from multiple antennas are\nreceived asynchronously; or mixtures of acoustic or seismic signals recorded by\nsensors located at different positions; or when a shift in frequency is induced\nby the Doppler effect. By applying our method to synthetic datasets, we\ndemonstrate its ability to identify the unknown number of sources as well as\nthe waveforms, the delays, and the strengths of the signals. Using Bayesian\nanalysis, we also evaluate estimation uncertainties and identify the region of\nlikelihood where the positions of the sources can be found.\n"]},
{"authors": ["Bokai Cao", "Hucheng Zhou", "Guoqiang Li", "Philip S. Yu"], "title": ["Multi-View Factorization Machines"], "date": ["2015-06-03T03:06:42Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1506.01110v2"], "summary": ["  For a learning task, data can usually be collected from different sources or\nbe represented from multiple views. For example, laboratory results from\ndifferent medical examinations are available for disease diagnosis, and each of\nthem can only reflect the health state of a person from a particular\naspect/view. Therefore, different views provide complementary information for\nlearning tasks. An effective integration of the multi-view information is\nexpected to facilitate the learning performance. In this paper, we propose a\ngeneral predictor, named multi-view machines (MVMs), that can effectively\ninclude all the possible interactions between features from multiple views. A\njoint factorization is embedded for the full-order interaction parameters which\nallows parameter estimation under sparsity. Moreover, MVMs can work in\nconjunction with different loss functions for a variety of machine learning\ntasks. A stochastic gradient descent method is presented to learn the MVM\nmodel. We further illustrate the advantages of MVMs through comparison with\nother methods for multi-view classification, including support vector machines\n(SVMs), support tensor machines (STMs) and factorization machines (FMs).\n"]},
{"authors": ["Bokai Cao"], "title": ["Broad Learning for Healthcare"], "date": ["2018-03-23T21:01:20Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08978v1"], "summary": ["  A broad spectrum of data from different modalities are generated in the\nhealthcare domain every day, including scalar data (e.g., clinical measures\ncollected at hospitals), tensor data (e.g., neuroimages analyzed by research\ninstitutes), graph data (e.g., brain connectivity networks), and sequence data\n(e.g., digital footprints recorded on smart sensors). Capability for modeling\ninformation from these heterogeneous data sources is potentially transformative\nfor investigating disease mechanisms and for informing therapeutic\ninterventions.\n  Our works in this thesis attempt to facilitate healthcare applications in the\nsetting of broad learning which focuses on fusing heterogeneous data sources\nfor a variety of synergistic knowledge discovery and machine learning tasks. We\nare generally interested in computer-aided diagnosis, precision medicine, and\nmobile health by creating accurate user profiles which include important\nbiomarkers, brain connectivity patterns, and latent representations. In\nparticular, our works involve four different data mining problems with\napplication to the healthcare domain: multi-view feature selection, subgraph\npattern mining, brain network embedding, and multi-view sequence prediction.\n"]},
{"authors": ["Cong Xie", "Oluwasanmi Koyejo", "Indranil Gupta"], "title": ["Generalized Byzantine-tolerant SGD"], "date": ["2018-02-27T19:06:15Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.10116v3"], "summary": ["  We propose three new robust aggregation rules for distributed synchronous\nStochastic Gradient Descent~(SGD) under a general Byzantine failure model. The\nattackers can arbitrarily manipulate the data transferred between the servers\nand the workers in the parameter server~(PS) architecture. We prove the\nByzantine resilience properties of these aggregation rules. Empirical analysis\nshows that the proposed techniques outperform current approaches for realistic\nuse cases and Byzantine attack scenarios.\n"]},
{"authors": ["Firas A. Khasawneh", "Elizabeth Munch", "Jose A. Perea"], "title": ["Chatter Classification in Turning Using Machine Learning and Topological\n  Data Analysis"], "date": ["2018-03-23T18:13:07Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.02261v1"], "summary": ["  Chatter identification and detection in machining processes has been an\nactive area of research in the past two decades. Part of the challenge in\nstudying chatter is that machining equations that describe its occurrence are\noften nonlinear delay differential equations. The majority of the available\ntools for chatter identification rely on defining a metric that captures the\ncharacteristics of chatter, and a threshold that signals its occurrence. The\ndifficulty in choosing these parameters can be somewhat alleviated by utilizing\nmachine learning techniques. However, even with a successful classification\nalgorithm, the transferability of typical machine learning methods from one\ndata set to another remains very limited. In this paper we combine supervised\nmachine learning with Topological Data Analysis (TDA) to obtain a descriptor of\nthe process which can detect chatter. The features we use are derived from the\npersistence diagram of an attractor reconstructed from the time series via\nTakens embedding. We test the approach using deterministic and stochastic\nturning models, where the stochasticity is introduced via the cutting\ncoefficient term. Our results show a 97% successful classification rate on the\ndeterministic model labeled by the stability diagram obtained using the\nspectral element method. The features gleaned from the deterministic model are\nthen utilized for characterization of chatter in a stochastic turning model\nwhere there are very limited analysis methods.\n"]},
{"authors": ["Dan Alistarh", "Zeyuan Allen-Zhu", "Jerry Li"], "title": ["Byzantine Stochastic Gradient Descent"], "date": ["2018-03-23T17:58:54Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08917v1"], "summary": ["  This paper studies the problem of distributed stochastic optimization in an\nadversarial setting where, out of the $m$ machines which allegedly compute\nstochastic gradients every iteration, an $\\alpha$-fraction are Byzantine, and\ncan behave arbitrarily and adversarially. Our main result is a variant of\nstochastic gradient descent (SGD) which finds $\\varepsilon$-approximate\nminimizers of convex functions in $T = \\tilde{O}\\big( \\frac{1}{\\varepsilon^2 m}\n+ \\frac{\\alpha^2}{\\varepsilon^2} \\big)$ iterations. In contrast, traditional\nmini-batch SGD needs $T = O\\big( \\frac{1}{\\varepsilon^2 m} \\big)$ iterations,\nbut cannot tolerate Byzantine failures. Further, we provide a lower bound\nshowing that, up to logarithmic factors, our algorithm is\ninformation-theoretically optimal both in terms of sampling complexity and time\ncomplexity.\n"]},
{"authors": ["Garoe Dorta", "Sara Vicente", "Lourdes Agapito", "Neill D. F. Campbell", "Ivor Simpson"], "title": ["Structured Uncertainty Prediction Networks"], "date": ["2018-02-20T12:19:59Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.07079v2"], "summary": ["  This paper is the first work to propose a network to predict a structured\nuncertainty distribution for a synthesized image. Previous approaches have been\nmostly limited to predicting diagonal covariance matrices. Our novel model\nlearns to predict a full Gaussian covariance matrix for each reconstruction,\nwhich permits efficient sampling and likelihood evaluation.\n  We demonstrate that our model can accurately reconstruct ground truth\ncorrelated residual distributions for synthetic datasets and generate plausible\nhigh frequency samples for real face images. We also illustrate the use of\nthese predicted covariances for structure preserving image denoising.\n"]},
{"authors": ["Renjie Liao", "Yuwen Xiong", "Ethan Fetaya", "Lisa Zhang", "KiJung Yoon", "Xaq Pitkow", "Raquel Urtasun", "Richard Zemel"], "title": ["Reviving and Improving Recurrent Back-Propagation"], "date": ["2018-03-16T20:57:36Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06396v2"], "summary": ["  In this paper, we revisit the recurrent back-propagation (RBP) algorithm,\ndiscuss the conditions under which it applies as well as how to satisfy them in\ndeep neural networks. We show that RBP can be unstable and propose two variants\nbased on conjugate gradient on the normal equations (CG-RBP) and Neumann series\n(Neumann-RBP). We further investigate the relationship between Neumann-RBP and\nback propagation through time (BPTT) and its truncated version (TBPTT). Our\nNeumann-RBP has the same time complexity as TBPTT but only requires constant\nmemory, whereas TBPTT's memory cost scales linearly with the number of\ntruncation steps. We examine all RBP variants along with BPTT and TBPTT in\nthree different application domains: associative memory with continuous\nHopfield networks, document classification in citation networks using graph\nneural networks and hyperparameter optimization for fully connected networks.\nAll experiments demonstrate that RBPs, especially the Neumann-RBP variant, are\nefficient and effective for optimizing convergent recurrent neural networks.\n"]},
{"authors": ["Alexander B\u00f6ttcher", "Wieland Brendel", "Bernhard Englitz", "Matthias Bethge"], "title": ["Trace your sources in large-scale data: one ring to find them all"], "date": ["2018-03-23T16:56:13Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08882v1"], "summary": ["  An important preprocessing step in most data analysis pipelines aims to\nextract a small set of sources that explain most of the data. Currently used\nalgorithms for blind source separation (BSS), however, often fail to extract\nthe desired sources and need extensive cross-validation. In contrast, their\nrarely used probabilistic counterparts can get away with little\ncross-validation and are more accurate and reliable but no simple and scalable\nimplementations are available. Here we present a novel probabilistic BSS\nframework (DECOMPOSE) that can be flexibly adjusted to the data, is extensible\nand easy to use, adapts to individual sources and handles large-scale data\nthrough algorithmic efficiency. DECOMPOSE encompasses and generalises many\ntraditional BSS algorithms such as PCA, ICA and NMF and we demonstrate\nsubstantial improvements in accuracy and robustness on artificial and real\ndata.\n"]},
{"authors": ["Dan Alistarh", "Christopher De Sa", "Nikola Konstantinov"], "title": ["The Convergence of Stochastic Gradient Descent in Asynchronous Shared\n  Memory"], "date": ["2018-03-23T15:32:42Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08841v1"], "summary": ["  Stochastic Gradient Descent (SGD) is a fundamental algorithm in machine\nlearning, representing the optimization backbone for training several classic\nmodels, from regression to neural networks. Given the recent practical focus on\ndistributed machine learning, significant work has been dedicated to the\nconvergence properties of this algorithm under the inconsistent and noisy\nupdates arising from execution in a distributed environment. However,\nsurprisingly, the convergence properties of this classic algorithm in the\nstandard shared-memory model are still not well-understood.\n  In this work, we address this gap, and provide new convergence bounds for\nlock-free concurrent stochastic gradient descent, executing in the classic\nasynchronous shared memory model, against a strong adaptive adversary. Our\nresults give improved upper and lower bounds on the \"price of asynchrony\" when\nexecuting the fundamental SGD algorithm in a concurrent setting. They show that\nthis classic optimization tool can converge faster and with a wider range of\nparameters than previously known under asynchronous iterations. At the same\ntime, we exhibit a fundamental trade-off between the maximum delay in the\nsystem and the rate at which SGD can converge, which governs the set of\nparameters under which this algorithm can still work efficiently.\n"]},
{"authors": ["Pankaj Mehta", "Marin Bukov", "Ching-Hao Wang", "Alexandre G. R. Day", "Clint Richardson", "Charles K. Fisher", "David J. Schwab"], "title": ["A high-bias, low-variance introduction to Machine Learning for\n  physicists"], "date": ["2018-03-23T14:53:05Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08823v1"], "summary": ["  Machine Learning (ML) is one of the most exciting and dynamic areas of modern\nresearch and application. The purpose of this review is to provide an\nintroduction to the core concepts and tools of machine learning in a manner\neasily understood and intuitive to physicists. The review begins by covering\nfundamental concepts in ML and modern statistics such as the bias-variance\ntradeoff, overfitting, regularization, and generalization before moving on to\nmore advanced topics in both supervised and unsupervised learning. Topics\ncovered in the review include ensemble models, deep learning and neural\nnetworks, clustering and data visualization, energy-based models (including\nMaxEnt models and Restricted Boltzmann Machines), and variational methods.\nThroughout, we emphasize the many natural connections between ML and\nstatistical physics. A notable aspect of the review is the use of Python\nnotebooks to introduce modern ML/statistical packages to readers using\nphysics-inspired datasets (the Ising Model and Monte-Carlo simulations of\nsupersymmetric decays of proton-proton collisions). We conclude with an\nextended outlook discussing possible uses of machine learning for furthering\nour understanding of the physical world as well as open problems in ML where\nphysicists maybe able to contribute. (Notebooks are available at\nhttps://physics.bu.edu/~pankajm/MLnotebooks.html )\n"]},
{"authors": ["Aurelia Bustos", "Antonio Pertusa"], "title": ["Learning Eligibility in Cancer Clinical Trials using Deep Neural\n  Networks"], "date": ["2018-03-22T11:38:53Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08312v2"], "summary": ["  Interventional cancer clinical trials are generally too restrictive and\npatients are often excluded from them on the basis of comorbidity, past or\nconcomitant treatments and the fact that they are over a certain age. The\nefficacy and safety of new treatments for patients with these characteristics\nare not, therefore, defined. In this work, we build a model with which to\nautomatically predict whether short clinical statements were considered\ninclusion or exclusion criteria. We used clinical trials protocols on cancer\nthat have been available in public registries for the last 18 years to train\nword embeddings, and constructed a dataset of 6M short free-texts labeled as\neligible or not eligible. We then trained and validated a text classifier,\nusing deep neural networks with pre-trained word-embedding as its inputs, to\npredict whether or not short free-text statements describing clinical\ninformation were considered eligible. The best model achieved an F-measure of\n0.91 and an almost perfect agreement when employing a validation set of 800K\nlabeled statements. The trained model was also tested on an independent set of\nclinical statements mimicking those used in routine clinical practice, yielding\na consistent performance. We additionally analyzed the semantic reasoning of\nthe word embedding representations obtained, and were able to identify\nequivalent treatments for a type of tumor in an analogy with the drugs used to\ntreat other tumors. The present work shows that representation learning using\nneural networks can be successfully leveraged to extract the medical knowledge\navailable on clinical trial protocols and potentially assist practitioners when\nprescribing treatments.\n"]},
{"authors": ["Chiliang Zhang", "Zhimou Yang", "Zuochang Ye"], "title": ["Detecting Adversarial Perturbations with Saliency"], "date": ["2018-03-23T12:52:28Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08773v1"], "summary": ["  In this paper we propose a novel method for detecting adversarial examples by\ntraining a binary classifier with both origin data and saliency data. In the\ncase of image classification model, saliency simply explain how the model make\ndecisions by identifying significant pixels for prediction. A model shows wrong\nclassification output always learns wrong features and shows wrong saliency as\nwell. Our approach shows good performance on detecting adversarial\nperturbations. We quantitatively evaluate generalization ability of the\ndetector, showing that detectors trained with strong adversaries perform well\non weak adversaries.\n"]},
{"authors": ["Rahaf Aljundi", "Francesca Babiloni", "Mohamed Elhoseiny", "Marcus Rohrbach", "Tinne Tuytelaars"], "title": ["Memory Aware Synapses: Learning what (not) to forget"], "date": ["2017-11-27T09:48:44Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.09601v2"], "summary": ["  Humans can learn in a continuous manner. Old rarely utilized knowledge can be\noverwritten by new incoming information while important, frequently used\nknowledge is prevented from being erased. In artificial learning systems,\nlifelong learning so far has focused mainly on accumulating knowledge over\ntasks and overcoming catastrophic forgetting. In this paper, we argue that,\ngiven the limited model capacity and the unlimited new information to be\nlearned, knowledge has to be preserved or erased selectively. Inspired by\nneuroplasticity, we propose a novel approach for lifelong learning, coined\nMemory Aware Synapses (MAS). It computes the importance of the parameters of a\nneural network in an unsupervised and online manner. Given a new sample which\nis fed to the network, MAS accumulates an importance measure for each parameter\nof the network, based on how sensitive the predicted output function is to a\nchange in this parameter. When learning a new task, changes to important\nparameters can then be penalized, effectively preventing important knowledge\nrelated to previous tasks from being overwritten. Further, we show an\ninteresting connection between a local version of our method and Hebb's\nrule,which is a model for the learning process in the brain. We test our method\non a sequence of object recognition tasks and on the challenging problem of\nlearning an embedding for predicting $<$subject, predicate, object$>$ triplets.\nWe show state-of-the-art performance and, for the first time, the ability to\nadapt the importance of the parameters based on unlabeled data towards what the\nnetwork needs (not) to forget, which may vary depending on test conditions.\n"]},
{"authors": ["Nicolas Tremblay", "Simon Barthelm\u00e9", "Pierre-Olivier Amblard"], "title": ["Determinantal Point Processes for Coresets"], "date": ["2018-03-23T09:17:48Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08700v1"], "summary": ["  When one is faced with a dataset too large to be used all at once, an obvious\nsolution is to retain only part of it. In practice this takes a wide variety of\ndifferent forms, but among them \"coresets\" are especially appealing. A coreset\nis a (small) weighted sample of the original data that comes with a guarantee:\nthat a cost function can be evaluated on the smaller set instead of the larger\none, with low relative error. For some classes of problems, and via a careful\nchoice of sampling distribution, iid random sampling has turned to be one of\nthe most successful methods to build coresets efficiently. However, independent\nsamples are sometimes overly redundant, and one could hope that enforcing\ndiversity would lead to better performance. The difficulty lies in proving\ncoreset properties in non-iid samples. We show that the coreset property holds\nfor samples formed with determinantal point processes (DPP). DPPs are\ninteresting because they are a rare example of repulsive point processes with\ntractable theoretical properties, enabling us to construct general coreset\ntheorems. We apply our results to the $k$-means problem, and give empirical\nevidence of the superior performance of DPP samples over state of the art\nmethods.\n"]},
{"authors": ["Emmi Jokinen", "Markus Heinonen", "Harri L\u00e4hdesm\u00e4ki"], "title": ["mGPfusion: Predicting protein stability changes with Gaussian process\n  kernel learning and data fusion"], "date": ["2018-02-08T13:41:37Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.02852v2"], "summary": ["  Proteins are commonly used by biochemical industry for numerous processes.\nRefining these proteins' properties via mutations causes stability effects as\nwell. Accurate computational method to predict how mutations affect protein\nstability are necessary to facilitate efficient protein design. However,\naccuracy of predictive models is ultimately constrained by the limited\navailability of experimental data. We have developed mGPfusion, a novel\nGaussian process (GP) method for predicting protein's stability changes upon\nsingle and multiple mutations. This method complements the limited experimental\ndata with large amounts of molecular simulation data. We introduce a Bayesian\ndata fusion model that re-calibrates the experimental and in silico data\nsources and then learns a predictive GP model from the combined data. Our\nprotein-specific model requires experimental data only regarding the protein of\ninterest and performs well even with few experimental measurements. The\nmGPfusion models proteins by contact maps and infers the stability effects\ncaused by mutations with a mixture of graph kernels. Our results show that\nmGPfusion outperforms state-of-the-art methods in predicting protein stability\non a dataset of 15 different proteins and that incorporating molecular\nsimulation data improves the model learning and prediction accuracy.\n"]},
{"authors": ["Daniel Jakubovitz", "Raja Giryes"], "title": ["Improving DNN Robustness to Adversarial Attacks using Jacobian\n  Regularization"], "date": ["2018-03-23T07:57:04Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08680v1"], "summary": ["  Deep neural networks have lately shown tremendous performance in various\napplications including vision and speech processing tasks. However, alongside\ntheir ability to perform these tasks with such high accuracy, it has been shown\nthat they are highly susceptible to adversarial attacks: a small change of the\ninput would cause the network to err with high confidence. This phenomenon\nexposes an inherent fault in these networks and their ability to generalize\nwell. For this reason, providing robustness to adversarial attacks is an\nimportant challenge in networks training, which has led to an extensive\nresearch. In this work, we suggest a theoretically inspired novel approach to\nimprove the networks' robustness. Our method applies regularization using the\nFrobenius norm of the Jacobian of the network, which is applied as\npost-processing, after regular training has finished. We demonstrate\nempirically that it leads to enhanced robustness results with a minimal change\nin the original network's accuracy.\n"]},
{"authors": ["Pramudita Satria Palar", "Koji Shimoyama"], "title": ["On efficient global optimization via universal Kriging surrogate models"], "date": ["2018-03-23T06:25:23Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08667v1"], "summary": ["  In this paper, we investigate the capability of the universal Kriging (UK)\nmodel for single-objective global optimization applied within an efficient\nglobal optimization (EGO) framework. We implemented this combined UK-EGO\nframework and studied four variants of the UK methods, that is, a UK with a\nfirst-order polynomial, a UK with a second-order polynomial, a blind Kriging\n(BK) implementation from the ooDACE toolbox, and a polynomial-chaos Kriging\n(PCK) implementation. The UK-EGO framework with automatic trend function\nselection derived from the BK and PCK models works by building a UK surrogate\nmodel and then performing optimizations via expected improvement criteria on\nthe Kriging model with the lowest leave-one-out cross-validation error. Next,\nwe studied and compared the UK-EGO variants and standard EGO using five\nsynthetic test functions and one aerodynamic problem. Our results show that the\nproper choice for the trend function through automatic feature selection can\nimprove the optimization performance of UK-EGO relative to EGO. From our\nresults, we found that PCK-EGO was the best variant, as it had more robust\nperformance as compared to the rest of the UK-EGO schemes; however, total-order\nexpansion should be used to generate the candidate trend function set for\nhigh-dimensional problems. Note that, for some test functions, the UK with\npredetermined polynomial trend functions performed better than that of BK and\nPCK, indicating that the use of automatic trend function selection does not\nalways lead to the best quality solutions. We also found that although some\nvariants of UK are not as globally accurate as the ordinary Kriging (OK), they\ncan still identify better-optimized solutions due to the addition of the trend\nfunction, which helps the optimizer locate the global optimum.\n"]},
{"authors": ["Saul Toscano-Palmerin", "Peter I. Frazier"], "title": ["Bayesian Optimization with Expensive Integrands"], "date": ["2018-03-23T05:53:26Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08661v1"], "summary": ["  We propose a Bayesian optimization algorithm for objective functions that are\nsums or integrals of expensive-to-evaluate functions, allowing noisy\nevaluations. These objective functions arise in multi-task Bayesian\noptimization for tuning machine learning hyperparameters, optimization via\nsimulation, and sequential design of experiments with random environmental\nconditions. Our method is average-case optimal by construction when a single\nevaluation of the integrand remains within our evaluation budget. Achieving\nthis one-step optimality requires solving a challenging value of information\noptimization problem, for which we provide a novel efficient\ndiscretization-free computational method. We also provide consistency proofs\nfor our method in both continuum and discrete finite domains for objective\nfunctions that are sums. In numerical experiments comparing against previous\nstate-of-the-art methods, including those that also leverage sum or integral\nstructure, our method performs as well or better across a wide range of\nproblems and offers significant improvements when evaluations are noisy or the\nintegrand varies smoothly in the integrated variables.\n"]},
{"authors": ["Rahul Meshram", "D. Manjunath", "Nikhil Karamchandani"], "title": ["Learning Recommendations While Influencing Interests"], "date": ["2018-03-23T04:09:24Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08651v1"], "summary": ["  Personalized recommendation systems (RS) are extensively used in many\nservices. Many of these are based on learning algorithms where the RS uses the\nrecommendation history and the user response to learn an optimal strategy.\nFurther, these algorithms are based on the assumption that the user interests\nare rigid. Specifically, they do not account for the effect of learning\nstrategy on the evolution of the user interests. In this paper we develop\ninfluence models for a learning algorithm that is used to optimally recommend\nwebsites to web users. We adapt the model of \\cite{Ioannidis10} to include an\nitem-dependent reward to the RS from the suggestions that are accepted by the\nuser. For this we first develop a static optimisation scheme when all the\nparameters are known. Next we develop a stochastic approximation based learning\nscheme for the RS to learn the optimal strategy when the user profiles are not\nknown. Finally, we describe several user-influence models for the learning\nalgorithm and analyze their effect on the steady user interests and on the\nsteady state optimal strategy as compared to that when the users are not\ninfluenced.\n"]},
{"authors": ["Hao Ge", "Yin Xia", "Xu Chen", "Randall Berry", "Ying Wu"], "title": ["Fictitious GAN: Training GANs with Historical Models"], "date": ["2018-03-23T03:46:12Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08647v1"], "summary": ["  Generative adversarial networks (GANs) are powerful tools for learning\ngenerative models. In practice, the training may suffer from lack of\nconvergence. GANs are commonly viewed as a two-player zero-sum game between two\nneural networks. Here, we leverage this game theoretic view to study the\nconvergence behavior of the training process. Inspired by the fictitious play\nlearning process, a novel training method, referred to as Fictitious GAN, is\nintroduced. Fictitious GAN trains the deep neural networks using a mixture of\nhistorical models. Specifically, the discriminator (resp. generator) is updated\naccording to the best-response to the mixture outputs from a sequence of\npreviously trained generators (resp. discriminators). It is shown that\nFictitious GAN can effectively resolve some convergence issues that cannot be\nresolved by the standard training approach. It is proved that asymptotically\nthe average of the generator outputs has the same distribution as the data\nsamples.\n"]},
{"authors": ["Tao Sun", "Hao Jiang", "Lizhi Cheng", "Wei Zhu"], "title": ["Iteratively Linearized Reweighted Alternating Direction Method of\n  Multipliers for a Class of Nonconvex Problems"], "date": ["2017-09-01T21:20:30Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1709.00483v5"], "summary": ["  In this paper, we consider solving a class of nonconvex and nonsmooth\nproblems frequently appearing in signal processing and machine learning\nresearch. The traditional alternating direction method of multipliers\nencounters troubles in both mathematics and computations in solving the\nnonconvex and nonsmooth subproblem. In view of this, we propose a reweighted\nalternating direction method of multipliers. In this algorithm, all subproblems\nare convex and easy to solve. We also provide several guarantees for the\nconvergence and prove that the algorithm globally converges to a critical point\nof an auxiliary function with the help of the Kurdyka-{\\L}ojasiewicz property.\nSeveral numerical results are presented to demonstrate the efficiency of the\nproposed algorithm.\n"]},
{"authors": ["Arnulf Jentzen", "Philippe von Wurstemberger"], "title": ["Lower error bounds for the stochastic gradient descent optimization\n  algorithm: Sharp convergence rates for slowly and fast decaying learning\n  rates"], "date": ["2018-03-22T22:31:03Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08600v1"], "summary": ["  The stochastic gradient descent (SGD) optimization algorithm plays a central\nrole in a series of machine learning applications. The scientific literature\nprovides a vast amount of upper error bounds for the SGD method. Much less\nattention as been paid to proving lower error bounds for the SGD method. It is\nthe key contribution of this paper to make a step in this direction. More\nprecisely, in this article we establish for every $\\gamma, \\nu \\in (0,\\infty)$\nessentially matching lower and upper bounds for the mean square error of the\nSGD process with learning rates $(\\frac{\\gamma}{n^\\nu})_{n \\in \\mathbb{N}}$\nassociated to a simple quadratic stochastic optimization problem. This allows\nus to precisely quantify the mean square convergence rate of the SGD method in\ndependence on the asymptotic behavior of the learning rates.\n"]},
{"authors": ["Rajeev Ranjan", "Swami Sankaranarayanan", "Carlos D. Castillo", "Rama Chellappa"], "title": ["Improving Network Robustness against Adversarial Attacks with Compact\n  Convolution"], "date": ["2017-12-03T03:09:31Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1712.00699v2"], "summary": ["  Though Convolutional Neural Networks (CNNs) have surpassed human-level\nperformance on tasks such as object classification and face verification, they\ncan easily be fooled by adversarial attacks. These attacks add a small\nperturbation to the input image that causes the network to misclassify the\nsample. In this paper, we focus on neutralizing adversarial attacks by compact\nfeature learning. In particular, we show that learning features in a closed and\nbounded space improves the robustness of the network. We explore the effect of\nL2-Softmax Loss, that enforces compactness in the learned features, thus\nresulting in enhanced robustness to adversarial perturbations. Additionally, we\npropose compact convolution, a novel method of convolution that when\nincorporated in conventional CNNs improves their robustness. Compact\nconvolution ensures feature compactness at every layer such that they are\nbounded and close to each other. Extensive experiments show that Compact\nConvolutional Networks (CCNs) neutralize multiple types of attacks, and perform\nbetter than existing methods in defending adversarial attacks, without\nincurring any additional training overhead compared to CNNs.\n"]},
{"authors": ["Di Chen", "Yexiang Xue", "Carla P. Gomes"], "title": ["End-to-End Learning for the Deep Multivariate Probit Model"], "date": ["2018-03-22T21:35:39Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08591v1"], "summary": ["  The multivariate probit model (MVP) is a popular classic model for studying\nbinary responses of multiple entities. Nevertheless, the computational\nchallenge of learning the MVP model, given that its likelihood involves\nintegrating over a multidimensional constrained space of latent variables,\nsignificantly limits its application in practice. We propose a flexible deep\ngeneralization of the classic MVP, the Deep Multivariate Probit Model (DMVP),\nwhich is an end-to-end learning scheme that uses an efficient parallel sampling\nprocess of the multivariate probit model to exploit GPU-boosted deep neural\nnetworks. We present both theoretical and empirical analysis of the convergence\nbehavior of DMVP's sampling process with respect to the resolution of the\ncorrelation structure. We provide convergence guarantees for DMVP and our\nempirical analysis demonstrates the advantages of DMVP's sampling compared with\nstandard MCMC-based methods. We also show that when applied to multi-entity\nmodelling problems, which are natural DMVP applications, DMVP trains faster\nthan classical MVP, by at least an order of magnitude, captures rich\ncorrelations among entities, and further improves the joint likelihood of\nentities compared with several competitive models.\n"]},
{"authors": ["Yining Wang", "Sivaraman Balakrishnan", "Aarti Singh"], "title": ["Optimization of Smooth Functions with Noisy Observations: Local Minimax\n  Rates"], "date": ["2018-03-22T21:21:02Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08586v1"], "summary": ["  We consider the problem of global optimization of an unknown non-convex\nsmooth function with zeroth-order feedback. In this setup, an algorithm is\nallowed to adaptively query the underlying function at different locations and\nreceives noisy evaluations of function values at the queried points (i.e. the\nalgorithm has access to zeroth-order information). Optimization performance is\nevaluated by the expected difference of function values at the estimated\noptimum and the true optimum. In contrast to the classical optimization setup,\nfirst-order information like gradients are not directly accessible to the\noptimization algorithm. We show that the classical minimax framework of\nanalysis, which roughly characterizes the worst-case query complexity of an\noptimization algorithm in this setting, leads to excessively pessimistic\nresults. We propose a local minimax framework to study the fundamental\ndifficulty of optimizing smooth functions with adaptive function evaluations,\nwhich provides a refined picture of the intrinsic difficulty of zeroth-order\noptimization. We show that for functions with fast level set growth around the\nglobal minimum, carefully designed optimization algorithms can identify a near\nglobal minimizer with many fewer queries. For the special case of strongly\nconvex and smooth functions, our implied convergence rates match the ones\ndeveloped for zeroth-order convex optimization problems. At the other end of\nthe spectrum, for worst-case smooth functions no algorithm can converge faster\nthan the minimax rate of estimating the entire unknown function in the\n$\\ell_\\infty$-norm. We provide an intuitive and efficient algorithm that\nattains the derived upper error bounds.\n"]},
{"authors": ["Shahab Asoodeh", "Tingran Gao", "James Evans"], "title": ["Curvature of Hypergraphs via Multi-Marginal Optimal Transport"], "date": ["2018-03-22T21:13:35Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08584v1"], "summary": ["  We introduce a novel definition of curvature for hypergraphs, a natural\ngeneralization of graphs, by introducing a multi-marginal optimal transport\nproblem for a naturally defined random walk on the hypergraph. This curvature,\ntermed \\emph{coarse scalar curvature}, generalizes a recent definition of Ricci\ncurvature for Markov chains on metric spaces by Ollivier [Journal of Functional\nAnalysis 256 (2009) 810-864], and is related to the scalar curvature when the\nhypergraph arises naturally from a Riemannian manifold. We investigate basic\nproperties of the coarse scalar curvature and obtain several bounds. Empirical\nexperiments indicate that coarse scalar curvatures are capable of detecting\n\"bridges\" across connected components in hypergraphs, suggesting it is an\nappropriate generalization of curvature on simple graphs.\n"]},
{"authors": ["Francois Fagan", "Garud Iyengar"], "title": ["Unbiased scalable softmax optimization"], "date": ["2018-03-22T20:32:32Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08577v1"], "summary": ["  Recent neural network and language models rely on softmax distributions with\nan extremely large number of categories. Since calculating the softmax\nnormalizing constant in this context is prohibitively expensive, there is a\ngrowing literature of efficiently computable but biased estimates of the\nsoftmax. In this paper we propose the first unbiased algorithms for maximizing\nthe softmax likelihood whose work per iteration is independent of the number of\nclasses and datapoints (and no extra work is required at the end of each\nepoch). We show that our proposed unbiased methods comprehensively outperform\nthe state-of-the-art on seven real world datasets.\n"]},
{"authors": ["Zhewei Yao", "Amir Gholami", "Qi Lei", "Kurt Keutzer", "Michael W. Mahoney"], "title": ["Hessian-based Analysis of Large Batch Training and Robustness to\n  Adversaries"], "date": ["2018-02-22T18:55:00Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.08241v2"], "summary": ["  Large batch size training of Neural Networks has been shown to incur accuracy\nloss when trained with the current methods. The precise underlying reasons for\nthis are still not completely understood. Here, we study large batch size\ntraining through the lens of the Hessian operator and robust optimization. In\nparticular, we perform a Hessian based study to analyze how the landscape of\nthe loss functional is different for large batch size training. We compute the\ntrue Hessian spectrum, without approximation, by back-propagating the second\nderivative. Our results on multiple networks show that, when training at large\nbatch sizes, one tends to stop at points in the parameter space with noticeably\nhigher/larger Hessian spectrum, i.e., where the eigenvalues of the Hessian are\nmuch larger. We then study how batch size affects robustness of the model in\nthe face of adversarial attacks. All the results show that models trained with\nlarge batches are more susceptible to adversarial attacks, as compared to\nmodels trained with small batch sizes. Furthermore, we prove a theoretical\nresult which shows that the problem of finding an adversarial perturbation is a\nsaddle-free optimization problem. Finally, we show empirical results that\ndemonstrate that adversarial training leads to areas with smaller Hessian\nspectrum. We present detailed experiments with five different network\narchitectures tested on MNIST, CIFAR-10, and CIFAR-100 datasets.\n"]},
{"authors": ["Lewis Smith", "Yarin Gal"], "title": ["Understanding Measures of Uncertainty for Adversarial Example Detection"], "date": ["2018-03-22T18:26:22Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08533v1"], "summary": ["  Measuring uncertainty is a promising technique for detecting adversarial\nexamples, crafted inputs on which the model predicts an incorrect class with\nhigh confidence. But many measures of uncertainty exist, including predictive\nen- tropy and mutual information, each capturing different types of\nuncertainty. We study these measures, and shed light on why mutual information\nseems to be effective at the task of adversarial example detection. We\nhighlight failure modes for MC dropout, a widely used approach for estimating\nuncertainty in deep models. This leads to an improved understanding of the\ndrawbacks of current methods, and a proposal to improve the quality of\nuncertainty estimates using probabilistic model ensembles. We give illustrative\nexperiments using MNIST to demonstrate the intuition underlying the different\nmeasures of uncertainty, as well as experiments on a real world Kaggle dogs vs\ncats classification dataset.\n"]},
{"authors": ["Felix Draxler", "Kambis Veschgini", "Manfred Salmhofer", "Fred A. Hamprecht"], "title": ["Essentially No Barriers in Neural Network Energy Landscape"], "date": ["2018-03-02T15:22:10Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.00885v3"], "summary": ["  Training neural networks involves finding minima of a high-dimensional\nnon-convex loss function. Knowledge of the structure of this energy landscape\nis sparse. Relaxing from linear interpolations, we construct continuous paths\nbetween minima of recent neural network architectures on CIFAR10 and CIFAR100.\nSurprisingly, the paths are essentially flat in both the training and test\nlandscapes. This implies that neural networks have enough capacity for\nstructural changes, or that these changes are small between minima. Also, each\nminimum has at least one vanishing Hessian eigenvalue in addition to those\nresulting from trivial invariance.\n"]},
{"authors": ["Zhe Li", "Shuo Wang", "Caiwen Ding", "Qinru Qiu", "Yanzhi Wang", "Yun Liang"], "title": ["Efficient Recurrent Neural Networks using Structured Matrices in FPGAs"], "date": ["2018-03-20T21:21:22Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07661v2"], "summary": ["  Recurrent Neural Networks (RNNs) are becoming increasingly important for time\nseries-related applications which require efficient and real-time\nimplementations. The recent pruning based work ESE suffers from degradation of\nperformance/energy efficiency due to the irregular network structure after\npruning. We propose block-circulant matrices for weight matrix representation\nin RNNs, thereby achieving simultaneous model compression and acceleration. We\naim to implement RNNs in FPGA with highest performance and energy efficiency,\nwith certain accuracy requirement (negligible accuracy degradation).\nExperimental results on actual FPGA deployments shows that the proposed\nframework achieves a maximum energy efficiency improvement of 35.7$\\times$\ncompared with ESE.\n"]},
{"authors": ["Mohammad Raihanul Islam", "B. Aditya Prakash", "Naren Ramakrishnan"], "title": ["SIGNet: Scalable Embeddings for Signed Networks"], "date": ["2017-02-22T14:51:48Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1702.06819v4"], "summary": ["  Recent successes in word embedding and document embedding have motivated\nresearchers to explore similar representations for networks and to use such\nrepresentations for tasks such as edge prediction, node label prediction, and\ncommunity detection. Such network embedding methods are largely focused on\nfinding distributed representations for unsigned networks and are unable to\ndiscover embeddings that respect polarities inherent in edges. We propose\nSIGNet, a fast scalable embedding method suitable for signed networks. Our\nproposed objective function aims to carefully model the social structure\nimplicit in signed networks by reinforcing the principles of social balance\ntheory. Our method builds upon the traditional word2vec family of embedding\napproaches and adds a new targeted node sampling strategy to maintain\nstructural balance in higher-order neighborhoods. We demonstrate the\nsuperiority of SIGNet over state-of-the-art methods proposed for both signed\nand unsigned networks on several real world datasets from different domains. In\nparticular, SIGNet offers an approach to generate a richer vocabulary of\nfeatures of signed networks to support representation and reasoning.\n"]},
{"authors": ["W. W. M. Kool", "M. Welling"], "title": ["Attention Solves Your TSP"], "date": ["2018-03-22T17:22:24Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08475v1"], "summary": ["  We propose a framework for solving combinatorial optimization problems of\nwhich the output can be represented as a sequence of input elements. As an\nalternative to the Pointer Network, we parameterize a policy by a model based\nentirely on (graph) attention layers, and train it efficiently using REINFORCE\nwith a simple and robust baseline based on a deterministic (greedy) rollout of\nthe best policy found during training. We significantly improve over\nstate-of-the-art results for learning algorithms for the 2D Euclidean TSP,\nreducing the optimality gap for a single tour construction by more than 75% (to\n0.33%) and 50% (to 2.28%) for instances with 20 and 50 nodes respectively.\n"]},
{"authors": ["Aaron Schein", "Zhiwei Steven Wu", "Mingyuan Zhou", "Hanna Wallach"], "title": ["Locally Private Bayesian Inference for Count Models"], "date": ["2018-03-22T17:14:29Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08471v1"], "summary": ["  As more aspects of social interaction are digitally recorded, there is a\ngrowing need to develop privacy-preserving data analysis methods. Social\nscientists will be more likely to adopt these methods if doing so entails\nminimal change to their current methodology. Toward that end, we present a\ngeneral and modular method for privatizing Bayesian inference for Poisson\nfactorization, a broad class of models that contains some of the most widely\nused models in the social sciences. Our method satisfies local differential\nprivacy, which ensures that no single centralized server need ever store the\nnon-privatized data. To formulate our local-privacy guarantees, we introduce\nand focus on limited-precision local privacy---the local privacy analog of\nlimited-precision differential privacy (Flood et al., 2013). We present two\ncase studies, one involving social networks and one involving text corpora,\nthat test our method's ability to form the posterior distribution over latent\nvariables under different levels of noise, and demonstrate our method's utility\nover a na\\\"{i}ve approach, wherein inference proceeds as usual, treating the\nprivatized data as if it were not privatized.\n"]},
{"authors": ["Stephan Alaniz"], "title": ["Deep Reinforcement Learning with Model Learning and Monte Carlo Tree\n  Search in Minecraft"], "date": ["2018-03-22T16:53:34Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08456v1"], "summary": ["  Deep reinforcement learning has been successfully applied to several\nvisual-input tasks using model-free methods. In this paper, we propose a\nmodel-based approach that combines learning a DNN-based transition model with\nMonte Carlo tree search to solve a block-placing task in Minecraft. Our learned\ntransition model predicts the next frame and the rewards one step ahead given\nthe last four frames of the agent's first-person-view image and the current\naction. Then a Monte Carlo tree search algorithm uses this model to plan the\nbest sequence of actions for the agent to perform. On the proposed task in\nMinecraft, our model-based approach reaches the performance comparable to the\nDeep Q-Network's, but learns faster and, thus, is more training sample\nefficient.\n"]},
{"authors": ["Ashkan Panahi", "Hamid Krim", "Liyi Dai"], "title": ["Demystifying Deep Learning: A Geometric Approach to Iterative\n  Projections"], "date": ["2018-03-22T15:49:32Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08416v1"], "summary": ["  Parametric approaches to Learning, such as deep learning (DL), are highly\npopular in nonlinear regression, in spite of their extremely difficult training\nwith their increasing complexity (e.g. number of layers in DL). In this paper,\nwe present an alternative semi-parametric framework which foregoes the\nordinarily required feedback, by introducing the novel idea of geometric\nregularization. We show that certain deep learning techniques such as residual\nnetwork (ResNet) architecture are closely related to our approach. Hence, our\ntechnique can be used to analyze these types of deep learning. Moreover, we\npresent preliminary results which confirm that our approach can be easily\ntrained to obtain complex structures.\n"]},
{"authors": ["Furui Liu", "Laiwan Chan"], "title": ["Causal Inference on Discrete Data via Estimating Distance Correlations"], "date": ["2018-03-21T01:39:08Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07712v2"], "summary": ["  In this paper, we deal with the problem of inferring causal directions when\nthe data is on discrete domain. By considering the distribution of the cause\n$P(X)$ and the conditional distribution mapping cause to effect $P(Y|X)$ as\nindependent random variables, we propose to infer the causal direction via\ncomparing the distance correlation between $P(X)$ and $P(Y|X)$ with the\ndistance correlation between $P(Y)$ and $P(X|Y)$. We infer \"$X$ causes $Y$\" if\nthe dependence coefficient between $P(X)$ and $P(Y|X)$ is smaller. Experiments\nare performed to show the performance of the proposed method.\n"]},
{"authors": ["Abien Fred Agarap"], "title": ["Deep Learning using Rectified Linear Units (ReLU)"], "date": ["2018-03-22T14:30:17Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08375v1"], "summary": ["  We introduce the use of rectified linear units (ReLU) as the classification\nfunction in a deep neural network (DNN). Conventionally, ReLU is used as an\nactivation function in DNNs, with Softmax function as their classification\nfunction. However, there have been several studies on using a classification\nfunction other than Softmax, and this study is an addition to those. We\naccomplish this by taking the activation of the penultimate layer $h_{n - 1}$\nin a neural network, then multiply it by weight parameters $\\theta$ to get the\nraw scores $o_{i}$. Afterwards, we threshold the raw scores $o_{i}$ by $0$,\ni.e. $f(o) = \\max(0, o_{i})$, where $f(o)$ is the ReLU function. We provide\nclass predictions $\\hat{y}$ through argmax function, i.e. argmax $f(x)$.\n"]},
{"authors": ["Jian Fang", "Shaobo Lin", "Zongben Xu"], "title": ["Learning through deterministic assignment of hidden parameters"], "date": ["2018-03-22T14:25:39Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08374v1"], "summary": ["  Supervised learning frequently boils down to determining hidden and bright\nparameters in a parameterized hypothesis space based on finite input-output\nsamples. The hidden parameters determine the attributions of hidden predictors\nor the nonlinear mechanism of an estimator, while the bright parameters\ncharacterize how hidden predictors are linearly combined or the linear\nmechanism. In traditional learning paradigm, hidden and bright parameters are\nnot distinguished and trained simultaneously in one learning process. Such an\none-stage learning (OSL) brings a benefit of theoretical analysis but suffers\nfrom the high computational burden. To overcome this difficulty, a two-stage\nlearning (TSL) scheme, featured by learning through deterministic assignment of\nhidden parameters (LtDaHP) was proposed, which suggests to deterministically\ngenerate the hidden parameters by using minimal Riesz energy points on a sphere\nand equally spaced points in an interval. We theoretically show that with such\ndeterministic assignment of hidden parameters, LtDaHP with a neural network\nrealization almost shares the same generalization performance with that of OSL.\nWe also present a series of simulations and application examples to support the\noutperformance of LtDaHP\n"]},
{"authors": ["KiJung Yoon", "Renjie Liao", "Yuwen Xiong", "Lisa Zhang", "Ethan Fetaya", "Raquel Urtasun", "Richard Zemel", "Xaq Pitkow"], "title": ["Inference in Probabilistic Graphical Models by Graph Neural Networks"], "date": ["2018-03-21T01:09:07Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07710v2"], "summary": ["  A useful computation when acting in a complex environment is to infer the\nmarginal probabilities or most probable states of task-relevant variables.\nProbabilistic graphical models can efficiently represent the structure of such\ncomplex data, but performing these inferences is generally difficult.\nMessage-passing algorithms, such as belief propagation, are a natural way to\ndisseminate evidence amongst correlated variables while exploiting the graph\nstructure, but these algorithms can struggle when the conditional dependency\ngraphs contain loops. Here we use Graph Neural Networks (GNNs) to learn a\nmessage-passing algorithm that solves these inference tasks. We first show that\nthe architecture of GNNs is well-matched to inference tasks. We then\ndemonstrate the efficacy of this inference approach by training GNNs on an\nensemble of graphical models and showing that they substantially outperform\nbelief propagation on loopy graphs. Our message-passing algorithms generalize\nout of the training set to larger graphs and graphs with different structure.\n"]},
{"authors": ["Hartmut Maennel", "Olivier Bousquet", "Sylvain Gelly"], "title": ["Gradient Descent Quantizes ReLU Network Features"], "date": ["2018-03-22T14:08:58Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08367v1"], "summary": ["  Deep neural networks are often trained in the over-parametrized regime (i.e.\nwith far more parameters than training examples), and understanding why the\ntraining converges to solutions that generalize remains an open problem.\nSeveral studies have highlighted the fact that the training procedure, i.e.\nmini-batch Stochastic Gradient Descent (SGD) leads to solutions that have\nspecific properties in the loss landscape. However, even with plain Gradient\nDescent (GD) the solutions found in the over-parametrized regime are pretty\ngood and this phenomenon is poorly understood.\n  We propose an analysis of this behavior for feedforward networks with a ReLU\nactivation function under the assumption of small initialization and learning\nrate and uncover a quantization effect: The weight vectors tend to concentrate\nat a small number of directions determined by the input data. As a consequence,\nwe show that for given input data there are only finitely many, \"simple\"\nfunctions that can be obtained, independent of the network size. This puts\nthese functions in analogy to linear interpolations (for given input data there\nare finitely many triangulations, which each determine a function by linear\ninterpolation). We ask whether this analogy extends to the generalization\nproperties - while the usual distribution-independent generalization property\ndoes not hold, it could be that for e.g. smooth functions with bounded second\nderivative an approximation property holds which could \"explain\" generalization\nof networks (of unbounded size) to unseen inputs.\n"]},
{"authors": ["Alexandre Garcia", "Slim Essid", "Chlo\u00e9 Clavel", "Florence d'Alch\u00e9-Buc"], "title": ["Structured Output Learning with Abstention: Application to Accurate\n  Opinion Prediction"], "date": ["2018-03-22T13:48:30Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08355v1"], "summary": ["  Motivated by Supervised Opinion Analysis, we propose a novel framework\ndevoted to Structured Output Learning with Abstention (SOLA). The structure\nprediction model is able to abstain from predicting some labels in the\nstructured output at a cost chosen by the user in a flexible way. For that\npurpose, we decompose the problem into the learning of a pair of predictors,\none devoted to structured abstention and the other, to structured output\nprediction. To compare fully labeled training data with predictions potentially\ncontaining abstentions, we define a wide class of asymmetric abstention-aware\nlosses. Learning is achieved by surrogate regression in an appropriate feature\nspace while prediction with abstention is performed by solving a new pre-image\nproblem. Thus, SOLA extends recent ideas about Structured Output Prediction via\nsurrogate problems and calibration theory and enjoys statistical guarantees on\nthe resulting excess risk. Instantiated on a hierarchical abstention-aware\nloss, SOLA is shown to be relevant for fine-grained opinion mining and gives\nstate-of-the-art results on this task. Moreover, the abstention-aware\nrepresentations can be used to competitively predict user-review ratings based\non a sentence-level opinion predictor.\n"]},
{"authors": ["Michael Minyi Zhang", "Henry Lam", "Lizhen Lin"], "title": ["Robust and Parallel Bayesian Model Selection"], "date": ["2016-10-19T20:09:51Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1610.06194v3"], "summary": ["  Effective and accurate model selection is an important problem in modern data\nanalysis. One of the major challenges is the computational burden required to\nhandle large data sets that cannot be stored or processed on one machine.\nAnother challenge one may encounter is the presence of outliers and\ncontaminations that damage the inference quality. The parallel \"divide and\nconquer\" model selection strategy divides the observations of the full data set\ninto roughly equal subsets and perform inference and model selection\nindependently on each subset. After local subset inference, this method\naggregates the posterior model probabilities or other model/variable selection\ncriteria to obtain a final model by using the notion of geometric median. This\napproach leads to improved concentration in finding the \"correct\" model and\nmodel parameters and also is provably robust to outliers and data\ncontamination.\n"]},
{"authors": ["Yinpeng Dong", "Fangzhou Liao", "Tianyu Pang", "Hang Su", "Jun Zhu", "Xiaolin Hu", "Jianguo Li"], "title": ["Boosting Adversarial Attacks with Momentum"], "date": ["2017-10-17T04:03:04Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.06081v3"], "summary": ["  Deep neural networks are vulnerable to adversarial examples, which poses\nsecurity concerns on these algorithms due to the potentially severe\nconsequences. Adversarial attacks serve as an important surrogate to evaluate\nthe robustness of deep learning models before they are deployed. However, most\nof existing adversarial attacks can only fool a black-box model with a low\nsuccess rate. To address this issue, we propose a broad class of momentum-based\niterative algorithms to boost adversarial attacks. By integrating the momentum\nterm into the iterative process for attacks, our methods can stabilize update\ndirections and escape from poor local maxima during the iterations, resulting\nin more transferable adversarial examples. To further improve the success rates\nfor black-box attacks, we apply momentum iterative algorithms to an ensemble of\nmodels, and show that the adversarially trained models with a strong defense\nability are also vulnerable to our black-box attacks. We hope that the proposed\nmethods will serve as a benchmark for evaluating the robustness of various deep\nmodels and defense methods. With this method, we won the first places in NIPS\n2017 Non-targeted Adversarial Attack and Targeted Adversarial Attack\ncompetitions.\n"]},
{"authors": ["Nikolaus Mayer", "Eddy Ilg", "Philipp Fischer", "Caner Hazirbas", "Daniel Cremers", "Alexey Dosovitskiy", "Thomas Brox"], "title": ["What Makes Good Synthetic Training Data for Learning Disparity and\n  Optical Flow Estimation?"], "date": ["2018-01-19T13:21:07Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1801.06397v3"], "summary": ["  The finding that very large networks can be trained efficiently and reliably\nhas led to a paradigm shift in computer vision from engineered solutions to\nlearning formulations. As a result, the research challenge shifts from devising\nalgorithms to creating suitable and abundant training data for supervised\nlearning. How to efficiently create such training data? The dominant data\nacquisition method in visual recognition is based on web data and manual\nannotation. Yet, for many computer vision problems, such as stereo or optical\nflow estimation, this approach is not feasible because humans cannot manually\nenter a pixel-accurate flow field. In this paper, we promote the use of\nsynthetically generated data for the purpose of training deep networks on such\ntasks.We suggest multiple ways to generate such data and evaluate the influence\nof dataset properties on the performance and generalization properties of the\nresulting networks. We also demonstrate the benefit of learning schedules that\nuse different types of data at selected stages of the training process.\n"]},
{"authors": ["Maxime Jumelle", "Taqiyeddine Sakmeche"], "title": ["Speaker Clustering With Neural Networks And Audio Processing"], "date": ["2018-03-22T09:21:56Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08276v1"], "summary": ["  Speaker clustering is the task of differentiating speakers in a recording. In\na way, the aim is to answer \"who spoke when\" in audio recordings. A common\nmethod used in industry is feature extraction directly from the recording\nthanks to MFCC features, and by using well-known techniques such as Gaussian\nMixture Models (GMM) and Hidden Markov Models (HMM). In this paper, we studied\nneural networks (especially CNN) followed by clustering and audio processing in\nthe quest to reach similar accuracy to state-of-the-art methods.\n"]},
{"authors": ["Partha P Mitra"], "title": ["Fast Convergence for Stochastic and Distributed Gradient Descent in the\n  Interpolation Limit"], "date": ["2018-03-08T00:19:11Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02922v2"], "summary": ["  Modern supervised learning techniques, particularly those using so called\ndeep nets, involve fitting high dimensional labelled data sets with functions\ncontaining very large numbers of parameters. Much of this work is empirical,\nand interesting phenomena have been observed that require theoretical\nexplanations, however the non-convexity of the loss functions complicates the\nanalysis. Recently it has been proposed that some of the success of these\ntechniques resides in the effectiveness of the simple stochastic gradient\ndescent algorithm in the so called interpolation limit in which all labels are\nfit perfectly. This analysis is made possible since the SGD algorithm reduces\nto a stochastic linear system near the interpolating minimum of the loss\nfunction. Here we exploit this insight by analyzing a distributed algorithm for\ngradient descent, also in the interpolating limit. The algorithm corresponds to\ngradient descent applied to a simple penalized distributed loss function,\n$L({\\bf w}_1,...,{\\bf w}_n) = \\Sigma_i l_i({\\bf w}_i) + \\mu \\sum_{<i,j>}|{\\bf\nw}_i-{\\bf w}_j|^2$. Here each node is allowed its own parameter vector and\n$<i,j>$ denotes edges of a connected graph defining the communication links\nbetween nodes. It is shown that this distributed algorithm converges linearly\n(ie the error reduces exponentially with iteration number), with a rate\n$1-\\frac{\\eta}{n}\\lambda_{min}(H)<R<1$ where $\\lambda_{min}(H)$ is the smallest\nnonzero eigenvalue of the sample covariance or the Hessian H. In contrast with\nprevious usage of similar penalty functions to enforce consensus between nodes,\nin the interpolating limit it is not required to take the penalty parameter to\ninfinity for consensus to occur. The analysis further reinforces the utility of\nthis limit in the theoretical treatment of modern machine learning algorithms.\n"]},
{"authors": ["Chenguang Lu"], "title": ["From Shannon's Channel to Semantic Channel via New Bayes' Formulas for\n  Machine Learning"], "date": ["2018-03-22T05:15:49Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08979v1"], "summary": ["  A group of transition probability functions form a Shannon's channel whereas\na group of truth functions form a semantic channel. By the third kind of Bayes'\ntheorem, we can directly convert a Shannon's channel into an optimized semantic\nchannel. When a sample is not big enough, we can use a truth function with\nparameters to produce the likelihood function, then train the truth function by\nthe conditional sampling distribution. The third kind of Bayes' theorem is\nproved. A semantic information theory is simply introduced. The semantic\ninformation measure reflects Popper's hypothesis-testing thought. The Semantic\nInformation Method (SIM) adheres to maximum semantic information criterion\nwhich is compatible with maximum likelihood criterion and Regularized Least\nSquares criterion. It supports Wittgenstein's view: the meaning of a word lies\nin its use. Letting the two channels mutually match, we obtain the Channels'\nMatching (CM) algorithm for machine learning. The CM algorithm is used to\nexplain the evolution of the semantic meaning of natural language, such as \"Old\nage\". The semantic channel for medical tests and the confirmation measures of\ntest-positive and test-negative are discussed. The applications of the CM\nalgorithm to semi-supervised learning and non-supervised learning are simply\nintroduced. As a predictive model, the semantic channel fits variable sources\nand hence can overcome class-imbalance problem. The SIM strictly distinguishes\nstatistical probability and logical probability and uses both at the same time.\nThis method is compatible with the thoughts of Bayes, Fisher, Shannon, Zadeh,\nTarski, Davidson, Wittgenstein, and Popper.It is a competitive alternative to\nBayesian inference.\n"]},
{"authors": ["Xin Bing", "Florentina Bunea", "Yang Ning", "Marten Wegkamp"], "title": ["Adaptive Estimation in Structured Factor Models with Applications to\n  Overlapping Clustering"], "date": ["2017-04-23T20:43:44Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1704.06977v3"], "summary": ["  This work introduces a novel estimation method, called LOVE, of the entries\nand structure of a loading matrix A in a sparse latent factor model X = AZ + E,\nfor an observable random vector X in Rp, with correlated unobservable factors Z\n\\in RK, with K unknown, and independent noise E. Each row of A is scaled and\nsparse. In order to identify the loading matrix A, we require the existence of\npure variables, which are components of X that are associated, via A, with one\nand only one latent factor. Despite the fact that the number of factors K, the\nnumber of the pure variables, and their location are all unknown, we only\nrequire a mild condition on the covariance matrix of Z, and a minimum of only\ntwo pure variables per latent factor to show that A is uniquely defined, up to\nsigned permutations. Our proofs for model identifiability are constructive, and\nlead to our novel estimation method of the number of factors and of the set of\npure variables, from a sample of size n of observations on X. This is the first\nstep of our LOVE algorithm, which is optimization-free, and has low\ncomputational complexity of order p2. The second step of LOVE is an easily\nimplementable linear program that estimates A. We prove that the resulting\nestimator is minimax rate optimal up to logarithmic factors in p. The model\nstructure is motivated by the problem of overlapping variable clustering,\nubiquitous in data science. We define the population level clusters as groups\nof those components of X that are associated, via the sparse matrix A, with the\nsame unobservable latent factor, and multi-factor association is allowed.\nClusters are respectively anchored by the pure variables, and form overlapping\nsub-groups of the p-dimensional random vector X. The Latent model approach to\nOVErlapping clustering is reflected in the name of our algorithm, LOVE.\n"]},
{"authors": ["Tianchen Zhao"], "title": ["Information Theoretic Interpretation of Deep learning"], "date": ["2018-03-21T16:03:29Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07980v2"], "summary": ["  We interpret part of the experimental results of Shwartz-Ziv and Tishby\n[2017]. Inspired by these results, we established a conjecture of the dynamics\nof the machinary of deep neural network. This conjecture can be used to explain\nthe counterpart result by Saxe et al. [2018].\n"]},
{"authors": ["Tristan Bepler", "Andrew Morin", "Alex J. Noble", "Julia Brasch", "Lawrence Shapiro", "Bonnie Berger"], "title": ["Positive-unlabeled convolutional neural networks for particle picking in\n  cryo-electron micrographs"], "date": ["2018-03-22T02:24:22Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08207v1"], "summary": ["  Cryo-electron microscopy (cryoEM) is fast becoming the preferred method for\nprotein structure determination. Particle picking is a significant bottleneck\nin the solving of protein structures from single particle cryoEM. Hand labeling\nsufficient numbers of particles can take months of effort and current\ncomputationally based approaches are often ineffective. Here, we frame particle\npicking as a positive-unlabeled classification problem in which we seek to\nlearn a convolutional neural network (CNN) to classify micrograph regions as\nparticle or background from a small number of labeled positive examples and\nmany unlabeled examples. However, model fitting with very few labeled data\npoints is a challenging machine learning problem. To address this, we develop a\nnovel objective function, GE-binomial, for learning model parameters in this\ncontext. This objective uses a newly-formulated generalized expectation\ncriteria to learn effectively from unlabeled data when using minibatched\nstochastic gradient descent optimizers. On a high-quality publicly available\ncryoEM dataset and a difficult unpublished dataset supplied by the Shapiro lab,\nwe show that CNNs trained with this objective classify particles accurately\nwith very few positive training examples and outperform EMAN2's byRef method by\na large margin even with fewer labeled training examples. Furthermore, we show\nthat incorporating an autoencoder improves generalization when very few labeled\ndata points are available. We also compare our GE-binomial method with other\npositive-unlabeled learning methods never before applied to particle picking.\nWe expect our particle picking tool, Topaz, based on CNNs trained with\nGE-binomial, to be an essential component of single particle cryoEM analysis\nand our GE-binomial objective function to be widely applicable to\npositive-unlabeled classification problems.\n"]},
{"authors": ["Kamil Nar", "Shankar Sastry"], "title": ["Residual Networks: Lyapunov Stability and Convex Decomposition"], "date": ["2018-03-22T02:14:08Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08203v1"], "summary": ["  While training error of most deep neural networks degrades as the depth of\nthe network increases, residual networks appear to be an exception. We show\nthat the main reason for this is the Lyapunov stability of the gradient descent\nalgorithm: for an arbitrarily chosen step size, the equilibria of the gradient\ndescent are most likely to remain stable for the parametrization of residual\nnetworks. We then present an architecture with a pair of residual networks to\napproximate a large class of functions by decomposing them into a convex and a\nconcave part. Some parameters of this model are shown to change little during\ntraining, and this imperfect optimization prevents overfitting the data and\nleads to solutions with small Lipschitz constants, while providing clues about\nthe generalization of other deep networks.\n"]},
{"authors": ["Hoi-To Wai", "Nikolaos M. Freris", "Angelia Nedic", "Anna Scaglione"], "title": ["SUCAG: Stochastic Unbiased Curvature-aided Gradient Method for\n  Distributed Optimization"], "date": ["2018-03-22T01:46:49Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08198v1"], "summary": ["  We propose and analyze a new stochastic gradient method, which we call\nStochastic Unbiased Curvature-aided Gra- dient (SUCAG), for finite sum\noptimization problems. SUCAG constitutes an unbiased total gradient tracking\ntechnique that uses Hessian information to accelerate convergence. We an- alyze\nour method under the general asynchronous model of computation, in which\nfunctions are selected infinitely often, but with delays that can grow\nsublinearly. For strongly convex problems, we establish linear convergence for\nthe SUCAG method. When the initialization point is sufficiently close to the\noptimal solution, the established convergence rate is only dependent on the\ncondition number of the problem, making it strictly faster than the known rate\nfor the SAGA method.\n  Furthermore, we describe a Markov-driven approach of implementing the SUCAG\nmethod in a distributed asynchronous multi-agent setting, via gossiping along a\nrandom walk on the communication graph. We show that our analysis applies as\nlong as the undirected graph is connected and, notably, establishes an\nasymptotic linear convergence rate that is robust to the graph topology.\nNumerical results demonstrate the merit of our algorithm over existing methods.\n"]},
{"authors": ["Panos Stinis", "Tobias Hagge", "Alexandre M. Tartakovsky", "Enoch Yeung"], "title": ["Enforcing constraints for interpolation and extrapolation in Generative\n  Adversarial Networks"], "date": ["2018-03-22T00:25:07Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08182v1"], "summary": ["  Generative Adversarial Networks (GANs) are becoming popular choices for\nunsupervised learning. At the same time there is a concerted effort in the\nmachine learning community to expand the range of tasks in which learning can\nbe applied as well as to utilize methods from other disciplines to accelerate\nlearning. With this in mind, in the current work we suggest ways to enforce\ngiven constraints in the output of a GAN both for interpolation and\nextrapolation. The two cases need to be treated differently.\n  For the case of interpolation, the incorporation of constraints is built into\nthe training of the GAN. The incorporation of the constraints respects the\nprimary game-theoretic setup of a GAN so it can be combined with existing\nalgorithms. However, it can exacerbate the problem of instability during\ntraining that is well-known for GANs. We suggest adding small noise to the\nconstraints as a simple remedy that has performed well in our numerical\nexperiments.\n  The case of extrapolation (prediction) is more involved. First, we employ a\nmodified interpolation training process that uses noisy data but does not\nnecessarily enforce the constraints during training. Second, the resulting\nmodified interpolator is used for extrapolation where the constraints are\nenforced after each step through projection on the space of constraints.\n"]},
{"authors": ["Zac Cranko", "Richard Nock"], "title": ["Boosted Density Estimation Remastered"], "date": ["2018-03-22T00:09:00Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08178v1"], "summary": ["  There has recently been a steadily increase in the iterative approaches to\nboosted density estimation and sampling, usually proceeding by adding candidate\n\"iterate\" densities to a model that gets more accurate with iterations. The\nrelative accompanying burst of formal convergence results has not yet changed a\nstriking picture: all results essentially pay the price of heavy assumptions on\niterates, often unrealistic or hard to check, and offer a blatant contrast with\nthe original boosting theory where such assumptions would be the weakest\npossible. In this paper, we show that all that suffices to achieve boosting for\n\\textit{density estimation} is a \\emph{weak learner} in the original boosting\ntheory sense, that is, an oracle that supplies \\textit{classifiers}. We provide\nconverge rates that comply with boosting requirements, being better and / or\nrelying on substantially weaker assumptions than the state of the art. One of\nour rates is to our knowledge the first to rely on not just weak but also\n\\textit{empirically testable} assumptions. We show that the model fit belongs\nto exponential families, and obtain in the course of our results a variational\ncharacterization of $f$-divergences better than $f$-GAN's. Experimental results\non several simulated problems display significantly better results than AdaGAN\nduring early boosting rounds, in particular for mode capture, and using\narchitectures less than the fifth's of AdaGAN's size.\n"]},
{"authors": ["Antreas Antoniou", "Amos Storkey", "Harrison Edwards"], "title": ["Data Augmentation Generative Adversarial Networks"], "date": ["2017-11-12T19:17:57Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.04340v3"], "summary": ["  Effective training of neural networks requires much data. In the low-data\nregime, parameters are underdetermined, and learnt networks generalise poorly.\nData Augmentation alleviates this by using existing data more effectively.\nHowever standard data augmentation produces only limited plausible alternative\ndata. Given there is potential to generate a much broader set of augmentations,\nwe design and train a generative model to do data augmentation. The model,\nbased on image conditional Generative Adversarial Networks, takes data from a\nsource domain and learns to take any data item and generalise it to generate\nother within-class data items. As this generative process does not depend on\nthe classes themselves, it can be applied to novel unseen classes of data. We\nshow that a Data Augmentation Generative Adversarial Network (DAGAN) augments\nstandard vanilla classifiers well. We also show a DAGAN can enhance few-shot\nlearning systems such as Matching Networks. We demonstrate these approaches on\nOmniglot, on EMNIST having learnt the DAGAN on Omniglot, and VGG-Face data. In\nour experiments we can see over 13% increase in accuracy in the low-data regime\nexperiments in Omniglot (from 69% to 82%), EMNIST (73.9% to 76%) and VGG-Face\n(4.5% to 12%); in Matching Networks for Omniglot we observe an increase of 0.5%\n(from 96.9% to 97.4%) and an increase of 1.8% in EMNIST (from 59.5% to 61.3%).\n"]},
{"authors": ["Linchen Xiao", "Arash Behboodi", "Rudolf Mathar"], "title": ["Learning the Localization Function: Machine Learning Approach to\n  Fingerprinting Localization"], "date": ["2018-03-21T22:25:34Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08153v1"], "summary": ["  Considered as a data-driven approach, Fingerprinting Localization Solutions\n(FPSs) enjoy huge popularity due to their good performance and minimal\nenvironment information requirement. This papers addresses applications of\nartificial intelligence to solve two problems in Received Signal Strength\nIndicator (RSSI) based FPS, first the cumbersome training database construction\nand second the extrapolation of fingerprinting algorithm for similar buildings\nwith slight environmental changes. After a concise overview of deep learning\ndesign techniques, two main techniques widely used in deep learning are\nexploited for the above mentioned issues namely data augmentation and transfer\nlearning. We train a multi-layer neural network that learns the mapping from\nthe observations to the locations. A data augmentation method is proposed to\nincrease the training database size based on the structure of RSSI measurements\nand hence reducing effectively the amount of training data. Then it is shown\nexperimentally how a model trained for a particular building can be transferred\nto a similar one by fine tuning with significantly smaller training numbers.\nThe paper implicitly discusses the new guidelines to consider about deep\nlearning designs when they are employed in a new application context.\n"]},
{"authors": ["Cencheng Shen", "Qing Wang", "Carey E. Priebe", "Mauro Maggioni", "Joshua T. Vogelstein"], "title": ["Discovering Relationships and their Structures Across Disparate Data\n  Modalities"], "date": ["2016-09-16T17:29:01Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1609.05148v5"], "summary": ["  Determining how certain properties are related to other properties is\nfundamental to scientific discovery. As data collection rates accelerate, it is\nbecoming increasingly difficult yet ever more important to determine whether\none property of data (e.g., cloud density) is related to another (e.g., grass\nwetness). Only if two properties are related are further investigations into\nthe geometry of the relationship warranted. While existing approaches can test\nwhether two properties are related, they may require unfeasibly large sample\nsizes in real data scenarios, and do not address how they are related. Our key\ninsight is that one can adaptively restrict the analysis to the \"jointly local\"\nobservations---that is, one can estimate the scales with the most informative\nneighbors for determining the existence and geometry of a relationship.\n\"Multiscale Graph Correlation\" (MGC) is a framework that extends global\nprocedures to be multiscale; consequently, MGC tests typically require far\nfewer samples than existing methods for a wide variety of dependence structures\nand dimensionalities, while maintaining computational efficiency. Moreover, MGC\nprovides a simple and elegant multiscale characterization of the potentially\ncomplex latent geometry underlying the relationship. In several real data\napplications, MGC uniquely detects the presence and reveals the geometry of the\nrelationships.\n"]},
{"authors": ["Sathya N. Ravi", "Ronak Mehta", "Vikas Singh"], "title": ["Robust Blind Deconvolution via Mirror Descent"], "date": ["2018-03-21T20:55:26Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08137v1"], "summary": ["  We revisit the Blind Deconvolution problem with a focus on understanding its\nrobustness and convergence properties. Provable robustness to noise and other\nperturbations is receiving recent interest in vision, from obtaining immunity\nto adversarial attacks to assessing and describing failure modes of algorithms\nin mission critical applications. Further, many blind deconvolution methods\nbased on deep architectures internally make use of or optimize the basic\nformulation, so a clearer understanding of how this sub-module behaves, when it\ncan be solved, and what noise injection it can tolerate is a first order\nrequirement. We derive new insights into the theoretical underpinnings of blind\ndeconvolution. The algorithm that emerges has nice convergence guarantees and\nis provably robust in a sense we formalize in the paper. Interestingly, these\ntechnical results play out very well in practice, where on standard datasets\nour algorithm yields results competitive with or superior to the state of the\nart. Keywords: blind deconvolution, robust continuous optimization\n"]},
{"authors": ["Antonio G. Ache", "Micah W. Warren"], "title": ["Ricci Curvature and the Manifold Learning Problem"], "date": ["2014-10-13T15:37:20Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1410.3351v5"], "summary": ["  Consider a sample of $n$ points taken i.i.d from a submanifold $\\Sigma$ of\nEuclidean space. We show that there is a way to estimate the Ricci curvature of\n$\\Sigma$ with respect to the induced metric from the sample. Our method is\ngrounded in the notions of Carr\\'e du Champ for diffusion semi-groups, the\ntheory of Empirical processes and local Principal Component Analysis.\n"]},
{"authors": ["Christina Heinze-Deml", "Nicolai Meinshausen"], "title": ["Conditional Variance Penalties and Domain Shift Robustness"], "date": ["2017-10-31T13:52:12Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.11469v3"], "summary": ["  When training a deep network for image classification, one can broadly\ndistinguish between two types of latent features of images that will drive the\nclassification. Following the notation of Gong et al. (2016), we can divide\nlatent features into (i) \"core\" features $X^\\text{core}$ whose distribution\n$X^\\text{core}\\vert Y$ does not change substantially across domains and (ii)\n\"style\" features $X^{\\text{style}}$ whose distribution $X^{\\text{style}}\\vert\nY$ can change substantially across domains. These latter orthogonal features\nwould generally include features such as rotation, image quality or brightness\nbut also more complex ones like hair color or posture for images of persons.\nGuarding against future adversarial domain shifts implies that the influence of\nthe second type of style features in the prediction has to be limited. We\nassume that the domain itself is not observed and hence a latent variable. We\ndo assume, however, that we can sometimes observe a typically discrete\nidentifier or $\\mathrm{ID}$ variable. We know in some applications, for\nexample, that two images show the same person, and $\\mathrm{ID}$ then refers to\nthe identity of the person. The method requires only a small fraction of images\nto have an $\\mathrm{ID}$ variable. We group data samples if they share the same\nclass and identifier $(Y,\\mathrm{ID})=(y,\\mathrm{id})$ and penalize the\nconditional variance of the prediction if we condition on $(Y,\\mathrm{ID})$.\nUsing this approach is shown to protect against shifts in the distribution of\nthe style variables for both regression and classification models.\nSpecifically, the conditional variance penalty CoRe is shown to be equivalent\nto minimizing the risk under noise interventions in a regression setting and is\nshown to lead to adversarial risk consistency in a partially linear\nclassification setting.\n"]},
{"authors": ["David M. Burns", "Cari M. Whyne"], "title": ["Seglearn: A Python Package for Learning Sequences and Time Series"], "date": ["2018-03-21T20:30:34Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08118v1"], "summary": ["  Seglearn is an open-source python package for machine learning time series or\nsequences using a sliding window segmentation approach. The implementation\nprovides a flexible pipeline for tackling classification, regression, and\nforecasting problems with multivariate sequence and contextual data. This\npackage is compatible with scikit-learn and is listed under scikit-learn\nRelated Projects. The package depends on numpy, scipy, and scikit-learn.\nSeglearn is distributed under the BSD 3-Clause License. Documentation includes\na detailed API description, user guide, and examples. Unit tests provide a high\ndegree of code coverage.\n"]},
{"authors": ["Geoff Boeing"], "title": ["Clustering to Reduce Spatial Data Set Size"], "date": ["2018-03-21T19:38:27Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08101v1"], "summary": ["  Traditionally it had been a problem that researchers did not have access to\nenough spatial data to answer pressing research questions or build compelling\nvisualizations. Today, however, the problem is often that we have too much\ndata. Spatially redundant or approximately redundant points may refer to a\nsingle feature (plus noise) rather than many distinct spatial features. We use\na machine learning approach with density-based clustering to compress such\nspatial data into a set of representative features.\n"]},
{"authors": ["Giulia Denevi", "Carlo Ciliberto", "Dimitris Stamos", "Massimiliano Pontil"], "title": ["Incremental Learning-to-Learn with Statistical Guarantees"], "date": ["2018-03-21T18:50:18Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08089v1"], "summary": ["  In learning-to-learn the goal is to infer a learning algorithm that works\nwell on a class of tasks sampled from an unknown meta distribution. In contrast\nto previous work on batch learning-to-learn, we consider a scenario where tasks\nare presented sequentially and the algorithm needs to adapt incrementally to\nimprove its performance on future tasks. Key to this setting is for the\nalgorithm to rapidly incorporate new observations into the model as they\narrive, without keeping them in memory. We focus on the case where the\nunderlying algorithm is ridge regression parameterized by a positive\nsemidefinite matrix. We propose to learn this matrix by applying a stochastic\nstrategy to minimize the empirical error incurred by ridge regression on future\ntasks sampled from the meta distribution. We study the statistical properties\nof the proposed algorithm and prove non-asymptotic bounds on its excess\ntransfer risk, that is, the generalization performance on new tasks from the\nsame meta distribution. We compare our online learning-to-learn approach with a\nstate of the art batch method, both theoretically and empirically.\n"]},
{"authors": ["Amirsina Torfi", "Rouzbeh A. Shirvani", "Sobhan Soleymani", "Nasser M. Nasrabadi"], "title": ["Attention-Based Guided Structured Sparsity of Deep Neural Networks"], "date": ["2018-02-13T04:24:49Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.09902v2"], "summary": ["  Network pruning is aimed at imposing sparsity in a neural network\narchitecture by increasing the portion of zero-valued weights for reducing its\nsize regarding energy-efficiency consideration and increasing evaluation speed.\nIn most of the conducted research efforts, the sparsity is enforced for network\npruning without any attention to the internal network characteristics such as\nunbalanced outputs of the neurons or more specifically the distribution of the\nweights and outputs of the neurons. That may cause severe accuracy drop due to\nuncontrolled sparsity. In this work, we propose an attention mechanism that\nsimultaneously controls the sparsity intensity and supervised network pruning\nby keeping important information bottlenecks of the network to be active. On\nCIFAR-10, the proposed method outperforms the best baseline method by 6% and\nreduced the accuracy drop by 2.6x at the same level of sparsity.\n"]},
{"authors": ["Yuan Zeng", "Kevin Devincentis", "Yao Xiao", "Zubayer Ibne Ferdous", "Xiaochen Guo", "Zhiyuan Yan", "Yevgeny Berdichevsky"], "title": ["A Supervised STDP-based Training Algorithm for Living Neural Networks"], "date": ["2017-10-30T13:55:59Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.10944v3"], "summary": ["  Neural networks have shown great potential in many applications like speech\nrecognition, drug discovery, image classification, and object detection. Neural\nnetwork models are inspired by biological neural networks, but they are\noptimized to perform machine learning tasks on digital computers. The proposed\nwork explores the possibilities of using living neural networks in vitro as\nbasic computational elements for machine learning applications. A new\nsupervised STDP-based learning algorithm is proposed in this work, which\nconsiders neuron engineering constrains. A 74.7% accuracy is achieved on the\nMNIST benchmark for handwritten digit recognition.\n"]},
{"authors": ["Katherine Fraser", "Matthew D. Schwartz"], "title": ["Jet Charge and Machine Learning"], "date": ["2018-03-21T18:02:02Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08066v1"], "summary": ["  Modern machine learning techniques, such as convolutional, recurrent and\nrecursive neural networks, have shown promise for jet substructure at the Large\nHadron Collider. For example, they have demonstrated effectiveness at boosted\ntop or W boson identification or for quark/gluon discrimination. We explore\nthese methods for the purpose of classifying jets according to their electric\ncharge. We find that neural networks that incorporate distance within the jet\nas an input can provide significant improvement in jet charge extraction over\ntraditional methods. We find that both convolutional and recurrent networks are\neffective and both train faster than recursive networks. The advantages of\nusing a fixed-size input representation (as with the CNN) or a smaller input\nrepresentation (as with the RNN) suggest that both convolutional and recurrent\nnetworks will be essential to the future of modern machine learning at\ncolliders.\n"]},
{"authors": ["Daniel Soudry", "Elad Hoffer", "Mor Shpigel Nacson", "Suriya Gunasekar", "Nathan Srebro"], "title": ["The Implicit Bias of Gradient Descent on Separable Data"], "date": ["2017-10-27T21:47:58Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.10345v3"], "summary": ["  We show that gradient descent on an unregularized logistic regression\nproblem, for linearly separable datasets, converges to the direction of the\nmax-margin (hard margin SVM) solution. The result generalizes also to other\nmonotone decreasing loss functions with an infimum at infinity, to multi-class\nproblems, and to training a weight layer in a deep network in a certain\nrestricted setting. Furthermore, we show this convergence is very slow, and\nonly logarithmic in the convergence of the loss itself. This can help explain\nthe benefit of continuing to optimize the logistic or cross-entropy loss even\nafter the training error is zero and the training loss is extremely small, and,\nas we show, even if the validation loss increases. Our methodology can also aid\nin understanding implicit regularization in more complex models and with other\noptimization methods.\n"]},
{"authors": ["Miko\u0142aj Bi\u0144kowski", "Dougal J. Sutherland", "Michael Arbel", "Arthur Gretton"], "title": ["Demystifying MMD GANs"], "date": ["2018-01-04T15:25:26Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1801.01401v4"], "summary": ["  We investigate the training and performance of generative adversarial\nnetworks using the Maximum Mean Discrepancy (MMD) as critic, termed MMD GANs.\nAs our main theoretical contribution, we clarify the situation with bias in GAN\nloss functions raised by recent work: we show that gradient estimators used in\nthe optimization process for both MMD GANs and Wasserstein GANs are unbiased,\nbut learning a discriminator based on samples leads to biased gradients for the\ngenerator parameters. We also discuss the issue of kernel choice for the MMD\ncritic, and characterize the kernel corresponding to the energy distance used\nfor the Cramer GAN critic. Being an integral probability metric, the MMD\nbenefits from training strategies recently developed for Wasserstein GANs. In\nexperiments, the MMD GAN is able to employ a smaller critic network than the\nWasserstein GAN, resulting in a simpler and faster-training algorithm with\nmatching performance. We also propose an improved measure of GAN convergence,\nthe Kernel Inception Distance, and show how to use it to dynamically adapt\nlearning rates during GAN training.\n"]},
{"authors": ["Miles E. Lopes", "Shusen Wang", "Michael W. Mahoney"], "title": ["Error Estimation for Randomized Least-Squares Algorithms via the\n  Bootstrap"], "date": ["2018-03-21T17:19:41Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08021v1"], "summary": ["  Over the course of the past decade, a variety of randomized algorithms have\nbeen proposed for computing approximate least-squares (LS) solutions in\nlarge-scale settings. A longstanding practical issue is that, for any given\ninput, the user rarely knows the actual error of an approximate solution\n(relative to the exact solution). Likewise, it is difficult for the user to\nknow precisely how much computation is needed to achieve the desired error\ntolerance. Consequently, the user often appeals to worst-case error bounds that\ntend to offer only qualitative guidance. As a more practical alternative, we\npropose a bootstrap method to compute a posteriori error estimates for\nrandomized LS algorithms. These estimates permit the user to numerically assess\nthe error of a given solution, and to predict how much work is needed to\nimprove a \"preliminary\" solution. In addition, we provide theoretical\nconsistency results for the method, which are the first such results in this\ncontext (to the best of our knowledge). From a practical standpoint, the method\nalso has considerable flexibility, insofar as it can be applied to several\npopular sketching algorithms, as well as a variety of error metrics. Moreover,\nthe extra step of error estimation does not add much cost to an underlying\nsketching algorithm. Finally, we demonstrate the effectiveness of the method\nwith empirical results.\n"]},
{"authors": ["Sungkyu Jung"], "title": ["Continuum directions for supervised dimension reduction"], "date": ["2016-06-20T06:52:41Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1606.05988v3"], "summary": ["  Dimension reduction of multivariate data supervised by auxiliary information\nis considered. A series of basis for dimension reduction is obtained as\nminimizers of a novel criterion. The proposed method is akin to continuum\nregression, and the resulting basis is called continuum directions. With a\npresence of binary supervision data, these directions continuously bridge the\nprincipal component, mean difference and linear discriminant directions, thus\nranging from unsupervised to fully supervised dimension reduction.\nHigh-dimensional asymptotic studies of continuum directions for binary\nsupervision reveal several interesting facts. The conditions under which the\nsample continuum directions are inconsistent, but their classification\nperformance is good, are specified. While the proposed method can be directly\nused for binary and multi-category classification, its generalizations to\nincorporate any form of auxiliary data are also presented. The proposed method\nenjoys fast computation, and the performance is better or on par with more\ncomputer-intensive alternatives.\n"]},
{"authors": ["Indrayudh Ghosal", "Giles Hooker"], "title": ["Boosting Random Forests to Reduce Bias; One-Step Boosted Forest and its\n  Variance Estimate"], "date": ["2018-03-21T16:41:30Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.08000v1"], "summary": ["  In this paper we propose using the principle of boosting to reduce the bias\nof a random forest prediction in the regression setting. From the original\nrandom forest fit we extract the residuals and then fit another random forest\nto these residuals. We call the sum of these two random forests a\n\\textit{one-step boosted forest}. We have shown with simulated and real data\nthat the one-step boosted forest has a reduced bias compared to the original\nrandom forest. The paper also provides a variance estimate of the one-step\nboosted forest by an extension of the infinitesimal Jackknife estimator. Using\nthis variance estimate we can construct prediction intervals for the boosted\nforest and we show that they have good coverage probabilities. Combining the\nbias reduction and the variance estimate we have shown that the one-step\nboosted forest has a significant reduction in predictive mean squared error and\nthus an improvement in predictive performance. When applied on datasets from\nthe UCI database we have empirically proven that the one-step boosted forest\nperforms better than the random forest and gradient boosting machine\nalgorithms. Theoretically we can also extend such a boosting process to more\nthan one step and the same principles outlined in this paper can be used to\nfind variance estimates for such predictors. Such boosting will reduce bias\neven further but it risks over-fitting and also increases the computational\nburden.\n"]},
{"authors": ["Joachim Folz", "Sebastian Palacio", "Joern Hees", "Damian Borth", "Andreas Dengel"], "title": ["Adversarial Defense based on Structure-to-Signal Autoencoders"], "date": ["2018-03-21T16:25:26Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07994v1"], "summary": ["  Adversarial attack methods have demonstrated the fragility of deep neural\nnetworks. Their imperceptible perturbations are frequently able fool\nclassifiers into potentially dangerous misclassifications. We propose a novel\nway to interpret adversarial perturbations in terms of the effective input\nsignal that classifiers actually use. Based on this, we apply specially trained\nautoencoders, referred to as S2SNets, as defense mechanism. They follow a\ntwo-stage training scheme: first unsupervised, followed by a fine-tuning of the\ndecoder, using gradients from an existing classifier. S2SNets induce a shift in\nthe distribution of gradients propagated through them, stripping them from\nclass-dependent signal. We analyze their robustness against several white-box\nand gray-box scenarios on the large ImageNet dataset. Our approach reaches\ncomparable resilience in white-box attack scenarios as other state-of-the-art\ndefenses in gray-box scenarios. We further analyze the relationships of\nAlexNet, VGG 16, ResNet 50 and Inception v3 in adversarial space, and found\nthat VGG 16 is the easiest to fool, while perturbations from ResNet 50 are the\nmost transferable.\n"]},
{"authors": ["Lawrence M. Murray", "Daniel Lund\u00e9n", "Jan Kudlicka", "David Broman", "Thomas B. Sch\u00f6n"], "title": ["Delayed Sampling and Automatic Rao-Blackwellization of Probabilistic\n  Programs"], "date": ["2017-08-25T15:48:20Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1708.07787v2"], "summary": ["  We introduce a dynamic mechanism for the solution of analytically-tractable\nsubstructure in probabilistic programs, using conjugate priors and affine\ntransformations to reduce variance in Monte Carlo estimators. For inference\nwith Sequential Monte Carlo, this automatically yields improvements such as\nlocally-optimal proposals and Rao-Blackwellization. The mechanism maintains a\ndirected graph alongside the running program that evolves dynamically as\noperations are triggered upon it. Nodes of the graph represent random\nvariables, edges the analytically-tractable relationships between them. Random\nvariables remain in the graph for as long as possible, to be sampled only when\nthey are used by the program in a way that cannot be resolved analytically. In\nthe meantime, they are conditioned on as many observations as possible. We\ndemonstrate the mechanism with a few pedagogical examples, as well as a\nlinear-nonlinear state-space model with simulated data, and an epidemiological\nmodel with real data of a dengue outbreak in Micronesia. In all cases one or\nmore variables are automatically marginalized out to significantly reduce\nvariance in estimates of the marginal likelihood, in the final case\nfacilitating a random-weight or pseudo-marginal-type importance sampler for\nparameter estimation. We have implemented the approach in Anglican and a new\nprobabilistic programming language called Birch.\n"]},
{"authors": ["Bicheng Ying", "Kun Yuan", "Stefan Vlaski", "Ali H. Sayed"], "title": ["Stochastic Learning under Random Reshuffling"], "date": ["2018-03-21T15:27:52Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07964v1"], "summary": ["  In empirical risk optimization, it has been observed that stochastic gradient\nimplementations that rely on random reshuffling of the data achieve better\nperformance than implementations that rely on sampling the data uniformly.\nRecent works have pursued justifications for this behavior by examining the\nconvergence rate of the learning process under diminishing step-sizes. This\nwork focuses on the constant step-size case. In this case, convergence is\nguaranteed to a small neighborhood of the optimizer albeit at a linear rate.\nThe analysis establishes analytically that random reshuffling outperforms\nuniform sampling by showing explicitly that iterates approach a smaller\nneighborhood of size $O(\\mu^2)$ around the minimizer rather than $O(\\mu)$.\nFurthermore, we derive an analytical expression for the steady-state\nmean-square-error performance of the algorithm, which helps clarify in greater\ndetail the differences between sampling with and without replacement. We also\nexplain the periodic behavior that is observed in random reshuffling\nimplementations.\n"]},
{"authors": ["Vadim Smolyakov"], "title": ["Information Planning for Text Data"], "date": ["2018-02-09T17:25:43Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.03360v3"], "summary": ["  Information planning enables faster learning with fewer training examples. It\nis particularly applicable when training examples are costly to obtain. This\nwork examines the advantages of information planning for text data by focusing\non three supervised models: Naive Bayes, supervised LDA and deep neural\nnetworks. We show that planning based on entropy and mutual information\noutperforms random selection baseline and therefore accelerates learning.\n"]},
{"authors": ["Karl \u00d8yvind Mikalsen", "Cristina Soguero-Ruiz", "Filippo Maria Bianchi", "Arthur Revhaug", "Robert Jenssen"], "title": ["An Unsupervised Multivariate Time Series Kernel Approach for Identifying\n  Patients with Surgical Site Infection from Blood Samples"], "date": ["2018-03-21T12:20:43Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07879v1"], "summary": ["  A large fraction of the electronic health records consists of clinical\nmeasurements collected over time, such as blood tests, which provide important\ninformation about the health status of a patient. These sequences of clinical\nmeasurements are naturally represented as time series, characterized by\nmultiple variables and the presence of missing data, which complicate analysis.\nIn this work, we propose a surgical site infection detection framework for\npatients undergoing colorectal cancer surgery that is completely unsupervised,\nhence alleviating the problem of getting access to labelled training data. The\nframework is based on powerful kernels for multivariate time series that\naccount for missing data when computing similarities. Our approach show\nsuperior performance compared to baselines that have to resort to imputation\ntechniques and performs comparable to a supervised classification baseline.\n"]},
{"authors": ["Meire Fortunato", "Charles Blundell", "Oriol Vinyals"], "title": ["Bayesian Recurrent Neural Networks"], "date": ["2017-04-10T10:59:05Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1704.02798v3"], "summary": ["  In this work we explore a straightforward variational Bayes scheme for\nRecurrent Neural Networks. Firstly, we show that a simple adaptation of\ntruncated backpropagation through time can yield good quality uncertainty\nestimates and superior regularisation at only a small extra computational cost\nduring training, also reducing the amount of parameters by 80\\%. Secondly, we\ndemonstrate how a novel kind of posterior approximation yields further\nimprovements to the performance of Bayesian RNNs. We incorporate local gradient\ninformation into the approximate posterior to sharpen it around the current\nbatch statistics. We show how this technique is not exclusive to recurrent\nneural networks and can be applied more widely to train Bayesian neural\nnetworks. We also empirically demonstrate how Bayesian RNNs are superior to\ntraditional RNNs on a language modelling benchmark and an image captioning\ntask, as well as showing how each of these methods improve our model over a\nvariety of other schemes for training them. We also introduce a new benchmark\nfor studying uncertainty for language models so future methods can be easily\ncompared.\n"]},
{"authors": ["Patrick J\u00e4hnichen", "Florian Wenzel", "Marius Kloft", "Stephan Mandt"], "title": ["Scalable Generalized Dynamic Topic Models"], "date": ["2018-03-21T11:50:35Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07868v1"], "summary": ["  Dynamic topic models (DTMs) model the evolution of prevalent themes in\nliterature, online media, and other forms of text over time. DTMs assume that\nword co-occurrence statistics change continuously and therefore impose\ncontinuous stochastic process priors on their model parameters. These dynamical\npriors make inference much harder than in regular topic models, and also limit\nscalability. In this paper, we present several new results around DTMs. First,\nwe extend the class of tractable priors from Wiener processes to the generic\nclass of Gaussian processes (GPs). This allows us to explore topics that\ndevelop smoothly over time, that have a long-term memory or are temporally\nconcentrated (for event detection). Second, we show how to perform scalable\napproximate inference in these models based on ideas around stochastic\nvariational inference and sparse Gaussian processes. This way we can train a\nrich family of DTMs to massive data. Our experiments on several large-scale\ndatasets show that our generalized model allows us to find interesting patterns\nthat were not accessible by previous approaches.\n"]},
{"authors": ["Arno Solin", "Manon Kok", "Niklas Wahlstr\u00f6m", "Thomas B. Sch\u00f6n", "Simo S\u00e4rkk\u00e4"], "title": ["Modeling and interpolation of the ambient magnetic field by Gaussian\n  processes"], "date": ["2015-09-15T16:42:08Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1509.04634v2"], "summary": ["  Anomalies in the ambient magnetic field can be used as features in indoor\npositioning and navigation. By using Maxwell's equations, we derive and present\na Bayesian non-parametric probabilistic modeling approach for interpolation and\nextrapolation of the magnetic field. We model the magnetic field components\njointly by imposing a Gaussian process (GP) prior on the latent scalar\npotential of the magnetic field. By rewriting the GP model in terms of a\nHilbert space representation, we circumvent the computational pitfalls\nassociated with GP modeling and provide a computationally efficient and\nphysically justified modeling tool for the ambient magnetic field. The model\nallows for sequential updating of the estimate and time-dependent changes in\nthe magnetic field. The model is shown to work well in practice in different\napplications: we demonstrate mapping of the magnetic field both with an\ninexpensive Raspberry Pi powered robot and on foot using a standard smartphone.\n"]},
{"authors": ["Jack Kuipers", "Polina Suter", "Giusi Moffa"], "title": ["Efficient Structure Learning and Sampling of Bayesian Networks"], "date": ["2018-03-21T11:12:42Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07859v1"], "summary": ["  Bayesian networks are probabilistic graphical models widely employed to\nunderstand dependencies in high dimensional data, and even to facilitate causal\ndiscovery. Learning the underlying network structure, which is encoded as a\ndirected acyclic graph (DAG) is highly challenging mainly due to the vast\nnumber of possible networks. Efforts have focussed on two fronts: constraint\nbased methods that perform conditional independence tests to exclude edges and\nscore and search approaches which explore the DAG space with greedy or MCMC\nschemes. Here we synthesise these two fields in a novel hybrid method which\nreduces the complexity of MCMC approaches to that of a constraint based method.\nIndividual steps in the MCMC scheme only require simple table lookups so that\nvery long chains can be efficiently obtained. Furthermore, the scheme includes\nan iterative procedure to correct for errors from the conditional independence\ntests. The algorithm not only offers markedly superior performance to\nalternatives, but DAGs can also be sampled from the posterior distribution\nenabling full Bayesian modelling averaging for much larger Bayesian networks.\n"]},
{"authors": ["Riikka Huusari", "Hachem Kadri", "C\u00e9cile Capponi"], "title": ["Multi-view Metric Learning in Vector-valued Kernel Spaces"], "date": ["2018-03-21T09:56:33Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07821v1"], "summary": ["  We consider the problem of metric learning for multi-view data and present a\nnovel method for learning within-view as well as between-view metrics in\nvector-valued kernel spaces, as a way to capture multi-modal structure of the\ndata. We formulate two convex optimization problems to jointly learn the metric\nand the classifier or regressor in kernel feature spaces. An iterative\nthree-step multi-view metric learning algorithm is derived from the\noptimization problems. In order to scale the computation to large training\nsets, a block-wise Nystr{\\\"o}m approximation of the multi-view kernel matrix is\nintroduced. We justify our approach theoretically and experimentally, and show\nits performance on real-world datasets against relevant state-of-the-art\nmethods.\n"]},
{"authors": ["G. Biau", "B. Cadre", "M. Sangnier", "U. Tanielian"], "title": ["Some Theoretical Properties of GANs"], "date": ["2018-03-21T09:52:14Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07819v1"], "summary": ["  Generative Adversarial Networks (GANs) are a class of generative algorithms\nthat have been shown to produce state-of-the art samples, especially in the\ndomain of image creation. The fundamental principle of GANs is to approximate\nthe unknown distribution of a given data set by optimizing an objective\nfunction through an adversarial game between a family of generators and a\nfamily of discriminators. In this paper, we offer a better theoretical\nunderstanding of GANs by analyzing some of their mathematical and statistical\nproperties. We study the deep connection between the adversarial principle\nunderlying GANs and the Jensen-Shannon divergence, together with some\noptimality characteristics of the problem. An analysis of the role of the\ndiscriminator family via approximation arguments is also provided. In addition,\ntaking a statistical point of view, we study the large sample properties of the\nestimated distribution and prove in particular a central limit theorem. Some of\nour results are illustrated with simulated examples.\n"]},
{"authors": ["Christopher J. Cueva", "Xue-Xin Wei"], "title": ["Emergence of grid-like representations by training recurrent neural\n  networks to perform spatial localization"], "date": ["2018-03-21T07:09:57Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07770v1"], "summary": ["  Decades of research on the neural code underlying spatial navigation have\nrevealed a diverse set of neural response properties. The Entorhinal Cortex\n(EC) of the mammalian brain contains a rich set of spatial correlates,\nincluding grid cells which encode space using tessellating patterns. However,\nthe mechanisms and functional significance of these spatial representations\nremain largely mysterious. As a new way to understand these neural\nrepresentations, we trained recurrent neural networks (RNNs) to perform\nnavigation tasks in 2D arenas based on velocity inputs. Surprisingly, we find\nthat grid-like spatial response patterns emerge in trained networks, along with\nunits that exhibit other spatial correlates, including border cells and\nband-like cells. All these different functional types of neurons have been\nobserved experimentally. The order of the emergence of grid-like and border\ncells is also consistent with observations from developmental studies.\nTogether, our results suggest that grid cells, border cells and others as\nobserved in EC may be a natural solution for representing space efficiently\ngiven the predominant recurrent connections in the neural circuits.\n"]},
{"authors": ["Salar Fattahi", "Somayeh Sojoudi"], "title": ["Data-Driven Sparse System Identification"], "date": ["2018-03-21T05:55:11Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07753v1"], "summary": ["  In this paper, we study the system identification porblem for sparse linear\ntime-invariant systems. We propose a sparsity promoting Lasso-type estimator to\nidentify the dynamics of the system with only a limited number of input-state\ndata samples. Using contemporary results on high-dimensional statistics, we\nprove that $\\Omega(k_{\\max}\\log(m+n))$ data samples are enough to reliably\nestimate the system dynamics, where $n$ and $m$ are the number of states and\ninputs, respectively, and $k_{\\max}$ is the maximum number of nonzero elements\nin the rows of input and state matrices. The number of samples in the developed\nestimator is significantly smaller than the dimension of the problem for sparse\nsystems, and yet it offers a small estimation error entry-wise. Furthermore, we\nshow that, unlike the recently celebrated least-squares estimators for system\nidentification problems, the method developed in this work is capable of\n\\textit{exact recovery} of the underlying sparsity structure of the system with\nthe aforementioned number of data samples. Extensive case studies on\nsynthetically generated systems and physical mass-spring networks are offered\nto demonstrate the effectiveness of the proposed method.\n"]},
{"authors": ["Yuxin Chen", "Yuejie Chi", "Jianqing Fan", "Cong Ma"], "title": ["Gradient Descent with Random Initialization: Fast Global Convergence for\n  Nonconvex Phase Retrieval"], "date": ["2018-03-21T03:14:16Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07726v1"], "summary": ["  This paper considers the problem of solving systems of quadratic equations,\nnamely, recovering an object of interest\n$\\mathbf{x}^{\\natural}\\in\\mathbb{R}^{n}$ from $m$ quadratic equations/samples\n$y_{i}=(\\mathbf{a}_{i}^{\\top}\\mathbf{x}^{\\natural})^{2}$, $1\\leq i\\leq m$. This\nproblem, also dubbed as phase retrieval, spans multiple domains including\nphysical sciences and machine learning.\n  We investigate the efficiency of gradient descent (or Wirtinger flow)\ndesigned for the nonconvex least squares problem. We prove that under Gaussian\ndesigns, gradient descent --- when randomly initialized --- yields an\n$\\epsilon$-accurate solution in $O\\big(\\log n+\\log(1/\\epsilon)\\big)$ iterations\ngiven nearly minimal samples, thus achieving near-optimal computational and\nsample complexities at once. This provides the first global convergence\nguarantee concerning vanilla gradient descent for phase retrieval, without the\nneed of (i) carefully-designed initialization, (ii) sample splitting, or (iii)\nsophisticated saddle-point escaping schemes. All of these are achieved by\nexploiting the statistical models in analyzing optimization algorithms, via a\nleave-one-out approach that enables the decoupling of certain statistical\ndependency between the gradient descent iterates and the data.\n"]},
{"authors": ["Lorin Crawford", "Seth R. Flaxman", "Daniel E. Runcie", "Mike West"], "title": ["Predictor Variable Prioritization in Nonlinear Models: A Genetic\n  Association Case Study"], "date": ["2018-01-22T20:57:39Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1801.07318v2"], "summary": ["  The central aim in this paper is to address variable selection questions in\nnonlinear and nonparametric regression. Motivated by statistical genetics,\nwhere nonlinear interactions are of particular interest, we introduce a novel,\ninterpretable, and computationally efficient way to summarize the relative\nimportance of predictor variables. Methodologically, we develop the \"RelATive\ncEntrality\" (RATE) measure to prioritize candidate genetic variants that are\nnot just marginally important, but whose associations also stem from\nsignificant covarying relationships with other variants in the data. We\nillustrate RATE through Bayesian Gaussian process regression, but the\nmethodological innovations apply to other nonlinear methods. It is known that\nnonlinear models often exhibit greater predictive accuracy than linear models,\nparticularly for phenotypes generated by complex genetic architectures. With\ndetailed simulations and an Arabidopsis thaliana QTL mapping study, we show\nthat applying RATE enables an explanation for this improved performance.\n"]},
{"authors": ["\u00c2ngelo Cardoso", "Fabio Daolio", "Sa\u00fal Vargas"], "title": ["Product Characterisation towards Personalisation: Learning Attributes\n  from Unstructured Data to Recommend Fashion Products"], "date": ["2018-03-20T22:25:29Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07679v1"], "summary": ["  In this paper, we describe a solution to tackle a common set of challenges in\ne-commerce, which arise from the fact that new products are continually being\nadded to the catalogue. The challenges involve properly personalising the\ncustomer experience, forecasting demand and planning the product range. We\nargue that the foundational piece to solve all of these problems is having\nconsistent and detailed information about each product, information that is\nrarely available or consistent given the multitude of suppliers and types of\nproducts. We describe in detail the architecture and methodology implemented at\nASOS, one of the world's largest fashion e-commerce retailers, to tackle this\nproblem. We then show how this quantitative understanding of the products can\nbe leveraged to improve recommendations in a hybrid recommender system\napproach.\n"]},
{"authors": ["Edward Cheung", "Yuying Li"], "title": ["Nonsmooth Frank-Wolfe using Uniform Affine Approximations"], "date": ["2017-10-16T15:16:20Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.05776v2"], "summary": ["  Frank-Wolfe methods (FW) have gained significant interest in the machine\nlearning community due to its ability to efficiently solve large problems that\nadmit a sparse structure (e.g. sparse vectors and low-rank matrices). However\nthe performance of the existing FW method hinges on the quality of the linear\napproximation. This typically restricts FW to smooth functions for which the\napproximation quality, indicated by a global curvature measure, is reasonably\ngood.\n  In this paper, we propose a modified FW algorithm amenable to nonsmooth\nfunctions by optimizing for approximation quality over all affine\napproximations given a neighborhood of interest. We analyze theoretical\nproperties of the proposed algorithm and demonstrate that it overcomes many\nissues associated with existing methods in the context of nonsmooth low-rank\nmatrix estimation.\n"]},
{"authors": ["Yuan Li", "Garvesh Raskutti", "Rebecca Willett"], "title": ["Graph-based regularization for regression problems with\n  highly-correlated designs"], "date": ["2018-03-20T21:07:36Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07658v1"], "summary": ["  Sparse models for high-dimensional linear regression and machine learning\nhave received substantial attention over the past two decades. Model selection,\nor determining which features or covariates are the best explanatory variables,\nis critical to the interpretability of a learned model. Much of the current\nliterature assumes that covariates are only mildly correlated. However, in\nmodern applications ranging from functional MRI to genome-wide association\nstudies, covariates are highly correlated and do not exhibit key properties\n(such as the restricted eigenvalue condition, RIP, or other related\nassumptions). This paper considers a high-dimensional regression setting in\nwhich a graph governs both correlations among the covariates and the similarity\namong regression coefficients. Using side information about the strength of\ncorrelations among features, we form a graph with edge weights corresponding to\npairwise covariances. This graph is used to define a graph total variation\nregularizer that promotes similar weights for highly correlated features. The\ngraph structure encapsulated by this regularizer helps precondition correlated\nfeatures to yield provably accurate estimates. Using graph-based regularizers\nto develop theoretical guarantees for highly-correlated covariates has not been\npreviously examined. This paper shows how our proposed graph-based\nregularization yields mean-squared error guarantees for a broad range of\ncovariance graph structures and correlation strengths which in many cases are\noptimal by imposing additional structure on $\\beta^{\\star}$ which encourages\n\\emph{alignment} with the covariance graph. Our proposed approach outperforms\nother state-of-the-art methods for highly-correlated design in a variety of\nexperiments on simulated and real fMRI data.\n"]},
{"authors": ["Andrei Atanov", "Arsenii Ashukha", "Dmitry Molchanov", "Kirill Neklyudov", "Dmitry Vetrov"], "title": ["Uncertainty Estimation via Stochastic Batch Normalization"], "date": ["2018-02-13T23:22:16Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.04893v2"], "summary": ["  In this work, we investigate Batch Normalization technique and propose its\nprobabilistic interpretation. We propose a probabilistic model and show that\nBatch Normalization maximazes the lower bound of its marginalized\nlog-likelihood. Then, according to the new probabilistic model, we design an\nalgorithm which acts consistently during train and test. However, inference\nbecomes computationally inefficient. To reduce memory and computational cost,\nwe propose Stochastic Batch Normalization -- an efficient approximation of\nproper inference procedure. This method provides us with a scalable uncertainty\nestimation technique. We demonstrate the performance of Stochastic Batch\nNormalization on popular architectures (including deep convolutional\narchitectures: VGG-like and ResNets) for MNIST and CIFAR-10 datasets.\n"]},
{"authors": ["Twan van Laarhoven", "Elena Marchiori"], "title": ["Domain Adaptation with Randomized Expectation Maximization"], "date": ["2018-03-20T20:13:09Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07634v1"], "summary": ["  Domain adaptation (DA) is the task of classifying an unlabeled dataset\n(target) using a labeled dataset (source) from a related domain. The majority\nof successful DA methods try to directly match the distributions of the source\nand target data by transforming the feature space. Despite their success, state\nof the art methods based on this approach are either involved or unable to\ndirectly scale to data with many features. This article shows that domain\nadaptation can be successfully performed by using a very simple randomized\nexpectation maximization (EM) method. We consider two instances of the method,\nwhich involve logistic regression and support vector machine, respectively. The\nunderlying assumption of the proposed method is the existence of a good single\nlinear classifier for both source and target domain. The potential limitations\nof this assumption are alleviated by the flexibility of the method, which can\ndirectly incorporate deep features extracted from a pre-trained deep neural\nnetwork. The resulting algorithm is strikingly easy to implement and apply. We\ntest its performance on 36 real-life adaptation tasks over text and image data\nwith diverse characteristics. The method achieves state-of-the-art results,\ncompetitive with those of involved end-to-end deep transfer-learning methods.\n"]},
{"authors": ["Dylan J. Foster", "Alexander Rakhlin", "Karthik Sridharan"], "title": ["Online Learning: Sufficient Statistics and the Burkholder Method"], "date": ["2018-03-20T19:29:46Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07617v1"], "summary": ["  We uncover a fairly general principle in online learning: If regret can be\n(approximately) expressed as a function of certain \"sufficient statistics\" for\nthe data sequence, then there exists a special Burkholder function that 1) can\nbe used algorithmically to achieve the regret bound and 2) only depends on\nthese sufficient statistics, not the entire data sequence, so that the online\nstrategy is only required to keep the sufficient statistics in memory. This\ncharacterization is achieved by bringing the full power of the Burkholder\nMethod --- originally developed for certifying probabilistic martingale\ninequalities --- to bear on the online learning setting.\n  To demonstrate the scope and effectiveness of the Burkholder method, we\ndevelop a novel online strategy for matrix prediction that attains a regret\nbound corresponding to the variance term in matrix concentration inequalities.\nWe also present a linear-time/space prediction strategy for parameter free\nsupervised learning with linear classes and general smooth norms.\n"]},
{"authors": ["Twan van Laarhoven", "Elena Marchiori"], "title": ["Unsupervised Domain Adaptation with Random Walks on Target Labelings"], "date": ["2017-06-16T16:21:10Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1706.05335v2"], "summary": ["  Unsupervised Domain Adaptation (DA) is used to automatize the task of\nlabeling data: an unlabeled dataset (target) is annotated using a labeled\ndataset (source) from a related domain. We cast domain adaptation as the\nproblem of finding stable labels for target examples. A new definition of label\nstability is proposed, motivated by a generalization error bound for large\nmargin linear classifiers: a target labeling is stable when, with high\nprobability, a classifier trained on a random subsample of the target with that\nlabeling yields the same labeling. We find stable labelings using a random walk\non a directed graph with transition probabilities based on labeling stability.\nThe majority vote of those labelings visited by the walk yields a stable label\nfor each target example. The resulting domain adaptation algorithm is\nstrikingly easy to implement and apply: It does not rely on data\ntransformations, which are in general computational prohibitive in the presence\nof many input features, and does not need to access the source data, which is\nadvantageous when data sharing is restricted. By acting on the original feature\nspace, our method is able to take full advantage of deep features from external\npre-trained neural networks, as demonstrated by the results of our experiments.\n"]},
{"authors": ["Cem M. Deniz", "Siyuan Xiang", "Spencer Hallyburton", "Arakua Welbeck", "Stephen Honig", "Kyunghyun Cho", "Gregory Chang"], "title": ["Segmentation of the Proximal Femur from MR Images using Deep\n  Convolutional Neural Networks"], "date": ["2017-04-20T14:54:29Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1704.06176v4"], "summary": ["  Magnetic resonance imaging (MRI) has been proposed as a complimentary method\nto measure bone quality and assess fracture risk. However, manual segmentation\nof MR images of bone is time-consuming, limiting the use of MRI measurements in\nthe clinical practice. The purpose of this paper is to present an automatic\nproximal femur segmentation method that is based on deep convolutional neural\nnetworks (CNNs). This study had institutional review board approval and written\ninformed consent was obtained from all subjects. A dataset of volumetric\nstructural MR images of the proximal femur from 86 subject were\nmanually-segmented by an expert. We performed experiments by training two\ndifferent CNN architectures with multiple number of initial feature maps and\nlayers, and tested their segmentation performance against the gold standard of\nmanual segmentations using four-fold cross-validation. Automatic segmentation\nof the proximal femur achieved a high dice similarity score of 0.94$\\pm$0.05\nwith precision = 0.95$\\pm$0.02, and recall = 0.94$\\pm$0.08 using a CNN\narchitecture based on 3D convolution exceeding the performance of 2D CNNs. The\nhigh segmentation accuracy provided by CNNs has the potential to help bring the\nuse of structural MRI measurements of bone quality into clinical practice for\nmanagement of osteoporosis.\n"]},
{"authors": ["Lijun Ding", "Yudong Chen"], "title": ["The Leave-one-out Approach for Matrix Completion: Primal and Dual\n  Analysis"], "date": ["2018-03-20T17:54:49Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07554v1"], "summary": ["  In this paper, we introduce a powerful technique, Leave-One-Out, to the\nanalysis of low-rank matrix completion problems. Using this technique, we\ndevelop a general approach for obtaining fine-grained, entry-wise bounds on\niterative stochastic procedures. We demonstrate the power of this approach in\nanalyzing two of the most important algorithms for matrix completion: the\nnon-convex approach based on Singular Value Projection (SVP), and the convex\nrelaxation approach based on nuclear norm minimization (NNM). In particular, we\nprove for the first time that the original form of SVP, without re-sampling or\nsample splitting, converges linearly in the infinity norm. We further apply our\nleave-one-out approach to an iterative procedure that arises in the analysis of\nthe dual solutions of NNM. Our results show that NNM recovers the true $ d\n$-by-$ d $ rank-$ r $ matrix with $\\mathcal{O}(\\mu^2 r^3d \\log d )$ observed\nentries, which has optimal dependence on the dimension and is independent of\nthe condition number of the matrix. To the best of our knowledge, this is the\nfirst sample complexity result for a tractable matrix completion algorithm that\nsatisfies these two properties simultaneously.\n"]},
{"authors": ["Steind\u00f3r S\u00e6mundsson", "Katja Hofmann", "Marc Peter Deisenroth"], "title": ["Meta Reinforcement Learning with Latent Variable Gaussian Processes"], "date": ["2018-03-20T17:51:10Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07551v1"], "summary": ["  Data efficiency, i.e., learning from small data sets, is critical in many\npractical applications where data collection is time consuming or expensive,\ne.g., robotics, animal experiments or drug design. Meta learning is one way to\nincrease the data efficiency of learning algorithms by generalizing learned\nconcepts from a set of training tasks to unseen, but related, tasks. Often,\nthis relationship between tasks is hard coded or relies in some other way on\nhuman expertise. In this paper, we propose to automatically learn the\nrelationship between tasks using a latent variable model. Our approach finds a\nvariational posterior over tasks and averages over all plausible (according to\nthis posterior) tasks when making predictions. We apply this framework within a\nmodel-based reinforcement learning setting for learning dynamics models and\ncontrollers of many related tasks. We apply our framework in a model-based\nreinforcement learning setting, and show that our model effectively generalizes\nto novel tasks, and that it reduces the average interaction time needed to\nsolve tasks by up to 60% compared to strong baselines.\n"]},
{"authors": ["Charles Lu", "M. Marx", "M. Zahid", "C. W. Lo", "C. Chennubhotla", "S. P. Quinn"], "title": ["Stacked Neural Networks for end-to-end ciliary motion analysis"], "date": ["2018-03-20T17:17:39Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07534v1"], "summary": ["  Cilia are hairlike structures protruding from nearly every cell in the body.\nDiseases known as ciliopathies, where cilia function is disrupted, can result\nin a wide spectrum of disorders. However, most techniques for assessing ciliary\nmotion rely on manual identification and tracking of cilia; this process is\nlaborious and error-prone, and does not scale well. Even where automated\nciliary motion analysis tools exist, their applicability is limited. Here, we\npropose an end-to-end computational machine learning pipeline that\nautomatically identifies regions of cilia from videos, extracts patches of\ncilia, and classifies patients as exhibiting normal or abnormal ciliary motion.\nIn particular, we demonstrate how convolutional LSTM are able to encode complex\nfeatures while remaining sensitive enough to differentiate between a variety of\nmotion patterns. Our framework achieves 90% with only a few hundred training\nepochs. We find that the combination of segmentation and classification\nnetworks in a single pipeline yields performance comparable to existing\ncomputational pipelines, while providing the additional benefit of an\nend-to-end, fully-automated analysis toolbox for ciliary motion.\n"]},
{"authors": ["Sungsoo Ahn", "Michael Chertkov", "Adrian Weller", "Jinwoo Shin"], "title": ["Bucket Renormalization for Approximate Inference"], "date": ["2018-03-14T02:16:54Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05104v3"], "summary": ["  Probabilistic graphical models are a key tool in machine learning\napplications. Computing the partition function, i.e., normalizing constant, is\na fundamental task of statistical inference but it is generally computationally\nintractable, leading to extensive study of approximation methods. Iterative\nvariational methods are a popular and successful family of approaches. However,\neven state of the art variational methods can return poor results or fail to\nconverge on difficult instances. In this paper, we instead consider computing\nthe partition function via sequential summation over variables. We develop\nrobust approximate algorithms by combining ideas from mini-bucket elimination\nwith tensor network and renormalization group methods from statistical physics.\nThe resulting \"convergence-free\" methods show good empirical performance on\nboth synthetic and real-world benchmark models, even for difficult instances.\n"]},
{"authors": ["Lei Ma", "Felix Juefei-Xu", "Jiyuan Sun", "Chunyang Chen", "Ting Su", "Fuyuan Zhang", "Minhui Xue", "Bo Li", "Li Li", "Yang Liu", "Jianjun Zhao", "Yadong Wang"], "title": ["DeepGauge: Comprehensive and Multi-Granularity Testing Criteria for\n  Gauging the Robustness of Deep Learning Systems"], "date": ["2018-03-20T16:52:12Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07519v1"], "summary": ["  Deep learning defines a new data-driven programming paradigm that constructs\nthe internal system logic of a crafted neuron network through a set of training\ndata. Deep learning (DL) has been widely adopted in many safety-critical\nscenarios. However, a plethora of studies have shown that the state-of-the-art\nDL systems suffer from various vulnerabilities which can lead to severe\nconsequences when applied to real-world applications. Currently, the robustness\nof a DL system against adversarial attacks is usually measured by the accuracy\nof test data. Considering the limitation of accessible test data, good\nperformance on test data can hardly guarantee the robustness and generality of\nDL systems. Different from traditional software systems which have clear and\ncontrollable logic and functionality, a DL system is trained with data and\nlacks thorough understanding. This makes it difficult for system analysis and\ndefect detection, which could potentially hinder its real-world deployment\nwithout safety guarantees. In this paper, we propose DeepGauge, a comprehensive\nand multi-granularity testing criteria for DL systems, which renders a complete\nand multi-faceted portrayal of the testbed. The in-depth evaluation of our\nproposed testing criteria is demonstrated on two well-known datasets, five DL\nsystems, with four state-of-the-art adversarial data generation techniques. The\neffectiveness of DeepGauge sheds light on the construction of robust DL\nsystems.\n"]},
{"authors": ["Kiran Karra", "Lamine Mili"], "title": ["Copula Index for Detecting Dependence and Monotonicity between\n  Stochastic Signals"], "date": ["2017-03-20T11:26:04Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1703.06686v4"], "summary": ["  This paper introduces a nonparametric copula-based index for detecting the\nstrength and monotonicity structure of linear and nonlinear statistical\ndependence between pairs of random variables or stochastic signals. Our index,\ntermed Copula Index for Detecting Dependence and Monotonicity (CIM), satisfies\nseveral desirable properties of measures of association, including R\\'enyi's\nproperties, the data processing inequality (DPI), and consequently\nself-equitability. Synthetic data simulations reveal that the statistical power\nof CIM compares favorably to other state-of-the-art measures of association\nthat are proven to satisfy the DPI. Simulation results with real-world data\nreveal the CIM's unique ability to detect the monotonicity structure among\nstochastic signals to find interesting dependencies in large datasets.\nAdditionally, simulations show that the CIM shows favorable performance to\nestimators of mutual information when discovering Markov network structure.\n"]},
{"authors": ["Yishai Shimoni", "Chen Yanover", "Ehud Karavani", "Yaara Goldschmnidt"], "title": ["Benchmarking Framework for Performance-Evaluation of Causal Inference\n  Analysis"], "date": ["2018-02-14T11:41:56Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.05046v2"], "summary": ["  Causal inference analysis is the estimation of the effects of actions on\noutcomes. In the context of healthcare data this means estimating the outcome\nof counter-factual treatments (i.e. including treatments that were not\nobserved) on a patient's outcome. Compared to classic machine learning methods,\nevaluation and validation of causal inference analysis is more challenging\nbecause ground truth data of counter-factual outcome can never be obtained in\nany real-world scenario. Here, we present a comprehensive framework for\nbenchmarking algorithms that estimate causal effect. The framework includes\nunlabeled data for prediction, labeled data for validation, and code for\nautomatic evaluation of algorithm predictions using both established and novel\nmetrics. The data is based on real-world covariates, and the treatment\nassignments and outcomes are based on simulations, which provides the basis for\nvalidation. In this framework we address two questions: one of scaling, and the\nother of data-censoring. The framework is available as open source code at\nhttps://github.com/IBM-HRL-MLHLS/IBM-Causal-Inference-Benchmarking-Framework\n"]},
{"authors": ["Ethan Knight", "Osher Lerner"], "title": ["Natural Gradient Deep Q-learning"], "date": ["2018-03-20T15:22:52Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07482v1"], "summary": ["  This paper presents findings for training a Q-learning reinforcement learning\nagent using natural gradient techniques. We compare the original deep Q-network\n(DQN) algorithm to its natural gradient counterpart (NGDQN), measuring NGDQN\nand DQN performance on classic controls environments without target networks.\nWe find that NGDQN performs favorably relative to DQN, converging to\nsignificantly better policies faster and more frequently. These results\nindicate that natural gradient could be used for value function optimization in\nreinforcement learning to accelerate and stabilize training.\n"]},
{"authors": ["Julien Gout", "Markus Quade", "Kamran Shafi", "Robert K. Niven", "Markus Abel"], "title": ["Learning Optimal Control of Synchronization in Networks of Coupled\n  Oscillators using Genetic Programming-based Symbolic Regression"], "date": ["2016-12-15T21:20:27Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1612.05276v2"], "summary": ["  Networks of coupled dynamical systems provide a powerful way to model systems\nwith enormously complex dynamics, such as the human brain. Control of\nsynchronization in such networked systems has far reaching applications in many\ndomains, including engineering and medicine. In this paper, we formulate the\nsynchronization control in dynamical systems as an optimization problem and\npresent a multi-objective genetic programming-based approach to infer optimal\ncontrol functions that drive the system from a synchronized to a\nnon-synchronized state and vice-versa. The genetic programming-based controller\nallows learning optimal control functions in an interpretable symbolic form.\nThe effectiveness of the proposed approach is demonstrated in controlling\nsynchronization in coupled oscillator systems linked in networks of increasing\norder complexity, ranging from a simple coupled oscillator system to a\nhierarchical network of coupled oscillators. The results show that the proposed\nmethod can learn highly-effective and interpretable control functions for such\nsystems.\n"]},
{"authors": ["Furui Liu", "Laiwan Chan"], "title": ["Confounder Detection in High Dimensional Linear Models using First\n  Moments of Spectral Measures"], "date": ["2018-03-19T10:00:47Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06852v2"], "summary": ["  In this paper, we study the confounder detection problem in the linear model,\nwhere the target variable $Y$ is predicted using its $n$ potential causes\n$X_n=(x_1,...,x_n)^T$. Based on an assumption of rotation invariant generating\nprocess of the model, recent study shows that the spectral measure induced by\nthe regression coefficient vector with respect to the covariance matrix of\n$X_n$ is close to a uniform measure in purely causal cases, but it differs from\na uniform measure characteristically in the presence of a scalar confounder.\nThen, analyzing spectral measure pattern could help to detect confounding. In\nthis paper, we propose to use the first moment of the spectral measure for\nconfounder detection. We calculate the first moment of the regression vector\ninduced spectral measure, and compare it with the first moment of a uniform\nspectral measure, both defined with respect to the covariance matrix of $X_n$.\nThe two moments coincide in non-confounding cases, and differ from each other\nin the presence of confounding. This statistical causal-confounding asymmetry\ncan be used for confounder detection. Without the need of analyzing the\nspectral measure pattern, our method does avoid the difficulty of metric choice\nand multiple parameter optimization. Experiments on synthetic and real data\nshow the performance of this method.\n"]},
{"authors": ["Henggang Cui", "Gregory R. Ganger", "Phillip B. Gibbons"], "title": ["MLtuner: System Support for Automatic Machine Learning Tuning"], "date": ["2018-03-20T14:17:36Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07445v1"], "summary": ["  MLtuner automatically tunes settings for training tunables (such as the\nlearning rate, the momentum, the mini-batch size, and the data staleness bound)\nthat have a significant impact on large-scale machine learning (ML)\nperformance. Traditionally, these tunables are set manually, which is\nunsurprisingly error-prone and difficult to do without extensive domain\nknowledge. MLtuner uses efficient snapshotting, branching, and\noptimization-guided online trial-and-error to find good initial settings as\nwell as to re-tune settings during execution. Experiments show that MLtuner can\nrobustly find and re-tune tunable settings for a variety of ML applications,\nincluding image classification (for 3 models and 2 datasets), video\nclassification, and matrix factorization. Compared to state-of-the-art ML\nauto-tuning approaches, MLtuner is more robust for large problems and over an\norder of magnitude faster.\n"]},
{"authors": ["Kamil Ciosek", "Shimon Whiteson"], "title": ["Expected Policy Gradients"], "date": ["2017-06-15T18:27:03Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1706.05374v5"], "summary": ["  We propose expected policy gradients (EPG), which unify stochastic policy\ngradients (SPG) and deterministic policy gradients (DPG) for reinforcement\nlearning. Inspired by expected sarsa, EPG integrates across the action when\nestimating the gradient, instead of relying only on the action in the sampled\ntrajectory. We establish a new general policy gradient theorem, of which the\nstochastic and deterministic policy gradient theorems are special cases. We\nalso prove that EPG reduces the variance of the gradient estimates without\nrequiring deterministic policies and, for the Gaussian case, with no\ncomputational overhead. Finally, we show that it is optimal in a certain sense\nto explore with a Gaussian policy such that the covariance is proportional to\nthe exponential of the scaled Hessian of the critic with respect to the\nactions. We present empirical results confirming that this new form of\nexploration substantially outperforms DPG with the Ornstein-Uhlenbeck heuristic\nin four challenging MuJoCo domains.\n"]},
{"authors": ["Beilun Wang", "Ji Gao", "Yanjun Qi"], "title": ["A Fast and Scalable Joint Estimator for Learning Multiple Related Sparse\n  Gaussian Graphical Models"], "date": ["2017-02-09T06:09:48Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1702.02715v3"], "summary": ["  Estimating multiple sparse Gaussian Graphical Models (sGGMs) jointly for many\nrelated tasks (large $K$) under a high-dimensional (large $p$) situation is an\nimportant task. Most previous studies for the joint estimation of multiple\nsGGMs rely on penalized log-likelihood estimators that involve expensive and\ndifficult non-smooth optimizations. We propose a novel approach, FASJEM for\n\\underline{fa}st and \\underline{s}calable \\underline{j}oint\nstructure-\\underline{e}stimation of \\underline{m}ultiple sGGMs at a large\nscale. As the first study of joint sGGM using the Elementary Estimator\nframework, our work has three major contributions: (1) We solve FASJEM through\nan entry-wise manner which is parallelizable. (2) We choose a proximal\nalgorithm to optimize FASJEM. This improves the computational efficiency from\n$O(Kp^3)$ to $O(Kp^2)$ and reduces the memory requirement from $O(Kp^2)$ to\n$O(K)$. (3) We theoretically prove that FASJEM achieves a consistent estimation\nwith a convergence rate of $O(\\log(Kp)/n_{tot})$. On several synthetic and four\nreal-world datasets, FASJEM shows significant improvements over baselines on\naccuracy, computational complexity, and memory costs.\n"]},
{"authors": ["Arun Venkitaraman", "Saikat Chatterjee", "Peter H\u00e4ndel"], "title": ["Gaussian Processes Over Graphs"], "date": ["2018-03-15T14:27:49Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05776v2"], "summary": ["  We propose Gaussian processes for signals over graphs (GPG) using the apriori\nknowledge that the target vectors lie over a graph. We incorporate this\ninformation using a graph- Laplacian based regularization which enforces the\ntarget vectors to have a specific profile in terms of graph Fourier transform\ncoeffcients, for example lowpass or bandpass graph signals. We discuss how the\nregularization affects the mean and the variance in the prediction output. In\nparticular, we prove that the predictive variance of the GPG is strictly\nsmaller than the conventional Gaussian process (GP) for any non-trivial graph.\nWe validate our concepts by application to various real-world graph signals.\nOur experiments show that the performance of the GPG is superior to GP for\nsmall training data sizes and under noisy training.\n"]},
{"authors": ["Thomas Kerdreux", "Fabian Pedregosa", "Alexandre d'Aspremont"], "title": ["Frank-Wolfe with Subsampling Oracle"], "date": ["2018-03-20T10:18:59Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07348v1"], "summary": ["  We analyze two novel randomized variants of the Frank-Wolfe (FW) or\nconditional gradient algorithm. While classical FW algorithms require solving a\nlinear minimization problem over the domain at each iteration, the proposed\nmethod only requires to solve a linear minimization problem over a small\n\\emph{subset} of the original domain. The first algorithm that we propose is a\nrandomized variant of the original FW algorithm and achieves a\n$\\mathcal{O}(1/t)$ sublinear convergence rate as in the deterministic\ncounterpart. The second algorithm is a randomized variant of the Away-step FW\nalgorithm, and again as its deterministic counterpart, reaches linear (i.e.,\nexponential) convergence rate making it the first provably convergent\nrandomized variant of Away-step FW. In both cases, while subsampling reduces\nthe convergence rate by a constant factor, the linear minimization step can be\na fraction of the cost of that of the deterministic versions, especially when\nthe data is streamed. We illustrate computational gains of the algorithms on\nregression problems, involving both $\\ell_1$ and latent group lasso penalties.\n"]},
{"authors": ["Jonas Rauber", "Wieland Brendel", "Matthias Bethge"], "title": ["Foolbox: A Python toolbox to benchmark the robustness of machine\n  learning models"], "date": ["2017-07-13T13:59:15Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1707.04131v3"], "summary": ["  Even todays most advanced machine learning models are easily fooled by almost\nimperceptible perturbations of their inputs. Foolbox is a new Python package to\ngenerate such adversarial perturbations and to quantify and compare the\nrobustness of machine learning models. It is build around the idea that the\nmost comparable robustness measure is the minimum perturbation needed to craft\nan adversarial example. To this end, Foolbox provides reference implementations\nof most published adversarial attack methods alongside some new ones, all of\nwhich perform internal hyperparameter tuning to find the minimum adversarial\nperturbation. Additionally, Foolbox interfaces with most popular deep learning\nframeworks such as PyTorch, Keras, TensorFlow, Theano and MXNet and allows\ndifferent adversarial criteria such as targeted misclassification and top-k\nmisclassification as well as different distance measures. The code is licensed\nunder the MIT license and is openly available at\nhttps://github.com/bethgelab/foolbox . The most up-to-date documentation can be\nfound at http://foolbox.readthedocs.io .\n"]},
{"authors": ["Kirill Neklyudov", "Dmitry Molchanov", "Arsenii Ashukha", "Dmitry Vetrov"], "title": ["Variance Networks: When Expectation Does Not Meet Your Expectations"], "date": ["2018-03-10T06:01:40Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03764v3"], "summary": ["  In this paper, we propose variance networks, a new model that stores the\nlearned information in the variances of the network weights. Surprisingly, no\ninformation gets stored in the expectations of the weights, therefore if we\nreplace these weights with their expectations, we would obtain a random guess\nquality prediction. We provide a numerical criterion that uses the loss\ncurvature to determine which random variables can be replaced with their\nexpected values, and find that only a small fraction of weights is needed for\nensembling. Variance networks represent a diverse ensemble that is more robust\nto adversarial attacks than conventional low-variance ensembles. The success of\nthis model raises several counter-intuitive implications for the training and\napplication of Deep Learning models.\n"]},
{"authors": ["Mario Lucic", "Karol Kurach", "Marcin Michalski", "Sylvain Gelly", "Olivier Bousquet"], "title": ["Are GANs Created Equal? A Large-Scale Study"], "date": ["2017-11-28T15:19:53Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.10337v3"], "summary": ["  Generative adversarial networks (GAN) are a powerful subclass of generative\nmodels. Despite a very rich research activity leading to numerous interesting\nGAN algorithms, it is still very hard to assess which algorithm(s) perform\nbetter than others. We conduct a neutral, multi-faceted large-scale empirical\nstudy on state-of-the art models and evaluation measures. We find that most\nmodels can reach similar scores with enough hyperparameter optimization and\nrandom restarts. This suggests that improvements can arise from a higher\ncomputational budget and tuning more than fundamental algorithmic changes. To\novercome some limitations of the current metrics, we also propose several data\nsets on which precision and recall can be computed. Our experimental results\nsuggest that future GAN research should be based on more systematic and\nobjective evaluation procedures. Finally, we did not find evidence that any of\nthe tested algorithms consistently outperforms the original one.\n"]},
{"authors": ["Elad Hoffer", "Itay Hubara", "Daniel Soudry"], "title": ["Fix your classifier: the marginal value of training the last weight\n  layer"], "date": ["2018-01-14T12:00:43Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1801.04540v2"], "summary": ["  Neural networks are commonly used as models for classification for a wide\nvariety of tasks. Typically, a learned affine transformation is placed at the\nend of such models, yielding a per-class value used for classification. This\nclassifier can have a vast number of parameters, which grows linearly with the\nnumber of possible classes, thus requiring increasingly more resources. In this\nwork we argue that this classifier can be fixed, up to a global scale constant,\nwith little or no loss of accuracy for most tasks, allowing memory and\ncomputational benefits. Moreover, we show that by initializing the classifier\nwith a Hadamard matrix we can speed up inference as well. We discuss the\nimplications for current understanding of neural network models.\n"]},
{"authors": ["Ziwei Ji", "Matus Telgarsky"], "title": ["Risk and parameter convergence of logistic regression"], "date": ["2018-03-20T08:47:27Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07300v1"], "summary": ["  The logistic loss is strictly convex and does not attain its infimum;\nconsequently the solutions of logistic regression are in general off at\ninfinity. This work provides a convergence analysis of gradient descent applied\nto logistic regression under no assumptions on the problem instance. Firstly,\nthe risk is shown to converge at a rate $\\mathcal{O}(\\ln(t)^2/t)$. Secondly,\nthe parameter convergence is characterized along a unique pair of complementary\nsubspaces defined by the problem instance: one subspace along which strong\nconvexity induces parameters to converge at rate\n$\\mathcal{O}(\\ln(t)^2/\\sqrt{t})$, and its orthogonal complement along which\nseparability induces parameters to converge in direction at rate\n$\\mathcal{O}(\\ln\\ln(t) / \\ln(t))$.\n"]},
{"authors": ["Zhenglin Wu", "Haohan Wang", "Mingze Cao", "Yin Chen", "Eric P. Xing"], "title": ["Fair Deep Learning Prediction for Healthcare Applications with\n  Confounder Filtering"], "date": ["2018-03-20T07:24:40Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07276v1"], "summary": ["  The rapid development of deep learning methods has permitted the fast and\naccurate medical decision making from complex structured data, like CT images\nor MRI. However, some problems still exist in such applications that may lead\nto imperfect predictions. Previous observations have shown that, confounding\nfactors, if handled inappropriately, will lead to biased prediction results\ntowards some major properties of the data distribution. In other words, naively\napplying deep learning methods in these applications will lead to unfair\nprediction results for the minority group defined by the characteristics\nincluding age, gender, or even the hospital that collects the data, etc. In\nthis paper, extending previous successes in correcting confounders, we propose\na more stable method, namely Confounder Filtering, that can effectively reduce\nthe influence of confounding factors, leading to better generalizability of\ntrained discriminative deep neural networks, therefore, fairer prediction\nresults. Our experimental results indicate that the Confounder Filtering method\nis able to improve the performance for different neural networks including CNN,\nLSTM, and other arbitrary architecture, different data types including CT-scan,\nMRI, and EEG brain wave data, as well as different confounding factors\nincluding age, gender, and physical factors of medical devices etc\n"]},
{"authors": ["Ziping Zhao", "Daniel P. Palomar"], "title": ["Sparse Reduced Rank Regression With Nonconvex Regularization"], "date": ["2018-03-20T04:07:02Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07247v1"], "summary": ["  In this paper, the estimation problem for sparse reduced rank regression\n(SRRR) model is considered. The SRRR model is widely used for dimension\nreduction and variable selection with applications in signal processing,\neconometrics, etc. The problem is formulated to minimize the least squares loss\nwith a sparsity-inducing penalty considering an orthogonality constraint.\nConvex sparsity-inducing functions have been used for SRRR in literature. In\nthis work, a nonconvex function is proposed for better sparsity inducing. An\nefficient algorithm is developed based on the alternating minimization (or\nprojection) method to solve the nonconvex optimization problem. Numerical\nsimulations show that the proposed algorithm is much more efficient compared to\nthe benchmark methods and the nonconvex function can result in a better\nestimation accuracy.\n"]},
{"authors": ["Cathy Wu", "Aravind Rajeswaran", "Yan Duan", "Vikash Kumar", "Alexandre M Bayen", "Sham Kakade", "Igor Mordatch", "Pieter Abbeel"], "title": ["Variance Reduction for Policy Gradient with Action-Dependent Factorized\n  Baselines"], "date": ["2018-03-20T03:52:04Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07246v1"], "summary": ["  Policy gradient methods have enjoyed great success in deep reinforcement\nlearning but suffer from high variance of gradient estimates. The high variance\nproblem is particularly exasperated in problems with long horizons or\nhigh-dimensional action spaces. To mitigate this issue, we derive a bias-free\naction-dependent baseline for variance reduction which fully exploits the\nstructural form of the stochastic policy itself and does not make any\nadditional assumptions about the MDP. We demonstrate and quantify the benefit\nof the action-dependent baseline through both theoretical analysis as well as\nnumerical results, including an analysis of the suboptimality of the optimal\nstate-dependent baseline. The result is a computationally efficient policy\ngradient algorithm, which scales to high-dimensional control problems, as\ndemonstrated by a synthetic 2000-dimensional target matching task. Our\nexperimental results indicate that action-dependent baselines allow for faster\nlearning on standard reinforcement learning benchmarks and high-dimensional\nhand manipulation and synthetic tasks. Finally, we show that the general idea\nof including additional information in baselines for improved variance\nreduction can be extended to partially observed and multi-agent tasks.\n"]},
{"authors": ["Carlo Baldassi", "Federica Gerace", "Hilbert J. Kappen", "Carlo Lucibello", "Luca Saglietti", "Enzo Tartaglione", "Riccardo Zecchina"], "title": ["On the role of synaptic stochasticity in training low-precision neural\n  networks"], "date": ["2017-10-26T17:42:23Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.09825v2"], "summary": ["  Stochasticity and limited precision of synaptic weights in neural network\nmodels are key aspects of both biological and hardware modeling of learning\nprocesses. Here we show that a neural network model with stochastic binary\nweights naturally gives prominence to exponentially rare dense regions of\nsolutions with a number of desirable properties such as robustness and good\ngeneralization performance, while typical solutions are isolated and hard to\nfind. Binary solutions of the standard perceptron problem are obtained from a\nsimple gradient descent procedure on a set of real values parametrizing a\nprobability distribution over the binary synapses. Both analytical and\nnumerical results are presented. An algorithmic extension aimed at training\ndiscrete deep neural networks is also investigated.\n"]},
{"authors": ["Frank Nielsen", "Ga\u00ebtan Hadjeres"], "title": ["Monte Carlo Information Geometry: The dually flat case"], "date": ["2018-03-20T02:39:37Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07225v1"], "summary": ["  Exponential families and mixture families are parametric probability models\nthat can be geometrically studied as smooth statistical manifolds with respect\nto any statistical divergence like the Kullback-Leibler (KL) divergence or the\nHellinger divergence. When equipping a statistical manifold with the KL\ndivergence, the induced manifold structure is dually flat, and the KL\ndivergence between distributions amounts to an equivalent Bregman divergence on\ntheir corresponding parameters. In practice, the corresponding Bregman\ngenerators of mixture/exponential families require to perform definite integral\ncalculus that can either be too time-consuming (for exponentially large\ndiscrete support case) or even do not admit closed-form formula (for continuous\nsupport case). In these cases, the dually flat construction remains theoretical\nand cannot be used by information-geometric algorithms. To bypass this problem,\nwe consider performing stochastic Monte Carlo (MC) estimation of those\nintegral-based mixture/exponential family Bregman generators. We show that,\nunder natural assumptions, these MC generators are almost surely Bregman\ngenerators. We define a series of dually flat information geometries, termed\nMonte Carlo Information Geometries, that increasingly-finely approximate the\nuntractable geometry. The advantage of this MCIG is that it allows a practical\nuse of the Bregman algorithmic toolbox on a wide range of probability\ndistribution families. We demonstrate our approach with a clustering task on a\nmixture family manifold.\n"]},
{"authors": ["Kazuyuki Tanaka", "Masamichi Nakamura", "Shun Kataoka", "Masayuki Ohzeki", "Muneki Yasuda"], "title": ["Momentum-Space Renormalization Group Transformation in Bayesian Image\n  Modeling by Gaussian Graphical Model"], "date": ["2018-03-20T01:29:13Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1804.00727v1"], "summary": ["  A new Bayesian modeling method is proposed by combining the maximization of\nthe marginal likelihood with a momentum-space renormalization group\ntransformation for Gaussian graphical models. Moreover, we present a scheme for\ncomputint the statistical averages of hyperparameters and mean square errors in\nour proposed method based on a momentumspace renormalization transformation.\n"]},
{"authors": ["Timur Garipov", "Pavel Izmailov", "Dmitrii Podoprikhin", "Dmitry Vetrov", "Andrew Gordon Wilson"], "title": ["Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs"], "date": ["2018-02-27T17:13:28Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.10026v3"], "summary": ["  The loss functions of deep neural networks are complex and their geometric\nproperties are not well understood. We show that the optima of these complex\nloss functions are in fact connected by simple curves, such as a polygonal\nchain with only one bend, over which training and test accuracy are nearly\nconstant. We introduce a training procedure to discover these high-accuracy\npathways between modes. Inspired by this new geometric insight, we also propose\na new ensembling method entitled Fast Geometric Ensembling (FGE). Using FGE we\ncan train high-performing ensembles in the time required to train a single\nmodel. We achieve improved performance compared to the recent state-of-the-art\nSnapshot Ensembles, on CIFAR-10 and CIFAR-100, using state-of-the-art deep\nresidual networks. On ImageNet we improve the top-1 error-rate of a pre-trained\nResNet by 0.56% by running FGE for just 5 epochs.\n"]},
{"authors": ["Raunak Dey", "Zhongjie Lu", "Yi Hong"], "title": ["Diagnostic Classification Of Lung Nodules Using 3D Neural Networks"], "date": ["2018-03-19T23:02:37Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07192v1"], "summary": ["  Lung cancer is the leading cause of cancer-related death worldwide. Early\ndiagnosis of pulmonary nodules in Computed Tomography (CT) chest scans provides\nan opportunity for designing effective treatment and making financial and care\nplans. In this paper, we consider the problem of diagnostic classification\nbetween benign and malignant lung nodules in CT images, which aims to learn a\ndirect mapping from 3D images to class labels. To achieve this goal, four\ntwo-pathway Convolutional Neural Networks (CNN) are proposed, including a basic\n3D CNN, a novel multi-output network, a 3D DenseNet, and an augmented 3D\nDenseNet with multi-outputs. These four networks are evaluated on the public\nLIDC-IDRI dataset and outperform most existing methods. In particular, the 3D\nmulti-output DenseNet (MoDenseNet) achieves the state-of-the-art classification\naccuracy on the task of end-to-end lung nodule diagnosis. In addition, the\nnetworks pretrained on the LIDC-IDRI dataset can be further extended to handle\nsmaller datasets using transfer learning. This is demonstrated on our dataset\nwith encouraging prediction accuracy in lung nodule classification.\n"]},
{"authors": ["Tyler M. Tomita", "James Browne", "Cencheng Shen", "Carey E. Priebe", "Randal Burns", "Mauro Maggioni", "Joshua T. Vogelstein"], "title": ["Randomer Forests"], "date": ["2015-06-10T17:55:51Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1506.03410v3"], "summary": ["  Ensemble methods -- particularly those based on decision trees -- have\nrecently demonstrated superior performance in a variety of machine learning\nsettings. Specifically, Random Forest (RF) was found to outperform >100 other\nmethods in several manuscripts, and gradient boosting trees have been a crucial\ncomponent of several recent Kaggle competition victories. Building off these\nsuccesses and recent advances in sparse learning and random matrix theory, we\npropose a novel ensemble tree method called \"Randomer Forest\" (RerF). The key\nintuition behind RerF is that we can use sparse linear combinations at each\ndecision node rather than just one feature (as in RF) or all of them (as in\nRotation Forests). RerF significantly outperforms other methods on a standard\nbenchmark suite containing 105 problems with varying dimension, sample size,\nand number of classes. Moreover, we provide an implementation that scales as or\nmore efficiently than other available packages. Via a combination of basic\nprinciples, theory, and extensive numerical experiments, we demonstrate why,\nwhen, and how RerF achieves its performance properties.\n"]},
{"authors": ["Aleksandar Nikolov", "Mohit Singh", "Uthaipon Tao Tantipongpipat"], "title": ["Proportional Volume Sampling and Approximation Algorithms for A-Optimal\n  Design"], "date": ["2018-02-22T22:02:42Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.08318v2"], "summary": ["  We study the $A$-optimal design problem where we are given vectors\n$v_1,\\ldots,v_n\\in\\mathbb{R}^d$, an integer $k\\geq d$, and the goal is to\nselect a set $S$ of $k$ vectors that minimizes the trace of $(\\sum_{i\\in\nS}v_iv_i^\\top)^{-1}$. Traditionally, the problem is an instance of optimal\ndesign of experiments in statistics where each vector corresponds to a linear\nmeasurement of an unknown vector and the goal is to pick $k$ of them that\nminimize the average variance of the error in the maximum likelihood estimate\nof the vector being measured. The problem also finds applications in sensor\nplacement in wireless networks, sparse least squares regression, feature\nselection for $k$-means clustering, and matrix approximation. In this paper, we\nintroduce proportional volume sampling to obtain improved approximation\nalgorithms for $A$-optimal design.\n  Given a matrix, proportional volume sampling picks a set of columns $S$ of\nsize $k$ with probability proportional to $\\mu(S)$ times $\\det(\\sum_{i\\in\nS}v_iv_i^\\top)$ for some measure $\\mu$. Our main result is to show the\napproximability of the $A$-optimal design problem can be reduced to approximate\nindependence properties of the measure $\\mu$. We appeal to hard-core\ndistributions as candidate distributions $\\mu$ that allow us to obtain improved\napproximation algorithms for the $A$-optimal design. Our results include a\n$d$-approximation when $k=d$, an $(1+\\epsilon)$-approximation when\n$k=\\Omega\\left(\\frac{d}{\\epsilon}+\\frac{1}{\\epsilon^2}\\log\\frac{1}{\\epsilon}\\right)$\nand $\\frac{k}{k-d+1}$-approximation when repetitions of vectors are allowed in\nthe solution. We consider generalization of the problem for $k\\leq d$ and\nobtain a $k$-approximation. The last result implies a restricted invertibility\nprinciple for the harmonic mean of singular values. We also show that the\nproblem is $\\mathsf{NP}$-hard to approximate within a fixed constant when\n$k=d$.\n"]},
{"authors": ["Greg Lewis", "Vasilis Syrgkanis"], "title": ["Adversarial Generalized Method of Moments"], "date": ["2018-03-19T21:02:51Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07164v1"], "summary": ["  We provide an approach for learning deep neural net representations of models\ndescribed via conditional moment restrictions. Conditional moment restrictions\nare widely used, as they are the language by which social scientists describe\nthe assumptions they make to enable causal inference. We formulate the problem\nof estimating the underling model as a zero-sum game between a modeler and an\nadversary and apply adversarial training. Our approach is similar in nature to\nGenerative Adversarial Networks (GAN), though here the modeler is learning a\nrepresentation of a function that satisfies a continuum of moment conditions\nand the adversary is identifying violating moments. We outline ways of\nconstructing effective adversaries in practice, including kernels centered by\nk-means clustering, and random forests. We examine the practical performance of\nour approach in the setting of non-parametric instrumental variable regression.\n"]},
{"authors": ["G\u00e1bor Petneh\u00e1zi", "J\u00f3zsef G\u00e1ll"], "title": ["Exploring the predictability of range-based volatility estimators using\n  RNNs"], "date": ["2018-03-19T20:31:09Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07152v1"], "summary": ["  We investigate the predictability of several range-based stock volatility\nestimators, and compare them to the standard close-to-close estimator which is\nmost commonly acknowledged as the volatility. The patterns of volatility\nchanges are analyzed using LSTM recurrent neural networks, which are a state of\nthe art method of sequence learning. We implement the analysis on all current\nconstituents of the Dow Jones Industrial Average index, and report averaged\nevaluation results. We find that changes in the values of range-based\nestimators are more predictable than that of the estimator using daily closing\nvalues only.\n"]},
{"authors": ["Jiaqi Mu", "Suma Bhat", "Pramod Viswanath"], "title": ["All-but-the-Top: Simple and Effective Postprocessing for Word\n  Representations"], "date": ["2017-02-05T15:43:07Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1702.01417v2"], "summary": ["  Real-valued word representations have transformed NLP applications; popular\nexamples are word2vec and GloVe, recognized for their ability to capture\nlinguistic regularities. In this paper, we demonstrate a {\\em very simple}, and\nyet counter-intuitive, postprocessing technique -- eliminate the common mean\nvector and a few top dominating directions from the word vectors -- that\nrenders off-the-shelf representations {\\em even stronger}. The postprocessing\nis empirically validated on a variety of lexical-level intrinsic tasks (word\nsimilarity, concept categorization, word analogy) and sentence-level tasks\n(semantic textural similarity and { text classification}) on multiple datasets\nand with a variety of representation methods and hyperparameter choices in\nmultiple languages; in each case, the processed representations are\nconsistently better than the original ones.\n"]},
{"authors": ["Dong Xia", "Ming Yuan", "Cun-Hui Zhang"], "title": ["Statistically Optimal and Computationally Efficient Low Rank Tensor\n  Completion from Noisy Entries"], "date": ["2017-11-14T03:46:05Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.04934v2"], "summary": ["  In this article, we develop methods for estimating a low rank tensor from\nnoisy observations on a subset of its entries to achieve both statistical and\ncomputational efficiencies. There have been a lot of recent interests in this\nproblem of noisy tensor completion. Much of the attention has been focused on\nthe fundamental computational challenges often associated with problems\ninvolving higher order tensors, yet very little is known about their\nstatistical performance. To fill in this void, in this article, we characterize\nthe fundamental statistical limits of noisy tensor completion by establishing\nminimax optimal rates of convergence for estimating a $k$th order low rank\ntensor under the general $\\ell_p$ ($1\\le p\\le 2$) norm which suggest\nsignificant room for improvement over the existing approaches. Furthermore, we\npropose a polynomial-time computable estimating procedure based upon power\niteration and a second-order spectral initialization that achieves the optimal\nrates of convergence. Our method is fairly easy to implement and numerical\nexperiments are presented to further demonstrate the practical merits of our\nestimator.\n"]},
{"authors": ["Gonzalo Rios", "Felipe Tobar"], "title": ["Learning non-Gaussian Time Series using the Box-Cox Gaussian Process"], "date": ["2018-03-19T18:21:34Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07102v1"], "summary": ["  Gaussian processes (GPs) are Bayesian nonparametric generative models that\nprovide interpretability of hyperparameters, admit closed-form expressions for\ntraining and inference, and are able to accurately represent uncertainty. To\nmodel general non-Gaussian data with complex correlation structure, GPs can be\npaired with an expressive covariance kernel and then fed into a nonlinear\ntransformation (or warping). However, overparametrising the kernel and the\nwarping is known to, respectively, hinder gradient-based training and make the\npredictions computationally expensive. We remedy this issue by (i) training the\nmodel using derivative-free global-optimisation techniques so as to find\nmeaningful maxima of the model likelihood, and (ii) proposing a warping\nfunction based on the celebrated Box-Cox transformation that requires minimal\nnumerical approximations---unlike existing warped GP models. We validate the\nproposed approach by first showing that predictions can be computed\nanalytically, and then on a learning, reconstruction and forecasting experiment\nusing real-world datasets.\n"]},
{"authors": ["Qi Liu", "Tao Liu", "Zihao Liu", "Yanzhi Wang", "Yier Jin", "Wujie Wen"], "title": ["Security Analysis and Enhancement of Model Compressed Deep Learning\n  Systems under Adversarial Attacks"], "date": ["2018-02-14T16:31:35Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.05193v2"], "summary": ["  DNN is presenting human-level performance for many complex intelligent tasks\nin real-world applications. However, it also introduces ever-increasing\nsecurity concerns. For example, the emerging adversarial attacks indicate that\neven very small and often imperceptible adversarial input perturbations can\neasily mislead the cognitive function of deep learning systems (DLS). Existing\nDNN adversarial studies are narrowly performed on the ideal software-level DNN\nmodels with a focus on single uncertainty factor, i.e. input perturbations,\nhowever, the impact of DNN model reshaping on adversarial attacks, which is\nintroduced by various hardware-favorable techniques such as hash-based weight\ncompression during modern DNN hardware implementation, has never been\ndiscussed. In this work, we for the first time investigate the multi-factor\nadversarial attack problem in practical model optimized deep learning systems\nby jointly considering the DNN model-reshaping (e.g. HashNet based deep\ncompression) and the input perturbations. We first augment adversarial example\ngenerating method dedicated to the compressed DNN models by incorporating the\nsoftware-based approaches and mathematical modeled DNN reshaping. We then\nconduct a comprehensive robustness and vulnerability analysis of deep\ncompressed DNN models under derived adversarial attacks. A defense technique\nnamed \"gradient inhibition\" is further developed to ease the generating of\nadversarial examples thus to effectively mitigate adversarial attacks towards\nboth software and hardware-oriented DNNs. Simulation results show that\n\"gradient inhibition\" can decrease the average success rate of adversarial\nattacks from 87.99% to 4.77% (from 86.74% to 4.64%) on MNIST (CIFAR-10)\nbenchmark with marginal accuracy degradation across various DNNs.\n"]},
{"authors": ["Hanlin Tang", "Xiangru Lian", "Ming Yan", "Ce Zhang", "Ji Liu"], "title": ["D$^2$: Decentralized Training over Decentralized Data"], "date": ["2018-03-19T17:59:11Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07068v1"], "summary": ["  While training a machine learning model using multiple workers, each of which\ncollects data from their own data sources, it would be most useful when the\ndata collected from different workers can be {\\em unique} and {\\em different}.\nIronically, recent analysis of decentralized parallel stochastic gradient\ndescent (D-PSGD) relies on the assumption that the data hosted on different\nworkers are {\\em not too different}. In this paper, we ask the question: {\\em\nCan we design a decentralized parallel stochastic gradient descent algorithm\nthat is less sensitive to the data variance across workers?} In this paper, we\npresent D$^2$, a novel decentralized parallel stochastic gradient descent\nalgorithm designed for large data variance \\xr{among workers} (imprecisely,\n\"decentralized\" data). The core of D$^2$ is a variance blackuction extension of\nthe standard D-PSGD algorithm, which improves the convergence rate from\n$O\\left({\\sigma \\over \\sqrt{nT}} + {(n\\zeta^2)^{\\frac{1}{3}} \\over\nT^{2/3}}\\right)$ to $O\\left({\\sigma \\over \\sqrt{nT}}\\right)$ where $\\zeta^{2}$\ndenotes the variance among data on different workers. As a result, D$^2$ is\nrobust to data variance among workers. We empirically evaluated D$^2$ on image\nclassification tasks where each worker has access to only the data of a limited\nset of labels, and find that D$^2$ significantly outperforms D-PSGD.\n"]},
{"authors": ["A. Rupam Mahmood", "Dmytro Korenkevych", "Brent J. Komer", "James Bergstra"], "title": ["Setting up a Reinforcement Learning Task with a Real-World Robot"], "date": ["2018-03-19T17:59:05Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07067v1"], "summary": ["  Reinforcement learning is a promising approach to developing hard-to-engineer\nadaptive solutions for complex and diverse robotic tasks. However, learning\nwith real-world robots is often unreliable and difficult, which resulted in\ntheir low adoption in reinforcement learning research. This difficulty is\nworsened by the lack of guidelines for setting up learning tasks with robots.\nIn this work, we develop a learning task with a UR5 robotic arm to bring to\nlight some key elements of a task setup and study their contributions to the\nchallenges with robots. We find that learning performance can be highly\nsensitive to the setup, and thus oversights and omissions in setup details can\nmake effective learning, reproducibility, and fair comparison hard. Our study\nsuggests some mitigating steps to help future experimenters avoid difficulties\nand pitfalls. We show that highly reliable and repeatable experiments can be\nperformed in our setup, indicating the possibility of reinforcement learning\nresearch extensively based on real-world robots.\n"]},
{"authors": ["Geoff Pleiss", "Jacob R. Gardner", "Kilian Q. Weinberger", "Andrew Gordon Wilson"], "title": ["Constant-Time Predictive Distributions for Gaussian Processes"], "date": ["2018-03-16T02:31:45Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06058v2"], "summary": ["  One of the most compelling features of Gaussian process (GP) regression is\nits ability to provide well calibrated posterior distributions. Recent advances\nin inducing point methods have drastically sped up marginal likelihood and\nposterior mean computations, leaving posterior covariance estimation and\nsampling as the remaining computational bottlenecks. In this paper we address\nthis shortcoming by using the Lanczos decomposition algorithm to rapidly\napproximate the predictive covariance matrix. Our approach, which we refer to\nas LOVE (LanczOs Variance Estimates), substantially reduces the time and space\ncomplexity over any previous method. In practice, it can compute predictive\ncovariances up to 2,000 times faster and draw samples 18,000 time faster than\nexisting methods, all without sacrificing accuracy.\n"]},
{"authors": ["Horia Mania", "Aurelia Guy", "Benjamin Recht"], "title": ["Simple random search provides a competitive approach to reinforcement\n  learning"], "date": ["2018-03-19T17:35:14Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07055v1"], "summary": ["  A common belief in model-free reinforcement learning is that methods based on\nrandom search in the parameter space of policies exhibit significantly worse\nsample complexity than those that explore the space of actions. We dispel such\nbeliefs by introducing a random search method for training static, linear\npolicies for continuous control problems, matching state-of-the-art sample\nefficiency on the benchmark MuJoCo locomotion tasks. Our method also finds a\nnearly optimal controller for a challenging instance of the Linear Quadratic\nRegulator, a classical problem in control theory, when the dynamics are not\nknown. Computationally, our random search algorithm is at least 15 times more\nefficient than the fastest competing model-free methods on these benchmarks. We\ntake advantage of this computational efficiency to evaluate the performance of\nour method over hundreds of random seeds and many different hyperparameter\nconfigurations for each benchmark task. Our simulations highlight a high\nvariability in performance in these benchmark tasks, suggesting that commonly\nused estimations of sample efficiency do not adequately evaluate the\nperformance of RL algorithms.\n"]},
{"authors": ["Nicolai Baldin", "Quentin Berthet"], "title": ["Optimal link prediction with matrix logistic regression"], "date": ["2018-03-19T17:32:50Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07054v1"], "summary": ["  We consider the problem of link prediction, based on partial observation of a\nlarge network, and on side information associated to its vertices. The\ngenerative model is formulated as a matrix logistic regression. The performance\nof the model is analysed in a high-dimensional regime under a structural\nassumption. The minimax rate for the Frobenius-norm risk is established and a\ncombinatorial estimator based on the penalised maximum likelihood approach is\nshown to achieve it. Furthermore, it is shown that this rate cannot be attained\nby any (randomised) algorithm computable in polynomial time under a\ncomputational complexity assumption.\n"]},
{"authors": ["Elena Facco", "Maria d'Errico", "Alex Rodriguez", "Alessandro Laio"], "title": ["Estimating the intrinsic dimension of datasets by a minimal neighborhood\n  information"], "date": ["2018-03-19T15:31:41Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06992v1"], "summary": ["  Analyzing large volumes of high-dimensional data is an issue of fundamental\nimportance in data science, molecular simulations and beyond. Several\napproaches work on the assumption that the important content of a dataset\nbelongs to a manifold whose Intrinsic Dimension (ID) is much lower than the\ncrude large number of coordinates. Such manifold is generally twisted and\ncurved, in addition points on it will be non-uniformly distributed: two factors\nthat make the identification of the ID and its exploitation really hard. Here\nwe propose a new ID estimator using only the distance of the first and the\nsecond nearest neighbor of each point in the sample. This extreme minimality\nenables us to reduce the effects of curvature, of density variation, and the\nresulting computational cost. The ID estimator is theoretically exact in\nuniformly distributed datasets, and provides consistent measures in general.\nWhen used in combination with block analysis, it allows discriminating the\nrelevant dimensions as a function of the block size. This allows estimating the\nID even when the data lie on a manifold perturbed by a high-dimensional noise,\na situation often encountered in real world data sets. We demonstrate the\nusefulness of the approach on molecular simulations and image analysis.\n"]},
{"authors": ["George C. Linderman", "Stefan Steinerberger"], "title": ["Numerical Integration on Graphs: where to sample and how to weigh"], "date": ["2018-03-19T15:27:59Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06989v1"], "summary": ["  Let $G=(V,E,w)$ be a finite, connected graph with weighted edges. We are\ninterested in the problem of finding a subset $W \\subset V$ of vertices and\nweights $a_w$ such that $$ \\frac{1}{|V|}\\sum_{v \\in V}^{}{f(v)} \\sim \\sum_{w\n\\in W}{a_w f(w)}$$ for functions $f:V \\rightarrow \\mathbb{R}$ that are `smooth'\nwith respect to the geometry of the graph. The main application are problems\nwhere $f$ is known to somehow depend on the underlying graph but is expensive\nto evaluate on even a single vertex. We prove an inequality showing that the\nintegration problem can be rewritten as a geometric problem (`the optimal\npacking of heat balls'). We discuss how one would construct approximate\nsolutions of the heat ball packing problem; numerical examples demonstrate the\nefficiency of the method.\n"]},
{"authors": ["Xiaolin Huang", "Lei Shi", "Ming Yan", "Johan A. K. Suykens"], "title": ["Pinball Loss Minimization for One-bit Compressive Sensing: Convex Models\n  and Algorithms"], "date": ["2015-05-14T21:51:40Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1505.03898v2"], "summary": ["  The one-bit quantization is implemented by one single comparator that\noperates at low power and a high rate. Hence one-bit compressive sensing\n(1bit-CS) becomes attractive in signal processing. When measurements are\ncorrupted by noise during signal acquisition and transmission, 1bit-CS is\nusually modeled as minimizing a loss function with a sparsity constraint. The\none-sided $\\ell_1$ loss and the linear loss are two popular loss functions for\n1bit-CS. To improve the decoding performance on noisy data, we consider the\npinball loss, which provides a bridge between the one-sided $\\ell_1$ loss and\nthe linear loss. Using the pinball loss, two convex models, an elastic-net\npinball model and its modification with the $\\ell_1$-norm constraint, are\nproposed. To efficiently solve them, the corresponding dual coordinate ascent\nalgorithms are designed and their convergence is proved. The numerical\nexperiments confirm the effectiveness of the proposed algorithms and the\nperformance of the pinball loss minimization for 1bit-CS.\n"]},
{"authors": ["Cihang Xie", "Zhishuai Zhang", "Jianyu Wang", "Yuyin Zhou", "Zhou Ren", "Alan Yuille"], "title": ["Improving Transferability of Adversarial Examples with Input Diversity"], "date": ["2018-03-19T15:07:51Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06978v1"], "summary": ["  Though convolutional neural networks have achieved state-of-the-art\nperformance on various vision tasks, they are extremely vulnerable to\nadversarial examples, which are obtained by adding human-imperceptible\nperturbations to the original images. Adversarial examples can thus be used as\nan useful tool to evaluate and select the most robust models in safety-critical\napplications. However, most of the existing adversarial attacks only achieve\nrelatively low success rates under the challenging black-box setting, where the\nattackers have no knowledge of the model structure and parameters. To this end,\nwe propose to improve the transferability of adversarial examples by creating\ndiverse input patterns. Instead of only using the original images to generate\nadversarial examples, our method applies random transformations to the input\nimages at each iteration. Extensive experiments on ImageNet show that the\nproposed attack method can generate adversarial examples that transfer much\nbetter to different networks than existing baselines. To further improve the\ntransferability, we (1) integrate the recently proposed momentum method into\nthe attack process; and (2) attack an ensemble of networks simultaneously. By\nevaluating our method against top defense submissions and official baselines\nfrom NIPS 2017 adversarial competition, this enhanced attack reaches an average\nsuccess rate of 73.0%, which outperforms the top 1 attack submission in the\nNIPS competition by a large margin of 6.6%. We hope that our proposed attack\nstrategy can serve as a benchmark for evaluating the robustness of networks to\nadversaries and the effectiveness of different defense methods in future. The\ncode is public available at https://github.com/cihangxie/DI-2-FGSM.\n"]},
{"authors": ["Lilian Besson", "Emilie Kaufmann"], "title": ["What Doubling Tricks Can and Can't Do for Multi-Armed Bandits"], "date": ["2018-03-19T15:02:15Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06971v1"], "summary": ["  An online reinforcement learning algorithm is anytime if it does not need to\nknow in advance the horizon T of the experiment. A well-known technique to\nobtain an anytime algorithm from any non-anytime algorithm is the \"Doubling\nTrick\". In the context of adversarial or stochastic multi-armed bandits, the\nperformance of an algorithm is measured by its regret, and we study two\nfamilies of sequences of growing horizons (geometric and exponential) to\ngeneralize previously known results that certain doubling tricks can be used to\nconserve certain regret bounds. In a broad setting, we prove that a geometric\ndoubling trick can be used to conserve (minimax) bounds in $R\\_T = O(\\sqrt{T})$\nbut cannot conserve (distribution-dependent) bounds in $R\\_T = O(\\log T)$. We\ngive insights as to why exponential doubling tricks may be better, as they\nconserve bounds in $R\\_T = O(\\log T)$, and are close to conserving bounds in\n$R\\_T = O(\\sqrt{T})$.\n"]},
{"authors": ["M. Baity-Jesi", "L. Sagun", "M. Geiger", "S. Spigler", "G. Ben Arous", "C. Cammarota", "Y. LeCun", "M. Wyart", "G. Biroli"], "title": ["Comparing Dynamics: Deep Neural Networks versus Glassy Systems"], "date": ["2018-03-19T14:59:01Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06969v1"], "summary": ["  We analyze numerically the training dynamics of deep neural networks (DNN) by\nusing methods developed in statistical physics of glassy systems. The two main\nissues we address are the complexity of the loss-landscape and of the dynamics\nwithin it, and to what extent DNNs share similarities with glassy systems. Our\nfindings, obtained for different architectures and datasets, suggest that\nduring the training process the dynamics slows down because of an increasingly\nlarge number of flat directions. At large times, when the loss is approaching\nzero, the system diffuses at the bottom of the landscape. Despite some\nsimilarities with the dynamics of mean-field glassy systems, in particular, the\nabsence of barrier crossing, we find distinctive dynamical behaviors in the two\ncases, showing that the statistical properties of the corresponding loss and\nenergy landscapes are different. In contrast, when the network is\nunder-parametrized we observe a typical glassy behavior, thus suggesting the\nexistence of different phases depending on whether the network is\nunder-parametrized or over-parametrized.\n"]},
{"authors": ["Ari S. Morcos", "David G. T. Barrett", "Neil C. Rabinowitz", "Matthew Botvinick"], "title": ["On the importance of single directions for generalization"], "date": ["2018-03-19T14:42:19Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06959v1"], "summary": ["  Despite their ability to memorize large datasets, deep neural networks often\nachieve good generalization performance. However, the differences between the\nlearned solutions of networks which generalize and those which do not remain\nunclear. Additionally, the tuning properties of single directions (defined as\nthe activation of a single unit or some linear combination of units in response\nto some input) have been highlighted, but their importance has not been\nevaluated. Here, we connect these lines of inquiry to demonstrate that a\nnetwork's reliance on single directions is a good predictor of its\ngeneralization performance, across networks trained on datasets with different\nfractions of corrupted labels, across ensembles of networks trained on datasets\nwith unmodified labels, across different hyperparameters, and over the course\nof training. While dropout only regularizes this quantity up to a point, batch\nnormalization implicitly discourages single direction reliance, in part by\ndecreasing the class selectivity of individual units. Finally, we find that\nclass selectivity is a poor predictor of task importance, suggesting not only\nthat networks which generalize well minimize their dependence on individual\nunits by reducing their selectivity, but also that individually selective units\nmay not be necessary for strong network performance.\n"]},
{"authors": ["Silvia L. Pintea", "Jan C. van Gemert", "Arnold W. M. Smeulders"], "title": ["Asymmetric kernel in Gaussian Processes for learning target variance"], "date": ["2018-03-19T14:34:35Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06952v1"], "summary": ["  This work incorporates the multi-modality of the data distribution into a\nGaussian Process regression model. We approach the problem from a\ndiscriminative perspective by learning, jointly over the training data, the\ntarget space variance in the neighborhood of a certain sample through metric\nlearning. We start by using data centers rather than all training samples.\nSubsequently, each center selects an individualized kernel metric. This enables\neach center to adjust the kernel space in its vicinity in correspondence with\nthe topology of the targets --- a multi-modal approach. We additionally add\ndescriptiveness by allowing each center to learn a precision matrix. We\ndemonstrate empirically the reliability of the model.\n"]},
{"authors": ["Justin Sirignano", "Rama Cont"], "title": ["Universal features of price formation in financial markets: perspectives\n  from Deep Learning"], "date": ["2018-03-19T13:46:37Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06917v1"], "summary": ["  Using a large-scale Deep Learning approach applied to a high-frequency\ndatabase containing billions of electronic market quotes and transactions for\nUS equities, we uncover nonparametric evidence for the existence of a universal\nand stationary price formation mechanism relating the dynamics of supply and\ndemand for a stock, as revealed through the order book, to subsequent\nvariations in its market price. We assess the model by testing its\nout-of-sample predictions for the direction of price moves given the history of\nprice and order flow, across a wide range of stocks and time periods. The\nuniversal price formation model is shown to exhibit a remarkably stable\nout-of-sample prediction accuracy across time, for a wide range of stocks from\ndifferent sectors. Interestingly, these results also hold for stocks which are\nnot part of the training sample, showing that the relations captured by the\nmodel are universal and not asset-specific.\n  The universal model --- trained on data from all stocks --- outperforms, in\nterms of out-of-sample prediction accuracy, asset-specific linear and nonlinear\nmodels trained on time series of any given stock, showing that the universal\nnature of price formation weighs in favour of pooling together financial data\nfrom various stocks, rather than designing asset- or sector-specific models as\ncommonly done. Standard data normalizations based on volatility, price level or\naverage spread, or partitioning the training data into sectors or categories\nsuch as large/small tick stocks, do not improve training results. On the other\nhand, inclusion of price and order flow history over many past observations is\nshown to improve forecasting performance, showing evidence of path-dependence\nin price dynamics.\n"]},
{"authors": ["Rui Shu", "Hung H. Bui", "Hirokazu Narui", "Stefano Ermon"], "title": ["A DIRT-T Approach to Unsupervised Domain Adaptation"], "date": ["2018-02-23T20:57:28Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.08735v2"], "summary": ["  Domain adaptation refers to the problem of leveraging labeled data in a\nsource domain to learn an accurate model in a target domain where labels are\nscarce or unavailable. A recent approach for finding a common representation of\nthe two domains is via domain adversarial training (Ganin & Lempitsky, 2015),\nwhich attempts to induce a feature extractor that matches the source and target\nfeature distributions in some feature space. However, domain adversarial\ntraining faces two critical limitations: 1) if the feature extraction function\nhas high-capacity, then feature distribution matching is a weak constraint, 2)\nin non-conservative domain adaptation (where no single classifier can perform\nwell in both the source and target domains), training the model to do well on\nthe source domain hurts performance on the target domain. In this paper, we\naddress these issues through the lens of the cluster assumption, i.e., decision\nboundaries should not cross high-density data regions. We propose two novel and\nrelated models: 1) the Virtual Adversarial Domain Adaptation (VADA) model,\nwhich combines domain adversarial training with a penalty term that punishes\nthe violation the cluster assumption; 2) the Decision-boundary Iterative\nRefinement Training with a Teacher (DIRT-T) model, which takes the VADA model\nas initialization and employs natural gradient steps to further minimize the\ncluster assumption violation. Extensive empirical results demonstrate that the\ncombination of these two models significantly improve the state-of-the-art\nperformance on the digit, traffic sign, and Wi-Fi recognition domain adaptation\nbenchmarks.\n"]},
{"authors": ["Yaniv Shachor", "Hayit Greenspan", "Jacob Goldberger"], "title": ["A Mixture of Views Network with Applications to the Classification of\n  Breast Microcalcifications"], "date": ["2018-03-19T13:11:10Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06898v1"], "summary": ["  In this paper we examine data fusion methods for multi-view data\nclassification. We present a decision concept which explicitly takes into\naccount the input multi-view structure, where for each case there is a\ndifferent subset of relevant views. This data fusion concept, which we dub\nMixture of Views, is implemented by a special purpose neural network\narchitecture. It is demonstrated on the task of classifying breast\nmicrocalcifications as benign or malignant based on CC and MLO mammography\nviews. The single view decisions are combined by a data-driven decision,\naccording to the relevance of each view in a given case, into a global\ndecision. The method is evaluated on a large multi-view dataset extracted from\nthe standardized digital database for screening mammography (DDSM). The\nexperimental results show that our method outperforms previously suggested\nfusion methods.\n"]},
{"authors": ["Andr\u00e9s Hoyos-Idrobo", "Ga\u00ebl Varoquaux", "Jonas Kahn", "Bertrand Thirion"], "title": ["Recursive nearest agglomeration (ReNA): fast clustering for\n  approximation of structured signals"], "date": ["2016-09-15T12:46:52Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1609.04608v2"], "summary": ["  In this work, we revisit fast dimension reduction approaches, as with random\nprojections and random sampling. Our goal is to summarize the data to decrease\ncomputational costs and memory footprint of subsequent analysis. Such dimension\nreduction can be very efficient when the signals of interest have a strong\nstructure, such as with images. We focus on this setting and investigate\nfeature clustering schemes for data reductions that capture this structure. An\nimpediment to fast dimension reduction is that good clustering comes with large\nalgorithmic costs. We address it by contributing a linear-time agglomerative\nclustering scheme, Recursive Nearest Agglomeration (ReNA). Unlike existing fast\nagglomerative schemes, it avoids the creation of giant clusters. We empirically\nvalidate that it approximates the data as well as traditional\nvariance-minimizing clustering schemes that have a quadratic complexity. In\naddition, we analyze signal approximation with feature clustering and show that\nit can remove noise, improving subsequent analysis steps. As a consequence,\ndata reduction by clustering features with ReNA yields very fast and accurate\nmodels, enabling to process large datasets on budget. Our theoretical analysis\nis backed by extensive experiments on publicly-available data that illustrate\nthe computation efficiency and the denoising properties of the resulting\ndimension reduction scheme.\n"]},
{"authors": ["Yuanzhi Li", "Tengyu Ma", "Hongyang Zhang"], "title": ["Algorithmic Regularization in Over-parameterized Matrix Sensing and\n  Neural Networks with Quadratic Activations"], "date": ["2017-12-26T08:04:43Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1712.09203v4"], "summary": ["  We show that the gradient descent algorithm provides an implicit\nregularization effect in the learning of over-parameterized matrix\nfactorization models and one-hidden-layer neural networks with quadratic\nactivations. Concretely, we show that given $\\tilde{O}(dr^{2})$ random linear\nmeasurements of a rank $r$ positive semidefinite matrix $X^{\\star}$, we can\nrecover $X^{\\star}$ by parameterizing it by $UU^\\top$ with $U\\in \\mathbb\nR^{d\\times d}$ and minimizing the squared loss, even if $r \\ll d$. We prove\nthat starting from a small initialization, gradient descent recovers\n$X^{\\star}$ in $\\tilde{O}(\\sqrt{r})$ iterations approximately. The results\nsolve the conjecture of Gunasekar et al.'17 under the restricted isometry\nproperty. The technique can be applied to analyzing neural networks with\none-hidden-layer quadratic activations with some technical modifications.\n"]},
{"authors": ["Yoshiaki Bando", "Masato Mimura", "Katsutoshi Itoyama", "Kazuyoshi Yoshii", "Tatsuya Kawahara"], "title": ["Statistical Speech Enhancement Based on Probabilistic Integration of\n  Variational Autoencoder and Non-Negative Matrix Factorization"], "date": ["2017-10-31T12:52:09Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.11439v4"], "summary": ["  This paper presents a statistical method of single-channel speech enhancement\nthat uses a variational autoencoder (VAE) as a prior distribution on clean\nspeech. A standard approach to speech enhancement is to train a deep neural\nnetwork (DNN) to take noisy speech as input and output clean speech. Although\nthis supervised approach requires a very large amount of pair data for\ntraining, it is not robust against unknown environments. Another approach is to\nuse non-negative matrix factorization (NMF) based on basis spectra trained on\nclean speech in advance and those adapted to noise on the fly. This\nsemi-supervised approach, however, causes considerable signal distortion in\nenhanced speech due to the unrealistic assumption that speech spectrograms are\nlinear combinations of the basis spectra. Replacing the poor linear generative\nmodel of clean speech in NMF with a VAE---a powerful nonlinear deep generative\nmodel---trained on clean speech, we formulate a unified probabilistic\ngenerative model of noisy speech. Given noisy speech as observed data, we can\nsample clean speech from its posterior distribution. The proposed method\noutperformed the conventional DNN-based method in unseen noisy environments.\n"]},
{"authors": ["Xinyuan Zhang", "Xin Yuan", "Lawrence Carin"], "title": ["Nonlocal Low-Rank Tensor Factor Analysis for Image Restoration"], "date": ["2018-03-19T03:48:14Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06795v1"], "summary": ["  Low-rank signal modeling has been widely leveraged to capture non-local\ncorrelation in image processing applications. We propose a new method that\nemploys low-rank tensor factor analysis for tensors generated by grouped image\npatches. The low-rank tensors are fed into the alternative direction multiplier\nmethod (ADMM) to further improve image reconstruction. The motivating\napplication is compressive sensing (CS), and a deep convolutional architecture\nis adopted to approximate the expensive matrix inversion in CS applications. An\niterative algorithm based on this low-rank tensor factorization strategy,\ncalled NLR-TFA, is presented in detail. Experimental results on noiseless and\nnoisy CS measurements demonstrate the superiority of the proposed approach,\nespecially at low CS sampling rates.\n"]},
{"authors": ["Urtats Etxegarai", "Eva Portillo", "Jon Irazusta", "Ander Arriandiaga", "Itziar Cabanes"], "title": ["Estimation of lactate threshold with machine learning techniques in\n  recreational runners"], "date": ["2018-03-15T23:11:59Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06030v2"], "summary": ["  Lactate threshold is considered an essential parameter when assessing\nperformance of elite and recreational runners and prescribing training\nintensities in endurance sports. However, the measurement of blood lactate\nconcentration requires expensive equipment and the extraction of blood samples,\nwhich are inconvenient for frequent monitoring. Furthermore, most recreational\nrunners do not have access to routine assessment of their physical fitness by\nthe aforementioned equipment so they are not able to calculate the lactate\nthreshold without resorting to an expensive and specialized centre. Therefore,\nthe main objective of this study is to create an intelligent system capable of\nestimating the lactate threshold of recreational athletes participating in\nendurance running sports. The solution here proposed is based on a machine\nlearning system which models the lactate evolution using recurrent neural\nnetworks and includes the proposal of standardization of the temporal axis as\nwell as a modification of the stratified sampling method. The results show that\nthe proposed system accurately estimates the lactate threshold of 89.52% of the\nathletes and its correlation with the experimentally measured lactate threshold\nis very high (R=0,89). Moreover, its behaviour with the test dataset is as good\nas with the training set, meaning that the generalization power of the model is\nhigh. Therefore, in this study a machine learning based system is proposed as\nalternative to the traditional invasive lactate threshold measurement tests for\nrecreational runners.\n"]},
{"authors": ["Tuomas Haarnoja", "Vitchyr Pong", "Aurick Zhou", "Murtaza Dalal", "Pieter Abbeel", "Sergey Levine"], "title": ["Composable Deep Reinforcement Learning for Robotic Manipulation"], "date": ["2018-03-19T01:17:16Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06773v1"], "summary": ["  Model-free deep reinforcement learning has been shown to exhibit good\nperformance in domains ranging from video games to simulated robotic\nmanipulation and locomotion. However, model-free methods are known to perform\npoorly when the interaction time with the environment is limited, as is the\ncase for most real-world robotic tasks. In this paper, we study how maximum\nentropy policies trained using soft Q-learning can be applied to real-world\nrobotic manipulation. The application of this method to real-world manipulation\nis facilitated by two important features of soft Q-learning. First, soft\nQ-learning can learn multimodal exploration strategies by learning policies\nrepresented by expressive energy-based models. Second, we show that policies\nlearned with soft Q-learning can be composed to create new policies, and that\nthe optimality of the resulting policy can be bounded in terms of the\ndivergence between the composed policies. This compositionality provides an\nespecially valuable tool for real-world manipulation, where constructing new\npolicies by composing existing skills can provide a large gain in efficiency\nover training from scratch. Our experimental evaluation demonstrates that soft\nQ-learning is substantially more sample efficient than prior model-free deep\nreinforcement learning methods, and that compositionality can be performed for\nboth simulated and real-world tasks.\n"]},
{"authors": ["Victor Chernozhukov", "Whitney Newey", "James Robins"], "title": ["Double/De-Biased Machine Learning Using Regularized Riesz Representers"], "date": ["2018-02-23T18:17:42Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.08667v2"], "summary": ["  We provide adaptive inference methods for linear functionals of sparse linear\napproximations to the conditional expectation function. Examples of such\nfunctionals include average derivatives, policy effects, average treatment\neffects, and many others. The construction relies on building Neyman-orthogonal\nequations that are approximately invariant to perturbations of the nuisance\nparameters, including the Riesz representer for the linear functionals. We use\nL1-regularized methods to learn approximations to the regression function and\nthe Riesz representer, and construct the estimator for the linear functionals\nas the solution to the orthogonal estimating equations. We establish that under\nweak assumptions the estimator concentrates in a 1/root n neighborhood of the\ntarget with deviations controlled by the normal laws, and the estimator attains\nthe semi-parametric efficiency bound in many cases. In particular, either the\napproximation to the regression function or the approximation to the Riesz\nrepresenter can be \"dense\" as long as one of them is sufficiently \"sparse\". Our\nmain results are non-asymptotic and imply asymptotic uniform validity over\nlarge classes of models.\n"]},
{"authors": ["Alexander Korotin", "Vladimir V'yugin", "Evgeny Burnaev"], "title": ["Aggregating Strategies for Long-term Forecasting"], "date": ["2018-03-18T20:04:07Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06727v1"], "summary": ["  The article is devoted to investigating the application of aggregating\nalgorithms to the problem of the long-term forecasting. We examine the classic\naggregating algorithms based on the exponential reweighing. For the general\nVovk's aggregating algorithm we provide its generalization for the long-term\nforecasting. For the special basic case of Vovk's algorithm we provide its two\nmodifications for the long-term forecasting. The first one is theoretically\nclose to an optimal algorithm and is based on replication of independent\ncopies. It provides the time-independent regret bound with respect to the best\nexpert in the pool. The second one is not optimal but is more practical and has\n$O(\\sqrt{T})$ regret bound, where $T$ is the length of the game.\n"]},
{"authors": ["Bowei Yan", "Purnamrita Sarkar", "Xiuyuan Cheng"], "title": ["Provable Estimation of the Number of Blocks in Block Models"], "date": ["2017-05-24T01:42:50Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1705.08580v3"], "summary": ["  Community detection is a fundamental unsupervised learning problem for\nunlabeled networks which has a broad range of applications. Many community\ndetection algorithms assume that the number of clusters $r$ is known apriori.\nIn this paper, we propose an approach based on semi-definite relaxations, which\ndoes not require prior knowledge of model parameters like many existing convex\nrelaxation methods and recovers the number of clusters and the clustering\nmatrix exactly under a broad parameter regime, with probability tending to one.\nOn a variety of simulated and real data experiments, we show that the proposed\nmethod often outperforms state-of-the-art techniques for estimating the number\nof clusters.\n"]},
{"authors": ["David Gamarnik", "Ilias Zadik"], "title": ["High Dimensional Linear Regression using Lattice Basis Reduction"], "date": ["2018-03-18T19:02:22Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06716v1"], "summary": ["  We consider a high dimensional linear regression problem where the goal is to\nefficiently recover an unknown vector $\\beta^*$ from $n$ noisy linear\nobservations $Y=X\\beta^*+W \\in \\mathbb{R}^n$, for known $X \\in \\mathbb{R}^{n\n\\times p}$ and unknown $W \\in \\mathbb{R}^n$. Unlike most of the literature on\nthis model we make no sparsity assumption on $\\beta^*$. Instead we adopt a\nregularization based on assuming that the underlying vectors $\\beta^*$ have\nrational entries with the same denominator $Q \\in \\mathbb{Z}_{>0}$. We call\nthis $Q$-rationality assumption.\n  We propose a new polynomial-time algorithm for this task which is based on\nthe seminal Lenstra-Lenstra-Lovasz (LLL) lattice basis reduction algorithm. We\nestablish that under the $Q$-rationality assumption, our algorithm recovers\nexactly the vector $\\beta^*$ for a large class of distributions for the iid\nentries of $X$ and non-zero noise $W$. We prove that it is successful under\nsmall noise, even when the learner has access to only one observation ($n=1$).\nFurthermore, we prove that in the case of the Gaussian white noise for $W$,\n$n=o\\left(p/\\log p\\right)$ and $Q$ sufficiently large, our algorithm tolerates\na nearly optimal information-theoretic level of the noise.\n"]},
{"authors": ["Xiaohan Yan", "Jacob Bien"], "title": ["Rare Feature Selection in High Dimensions"], "date": ["2018-03-18T15:15:49Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06675v1"], "summary": ["  It is common in modern prediction problems for many predictor variables to be\ncounts of rarely occurring events. This leads to design matrices in which many\ncolumns are highly sparse. The challenge posed by such \"rare features\" has\nreceived little attention despite its prevalence in diverse areas, ranging from\nnatural language processing (e.g., rare words) to biology (e.g., rare species).\nWe show, both theoretically and empirically, that not explicitly accounting for\nthe rareness of features can greatly reduce the effectiveness of an analysis.\nWe next propose a framework for aggregating rare features into denser features\nin a flexible manner that creates better predictors of the response. Our\nstrategy leverages side information in the form of a tree that encodes feature\nsimilarity.\n  We apply our method to data from TripAdvisor, in which we predict the\nnumerical rating of a hotel based on the text of the associated review. Our\nmethod achieves high accuracy by making effective use of rare words; by\ncontrast, the lasso is unable to identify highly predictive words if they are\ntoo rare. A companion R package, called rare, implements our new estimator,\nusing the alternating direction method of multipliers.\n"]},
{"authors": ["Garrett B. Goh", "Charles Siegel", "Abhinav Vishnu", "Nathan O. Hodas", "Nathan Baker"], "title": ["How Much Chemistry Does a Deep Neural Network Need to Know to Make\n  Accurate Predictions?"], "date": ["2017-10-05T23:53:59Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.02238v2"], "summary": ["  The meteoric rise of deep learning models in computer vision research, having\nachieved human-level accuracy in image recognition tasks is firm evidence of\nthe impact of representation learning of deep neural networks. In the chemistry\ndomain, recent advances have also led to the development of similar CNN models,\nsuch as Chemception, that is trained to predict chemical properties using\nimages of molecular drawings. In this work, we investigate the effects of\nsystematically removing and adding localized domain-specific information to the\nimage channels of the training data. By augmenting images with only 3\nadditional basic information, and without introducing any architectural\nchanges, we demonstrate that an augmented Chemception (AugChemception)\noutperforms the original model in the prediction of toxicity, activity, and\nsolvation free energy. Then, by altering the information content in the images,\nand examining the resulting model's performance, we also identify two distinct\nlearning patterns in predicting toxicity/activity as compared to solvation free\nenergy. These patterns suggest that Chemception is learning about its tasks in\nthe manner that is consistent with established knowledge. Thus, our work\ndemonstrates that advanced chemical knowledge is not a pre-requisite for deep\nlearning models to accurately predict complex chemical properties.\n"]},
{"authors": ["Garrett B. Goh", "Nathan O. Hodas", "Charles Siegel", "Abhinav Vishnu"], "title": ["SMILES2Vec: An Interpretable General-Purpose Deep Neural Network for\n  Predicting Chemical Properties"], "date": ["2017-12-06T04:29:28Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1712.02034v2"], "summary": ["  Chemical databases store information in text representations, and the SMILES\nformat is a universal standard used in many cheminformatics software. Encoded\nin each SMILES string is structural information that can be used to predict\ncomplex chemical properties. In this work, we develop SMILES2vec, a deep RNN\nthat automatically learns features from SMILES to predict chemical properties,\nwithout the need for additional explicit feature engineering. Using Bayesian\noptimization methods to tune the network architecture, we show that an\noptimized SMILES2vec model can serve as a general-purpose neural network for\npredicting distinct chemical properties including toxicity, activity,\nsolubility and solvation energy, while also outperforming contemporary MLP\nneural networks that uses engineered features. Furthermore, we demonstrate\nproof-of-concept of interpretability by developing an explanation mask that\nlocalizes on the most important characters used in making a prediction. When\ntested on the solubility dataset, it identified specific parts of a chemical\nthat is consistent with established first-principles knowledge with an accuracy\nof 88%. Our work demonstrates that neural networks can learn technically\naccurate chemical concept and provide state-of-the-art accuracy, making\ninterpretable deep neural networks a useful tool of relevance to the chemical\nindustry.\n"]},
{"authors": ["Garrett B. Goh", "Charles Siegel", "Abhinav Vishnu", "Nathan O. Hodas"], "title": ["Using Rule-Based Labels for Weak Supervised Learning: A ChemNet for\n  Transferable Chemical Property Prediction"], "date": ["2017-12-07T17:25:48Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1712.02734v2"], "summary": ["  With access to large datasets, deep neural networks (DNN) have achieved\nhuman-level accuracy in image and speech recognition tasks. However, in\nchemistry, data is inherently small and fragmented. In this work, we develop an\napproach of using rule-based knowledge for training ChemNet, a transferable and\ngeneralizable deep neural network for chemical property prediction that learns\nin a weak-supervised manner from large unlabeled chemical databases. When\ncoupled with transfer learning approaches to predict other smaller datasets for\nchemical properties that it was not originally trained on, we show that\nChemNet's accuracy outperforms contemporary DNN models that were trained using\nconventional supervised learning. Furthermore, we demonstrate that the ChemNet\npre-training approach is equally effective on both CNN (Chemception) and RNN\n(SMILES2vec) models, indicating that this approach is network architecture\nagnostic and is effective across multiple data modalities. Our results indicate\na pre-trained ChemNet that incorporates chemistry domain knowledge, enables the\ndevelopment of generalizable neural networks for more accurate prediction of\nnovel chemical properties.\n"]},
{"authors": ["Ke Ren", "Haichuan Yang", "Yu Zhao", "Mingshan Xue", "Hongyu Miao", "Shuai Huang", "Ji Liu"], "title": ["A Robust AUC Maximization Framework with Simultaneous Outlier Detection\n  and Feature Selection for Positive-Unlabeled Classification"], "date": ["2018-03-18T05:09:53Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06604v1"], "summary": ["  The positive-unlabeled (PU) classification is a common scenario in real-world\napplications such as healthcare, text classification, and bioinformatics, in\nwhich we only observe a few samples labeled as \"positive\" together with a large\nvolume of \"unlabeled\" samples that may contain both positive and negative\nsamples. Building robust classifier for the PU problem is very challenging,\nespecially for complex data where the negative samples overwhelm and mislabeled\nsamples or corrupted features exist. To address these three issues, we propose\na robust learning framework that unifies AUC maximization (a robust metric for\nbiased labels), outlier detection (for excluding wrong labels), and feature\nselection (for excluding corrupted features). The generalization error bounds\nare provided for the proposed model that give valuable insight into the\ntheoretical performance of the method and lead to useful practical guidance,\ne.g., to train a model, we find that the included unlabeled samples are\nsufficient as long as the sample size is comparable to the number of positive\nsamples in the training process. Empirical comparisons and two real-world\napplications on surgical site infection (SSI) and EEG seizure detection are\nalso conducted to show the effectiveness of the proposed model.\n"]},
{"authors": ["Qing Feng", "Meilei Jiang", "Jan Hannig", "J. S. Marron"], "title": ["Angle-Based Joint and Individual Variation Explained"], "date": ["2017-04-07T00:33:29Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1704.02060v3"], "summary": ["  Integrative analysis of disparate data blocks measured on a common set of\nexperimental subjects is a major challenge in modern data analysis. This data\nstructure naturally motivates the simultaneous exploration of the joint and\nindividual variation within each data block resulting in new insights. For\ninstance, there is a strong desire to integrate the multiple genomic data sets\nin The Cancer Genome Atlas to characterize the common and also the unique\naspects of cancer genetics and cell biology for each source. In this paper we\nintroduce Angle-Based Joint and Individual Variation Explained capturing both\njoint and individual variation within each data block. This is a major\nimprovement over earlier approaches to this challenge in terms of a new\nconceptual understanding, much better adaption to data heterogeneity and a fast\nlinear algebra computation. Important mathematical contributions are the use of\nscore subspaces as the principal descriptors of variation structure and the use\nof perturbation theory as the guide for variation segmentation. This leads to\nan exploratory data analysis method which is insensitive to the heterogeneity\namong data blocks and does not require separate normalization. An application\nto cancer data reveals different behaviors of each type of signal in\ncharacterizing tumor subtypes. An application to a mortality data set reveals\ninteresting historical lessons. Software and data are available at GitHub\n<https://github.com/MeileiJiang/AJIVE_Project>.\n"]},
{"authors": ["Reza Sadeghi", "Tanvi Banerjee", "William Romine"], "title": ["Early Hospital Mortality Prediction using Vital Signals"], "date": ["2018-03-18T00:35:42Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06589v1"], "summary": ["  Early hospital mortality prediction is critical as intensivists strive to\nmake efficient medical decisions about the severely ill patients staying in\nintensive care units. As a result, various methods have been developed to\naddress this problem based on clinical records. However, some of the laboratory\ntest results are time-consuming and need to be processed. In this paper, we\npropose a novel method to predict mortality using features extracted from the\nheart signals of patients within the first hour of ICU admission. In order to\npredict the risk, quantitative features have been computed based on the heart\nrate signals of ICU patients. Each signal is described in terms of 12\nstatistical and signal-based features. The extracted features are fed into\neight classifiers: decision tree, linear discriminant, logistic regression,\nsupport vector machine (SVM), random forest, boosted trees, Gaussian SVM, and\nK-nearest neighborhood (K-NN). To derive insight into the performance of the\nproposed method, several experiments have been conducted using the well-known\nclinical dataset named Medical Information Mart for Intensive Care III\n(MIMIC-III). The experimental results demonstrate the capability of the\nproposed method in terms of precision, recall, F1-score, and area under the\nreceiver operating characteristic curve (AUC). The decision tree classifier\nsatisfies both accuracy and interpretability better than the other classifiers,\nproducing an F1-score and AUC equal to 0.91 and 0.93, respectively. It\nindicates that heart rate signals can be used for predicting mortality in\npatients in the ICU, achieving a comparable performance with existing\npredictions that rely on high dimensional features from clinical records which\nneed to be processed and may contain missing information.\n"]},
{"authors": ["Christopher Tosh", "Sanjoy Dasgupta"], "title": ["Structural query-by-committee"], "date": ["2018-03-17T23:39:57Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06586v1"], "summary": ["  In this work, we describe a framework that unifies many different interactive\nlearning tasks. We present a generalization of the {\\it query-by-committee}\nactive learning algorithm for this setting, and we study its consistency and\nrate of convergence, both theoretically and empirically, with and without\nnoise.\n"]},
{"authors": ["Suchismit Mahapatra", "Varun Chandola"], "title": ["S-Isomap++: Multi Manifold Learning from Streaming Data"], "date": ["2017-10-17T18:30:57Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.06462v3"], "summary": ["  Manifold learning based methods have been widely used for non-linear\ndimensionality reduction (NLDR). However, in many practical settings, the need\nto process streaming data is a challenge for such methods, owing to the high\ncomputational complexity involved. Moreover, most methods operate under the\nassumption that the input data is sampled from a single manifold, embedded in a\nhigh dimensional space. We propose a method for streaming NLDR when the\nobserved data is either sampled from multiple manifolds or irregularly sampled\nfrom a single manifold. We show that existing NLDR methods, such as Isomap,\nfail in such situations, primarily because they rely on smoothness and\ncontinuity of the underlying manifold, which is violated in the scenarios\nexplored in this paper. However, the proposed algorithm is able to learn\neffectively in presence of multiple, and potentially intersecting, manifolds,\nwhile allowing for the input data to arrive as a massive stream.\n"]},
{"authors": ["Jiong Zhang", "Yibo Lin", "Zhao Song", "Inderjit S. Dhillon"], "title": ["Learning Long Term Dependencies via Fourier Recurrent Units"], "date": ["2018-03-17T23:06:31Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06585v1"], "summary": ["  It is a known fact that training recurrent neural networks for tasks that\nhave long term dependencies is challenging. One of the main reasons is the\nvanishing or exploding gradient problem, which prevents gradient information\nfrom propagating to early layers. In this paper we propose a simple recurrent\narchitecture, the Fourier Recurrent Unit (FRU), that stabilizes the gradients\nthat arise in its training while giving us stronger expressive power.\nSpecifically, FRU summarizes the hidden states $h^{(t)}$ along the temporal\ndimension with Fourier basis functions. This allows gradients to easily reach\nany layer due to FRU's residual learning structure and the global support of\ntrigonometric functions. We show that FRU has gradient lower and upper bounds\nindependent of temporal dimension. We also show the strong expressivity of\nsparse Fourier basis, from which FRU obtains its strong expressive power. Our\nexperimental study also demonstrates that with fewer parameters the proposed\narchitecture outperforms other recurrent architectures on many tasks.\n"]},
{"authors": ["Wenhu Chen", "Guanlin Li", "Shuo Ren", "Shujie Liu", "Zhirui Zhang", "Mu Li", "Ming Zhou"], "title": ["Generative Bridging Network in Neural Sequence Prediction"], "date": ["2017-06-28T07:44:17Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1706.09152v5"], "summary": ["  In order to alleviate data sparsity and overfitting problems in maximum\nlikelihood estimation (MLE) for sequence prediction tasks, we propose the\nGenerative Bridging Network (GBN), in which a novel bridge module is introduced\nto assist the training of the sequence prediction model (the generator\nnetwork). Unlike MLE directly maximizing the conditional likelihood, the bridge\nextends the point-wise ground truth to a bridge distribution conditioned on it,\nand the generator is optimized to minimize their KL-divergence. Three different\nGBNs, namely uniform GBN, language-model GBN and coaching GBN, are proposed to\npenalize confidence, enhance language smoothness and relieve learning burden.\nExperiments conducted on two recognized sequence prediction tasks (machine\ntranslation and abstractive text summarization) show that our proposed GBNs can\nyield significant improvements over strong baselines. Furthermore, by analyzing\nsamples drawn from different bridges, expected influences on the generator are\nverified.\n"]},
{"authors": ["Yining Wang"], "title": ["Convergence Rates of Latent Topic Models Under Relaxed Identifiability\n  Conditions"], "date": ["2017-10-30T17:05:28Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.11070v2"], "summary": ["  In this paper we study the frequentist convergence rate for the Latent\nDirichlet Allocation (Blei et al., 2003) topic models. We show that the maximum\nlikelihood estimator converges to one of the finitely many equivalent\nparameters in Wasserstein's distance metric at a rate of $n^{-1/4}$ without\nassuming separability or non-degeneracy of the underlying topics and/or the\nexistence of more than three words per document, thus generalizing the previous\nworks of Anandkumar et al. (2012, 2014) from an information-theoretical\nperspective. We also show that the $n^{-1/4}$ convergence rate is optimal in\nthe worst case.\n"]},
{"authors": ["Chen Luo", "Anshumali Shrivastava"], "title": ["Scaling-up Split-Merge MCMC with Locality Sensitive Sampling (LSS)"], "date": ["2018-02-21T07:03:32Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.07444v2"], "summary": ["  Split-Merge MCMC (Monte Carlo Markov Chain) is one of the essential and\npopular variants of MCMC for problems when an MCMC state consists of an unknown\nnumber of components. It is well known that state-of-the-art methods for\nsplit-merge MCMC do not scale well. Strategies for rapid mixing requires smart\nand informative proposals to reduce the rejection rate. However, all known\nsmart proposals involve expensive operations to suggest informative\ntransitions. As a result, the cost of each iteration is prohibitive for massive\nscale datasets. It is further known that uninformative but computationally\nefficient proposals, such as random split-merge, leads to extremely slow\nconvergence. This tradeoff between mixing time and per update cost seems hard\nto get around. In this paper, we get around this tradeoff by utilizing simple\nsimilarity information, such as cosine similarity, between the entity vectors\nto design a proposal distribution. Such information is readily available in\nalmost all applications. We show that the recent use of locality sensitive\nhashing for efficient adaptive sampling can be leveraged to obtain a\ncomputationally efficient pseudo-marginal MCMC. The new split-merge MCMC has\ncheap proposal which is also informative and needs significantly fewer\niterations than random split-merge. Overall, we obtain a sweet tradeoff between\nconvergence and per update cost. As a direct consequence, our proposal, named\nLSHSM, is around 5x faster than the state-of-the-art sampling methods on both\nsynthetic datasets and two large real datasets KDDCUP and PubMed with several\nmillions of entities and thousands of clusters.\n"]},
{"authors": ["Krishnamurthy Dvijotham", "Robert Stanforth", "Sven Gowal", "Timothy Mann", "Pushmeet Kohli"], "title": ["A Dual Approach to Scalable Verification of Deep Networks"], "date": ["2018-03-17T20:13:28Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06567v1"], "summary": ["  This paper addresses the problem of formally verifying desirable properties\nof neural networks, i.e., obtaining provable guarantees that the outputs of the\nneural network will always behave in a certain way for a given class of inputs.\nMost previous work on this topic was limited in its applicability by the size\nof the network, network architecture and the complexity of properties to be\nverified. In contrast, our framework applies to much more general class of\nactivation functions and specifications on neural network inputs and outputs.\nWe formulate verification as an optimization problem and solve a Lagrangian\nrelaxation of the optimization problem to obtain an upper bound on the\nverification objective. Our approach is anytime, i.e. it can be stopped at any\ntime and a valid bound on the objective can be obtained. We develop specialized\nverification algorithms with provable tightness guarantees under special\nassumptions and demonstrate the practical significance of our general\nverification approach on a variety of verification tasks.\n"]},
{"authors": ["Chen Yu", "Bojan Karlas", "Jie Zhong", "Ce Zhang", "Ji Liu"], "title": ["Multi-device, Multi-tenant Model Selection with GP-EI"], "date": ["2018-03-17T19:56:18Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06561v1"], "summary": ["  Bayesian optimization is the core technique behind the emergence of AutoML,\nwhich holds the promise of automatically searching for models and\nhyperparameters to make machine learning techniques more accessible. As such\nservices are moving towards the cloud, we ask -- {\\em When multiple AutoML\nusers share the same computational infrastructure, how should we allocate\nresources to maximize the \"global happiness\" of all users?}\n  We focus on GP-EI, one of the most popular algorithms for automatic model\nselection and hyperparameter tuning, and develop a novel multi-device,\nmulti-tenant extension that is aware of \\emph{multiple} computation devices and\nmultiple users sharing the same set of computation devices. Theoretically,\ngiven $N$ users and $M$ devices, we obtain a regret bound of $O((\\text{\\bf\n{MIU}}(T,K) + M)\\frac{N^2}{M})$, where $\\text{\\bf {MIU}}(T,K)$ refers to the\nmaximal incremental uncertainty up to time $T$ for the covariance matrix $K$.\nEmpirically, we evaluate our algorithm on two applications of automatic model\nselection, and show that our algorithm significantly outperforms the strategy\nof serving users independently. Moreover, when multiple computation devices are\navailable, we achieve near-linear speedup when the number of users is much\nlarger than the number of devices.\n"]},
{"authors": ["Deepjyoti Deka", "Michael Chertkov", "Scott Backhaus"], "title": ["Topology Estimation using Graphical Models in Multi-Phase Power\n  Distribution Grids"], "date": ["2018-03-17T16:18:40Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06531v1"], "summary": ["  Distribution grid is the medium and low voltage part of a large power system.\nStructurally, the majority of distribution networks operate radially, such that\nenergized lines form a collection of trees, i.e. forest, with a substation\nbeing at the root of any tree. The operational topology/forest may change from\ntime to time, however tracking these changes, even though important for the\ndistribution grid operation and control, is hindered by limited real-time\nmonitoring. This paper develops a learning framework to reconstruct radial\noperational structure of the distribution grid from synchronized voltage\nmeasurements in the grid subject to the exogenous fluctuations in nodal power\nconsumption. To detect operational lines our learning algorithm uses\nconditional independence tests for continuous random variables that is\napplicable to a wide class of probability distributions of the nodal\nconsumption and Gaussian injections in particular. Moreover, our algorithm\napplies to the practical case of unbalanced three-phase power flow. Algorithm\nperformance is validated on AC power flow simulations over IEEE distribution\ngrid test cases.\n"]},
{"authors": ["Sitan Chen", "Ankur Moitra"], "title": ["Learning Mixtures of Product Distributions via Higher Multilinear\n  Moments"], "date": ["2018-03-17T15:26:04Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06521v1"], "summary": ["  Learning mixtures of $k$ binary product distributions is a central problem in\ncomputational learning theory, but one where there are wide gaps between the\nbest known algorithms and lower bounds (even for restricted families of\nalgorithms). We narrow many of these gaps by developing novel insights about\nhow to reason about higher order multilinear moments. Our results include:\n  1) An $n^{O(k^2)}$ time algorithm for learning mixtures of binary product\ndistributions, giving the first improvement on the $n^{O(k^3)}$ time algorithm\nof Feldman, O'Donnell and Servedio\n  2) An $n^{\\Omega(\\sqrt{k})}$ statistical query lower bound, improving on the\n$n^{\\Omega(\\log k)}$ lower bound that is based on connections to sparse parity\nwith noise\n  3) An $n^{O(\\log k)}$ time algorithm for learning mixtures of $k$ subcubes.\nThis special case can still simulate many other hard learning problems, but is\nmuch richer than any of them alone. As a corollary, we obtain more flexible\nalgorithms for learning decision trees under the uniform distribution, that\nwork with stochastic transitions, when we are only given positive examples and\nwith a polylogarithmic number of samples for any fixed $k$.\n  Our algorithms are based on a win-win analysis where we either build a basis\nfor the moments or locate a degeneracy that can be used to simplify the\nproblem, which we believe will have applications to other learning problems\nover discrete domains.\n"]},
{"authors": ["Eric C. Chi", "Brian R. Gaines", "Will Wei Sun", "Hua Zhou", "Jian Yang"], "title": ["Provable Convex Co-clustering of Tensors"], "date": ["2018-03-17T15:15:28Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06518v1"], "summary": ["  Cluster analysis is a fundamental tool for pattern discovery of complex\nheterogeneous data. Prevalent clustering methods mainly focus on vector or\nmatrix-variate data and are not applicable to general-order tensors, which\narise frequently in modern scientific and business applications. Moreover,\nthere is a gap between statistical guarantees and computational efficiency for\nexisting tensor clustering solutions due to the nature of their non-convex\nformulations. In this work, we bridge this gap by developing a provable convex\nformulation of tensor co-clustering. Our convex co-clustering (CoCo) estimator\nenjoys stability guarantees and is both computationally and storage efficient.\nWe further establish a non-asymptotic error bound for the CoCo estimator, which\nreveals a surprising \"blessing of dimensionality\" phenomenon that does not\nexist in vector or matrix-variate cluster analysis. Our theoretical findings\nare supported by extensive simulated studies. Finally, we apply the CoCo\nestimator to the cluster analysis of advertisement click tensor data from a\nmajor online company. Our clustering results provide meaningful business\ninsights to improve advertising effectiveness.\n"]},
{"authors": ["Yingjie Fei", "Yudong Chen"], "title": ["Hidden Integrality of SDP Relaxation for Sub-Gaussian Mixture Models"], "date": ["2018-03-17T14:11:13Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06510v1"], "summary": ["  We consider the problem of estimating the discrete clustering structures\nunder Sub-Gaussian Mixture Models. Our main results establish a hidden\nintegrality property of a semidefinite programming (SDP) relaxation for this\nproblem: while the optimal solutions to the SDP are not integer-valued in\ngeneral, their estimation errors can be upper bounded in terms of the error of\nan idealized integer program. The error of the integer program, and hence that\nof the SDP, are further shown to decay exponentially in the signal-to-noise\nratio. To the best of our knowledge, this is the first exponentially decaying\nerror bound for convex relaxations of mixture models, and our results reveal\nthe \"global-to-local\" mechanism that drives the performance of the SDP\nrelaxation.\n  A corollary of our results shows that in certain regimes the SDP solutions\nare in fact integral and exact, improving on existing exact recovery results\nfor convex relaxations. More generally, our results establish sufficient\nconditions for the SDP to correctly recover the cluster memberships of\n$(1-\\delta)$ fraction of the points for any $\\delta\\in(0,1)$. As a special\ncase, we show that under the $d$-dimensional Stochastic Ball Model, SDP\nachieves non-trivial (sometimes exact) recovery when the center separation is\nas small as $\\sqrt{1/d}$, which complements previous exact recovery results\nthat require constant separation.\n"]},
{"authors": ["Saiprasad Koturwar", "Shabbir Merchant"], "title": ["Weight Initialization of Deep Neural Networks(DNNs) using Data\n  Statistics"], "date": ["2017-10-29T07:23:19Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.10570v2"], "summary": ["  Deep neural networks (DNNs) form the backbone of almost every\nstate-of-the-art technique in the fields such as computer vision, speech\nprocessing, and text analysis. The recent advances in computational technology\nhave made the use of DNNs more practical. Despite the overwhelming performances\nby DNN and the advances in computational technology, it is seen that very few\nresearchers try to train their models from the scratch. Training of DNNs still\nremains a difficult and tedious job. The main challenges that researchers face\nduring training of DNNs are the vanishing/exploding gradient problem and the\nhighly non-convex nature of the objective function which has up to million\nvariables. The approaches suggested in He and Xavier solve the vanishing\ngradient problem by providing a sophisticated initialization technique. These\napproaches have been quite effective and have achieved good results on standard\ndatasets, but these same approaches do not work very well on more practical\ndatasets. We think the reason for this is not making use of data statistics for\ninitializing the network weights. Optimizing such a high dimensional loss\nfunction requires careful initialization of network weights. In this work, we\npropose a data dependent initialization and analyze its performance against the\nstandard initialization techniques such as He and Xavier. We performed our\nexperiments on some practical datasets and the results show our algorithm's\nsuperior classification accuracy.\n"]},
{"authors": ["Taesik Na", "Jong Hwan Ko", "Saibal Mukhopadhyay"], "title": ["Cascade Adversarial Machine Learning Regularized with a Unified\n  Embedding"], "date": ["2017-08-08T17:58:40Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1708.02582v3"], "summary": ["  Injecting adversarial examples during training, known as adversarial\ntraining, can improve robustness against one-step attacks, but not for unknown\niterative attacks. To address this challenge, we first show iteratively\ngenerated adversarial images easily transfer between networks trained with the\nsame strategy. Inspired by this observation, we propose cascade adversarial\ntraining, which transfers the knowledge of the end results of adversarial\ntraining. We train a network from scratch by injecting iteratively generated\nadversarial images crafted from already defended networks in addition to\none-step adversarial images from the network being trained. We also propose to\nutilize embedding space for both classification and low-level (pixel-level)\nsimilarity learning to ignore unknown pixel level perturbation. During\ntraining, we inject adversarial images without replacing their corresponding\nclean images and penalize the distance between the two embeddings (clean and\nadversarial). Experimental results show that cascade adversarial training\ntogether with our proposed low-level similarity learning efficiently enhances\nthe robustness against iterative attacks, but at the expense of decreased\nrobustness against one-step attacks. We show that combining those two\ntechniques can also improve robustness under the worst case black box attack\nscenario.\n"]},
{"authors": ["Longshaokan Wang", "Eric B. Laber", "Katie Witkiewitz"], "title": ["Sufficient Markov Decision Processes with Alternating Deep Neural\n  Networks"], "date": ["2017-04-25T04:10:37Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1704.07531v2"], "summary": ["  Advances in mobile computing technologies have made it possible to monitor\nand apply data-driven interventions across complex systems in real time. Markov\ndecision processes (MDPs) are the primary model for sequential decision\nproblems with a large or indefinite time horizon. Choosing a representation of\nthe underlying decision process that is both Markov and low-dimensional is\nnon-trivial. We propose a method for constructing a low-dimensional\nrepresentation of the original decision process for which: 1. the MDP model\nholds; 2. a decision strategy that maximizes mean utility when applied to the\nlow-dimensional representation also maximizes mean utility when applied to the\noriginal process. We use a deep neural network to define a class of potential\nprocess representations and estimate the process of lowest dimension within\nthis class. The method is illustrated using data from a mobile study on heavy\ndrinking and smoking among college students.\n"]},
{"authors": ["Jize Zhang", "Tim Leung", "Aleksandr Y. Aravkin"], "title": ["Mean Reverting Portfolios via Penalized OU-Likelihood Estimation"], "date": ["2018-03-17T04:36:27Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06460v1"], "summary": ["  We study an optimization-based approach to con- struct a mean-reverting\nportfolio of assets. Our objectives are threefold: (1) design a portfolio that\nis well-represented by an Ornstein-Uhlenbeck process with parameters estimated\nby maximum likelihood, (2) select portfolios with desirable characteristics of\nhigh mean reversion and low variance, and (3) select a parsimonious portfolio,\ni.e. find a small subset of a larger universe of assets that can be used for\nlong and short positions. We present the full problem formulation, a\nspecialized algorithm that exploits partial minimization, and numerical\nexamples using both simulated and empirical price data.\n"]},
{"authors": ["Sathya N. Ravi", "Tuan Dinh", "Vishnu Sai Rao Lokhande", "Vikas Singh"], "title": ["Constrained Deep Learning using Conditional Gradient and Applications in\n  Computer Vision"], "date": ["2018-03-17T03:59:34Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06453v1"], "summary": ["  A number of results have recently demonstrated the benefits of incorporating\nvarious constraints when training deep architectures in vision and machine\nlearning. The advantages range from guarantees for statistical generalization\nto better accuracy to compression. But support for general constraints within\nwidely used libraries remains scarce and their broader deployment within many\napplications that can benefit from them remains under-explored. Part of the\nreason is that Stochastic gradient descent (SGD), the workhorse for training\ndeep neural networks, does not natively deal with constraints with global scope\nvery well. In this paper, we revisit a classical first order scheme from\nnumerical optimization, Conditional Gradients (CG), that has, thus far had\nlimited applicability in training deep models. We show via rigorous analysis\nhow various constraints can be naturally handled by modifications of this\nalgorithm. We provide convergence guarantees and show a suite of immediate\nbenefits that are possible -- from training ResNets with fewer layers but\nbetter accuracy simply by substituting in our version of CG to faster training\nof GANs with 50% fewer epochs in image inpainting applications to provably\nbetter generalization guarantees using efficiently implementable forms of\nrecently proposed regularizers.\n"]},
{"authors": ["Hannah K. Wayment-Steele", "Vijay S. Pande"], "title": ["Note: Variational Encoding of Protein Dynamics Benefits from Maximizing\n  Latent Autocorrelation"], "date": ["2018-03-17T03:27:31Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06449v1"], "summary": ["  As deep Variational Auto-Encoder (VAE) frameworks become more widely used for\nmodeling biomolecular simulation data, we emphasize the capability of the VAE\narchitecture to concurrently maximize the timescale of the latent space while\ninferring a reduced coordinate, which assists in finding slow processes as\naccording to the variational approach to conformational dynamics. We\nadditionally provide evidence that the VDE framework (Hern\\'andez et al.,\n2017), which uses this autocorrelation loss along with a time-lagged\nreconstruction loss, obtains a variationally optimized latent coordinate in\ncomparison with related loss functions. We thus recommend leveraging the\nautocorrelation of the latent space while training neural network models of\nbiomolecular simulation data to better represent slow processes.\n"]},
{"authors": ["Emre Demirkaya", "Yang Feng", "Pallavi Basu", "Jinchi Lv"], "title": ["Large-Scale Model Selection with Misspecification"], "date": ["2018-03-17T03:10:12Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07418v1"], "summary": ["  Model selection is crucial to high-dimensional learning and inference for\ncontemporary big data applications in pinpointing the best set of covariates\namong a sequence of candidate interpretable models. Most existing work assumes\nimplicitly that the models are correctly specified or have fixed\ndimensionality. Yet both features of model misspecification and high\ndimensionality are prevalent in practice. In this paper, we exploit the\nframework of model selection principles in misspecified models originated in Lv\nand Liu (2014) and investigate the asymptotic expansion of Bayesian principle\nof model selection in the setting of high-dimensional misspecified models. With\na natural choice of prior probabilities that encourages interpretability and\nincorporates Kullback-Leibler divergence, we suggest the high-dimensional\ngeneralized Bayesian information criterion with prior probability (HGBIC_p) for\nlarge-scale model selection with misspecification. Our new information\ncriterion characterizes the impacts of both model misspecification and high\ndimensionality on model selection. We further establish the consistency of\ncovariance contrast matrix estimation and the model selection consistency of\nHGBIC_p in ultra-high dimensions under some mild regularity conditions. The\nadvantages of our new method are supported by numerical studies.\n"]},
{"authors": ["Hanlin Tang", "Ce Zhang", "Shaoduo Gan", "Tong Zhang", "Ji Liu"], "title": ["Decentralization Meets Quantization"], "date": ["2018-03-17T01:51:09Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06443v1"], "summary": ["  Optimizing distributed learning systems is an art of balancing between\ncomputation and communication. There have been two lines of research that try\nto deal with slower networks: {\\em quantization} for low bandwidth networks,\nand {\\em decentralization} for high latency networks. In this paper, we explore\na natural question: {\\em can the combination of both decentralization and\nquantization lead to a system that is robust to both bandwidth and latency?}\n  Although the system implication of such combination is trivial, the\nunderlying theoretical principle and algorithm design is challenging: simply\nquantizing data sent in a decentralized training algorithm would accumulate the\nerror. In this paper, we develop a framework of quantized, decentralized\ntraining and propose two different strategies, which we call {\\em extrapolation\ncompression} and {\\em difference compression}. We analyze both algorithms and\nprove both converge at the rate of $O(1/\\sqrt{nT})$ where $n$ is the number of\nworkers and $T$ is the number of iterations, matching the {\\rc convergence}\nrate for full precision, centralized training. We evaluate our algorithms on\ntraining deep learning models, and find that our proposed algorithm outperforms\nthe best of merely decentralized and merely quantized algorithm significantly\nfor networks with {\\em both} high latency and low bandwidth.\n"]},
{"authors": ["Chunyu Tan", "Liming Zhang", "Hau-tieng Wu"], "title": ["A Novel Blaschke Unwinding Adaptive Fourier Decomposition based Signal\n  Compression Algorithm with Application on ECG Signals"], "date": ["2018-03-17T01:33:33Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06441v1"], "summary": ["  This paper presents a novel signal compression algorithm based on the\nBlaschke unwinding adaptive Fourier decomposition (AFD). The Blaschke unwinding\nAFD is a newly developed signal decomposition theory. It utilizes the\nNevanlinna factorization and the maximal selection principle in each\ndecomposition step, and achieves a faster convergence rate with higher\nfidelity. The proposed compression algorithm is applied to the\nelectrocardiogram signal. To assess the performance of the proposed compression\nalgorithm, in addition to the generic assessment criteria, we consider the less\ndiscussed criteria related to the clinical needs -- for the heart rate\nvariability analysis purpose, how accurate the R peak information is preserved\nis evaluated. The experiments are conducted on the MIT-BIH arrhythmia benchmark\ndatabase. The results show that the proposed algorithm performs better than\nother state-of-the-art approaches. Meanwhile, it also well preserves the R peak\ninformation.\n"]},
{"authors": ["Calvin Murdock", "Ming-Fang Chang", "Simon Lucey"], "title": ["Deep Component Analysis via Alternating Direction Neural Networks"], "date": ["2018-03-16T21:40:02Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06407v1"], "summary": ["  Despite a lack of theoretical understanding, deep neural networks have\nachieved unparalleled performance in a wide range of applications. On the other\nhand, shallow representation learning with component analysis is associated\nwith rich intuition and theory, but smaller capacity often limits its\nusefulness. To bridge this gap, we introduce Deep Component Analysis (DeepCA),\nan expressive multilayer model formulation that enforces hierarchical structure\nthrough constraints on latent variables in each layer. For inference, we\npropose a differentiable optimization algorithm implemented using recurrent\nAlternating Direction Neural Networks (ADNNs) that enable parameter learning\nusing standard backpropagation. By interpreting feed-forward networks as\nsingle-iteration approximations of inference in our model, we provide both a\nnovel theoretical perspective for understanding them and a practical technique\nfor constraining predictions with prior knowledge. Experimentally, we\ndemonstrate performance improvements on a variety of tasks, including\nsingle-image depth prediction with sparse output constraints.\n"]},
{"authors": ["Tzai-Shuen Chen"], "title": ["Evaluating Conditional Cash Transfer Policies with Machine Learning\n  Methods"], "date": ["2018-03-16T21:14:02Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06401v1"], "summary": ["  This paper presents an out-of-sample prediction comparison between major\nmachine learning models and the structural econometric model. Over the past\ndecade, machine learning has established itself as a powerful tool in many\nprediction applications, but this approach is still not widely adopted in\nempirical economic studies. To evaluate the benefits of this approach, I use\nthe most common machine learning algorithms, CART, C4.5, LASSO, random forest,\nand adaboost, to construct prediction models for a cash transfer experiment\nconducted by the Progresa program in Mexico, and I compare the prediction\nresults with those of a previous structural econometric study. Two prediction\ntasks are performed in this paper: the out-of-sample forecast and the long-term\nwithin-sample simulation. For the out-of-sample forecast, both the mean\nabsolute error and the root mean square error of the school attendance rates\nfound by all machine learning models are smaller than those found by the\nstructural model. Random forest and adaboost have the highest accuracy for the\nindividual outcomes of all subgroups. For the long-term within-sample\nsimulation, the structural model has better performance than do all of the\nmachine learning models. The poor within-sample fitness of the machine learning\nmodel results from the inaccuracy of the income and pregnancy prediction\nmodels. The result shows that the machine learning model performs better than\ndoes the structural model when there are many data to learn; however, when the\ndata are limited, the structural model offers a more sensible prediction. The\nfindings of this paper show promise for adopting machine learning in economic\npolicy analyses in the era of big data.\n"]},
{"authors": ["Sima Siami-Namini", "Akbar Siami Namin"], "title": ["Forecasting Economics and Financial Time Series: ARIMA vs. LSTM"], "date": ["2018-03-16T20:01:48Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06386v1"], "summary": ["  Forecasting time series data is an important subject in economics, business,\nand finance. Traditionally, there are several techniques to effectively\nforecast the next lag of time series data such as univariate Autoregressive\n(AR), univariate Moving Average (MA), Simple Exponential Smoothing (SES), and\nmore notably Autoregressive Integrated Moving Average (ARIMA) with its many\nvariations. In particular, ARIMA model has demonstrated its outperformance in\nprecision and accuracy of predicting the next lags of time series. With the\nrecent advancement in computational power of computers and more importantly\ndeveloping more advanced machine learning algorithms and approaches such as\ndeep learning, new algorithms are developed to forecast time series data. The\nresearch question investigated in this article is that whether and how the\nnewly developed deep learning-based algorithms for forecasting time series\ndata, such as \"Long Short-Term Memory (LSTM)\", are superior to the traditional\nalgorithms. The empirical studies conducted and reported in this article show\nthat deep learning-based algorithms such as LSTM outperform traditional-based\nalgorithms such as ARIMA model. More specifically, the average reduction in\nerror rates obtained by LSTM is between 84 - 87 percent when compared to ARIMA\nindicating the superiority of LSTM to ARIMA. Furthermore, it was noticed that\nthe number of training times, known as \"epoch\" in deep learning, has no effect\non the performance of the trained forecast model and it exhibits a truly random\nbehavior.\n"]},
{"authors": ["Rakshit Trivedi", "Mehrdad Farajtabar", "Prasenjeet Biswal", "Hongyuan Zha"], "title": ["Representation Learning over Dynamic Graphs"], "date": ["2018-03-11T22:00:33Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04051v2"], "summary": ["  How can we effectively encode evolving information over dynamic graphs into\nlow-dimensional representations? In this paper, we propose DyRep, an inductive\ndeep representation learning framework that learns a set of functions to\nefficiently produce low-dimensional node embeddings that evolves over time. The\nlearned embeddings drive the dynamics of two key processes namely,\ncommunication and association between nodes in dynamic graphs. These processes\nexhibit complex nonlinear dynamics that evolve at different time scales and\nsubsequently contribute to the update of node embeddings. We employ a\ntime-scale dependent multivariate point process model to capture these\ndynamics. We devise an efficient unsupervised learning procedure and\ndemonstrate that our approach significantly outperforms representative\nbaselines on two real-world datasets for the problem of dynamic link prediction\nand event time prediction.\n"]},
{"authors": ["Harini Kannan", "Alexey Kurakin", "Ian Goodfellow"], "title": ["Adversarial Logit Pairing"], "date": ["2018-03-16T19:03:45Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06373v1"], "summary": ["  In this paper, we develop improved techniques for defending against\nadversarial examples at scale. First, we implement the state of the art version\nof adversarial training at unprecedented scale on ImageNet and investigate\nwhether it remains effective in this setting - an important open scientific\nquestion (Athalye et al., 2018). Next, we introduce enhanced defenses using a\ntechnique we call logit pairing, a method that encourages logits for pairs of\nexamples to be similar. When applied to clean examples and their adversarial\ncounterparts, logit pairing improves accuracy on adversarial examples over\nvanilla adversarial training; we also find that logit pairing on clean examples\nonly is competitive with adversarial training in terms of accuracy on two\ndatasets. Finally, we show that adversarial logit pairing achieves the state of\nthe art defense on ImageNet against PGD white box attacks, with an accuracy\nimprovement from 1.5% to 27.9%. Adversarial logit pairing also successfully\ndamages the current state of the art defense against black box attacks on\nImageNet (Tramer et al., 2018), dropping its accuracy from 66.6% to 47.1%. With\nthis new accuracy drop, adversarial logit pairing ties with Tramer et al.(2018)\nfor the state of the art on black box attacks on ImageNet.\n"]},
{"authors": ["Ashish Vaswani", "Samy Bengio", "Eugene Brevdo", "Francois Chollet", "Aidan N. Gomez", "Stephan Gouws", "Llion Jones", "\u0141ukasz Kaiser", "Nal Kalchbrenner", "Niki Parmar", "Ryan Sepassi", "Noam Shazeer", "Jakob Uszkoreit"], "title": ["Tensor2Tensor for Neural Machine Translation"], "date": ["2018-03-16T18:49:22Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07416v1"], "summary": ["  Tensor2Tensor is a library for deep learning models that is well-suited for\nneural machine translation and includes the reference implementation of the\nstate-of-the-art Transformer model.\n"]},
{"authors": ["\u00darsula H\u00e9bert-Johnson", "Michael P. Kim", "Omer Reingold", "Guy N. Rothblum"], "title": ["Calibration for the (Computationally-Identifiable) Masses"], "date": ["2017-11-22T21:47:55Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.08513v2"], "summary": ["  As algorithms increasingly inform and influence decisions made about\nindividuals, it becomes increasingly important to address concerns that these\nalgorithms might be discriminatory. The output of an algorithm can be\ndiscriminatory for many reasons, most notably: (1) the data used to train the\nalgorithm might be biased (in various ways) to favor certain populations over\nothers; (2) the analysis of this training data might inadvertently or\nmaliciously introduce biases that are not borne out in the data. This work\nfocuses on the latter concern.\n  We develop and study multicalbration -- a new measure of algorithmic fairness\nthat aims to mitigate concerns about discrimination that is introduced in the\nprocess of learning a predictor from data. Multicalibration guarantees accurate\n(calibrated) predictions for every subpopulation that can be identified within\na specified class of computations. We think of the class as being quite rich;\nin particular, it can contain many overlapping subgroups of a protected group.\n  We show that in many settings this strong notion of protection from\ndiscrimination is both attainable and aligned with the goal of obtaining\naccurate predictions. Along the way, we present new algorithms for learning a\nmulticalibrated predictor, study the computational complexity of this task, and\ndraw new connections to computational learning models such as agnostic\nlearning.\n"]},
{"authors": ["Tom Rainforth"], "title": ["Nesting Probabilistic Programs"], "date": ["2018-03-16T17:30:35Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06328v1"], "summary": ["  We formalize the notion of nesting probabilistic programming queries and\ninvestigate the resulting statistical implications. We demonstrate that query\nnesting allows the definition of models which could not otherwise be expressed,\nsuch as those involving agents reasoning about other agents, but that existing\nsystems take approaches that lead to inconsistent estimates. We show how to\ncorrect this by delineating possible ways one might want to nest queries and\nasserting the respective conditions required for convergence. We further\nintroduce, and prove the correctness of, a new online nested Monte Carlo\nestimation method that makes it substantially easier to ensure these conditions\nare met, thereby providing a simple framework for designing statistically\ncorrect inference engines.\n"]},
{"authors": ["M. Arjumand Masood", "Finale Doshi-Velez"], "title": ["A particle-based variational approach to Bayesian Non-negative Matrix\n  Factorization"], "date": ["2018-03-16T17:20:19Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06321v1"], "summary": ["  Bayesian Non-negative Matrix Factorization (NMF) is a promising approach for\nunderstanding uncertainty and structure in matrix data. However, a large volume\nof applied work optimizes traditional non-Bayesian NMF objectives that fail to\nprovide a principled understanding of the non-identifiability inherent in NMF--\nan issue ideally addressed by a Bayesian approach. Despite their suitability,\ncurrent Bayesian NMF approaches have failed to gain popularity in an applied\nsetting; they sacrifice flexibility in modeling for tractable computation, tend\nto get stuck in local modes, and require many thousands of samples for\nmeaningful uncertainty estimates. We address these issues through a\nparticle-based variational approach to Bayesian NMF that only requires the\njoint likelihood to be differentiable for tractability, uses a novel\ninitialization technique to identify multiple modes in the posterior, and\nallows domain experts to inspect a `small' set of factorizations that\nfaithfully represent the posterior. We introduce and employ a class of\nlikelihood and prior distributions for NMF that formulate a Bayesian model\nusing popular non-Bayesian NMF objectives. On several real datasets, we obtain\nbetter particle approximations to the Bayesian NMF posterior in less time than\nbaselines and demonstrate the significant role that multimodality plays in\nNMF-related tasks.\n"]},
{"authors": ["Florian Bernard", "Johan Thunberg", "Jorge Goncalves", "Christian Theobalt"], "title": ["Synchronisation of Partial Multi-Matchings via Non-negative\n  Factorisations"], "date": ["2018-03-16T17:17:05Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06320v1"], "summary": ["  In this work we study permutation synchronisation for the challenging case of\npartial permutations, which plays an important role for the problem of matching\nmultiple objects (e.g. images or shapes). The term synchronisation refers to\nthe property that the set of pairwise matchings is cycle-consistent, i.e. in\nthe full matching case all compositions of pairwise matchings over cycles must\nbe equal to the identity. Motivated by clustering and matrix factorisation\nperspectives of cycle-consistency, we derive an algorithm to tackle the\npermutation synchronisation problem based on non-negative factorisations. In\norder to deal with the inherent non-convexity of the permutation\nsynchronisation problem, we use an initialisation procedure based on a novel\nrotation scheme applied to the solution of the spectral relaxation. Moreover,\nthis rotation scheme facilitates a convenient Euclidean projection to obtain a\nbinary solution after solving our relaxed problem. In contrast to\nstate-of-the-art methods, our approach is guaranteed to produce\ncycle-consistent results. We experimentally demonstrate the efficacy of our\nmethod and show that it achieves better results compared to existing methods.\n"]},
{"authors": ["Renjie Liao", "Marc Brockschmidt", "Daniel Tarlow", "Alexander L. Gaunt", "Raquel Urtasun", "Richard Zemel"], "title": ["Graph Partition Neural Networks for Semi-Supervised Classification"], "date": ["2018-03-16T15:34:06Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06272v1"], "summary": ["  We present graph partition neural networks (GPNN), an extension of graph\nneural networks (GNNs) able to handle extremely large graphs. GPNNs alternate\nbetween locally propagating information between nodes in small subgraphs and\nglobally propagating information between the subgraphs. To efficiently\npartition graphs, we experiment with several partitioning algorithms and also\npropose a novel variant for fast processing of large scale graphs. We\nextensively test our model on a variety of semi-supervised node classification\ntasks. Experimental results indicate that GPNNs are either superior or\ncomparable to state-of-the-art methods on a wide variety of datasets for\ngraph-based semi-supervised classification. We also show that GPNNs can achieve\nsimilar performance as standard GNNs with fewer propagation steps.\n"]},
{"authors": ["Marc Oliu", "Javier Selva", "Sergio Escalera"], "title": ["Folded Recurrent Neural Networks for Future Video Prediction"], "date": ["2017-12-01T13:31:56Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1712.00311v2"], "summary": ["  Future video prediction is an ill-posed Computer Vision problem that recently\nreceived much attention. Its main challenges are the high variability in video\ncontent, the propagation of errors through time, and the non-specificity of the\nfuture frames: given a sequence of past frames there is a continuous\ndistribution of possible futures. This work introduces bijective Gated\nRecurrent Units, a double mapping between the input and output of a GRU layer.\nThis allows for recurrent auto-encoders with state sharing between encoder and\ndecoder, stratifying the sequence representation and helping to prevent\ncapacity problems. We show how with this topology only the encoder or decoder\nneeds to be applied for input encoding and prediction, respectively. This\nreduces the computational cost and avoids re-encoding the predictions when\ngenerating a sequence of frames, mitigating the propagation of errors.\nFurthermore, it is possible to remove layers from an already trained model,\ngiving an insight to the role performed by each layer and making the model more\nexplainable. We evaluate our approach on three video datasets, outperforming\nstate of the art prediction results on MMNIST and UCF101, and obtaining\ncompetitive results on KTH with 2 and 3 times less memory usage and\ncomputational cost than the best scored approach.\n"]},
{"authors": ["Philipp Geiger", "Justus Winkelmann", "Claudius Proissl", "Michel Besserve", "Bernhard Sch\u00f6lkopf"], "title": ["Coordination via predictive assistants from a game-theoretic view"], "date": ["2018-03-16T14:27:12Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06247v1"], "summary": ["  We study machine learning-based assistants that support coordination between\nhumans in congested facilities via congestion forecasts. In our theoretical\nanalysis, we use game theory to study how an assistant's forecast that\ninfluences the outcome relates to Nash equilibria, and how they can be reached\nquickly in congestion game-like settings. Using information theory, we\ninvestigate approximations to given social choice functions under privacy\nconstraints w.r.t. assistants. And we study dynamics and training for a\nspecific exponential smoothing-based assistant via a linear dynamical systems\nand causal analysis. We report experiments conducted on a real congested\ncafeteria with about 400 daily customers where we evaluate this assistant and\nprediction baselines to gain further insight.\n"]},
{"authors": ["Andr\u00e9 Gensler", "Bernhard Sick"], "title": ["A Multi-Scheme Ensemble Using Coopetitive Soft-Gating With Application\n  to Power Forecasting for Renewable Energy Generation"], "date": ["2018-03-16T14:23:37Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06344v1"], "summary": ["  In this article, we propose a novel ensemble technique with a multi-scheme\nweighting based on a technique called coopetitive soft gating. This technique\ncombines both, ensemble member competition and cooperation, in order to\nmaximize the overall forecasting accuracy of the ensemble. The proposed\nalgorithm combines the ideas of multiple ensemble paradigms (power forecasting\nmodel ensemble, weather forecasting model ensemble, and lagged ensemble) in a\nhierarchical structure. The technique is designed to be used in a flexible\nmanner on single and multiple weather forecasting models, and for a variety of\nlead times. We compare the technique to other power forecasting models and\nensemble techniques with a flexible number of weather forecasting models, which\ncan have the same, or varying forecasting horizons. It is shown that the model\nis able to outperform those models on a number of publicly available data sets.\nThe article closes with a discussion of properties of the proposed model which\nare relevant in its application.\n"]},
{"authors": ["K. Pavan Srinath", "Ramji Venkataramanan"], "title": ["Cluster-Seeking James-Stein Estimators"], "date": ["2016-02-01T14:37:20Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1602.00542v4"], "summary": ["  This paper considers the problem of estimating a high-dimensional vector of\nparameters $\\boldsymbol{\\theta} \\in \\mathbb{R}^n$ from a noisy observation. The\nnoise vector is i.i.d. Gaussian with known variance. For a squared-error loss\nfunction, the James-Stein (JS) estimator is known to dominate the simple\nmaximum-likelihood (ML) estimator when the dimension $n$ exceeds two. The\nJS-estimator shrinks the observed vector towards the origin, and the risk\nreduction over the ML-estimator is greatest for $\\boldsymbol{\\theta}$ that lie\nclose to the origin. JS-estimators can be generalized to shrink the data\ntowards any target subspace. Such estimators also dominate the ML-estimator,\nbut the risk reduction is significant only when $\\boldsymbol{\\theta}$ lies\nclose to the subspace. This leads to the question: in the absence of prior\ninformation about $\\boldsymbol{\\theta}$, how do we design estimators that give\nsignificant risk reduction over the ML-estimator for a wide range of\n$\\boldsymbol{\\theta}$?\n  In this paper, we propose shrinkage estimators that attempt to infer the\nstructure of $\\boldsymbol{\\theta}$ from the observed data in order to construct\na good attracting subspace. In particular, the components of the observed\nvector are separated into clusters, and the elements in each cluster shrunk\ntowards a common attractor. The number of clusters and the attractor for each\ncluster are determined from the observed vector. We provide concentration\nresults for the squared-error loss and convergence results for the risk of the\nproposed estimators. The results show that the estimators give significant risk\nreduction over the ML-estimator for a wide range of $\\boldsymbol{\\theta}$,\nparticularly for large $n$. Simulation results are provided to support the\ntheoretical claims.\n"]},
{"authors": ["Cynthia Rush", "Ramji Venkataramanan"], "title": ["Finite Sample Analysis of Approximate Message Passing Algorithms"], "date": ["2016-06-06T15:59:14Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1606.01800v4"], "summary": ["  Approximate message passing (AMP) refers to a class of efficient algorithms\nfor statistical estimation in high-dimensional problems such as compressed\nsensing and low-rank matrix estimation. This paper analyzes the performance of\nAMP in the regime where the problem dimension is large but finite. For\nconcreteness, we consider the setting of high-dimensional regression, where the\ngoal is to estimate a high-dimensional vector $\\beta_0$ from a noisy\nmeasurement $y=A \\beta_0 + w$. AMP is a low-complexity, scalable algorithm for\nthis problem. Under suitable assumptions on the measurement matrix $A$, AMP has\nthe attractive feature that its performance can be accurately characterized in\nthe large system limit by a simple scalar iteration called state evolution.\nPrevious proofs of the validity of state evolution have all been asymptotic\nconvergence results. In this paper, we derive a concentration inequality for\nAMP with i.i.d. Gaussian measurement matrices with finite size $n \\times N$.\nThe result shows that the probability of deviation from the state evolution\nprediction falls exponentially in $n$. This provides theoretical support for\nempirical findings that have demonstrated excellent agreement of AMP\nperformance with state evolution predictions for moderately large dimensions.\nThe concentration inequality also indicates that the number of AMP iterations\n$t$ can grow no faster than order $\\frac{\\log n}{\\log \\log n}$ for the\nperformance to be close to the state evolution predictions with high\nprobability. The analysis can be extended to obtain similar non-asymptotic\nresults for AMP in other settings such as low-rank matrix estimation.\n"]},
{"authors": ["Fran\u00e7ois Bachoc", "Baptiste Broto", "Fabrice Gamboa", "Jean-Michel Loubes"], "title": ["Gaussian Processes indexed on the symmetric group: prediction and\n  learning"], "date": ["2018-03-16T09:19:36Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06118v1"], "summary": ["  In the framework of the supervised learning of a real function defined on a\nspace X , the so called Kriging method stands on a real Gaussian field defined\non X. The Euclidean case is well known and has been widely studied. In this\npaper, we explore the less classical case where X is the non commutative finite\ngroup of permutations. In this setting, we propose and study an harmonic\nanalysis of the covariance operators that enables to consider Gaussian\nprocesses models and forecasting issues. Our theory is motivated by statistical\nranking problems.\n"]},
{"authors": ["Richard Kenway"], "title": ["Vulnerability of Deep Learning"], "date": ["2018-03-16T08:52:04Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06111v1"], "summary": ["  The Renormalisation Group (RG) provides a framework in which it is possible\nto assess whether a deep-learning network is sensitive to small changes in the\ninput data and hence prone to error, or susceptible to adversarial attack.\nDistinct classification outputs are associated with different RG fixed points\nand sensitivity to small changes in the input data is due to the presence of\nrelevant operators at a fixed point. A numerical scheme, based on Monte Carlo\nRG ideas, is proposed for identifying the existence of relevant operators and\nthe corresponding directions of greatest sensitivity in the input data. Thus, a\ntrained deep-learning network may be tested for its robustness and, if it is\nvulnerable to attack, dangerous perturbations of the input data identified.\n"]},
{"authors": ["Tri Dao", "Albert Gu", "Alexander J. Ratner", "Virginia Smith", "Christopher De Sa", "Christopher R\u00e9"], "title": ["A Kernel Theory of Modern Data Augmentation"], "date": ["2018-03-16T06:05:32Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06084v1"], "summary": ["  Data augmentation, a technique in which a training set is expanded with\nclass-preserving transformations, is ubiquitous in modern machine learning\npipelines. In this paper, we seek to establish a theoretical framework for\nunderstanding modern data augmentation techniques. We start by showing that for\nkernel classifiers, data augmentation can be approximated by first-order\nfeature averaging and second-order variance regularization components. We\nconnect this general approximation framework to prior work in invariant\nkernels, tangent propagation, and robust optimization. Next, we explicitly\ntackle the compositional aspect of modern data augmentation techniques,\nproposing a novel model of data augmentation as a Markov process. Under this\nmodel, we show that performing $k$-nearest neighbors with data augmentation is\nasymptotically equivalent to a kernel classifier. Finally, we illustrate ways\nin which our theoretical framework can be leveraged to accelerate machine\nlearning workflows in practice, including reducing the amount of computation\nneeded to train on augmented data, and predicting the utility of a\ntransformation prior to training.\n"]},
{"authors": ["Hongyu Zhu", "Mohamed Akrout", "Bojian Zheng", "Andrew Pelegris", "Amar Phanishayee", "Bianca Schroeder", "Gennady Pekhimenko"], "title": ["TBD: Benchmarking and Analyzing Deep Neural Network Training"], "date": ["2018-03-16T05:16:06Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06905v1"], "summary": ["  The recent popularity of deep neural networks (DNNs) has generated a lot of\nresearch interest in performing DNN-related computation efficiently. However,\nthe primary focus is usually very narrow and limited to (i) inference -- i.e.\nhow to efficiently execute already trained models and (ii) image classification\nnetworks as the primary benchmark for evaluation.\n  Our primary goal in this work is to break this myopic view by (i) proposing a\nnew benchmark for DNN training, called TBD (TBD is short for Training Benchmark\nfor DNNs), that uses a representative set of DNN models that cover a wide range\nof machine learning applications: image classification, machine translation,\nspeech recognition, object detection, adversarial networks, reinforcement\nlearning, and (ii) by performing an extensive performance analysis of training\nthese different applications on three major deep learning frameworks\n(TensorFlow, MXNet, CNTK) across different hardware configurations (single-GPU,\nmulti-GPU, and multi-machine). TBD currently covers six major application\ndomains and eight different state-of-the-art models.\n  We present a new toolchain for performance analysis for these models that\ncombines the targeted usage of existing performance analysis tools, careful\nselection of new and existing metrics and methodologies to analyze the results,\nand utilization of domain specific characteristics of DNN training. We also\nbuild a new set of tools for memory profiling in all three major frameworks;\nmuch needed tools that can finally shed some light on precisely how much memory\nis consumed by different data structures (weights, activations, gradients,\nworkspace) in DNN training. By using our tools and methodologies, we make\nseveral important observations and recommendations on where the future research\nand optimization of DNN training should be focused.\n"]},
{"authors": ["Srayanta Mukherjee", "Devashish Shankar", "Atin Ghosh", "Nilam Tathawadekar", "Pramod Kompalli", "Sunita Sarawagi", "Krishnendu Chaudhury"], "title": ["ARMDN: Associative and Recurrent Mixture Density Networks for eRetail\n  Demand Forecasting"], "date": ["2018-03-10T12:45:11Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03800v2"], "summary": ["  Accurate demand forecasts can help on-line retail organizations better plan\ntheir supply-chain processes. The challenge, however, is the large number of\nassociative factors that result in large, non-stationary shifts in demand,\nwhich traditional time series and regression approaches fail to model. In this\npaper, we propose a Neural Network architecture called AR-MDN, that\nsimultaneously models associative factors, time-series trends and the variance\nin the demand. We first identify several causal features and use a combination\nof feature embeddings, MLP and LSTM to represent them. We then model the output\ndensity as a learned mixture of Gaussian distributions. The AR-MDN can be\ntrained end-to-end without the need for additional supervision. We experiment\non a dataset of an year's worth of data over tens-of-thousands of products from\nFlipkart. The proposed architecture yields a significant improvement in\nforecasting accuracy when compared with existing alternatives.\n"]},
{"authors": ["Zhixin Qi", "Hongzhi Wang", "Jianzhong Li", "Hong Gao"], "title": ["Impacts of Dirty Data: and Experimental Evaluation"], "date": ["2018-03-16T04:23:00Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06071v1"], "summary": ["  Data quality issues have attracted widespread attention due to the negative\nimpacts of dirty data on data mining and machine learning results. The\nrelationship between data quality and the accuracy of results could be applied\non the selection of the appropriate algorithm with the consideration of data\nquality and the determination of the data share to clean. However, rare\nresearch has focused on exploring such relationship. Motivated by this, this\npaper conducts an experimental comparison for the effects of missing,\ninconsistent and conflicting data on classification, clustering, and regression\nalgorithms. Based on the experimental findings, we provide guidelines for\nalgorithm selection and data cleaning.\n"]},
{"authors": ["Xenia Miscouridou", "Francois Caron", "Yee Whye Teh"], "title": ["Modelling sparsity, heterogeneity, reciprocity and community structure\n  in temporal interaction data"], "date": ["2018-03-16T04:00:41Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06070v1"], "summary": ["  We propose a novel class of network models for temporal dyadic interaction\ndata. Our goal is to capture a number of important features often observed in\nsocial interactions: sparsity, degree heterogeneity, community structure and\nreciprocity. We propose a family of models based on self-exciting Hawkes point\nprocesses in which events depend on the history of the process. The key\ncomponent is the conditional intensity function of the Hawkes Process, which\ncaptures the fact that interactions may arise as a response to past\ninteractions (reciprocity), or due to shared interests between individuals\n(community structure). In order to capture the sparsity and degree\nheterogeneity, the base (non time dependent) part of the intensity function\nbuilds on compound random measures following Todeschini et al. (2016). We\nconduct experiments on a variety of real-world temporal interaction data and\nshow that the proposed model outperforms many competing approaches for link\nprediction, and leads to interpretable parameters.\n"]},
{"authors": ["Zhixin Zhou", "Arash A. Amini"], "title": ["Optimal Bipartite Network Clustering"], "date": ["2018-03-15T23:19:30Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06031v1"], "summary": ["  We consider the problem of bipartite community detection in networks, or more\ngenerally the network biclustering problem. We present a fast two-stage\nprocedure based on spectral initialization followed by the application of a\npseudo-likelihood classifier twice. Under mild regularity conditions, we\nestablish the weak consistency of the procedure (i.e., the convergence of the\nmisclassification rate to zero) under a general bipartite stochastic block\nmodel. We show that the procedure is optimal in the sense that it achieves the\noptimal convergence rate that is achievable by a biclustering oracle,\nadaptively over the whole class, up to constants. The optimal rate we obtain\nsharpens some of the existing results and generalizes others to a wide regime\nof average degree growth. As a special case, we recover the known exact\nrecovery threshold in the $\\log n$ regime of sparsity. To obtain the general\nconsistency result, as part of the provable version of the algorithm, we\nintroduce a sub-block partitioning scheme that is also computationally\nattractive, allowing for distributed implementation of the algorithm without\nsacrificing optimality. The provable version of the algorithm is derived from a\ngeneral blueprint for pseudo-likelihood biclustering algorithms that employ\nsimple EM type updates. We show the effectiveness of this general class by\nnumerical simulations.\n"]},
{"authors": ["Tom Zahavy", "Alex Dikopoltsev", "Oren Cohen", "Shie Mannor", "Mordechai Segev"], "title": ["Deep Learning Reconstruction of Ultra-Short Pulses"], "date": ["2018-03-15T22:37:31Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06024v1"], "summary": ["  Ultra-short laser pulses with femtosecond to attosecond pulse duration are\nthe shortest systematic events humans can create. Characterization (amplitude\nand phase) of these pulses is a key ingredient in ultrafast science, e.g.,\nexploring chemical reactions and electronic phase transitions. Here, we propose\nand demonstrate, numerically and experimentally, the first deep neural network\ntechnique to reconstruct ultra-short optical pulses. We anticipate that this\napproach will extend the range of ultrashort laser pulses that can be\ncharacterized, e.g., enabling to diagnose very weak attosecond pulses.\n"]},
{"authors": ["Shannon R. McCurdy"], "title": ["Ridge Regression and Provable Deterministic Ridge Leverage Score\n  Sampling"], "date": ["2018-03-15T21:35:55Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.06010v1"], "summary": ["  Ridge leverage scores provide a balance between low-rank approximation and\nregularization, and are ubiquitous in randomized linear algebra and machine\nlearning. Deterministic algorithms are also of interest in the moderately big\ndata regime, because deterministic algorithms provide interpretability to the\npractitioner by having no failure probability and always returning the same\nresults.\n  We provide provable guarantees for deterministic column sampling using ridge\nleverage scores. The matrix sketch returned by our algorithm is a column subset\nof the original matrix, yielding additional interpretability. Like the\nrandomized counterparts, the deterministic algorithm provides (1 + {\\epsilon})\nerror column subset selection, (1 + {\\epsilon}) error projection-cost\npreservation, and an additive-multiplicative spectral bound. We also show that\nunder the assumption of power-law decay of ridge leverage scores, this\ndeterministic algorithm is provably as accurate as randomized algorithms.\n  Lastly, ridge regression is frequently used to regularize ill-posed linear\nleast- squares problems. While ridge regression provides shrinkage for the\nregression coefficients, many of the coefficients remain small but non-zero.\nPerforming ridge regression with the matrix sketch returned by our algorithm\nand a particular regularization parameter forces coefficients to zero and has a\nprovable (1 + {\\epsilon}) bound on the statistical risk. As such, it is an\ninteresting alternative to elastic net regularization.\n"]},
{"authors": ["Hadi Daneshmand", "Jonas Kohler", "Aurelien Lucchi", "Thomas Hofmann"], "title": ["Escaping Saddles with Stochastic Gradients"], "date": ["2018-03-15T20:48:06Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05999v1"], "summary": ["  We analyze the variance of stochastic gradients along negative curvature\ndirections in certain non-convex machine learning models and show that\nstochastic gradients exhibit a strong component along these directions.\nFurthermore, we show that - contrary to the case of isotropic noise - this\nvariance is proportional to the magnitude of the corresponding eigenvalues and\nnot decreasing in the dimensionality. Based upon this observation we propose a\nnew assumption under which we show that the injection of explicit, isotropic\nnoise usually applied to make gradient descent escape saddle points can\nsuccessfully be replaced by a simple SGD step. Additionally - and under the\nsame condition - we derive the first convergence rate for plain SGD to a\nsecond-order stationary point in a number of iterations that is independent of\nthe problem dimension.\n"]},
{"authors": ["Hossein Rajabzadeh", "Mansoor Zolghadri Jahromi", "Mohammad Sadegh Zare", "Mostafa Fakhrahmad"], "title": ["Local Distance Metric Learning for Nearest Neighbor Algorithm"], "date": ["2018-03-05T08:45:47Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.01562v2"], "summary": ["  Distance metric learning is a successful way to enhance the performance of\nthe nearest neighbor classifier. In most cases, however, the distribution of\ndata does not obey a regular form and may change in different parts of the\nfeature space. Regarding that, this paper proposes a novel local distance\nmetric learning method, namely Local Mahalanobis Distance Learning (LMDL), in\norder to enhance the performance of the nearest neighbor classifier. LMDL\nconsiders the neighborhood influence and learns multiple distance metrics for a\nreduced set of input samples. The reduced set is called as prototypes which try\nto preserve local discriminative information as much as possible. The proposed\nLMDL can be kernelized very easily, which is significantly desirable in the\ncase of highly nonlinear data. The quality as well as the efficiency of the\nproposed method assesses through a set of different experiments on various\ndatasets and the obtained results show that LDML as well as the kernelized\nversion is superior to the other related state-of-the-art methods.\n"]},
{"authors": ["Milena Cukic", "David Pokrajac", "Miodrag Stokic", "slobodan Simic", "Vlada Radivojevic", "Milos Ljubisavljevic"], "title": ["EEG machine learning with Higuchi fractal dimension and Sample Entropy\n  as features for successful detection of depression"], "date": ["2018-03-15T20:13:38Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05985v1"], "summary": ["  Reliable diagnosis of depressive disorder is essential for both optimal\ntreatment and prevention of fatal outcomes. In this study, we aimed to\nelucidate the effectiveness of two non-linear measures, Higuchi Fractal\nDimension (HFD) and Sample Entropy (SampEn), in detecting depressive disorders\nwhen applied on EEG. HFD and SampEn of EEG signals were used as features for\nseven machine learning algorithms including Multilayer Perceptron, Logistic\nRegression, Support Vector Machines with the linear and polynomial kernel,\nDecision Tree, Random Forest, and Naive Bayes classifier, discriminating EEG\nbetween healthy control subjects and patients diagnosed with depression. We\nconfirmed earlier observations that both non-linear measures can discriminate\nEEG signals of patients from healthy control subjects. The results suggest that\ngood classification is possible even with a small number of principal\ncomponents. Average accuracy among classifiers ranged from 90.24% to 97.56%.\nAmong the two measures, SampEn had better performance. Using HFD and SampEn and\na variety of machine learning techniques we can accurately discriminate\npatients diagnosed with depression vs controls which can serve as a highly\nsensitive, clinically relevant marker for the diagnosis of depressive\ndisorders.\n"]},
{"authors": ["Alejandro Mottini", "Rodrigo Acuna-Agost"], "title": ["Deep Choice Model Using Pointer Networks for Airline Itinerary\n  Prediction"], "date": ["2018-03-15T19:55:56Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05976v1"], "summary": ["  Travel providers such as airlines and on-line travel agents are becoming more\nand more interested in understanding how passengers choose among alternative\nitineraries when searching for flights. This knowledge helps them better\ndisplay and adapt their offer, taking into account market conditions and\ncustomer needs. Some common applications are not only filtering and sorting\nalternatives, but also changing certain attributes in real-time (e.g., changing\nthe price). In this paper, we concentrate with the problem of modeling air\npassenger choices of flight itineraries. This problem has historically been\ntackled using classical Discrete Choice Modelling techniques. Traditional\nstatistical approaches, in particular the Multinomial Logit model (MNL), is\nwidely used in industrial applications due to its simplicity and general good\nperformance. However, MNL models present several shortcomings and assumptions\nthat might not hold in real applications. To overcome these difficulties, we\npresent a new choice model based on Pointer Networks. Given an input sequence,\nthis type of deep neural architecture combines Recurrent Neural Networks with\nthe Attention Mechanism to learn the conditional probability of an output whose\nvalues correspond to positions in an input sequence. Therefore, given a\nsequence of different alternatives presented to a customer, the model can learn\nto point to the one most likely to be chosen by the customer. The proposed\nmethod was evaluated on a real dataset that combines on-line user search logs\nand airline flight bookings. Experimental results show that the proposed model\noutperforms the traditional MNL model on several metrics.\n"]},
{"authors": ["Housam Khalifa Bashier Babiker", "Randy Goebel"], "title": ["An Introduction to Deep Visual Explanation"], "date": ["2017-11-26T22:54:18Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.09482v2"], "summary": ["  The practical impact of deep learning on complex supervised learning problems\nhas been significant, so much so that almost every Artificial Intelligence\nproblem, or at least a portion thereof, has been somehow recast as a deep\nlearning problem. The applications appeal is significant, but this appeal is\nincreasingly challenged by what some call the challenge of explainability, or\nmore generally the more traditional challenge of debuggability: if the outcomes\nof a deep learning process produce unexpected results (e.g., less than expected\nperformance of a classifier), then there is little available in the way of\ntheories or tools to help investigate the potential causes of such unexpected\nbehavior, especially when this behavior could impact people's lives. We\ndescribe a preliminary framework to help address this issue, which we call\n\"deep visual explanation\" (DVE). \"Deep,\" because it is the development and\nperformance of deep neural network models that we want to understand. \"Visual,\"\nbecause we believe that the most rapid insight into a complex multi-dimensional\nmodel is provided by appropriate visualization techniques, and \"Explanation,\"\nbecause in the spectrum from instrumentation by inserting print statements to\nthe abductive inference of explanatory hypotheses, we believe that the key to\nunderstanding deep learning relies on the identification and exposure of\nhypotheses about the performance behavior of a learned deep model. In the\nexposition of our preliminary framework, we use relatively straightforward\nimage classification examples and a variety of choices on initial configuration\nof a deep model building scenario. By careful but not complicated\ninstrumentation, we expose classification outcomes of deep models using\nvisualization, and also show initial results for one potential application of\ninterpretability.\n"]},
{"authors": ["Jim W. Kay", "William A. Phillips"], "title": ["Contrasting information theoretic decompositions of modulatory and\n  arithmetic interactions in neural information processing systems"], "date": ["2018-03-15T17:51:21Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05897v1"], "summary": ["  Biological and artificial neural systems are composed of many local\nprocessors, and their capabilities depend upon the transfer function that\nrelates each local processor's outputs to its inputs. This paper uses a recent\nadvance in the foundations of information theory to study the properties of\nlocal processors that use contextual input to amplify or attenuate transmission\nof information about their driving inputs. This advance enables the information\ntransmitted by processors with two distinct inputs to be decomposed into those\ncomponents unique to each input, that shared between the two inputs, and that\nwhich depends on both though it is in neither, i.e. synergy. The decompositions\nthat we report here show that contextual modulation has information processing\nproperties that contrast with those of all four simple arithmetic operators,\nthat it can take various forms, and that the form used in our previous studies\nof artificial neural nets composed of local processors with both driving and\ncontextual inputs is particularly well-suited to provide the distinctive\ncapabilities of contextual modulation under a wide range of conditions. We\nargue that the decompositions reported here could be compared with those\nobtained from empirical neurobiological and psychophysical data under\nconditions thought to reflect contextual modulation. That would then shed new\nlight on the underlying processes involved. Finally, we suggest that such\ndecompositions could aid the design of context-sensitive machine learning\nalgorithms.\n"]},
{"authors": ["Daniel Emaasit", "Matthew Johnson"], "title": ["Capturing Structure Implicitly from Time-Series having Limited Data"], "date": ["2018-03-15T17:03:04Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05867v1"], "summary": ["  Scientific fields such as insider-threat detection and highway-safety\nplanning often lack sufficient amounts of time-series data to estimate\nstatistical models for the purpose of scientific discovery. Moreover, the\navailable limited data are quite noisy. This presents a major challenge when\nestimating time-series models that are robust to overfitting and have\nwell-calibrated uncertainty estimates. Most of the current literature in these\nfields involve visualizing the time-series for noticeable structure and hard\ncoding them into pre-specified parametric functions. This approach is\nassociated with two limitations. First, given that such trends may not be\neasily noticeable in small data, it is difficult to explicitly incorporate\nexpressive structure into the models during formulation. Second, it is\ndifficult to know $\\textit{a priori}$ the most appropriate functional form to\nuse. To address these limitations, a nonparametric Bayesian approach was\nproposed to implicitly capture hidden structure from time series having limited\ndata. The proposed model, a Gaussian process with a spectral mixture kernel,\nprecludes the need to pre-specify a functional form and hard code trends, is\nrobust to overfitting and has well-calibrated uncertainty estimates.\n"]},
{"authors": ["Karlson Pfannschmidt", "Pritha Gupta", "Eyke H\u00fcllermeier"], "title": ["Deep architectures for learning context-dependent ranking functions"], "date": ["2018-03-15T15:14:16Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05796v1"], "summary": ["  Object ranking is an important problem in the realm of preference learning.\nOn the basis of training data in the form of a set of rankings of objects,\nwhich are typically represented as feature vectors, the goal is to learn a\nranking function that predicts a linear order of any new set of objects.\nCurrent approaches commonly focus on ranking by scoring, i.e., on learning an\nunderlying latent utility function that seeks to capture the inherent utility\nof each object. These approaches, however, are not able to take possible\neffects of context-dependence into account, where context-dependence means that\nthe utility or usefulness of an object may also depend on what other objects\nare available as alternatives. In this paper, we formalize the problem of\ncontext-dependent ranking and present two general approaches based on two\nnatural representations of context-dependent ranking functions. Both approaches\nare instantiated by means of appropriate neural network architectures. We\ndemonstrate empirically that our methods outperform traditional approaches on\nbenchmark tasks, for which context-dependence is playing a relevant role.\n"]},
{"authors": ["Jaouad Mourtada", "St\u00e9phane Ga\u00efffas", "Erwan Scornet"], "title": ["Minimax optimal rates for Mondrian trees and forests"], "date": ["2018-03-15T14:43:04Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05784v1"], "summary": ["  Introduced by Breiman (2001), Random Forests are widely used as\nclassification and regression algorithms. While being initially designed as\nbatch algorithms, several variants have been proposed to handle online\nlearning. One particular instance of such forests is the Mondrian Forest, whose\ntrees are built using the so-called Mondrian process, therefore allowing to\neasily update their construction in a streaming fashion. In this paper, we\nstudy Mondrian Forests in a batch setting and prove their consistency assuming\na proper tuning of the lifetime sequence. A thorough theoretical study of\nMondrian partitions allows us to derive an upper bound for the risk of Mondrian\nForests, which turns out to be the minimax optimal rate for both Lipschitz and\ntwice differentiable regression functions. These results are actually the first\nto state that some particular random forests achieve minimax rates \\textit{in\narbitrary dimension}, paving the way to a refined theoretical analysis and thus\na deeper understanding of these black box algorithms.\n"]},
{"authors": ["Emmanuel Bacry", "Martin Bompaire", "St\u00e9phane Ga\u00efffas", "Soren Poulsen"], "title": ["Tick: a Python library for statistical learning, with a particular\n  emphasis on time-dependent modelling"], "date": ["2017-07-10T18:18:24Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1707.03003v2"], "summary": ["  Tick is a statistical learning library for Python~3, with a particular\nemphasis on time-dependent models, such as point processes, and tools for\ngeneralized linear models and survival analysis. The core of the library is an\noptimization module providing model computational classes, solvers and proximal\noperators for regularization. tick relies on a C++ implementation and\nstate-of-the-art optimization algorithms to provide very fast computations in a\nsingle node multi-core setting. Source code and documentation can be downloaded\nfrom https://github.com/X-DataInitiative/tick\n"]},
{"authors": ["Morgan A. Schmitz", "Matthieu Heitz", "Nicolas Bonneel", "Fred Maurice Ngol\u00e8 Mboula", "David Coeurjolly", "Marco Cuturi", "Gabriel Peyr\u00e9", "Jean-Luc Starck"], "title": ["Wasserstein Dictionary Learning: Optimal Transport-based unsupervised\n  non-linear dictionary learning"], "date": ["2017-08-07T01:00:40Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1708.01955v3"], "summary": ["  This paper introduces a new nonlinear dictionary learning method for\nhistograms in the probability simplex. The method leverages optimal transport\ntheory, in the sense that our aim is to reconstruct histograms using so-called\ndisplacement interpolations (a.k.a. Wasserstein barycenters) between dictionary\natoms; such atoms are themselves synthetic histograms in the probability\nsimplex. Our method simultaneously estimates such atoms, and, for each\ndatapoint, the vector of weights that can optimally reconstruct it as an\noptimal transport barycenter of such atoms. Our method is computationally\ntractable thanks to the addition of an entropic regularization to the usual\noptimal transportation problem, leading to an approximation scheme that is\nefficient, parallel and simple to differentiate. Both atoms and weights are\nlearned using a gradient-based descent method. Gradients are obtained by\nautomatic differentiation of the generalized Sinkhorn iterations that yield\nbarycenters with entropic smoothing. Because of its formulation relying on\nWasserstein barycenters instead of the usual matrix product between dictionary\nand codes, our method allows for nonlinear relationships between atoms and the\nreconstruction of input data. We illustrate its application in several\ndifferent image processing settings.\n"]},
{"authors": ["Christian Schmidt", "Lenka Zdeborov\u00e1"], "title": ["Dense Limit of the Dawid-Skene Model for Crowdsourcing and Regions of\n  Sub-optimality of Message Passing Algorithms"], "date": ["2018-03-13T16:31:37Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04924v2"], "summary": ["  Crowdsourcing is a strategy to categorize data through the contribution of\nmany individuals. A wide range of theoretical and algorithmic contributions are\nbased on the model of Dawid and Skene [1]. Recently it was shown in [2,3] that,\nin certain regimes, belief propagation is asymptotically optimal for data\ngenerated from the Dawid-Skene model. This paper is motivated by this recent\nprogress. We analyze the dense limit of the Dawid-Skene model. It is shown that\nit belongs to a larger class of low-rank matrix estimation problems for which\nit is possible to express the asymptotic, Bayes-optimal, performance in a\nsimple closed form. In the dense limit the mapping to a low-rank matrix\nestimation problem provides an approximate message passing algorithm that\nsolves the problem algorithmically. We identify the regions where the algorithm\nefficiently computes the Bayes-optimal estimates. Our analysis refines the\nresults of [2,3] about optimality of message passing algorithms by\ncharacterizing regions of parameters where these algorithms do not match the\nBayes-optimal performance. We further study numerically the performance of\napproximate message passing, derived in the dense limit, on sparse instances\nand carry out experiments on a real world dataset.\n"]},
{"authors": ["Szu-Wei Fu", "Tao-Wei Wang", "Yu Tsao", "Xugang Lu", "Hisashi Kawai"], "title": ["End-to-End Waveform Utterance Enhancement for Direct Evaluation Metrics\n  Optimization by Fully Convolutional Neural Networks"], "date": ["2017-09-12T02:24:50Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1709.03658v2"], "summary": ["  Speech enhancement model is used to map a noisy speech to a clean speech. In\nthe training stage, an objective function is often adopted to optimize the\nmodel parameters. However, in most studies, there is an inconsistency between\nthe model optimization criterion and the evaluation criterion on the enhanced\nspeech. For example, in measuring speech intelligibility, most of the\nevaluation metric is based on a short-time objective intelligibility (STOI)\nmeasure, while the frame based minimum mean square error (MMSE) between\nestimated and clean speech is widely used in optimizing the model. Due to the\ninconsistency, there is no guarantee that the trained model can provide optimal\nperformance in applications. In this study, we propose an end-to-end\nutterance-based speech enhancement framework using fully convolutional neural\nnetworks (FCN) to reduce the gap between the model optimization and evaluation\ncriterion. Because of the utterance-based optimization, temporal correlation\ninformation of long speech segments, or even at the entire utterance level, can\nbe considered when perception-based objective functions are used for the direct\noptimization. As an example, we implement the proposed FCN enhancement\nframework to optimize the STOI measure. Experimental results show that the STOI\nof test speech is better than conventional MMSE-optimized speech due to the\nconsistency between the training and evaluation target. Moreover, by\nintegrating the STOI in model optimization, the intelligibility of human\nsubjects and automatic speech recognition (ASR) system on the enhanced speech\nis also substantially improved compared to those generated by the MMSE\ncriterion.\n"]},
{"authors": ["Lei Zhou", "Xiao Bai", "Xianglong Liu", "Jun Zhou", "Hancock Edwin"], "title": ["Fast Subspace Clustering Based on the Kronecker Product"], "date": ["2018-03-15T09:31:44Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05657v1"], "summary": ["  Subspace clustering is a useful technique for many computer vision\napplications in which the intrinsic dimension of high-dimensional data is often\nsmaller than the ambient dimension. Spectral clustering, as one of the main\napproaches to subspace clustering, often takes on a sparse representation or a\nlow-rank representation to learn a block diagonal self-representation matrix\nfor subspace generation. However, existing methods require solving a large\nscale convex optimization problem with a large set of data, with computational\ncomplexity reaches O(N^3) for N data points. Therefore, the efficiency and\nscalability of traditional spectral clustering methods can not be guaranteed\nfor large scale datasets. In this paper, we propose a subspace clustering model\nbased on the Kronecker product. Due to the property that the Kronecker product\nof a block diagonal matrix with any other matrix is still a block diagonal\nmatrix, we can efficiently learn the representation matrix which is formed by\nthe Kronecker product of k smaller matrices. By doing so, our model\nsignificantly reduces the computational complexity to O(kN^{3/k}). Furthermore,\nour model is general in nature, and can be adapted to different regularization\nbased subspace clustering methods. Experimental results on two public datasets\nshow that our model significantly improves the efficiency compared with several\nstate-of-the-art methods. Moreover, we have conducted experiments on synthetic\ndata to verify the scalability of our model for large scale datasets.\n"]},
{"authors": ["Rianne van den Berg", "Leonard Hasenclever", "Jakub M. Tomczak", "Max Welling"], "title": ["Sylvester Normalizing Flows for Variational Inference"], "date": ["2018-03-15T09:15:14Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05649v1"], "summary": ["  Variational inference relies on flexible approximate posterior distributions.\nNormalizing flows provide a general recipe to construct flexible variational\nposteriors. We introduce Sylvester normalizing flows, which can be seen as a\ngeneralization of planar flows. Sylvester normalizing flows remove the\nwell-known single-unit bottleneck from planar flows, making a single\ntransformation much more flexible. We compare the performance of Sylvester\nnormalizing flows against planar flows and inverse autoregressive flows and\ndemonstrate that they compare favorably on several datasets.\n"]},
{"authors": ["Shen-Yi Zhao", "Gong-Duo Zhang", "Ming-Wei Li", "Wu-Jun Li"], "title": ["Proximal SCOPE for Distributed Sparse Learning: Better Data Partition\n  Implies Faster Convergence Rate"], "date": ["2018-03-15T07:38:50Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05621v1"], "summary": ["  Distributed sparse learning with a cluster of multiple machines has attracted\nmuch attention in machine learning, especially for large-scale applications\nwith high-dimensional data. One popular way to implement sparse learning is to\nuse $L_1$ regularization. In this paper, we propose a novel method, called\nproximal \\mbox{SCOPE}~(\\mbox{pSCOPE}), for distributed sparse learning with\n$L_1$ regularization. pSCOPE is based on a \\underline{c}ooperative\n\\underline{a}utonomous \\underline{l}ocal \\underline{l}earning~(\\mbox{CALL})\nframework. In the \\mbox{CALL} framework of \\mbox{pSCOPE}, we find that the data\npartition affects the convergence of the learning procedure, and subsequently\nwe define a metric to measure the goodness of a data partition. Based on the\ndefined metric, we theoretically prove that pSCOPE is convergent with a linear\nconvergence rate if the data partition is good enough. We also prove that\nbetter data partition implies faster convergence rate. Furthermore, pSCOPE is\nalso communication efficient. Experimental results on real data sets show that\npSCOPE can outperform other state-of-the-art distributed methods for sparse\nlearning.\n"]},
{"authors": ["Gamaleldin F. Elsayed", "Dilip Krishnan", "Hossein Mobahi", "Kevin Regan", "Samy Bengio"], "title": ["Large Margin Deep Networks for Classification"], "date": ["2018-03-15T05:33:13Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05598v1"], "summary": ["  We present a formulation of deep learning that aims at producing a large\nmargin classifier. The notion of margin, minimum distance to a decision\nboundary, has served as the foundation of several theoretically profound and\nempirically successful results for both classification and regression tasks.\nHowever, most large margin algorithms are applicable only to shallow models\nwith a preset feature representation; and conventional margin methods for\nneural networks only enforce margin at the output layer. Such methods are\ntherefore not well suited for deep networks.\n  In this work, we propose a novel loss function to impose a margin on any\nchosen set of layers of a deep network (including input and hidden layers). Our\nformulation allows choosing any norm on the metric measuring the margin. We\ndemonstrate that the decision boundary obtained by our loss has nice properties\ncompared to standard classification loss functions. Specifically, we show\nimproved empirical results on the MNIST, CIFAR-10 and ImageNet datasets on\nmultiple tasks: generalization from small training sets, corrupted labels, and\nrobustness against adversarial perturbations. The resulting loss is general and\ncomplementary to existing data augmentation (such as random/adversarial input\ntransform) and regularization techniques (such as weight decay, dropout, and\nbatch norm).\n"]},
{"authors": ["Rahul Kidambi", "Praneeth Netrapalli", "Prateek Jain", "Sham M. Kakade"], "title": ["On the insufficiency of existing momentum schemes for Stochastic\n  Optimization"], "date": ["2018-03-15T05:09:51Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05591v1"], "summary": ["  Momentum based stochastic gradient methods such as heavy ball (HB) and\nNesterov's accelerated gradient descent (NAG) method are widely used in\npractice for training deep networks and other supervised learning models, as\nthey often provide significant improvements over stochastic gradient descent\n(SGD). Rigorously speaking, \"fast gradient\" methods have provable improvements\nover gradient descent only for the deterministic case, where the gradients are\nexact. In the stochastic case, the popular explanations for their wide\napplicability is that when these fast gradient methods are applied in the\nstochastic case, they partially mimic their exact gradient counterparts,\nresulting in some practical gain. This work provides a counterpoint to this\nbelief by proving that there exist simple problem instances where these methods\ncannot outperform SGD despite the best setting of its parameters. These\nnegative problem instances are, in an informal sense, generic; they do not look\nlike carefully constructed pathological instances. These results suggest (along\nwith empirical evidence) that HB or NAG's practical performance gains are a\nby-product of mini-batching.\n  Furthermore, this work provides a viable (and provable) alternative, which,\non the same set of problem instances, significantly improves over HB, NAG, and\nSGD's performance. This algorithm, referred to as Accelerated Stochastic\nGradient Descent (ASGD), is a simple to implement stochastic algorithm, based\non a relatively less popular variant of Nesterov's Acceleration. Extensive\nempirical results in this paper show that ASGD has performance gains over HB,\nNAG, and SGD.\n"]},
{"authors": ["Shai Shalev-Shwartz", "Shaked Shammah", "Amnon Shashua"], "title": ["On a Formal Model of Safe and Scalable Self-driving Cars"], "date": ["2017-08-21T18:22:19Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1708.06374v5"], "summary": ["  In recent years, car makers and tech companies have been racing towards self\ndriving cars. It seems that the main parameter in this race is who will have\nthe first car on the road. The goal of this paper is to add to the equation two\nadditional crucial parameters. The first is standardization of safety assurance\n--- what are the minimal requirements that every self-driving car must satisfy,\nand how can we verify these requirements. The second parameter is scalability\n--- engineering solutions that lead to unleashed costs will not scale to\nmillions of cars, which will push interest in this field into a niche academic\ncorner, and drive the entire field into a \"winter of autonomous driving\". In\nthe first part of the paper we propose a white-box, interpretable, mathematical\nmodel for safety assurance, which we call Responsibility-Sensitive Safety\n(RSS). In the second part we describe a design of a system that adheres to our\nsafety assurance requirements and is scalable to millions of cars.\n"]},
{"authors": ["Wu Lin", "Nicolas Hubacher", "Mohammad Emtiyaz Khan"], "title": ["Variational Message Passing with Structured Inference Networks"], "date": ["2018-03-15T04:26:24Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05589v1"], "summary": ["  Recent efforts on combining deep models with probabilistic graphical models\nare promising in providing flexible models that are also easy to interpret. We\npropose a variational message-passing algorithm for variational inference in\nsuch models. We make three contributions. First, we propose structured\ninference networks that incorporate the structure of the graphical model in the\ninference network of variational auto-encoders (VAE). Second, we establish\nconditions under which such inference networks enable fast amortized inference\nsimilar to VAE. Finally, we derive a variational message passing algorithm to\nperform efficient natural-gradient inference while retaining the efficiency of\nthe amortized inference. By simultaneously enabling structured, amortized, and\nnatural-gradient inference for deep structured models, our method simplifies\nand generalizes existing methods.\n"]},
{"authors": ["Guorui Zhou", "Ying Fan", "Runpeng Cui", "Weijie Bian", "Xiaoqiang Zhu", "Kun Gai"], "title": ["Rocket Launching: A Universal and Efficient Framework for Training\n  Well-performing Light Net"], "date": ["2017-08-14T13:06:15Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1708.04106v3"], "summary": ["  Models applied on real time response task, like click-through rate (CTR)\nprediction model, require high accuracy and rigorous response time. Therefore,\ntop-performing deep models of high depth and complexity are not well suited for\nthese applications with the limitations on the inference time. In order to\nfurther improve the neural networks' performance given the time and\ncomputational limitations, we propose an approach that exploits a cumbersome\nnet to help train the lightweight net for prediction. We dub the whole process\nrocket launching, where the cumbersome booster net is used to guide the\nlearning of the target light net throughout the whole training process. We\nanalyze different loss functions aiming at pushing the light net to behave\nsimilarly to the booster net, and adopt the loss with best performance in our\nexperiments. We use one technique called gradient block to improve the\nperformance of the light net and booster net further. Experiments on benchmark\ndatasets and real-life industrial advertisement data present that our light\nmodel can get performance only previously achievable with more complex models.\n"]},
{"authors": ["Tim Salimans", "Han Zhang", "Alec Radford", "Dimitris Metaxas"], "title": ["Improving GANs Using Optimal Transport"], "date": ["2018-03-15T02:34:46Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05573v1"], "summary": ["  We present Optimal Transport GAN (OT-GAN), a variant of generative\nadversarial nets minimizing a new metric measuring the distance between the\ngenerator distribution and the data distribution. This metric, which we call\nmini-batch energy distance, combines optimal transport in primal form with an\nenergy distance defined in an adversarially learned feature space, resulting in\na highly discriminative distance function with unbiased mini-batch gradients.\nExperimentally we show OT-GAN to be highly stable when trained with large\nmini-batches, and we present state-of-the-art results on several popular\nbenchmark problems for image generation.\n"]},
{"authors": ["Lars Eidnes", "Arild N\u00f8kland"], "title": ["Shifting Mean Activation Towards Zero with Bipolar Activation Functions"], "date": ["2017-09-12T20:44:15Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1709.04054v3"], "summary": ["  We propose a simple extension to the ReLU-family of activation functions that\nallows them to shift the mean activation across a layer towards zero. Combined\nwith proper weight initialization, this alleviates the need for normalization\nlayers. We explore the training of deep vanilla recurrent neural networks\n(RNNs) with up to 144 layers, and show that bipolar activation functions help\nlearning in this setting. On the Penn Treebank and Text8 language modeling\ntasks we obtain competitive results, improving on the best reported results for\nnon-gated networks. In experiments with convolutional neural networks without\nbatch normalization, we find that bipolar activations produce a faster drop in\ntraining error, and results in a lower test error on the CIFAR-10\nclassification task.\n"]},
{"authors": ["Ayush Jaiswal", "Wael AbdAlmageed", "Yue Wu", "Premkumar Natarajan"], "title": ["Bidirectional Conditional Generative Adversarial Networks"], "date": ["2017-11-20T18:54:05Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.07461v2"], "summary": ["  Conditional Generative Adversarial Networks (cGANs) are generative models\nthat can produce data samples ($x$) conditioned on both latent variables ($z$)\nand known auxiliary information ($c$). We propose the Bidirectional cGAN\n(BiCoGAN), which effectively disentangles $z$ and $c$ in the generation process\nand provides an encoder that learns inverse mappings from $x$ to both $z$ and\n$c$, trained jointly with the generator and the discriminator. We present\ncrucial techniques for training BiCoGANs, which involve an extrinsic factor\nloss along with an associated dynamically-tuned importance weight. As compared\nto other encoder-based cGANs, BiCoGANs encode $c$ more accurately, and utilize\n$z$ and $c$ more effectively and in a more disentangled way to generate\nsamples.\n"]},
{"authors": ["Joeseph P. Smith", "Andrew D. Gronewold"], "title": ["Development and analysis of a Bayesian water balance model for large\n  lake systems"], "date": ["2017-10-26T12:49:05Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.10161v3"], "summary": ["  Water balance models (WBMs) are often employed to understand regional\nhydrologic cycles over various time scales. Most WBMs, however, are\nphysically-based, and few employ state-of-the-art statistical methods to\nreconcile independent input measurement uncertainty and bias. Further, few WBMs\nexist for large lakes, and most large lake WBMs perform additive accounting,\nwith minimal consideration towards input data uncertainty. Here, we introduce a\nframework for improving a previously developed large lake statistical water\nbalance model (L2SWBM). Focusing on the water balances of Lakes Superior and\nMichigan-Huron, we demonstrate our new analytical framework, identifying\nL2SWBMs from 26 alternatives that adequately close the water balance of the\nlakes with satisfactory computation times compared with the prototype model. We\nexpect our new framework will be used to develop water balance models for other\nlakes around the world.\n"]},
{"authors": ["Rajesh Ranganath", "Jaan Altosaar", "Dustin Tran", "David M. Blei"], "title": ["Operator Variational Inference"], "date": ["2016-10-27T23:32:25Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1610.09033v3"], "summary": ["  Variational inference is an umbrella term for algorithms which cast Bayesian\ninference as optimization. Classically, variational inference uses the\nKullback-Leibler divergence to define the optimization. Though this divergence\nhas been widely used, the resultant posterior approximation can suffer from\nundesirable statistical properties. To address this, we reexamine variational\ninference from its roots as an optimization problem. We use operators, or\nfunctions of functions, to design variational objectives. As one example, we\ndesign a variational objective with a Langevin-Stein operator. We develop a\nblack box algorithm, operator variational inference (OPVI), for optimizing any\noperator objective. Importantly, operators enable us to make explicit the\nstatistical and computational tradeoffs for variational inference. We can\ncharacterize different properties of variational objectives, such as objectives\nthat admit data subsampling---allowing inference to scale to massive data---as\nwell as objectives that admit variational programs---a rich class of posterior\napproximations that does not require a tractable density. We illustrate the\nbenefits of OPVI on a mixture model and a generative model of images.\n"]},
{"authors": ["Raj Agrawal", "Tamara Broderick", "Caroline Uhler"], "title": ["Minimal I-MAP MCMC for Scalable Structure Discovery in Causal DAG Models"], "date": ["2018-03-15T00:53:25Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05554v1"], "summary": ["  Learning a Bayesian network (BN) from data can be useful for decision-making\nor discovering causal relationships. However, traditional methods often fail in\nmodern applications, which exhibit a larger number of observed variables than\ndata points. The resulting uncertainty about the underlying network as well as\nthe desire to incorporate prior information recommend a Bayesian approach to\nlearning the BN, but the highly combinatorial structure of BNs poses a striking\nchallenge for inference. The current state-of-the-art methods such as order\nMCMC are faster than previous methods but prevent the use of many natural\nstructural priors and still have running time exponential in the maximum\nindegree of the true directed acyclic graph (DAG) of the BN. We here propose an\nalternative posterior approximation based on the observation that, if we\nincorporate empirical conditional independence tests, we can focus on a\nhigh-probability DAG associated with each order of the vertices. We show that\nour method allows the desired flexibility in prior specification, removes\ntiming dependence on the maximum indegree and yields provably good posterior\napproximations; in addition, we show that it achieves superior accuracy,\nscalability, and sampler mixing on several datasets.\n"]},
{"authors": ["Luchen Liu", "Jianhao Shen", "Ming Zhang", "Zichang Wang", "Jian Tang"], "title": ["Learning the Joint Representation of Heterogeneous Temporal Events for\n  Clinical Endpoint Prediction"], "date": ["2018-03-13T14:32:38Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04837v2"], "summary": ["  The availability of a large amount of electronic health records (EHR)\nprovides huge opportunities to improve health care service by mining these\ndata. One important application is clinical endpoint prediction, which aims to\npredict whether a disease, a symptom or an abnormal lab test will happen in the\nfuture according to patients' history records. This paper develops deep\nlearning techniques for clinical endpoint prediction, which are effective in\nmany practical applications. However, the problem is very challenging since\npatients' history records contain multiple heterogeneous temporal events such\nas lab tests, diagnosis, and drug administrations. The visiting patterns of\ndifferent types of events vary significantly, and there exist complex nonlinear\nrelationships between different events. In this paper, we propose a novel model\nfor learning the joint representation of heterogeneous temporal events. The\nmodel adds a new gate to control the visiting rates of different events which\neffectively models the irregular patterns of different events and their\nnonlinear correlations. Experiment results with real-world clinical data on the\ntasks of predicting death and abnormal lab tests prove the effectiveness of our\nproposed approach over competitive baselines.\n"]},
{"authors": ["Jiaming Song", "Shengjia Zhao", "Stefano Ermon"], "title": ["A-NICE-MC: Adversarial Training for MCMC"], "date": ["2017-06-23T04:19:04Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1706.07561v3"], "summary": ["  Existing Markov Chain Monte Carlo (MCMC) methods are either based on\ngeneral-purpose and domain-agnostic schemes which can lead to slow convergence,\nor hand-crafting of problem-specific proposals by an expert. We propose\nA-NICE-MC, a novel method to train flexible parametric Markov chain kernels to\nproduce samples with desired properties. First, we propose an efficient\nlikelihood-free adversarial training method to train a Markov chain and mimic a\ngiven data distribution. Then, we leverage flexible volume preserving flows to\nobtain parametric kernels for MCMC. Using a bootstrap approach, we show how to\ntrain efficient Markov chains to sample from a prescribed posterior\ndistribution by iteratively improving the quality of both the model and the\nsamples. A-NICE-MC provides the first framework to automatically design\nefficient domain-specific MCMC proposals. Empirical results demonstrate that\nA-NICE-MC combines the strong guarantees of MCMC with the expressiveness of\ndeep neural networks, and is able to significantly outperform competing methods\nsuch as Hamiltonian Monte Carlo.\n"]},
{"authors": ["Thomas Teh", "Chaiyawan Auepanwiriyakul", "John Alexander Harston", "A. Aldo Faisal"], "title": ["Generalised Structural CNNs (SCNNs) for time series data with arbitrary\n  graph-toplogies"], "date": ["2018-03-14T17:39:11Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05419v1"], "summary": ["  Deep Learning methods, specifically convolutional neural networks (CNNs),\nhave seen a lot of success in the domain of image-based data, where the data\noffers a clearly structured topology in the regular lattice of pixels. This\n4-neighbourhood topological simplicity makes the application of convolutional\nmasks straightforward for time series data, such as video applications, but\nmany high-dimensional time series data are not organised in regular lattices,\nand instead values may have adjacency relationships with non-trivial\ntopologies, such as small-world networks or trees. In our application case,\nhuman kinematics, it is currently unclear how to generalise convolutional\nkernels in a principled manner. Therefore we define and implement here a\nframework for general graph-structured CNNs for time series analysis. Our\nalgorithm automatically builds convolutional layers using the specified\nadjacency matrix of the data dimensions and convolutional masks that scale with\nthe hop distance. In the limit of a lattice-topology our method produces the\nwell-known image convolutional masks. We test our method first on synthetic\ndata of arbitrarily-connected graphs and human hand motion capture data, where\nthe hand is represented by a tree capturing the mechanical dependencies of the\njoints. We are able to demonstrate, amongst other things, that inclusion of the\ngraph structure of the data dimensions improves model prediction significantly,\nwhen compared against a benchmark CNN model with only time convolution layers.\n"]},
{"authors": ["Pavel Izmailov", "Dmitrii Podoprikhin", "Timur Garipov", "Dmitry Vetrov", "Andrew Gordon Wilson"], "title": ["Averaging Weights Leads to Wider Optima and Better Generalization"], "date": ["2018-03-14T17:09:27Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05407v1"], "summary": ["  Deep neural networks are typically trained by optimizing a loss function with\nan SGD variant, in conjunction with a decaying learning rate, until\nconvergence. We show that simple averaging of multiple points along the\ntrajectory of SGD, with a cyclical or constant learning rate, leads to better\ngeneralization than conventional training. We also show that this Stochastic\nWeight Averaging (SWA) procedure finds much broader optima than SGD, and\napproximates the recent Fast Geometric Ensembling (FGE) approach with a single\nmodel. Using SWA we achieve notable improvement in test accuracy over\nconventional SGD training on a range of state-of-the-art residual networks,\nPyramidNets, DenseNets, and Shake-Shake networks on CIFAR-10, CIFAR-100, and\nImageNet. In short, SWA is extremely easy to implement, improves\ngeneralization, and has almost no computational overhead.\n"]},
{"authors": ["Jeff M. Phillips", "Wai Ming Tai"], "title": ["Near-Optimal Coresets of Kernel Density Estimates"], "date": ["2018-02-06T01:06:47Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.01751v2"], "summary": ["  We construct near-optimal coresets for kernel density estimate for points in\n$\\mathbb{R^d}$ when the kernel is positive definite. Specifically we show a\npolynomial time construction for a coreset of size $O(\\sqrt{d\\log\n(1/\\epsilon)}/\\epsilon)$, and we show a near-matching lower bound of size\n$\\Omega(\\sqrt{d}/\\epsilon)$. The upper bound is a polynomial in $1/\\epsilon$\nimprovement when $d \\in [3,1/\\epsilon^2)$ (for all kernels except the Gaussian\nkernel which had a previous upper bound of $O((1/\\epsilon) \\log^d\n(1/\\epsilon))$) and the lower bound is the first known lower bound to depend on\n$d$ for this problem. Moreover, the upper bound restriction that the kernel is\npositive definite is significant in that it applies to a wide-variety of\nkernels, specifically those most important for machine learning. This includes\nkernels for information distances and the sinc kernel which can be negative.\n"]},
{"authors": ["Can Karakus", "Yifan Sun", "Suhas Diggavi", "Wotao Yin"], "title": ["Redundancy Techniques for Straggler Mitigation in Distributed\n  Optimization and Learning"], "date": ["2018-03-14T16:48:08Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05397v1"], "summary": ["  Performance of distributed optimization and learning systems is bottlenecked\nby \"straggler\" nodes and slow communication links, which significantly delay\ncomputation. We propose a distributed optimization framework where the dataset\nis \"encoded\" to have an over-complete representation with built-in redundancy,\nand the straggling nodes in the system are dynamically left out of the\ncomputation at every iteration, whose loss is compensated by the embedded\nredundancy. We show that oblivious application of several popular optimization\nalgorithms on encoded data, including gradient descent, L-BFGS, proximal\ngradient under data parallelism, and coordinate descent under model\nparallelism, converge to either approximate or exact solutions of the original\nproblem when stragglers are treated as erasures. These convergence results are\ndeterministic, i.e., they establish sample path convergence for arbitrary\nsequences of delay patterns or distributions on the nodes, and are independent\nof the tail behavior of the delay distribution. We demonstrate that equiangular\ntight frames have desirable properties as encoding matrices, and propose\nefficient mechanisms for encoding large-scale data. We implement the proposed\ntechnique on Amazon EC2 clusters, and demonstrate its performance over several\nlearning problems, including matrix factorization, LASSO, ridge regression and\nlogistic regression, and compare the proposed method with uncoded,\nasynchronous, and data replication strategies.\n"]},
{"authors": ["Yanzhi Wang", "Zheng Zhan", "Jiayu Li", "Jian Tang", "Bo Yuan", "Liang Zhao", "Wujie Wen", "Siyue Wang", "Xue Lin"], "title": ["On the Universal Approximation Property and Equivalence of Stochastic\n  Computing-based Neural Networks and Binary Neural Networks"], "date": ["2018-03-14T16:40:42Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05391v1"], "summary": ["  Large-scale deep neural networks are both memory intensive and\ncomputation-intensive, thereby posing stringent requirements on the computing\nplatforms. Hardware accelerations of deep neural networks have been extensively\ninvestigated in both industry and academia. Specific forms of binary neural\nnetworks (BNNs) and stochastic computing based neural networks (SCNNs) are\nparticularly appealing to hardware implementations since they can be\nimplemented almost entirely with binary operations. Despite the obvious\nadvantages in hardware implementation, these approximate computing techniques\nare questioned by researchers in terms of accuracy and universal applicability.\nAlso it is important to understand the relative pros and cons of SCNNs and BNNs\nin theory and in actual hardware implementations. In order to address these\nconcerns, in this paper we prove that the \"ideal\" SCNNs and BNNs satisfy the\nuniversal approximation property with probability 1 (due to the stochastic\nbehavior). The proof is conducted by first proving the property for SCNNs from\nthe strong law of large numbers, and then using SCNNs as a \"bridge\" to prove\nfor BNNs. Based on the universal approximation property, we further prove that\nSCNNs and BNNs exhibit the same energy complexity. In other words, they have\nthe same asymptotic energy consumption with the growing of network size. We\nalso provide a detailed analysis of the pros and cons of SCNNs and BNNs for\nhardware implementations and conclude that SCNNs are more suitable for\nhardware.\n"]},
{"authors": ["Rushil Anirudh", "Hyojin Kim", "Jayaraman J. Thiagarajan", "K. Aditya Mohan", "Kyle Champley", "Timo Bremer"], "title": ["Lose The Views: Limited Angle CT Reconstruction via Implicit Sinogram\n  Completion"], "date": ["2017-11-28T16:37:14Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.10388v2"], "summary": ["  Computed Tomography (CT) reconstruction is a fundamental component to a wide\nvariety of applications ranging from security, to healthcare. The classical\ntechniques require measuring projections, called sinograms, from a full\n180$^\\circ$ view of the object. This is impractical in a limited angle\nscenario, when the viewing angle is less than 180$^\\circ$, which can occur due\nto different factors including restrictions on scanning time, limited\nflexibility of scanner rotation, etc. The sinograms obtained as a result, cause\nexisting techniques to produce highly artifact-laden reconstructions. In this\npaper, we propose to address this problem through implicit sinogram completion,\non a challenging real world dataset containing scans of common checked-in\nluggage. We propose a system, consisting of 1D and 2D convolutional neural\nnetworks, that operates on a limited angle sinogram to directly produce the\nbest estimate of a reconstruction. Next, we use the x-ray transform on this\nreconstruction to obtain a \"completed\" sinogram, as if it came from a full\n180$^\\circ$ measurement. We feed this to standard analytical and iterative\nreconstruction techniques to obtain the final reconstruction. We show with\nextensive experimentation that this combined strategy outperforms many\ncompetitive baselines. We also propose a measure of confidence for the\nreconstruction that enables a practitioner to gauge the reliability of a\nprediction made by our network. We show that this measure is a strong indicator\nof quality as measured by the PSNR, while not requiring ground truth at test\ntime. Finally, using a segmentation experiment, we show that our reconstruction\npreserves the 3D structure of objects effectively.\n"]},
{"authors": ["F. Albarr\u00e1n-Arriagada", "J. C. Retamal", "E. Solano", "L. Lamata"], "title": ["Measurement-based adaptation protocol with quantum reinforcement\n  learning"], "date": ["2018-03-14T15:06:11Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05340v1"], "summary": ["  Machine learning employs dynamical algorithms that mimic the human capacity\nto learn, where the reinforcement learning ones are among the most similar to\nhumans in this respect. On the other hand, adaptability is an essential aspect\nto perform any task efficiently in a changing environment, and it is\nfundamental for many purposes, such as natural selection. Here, we propose an\nalgorithm based on successive measurements to adapt one quantum state to a\nreference unknown state, in the sense of achieving maximum overlap. The\nprotocol naturally provides many identical copies of the reference state, such\nthat in each measurement iteration more information about it is obtained. In\nour protocol, we consider a system composed of three parts, the \"environment\"\nsystem, which provides the reference state copies; the register, which is an\nauxiliary subsystem that interacts with the environment to acquire information\nfrom it; and the agent, which corresponds to the quantum state that is adapted\nby digital feedback with input corresponding to the outcome of the measurements\non the register. With this proposal we can achieve an average fidelity between\nthe environment and the agent of more than $90\\% $ with less than $30$\niterations of the protocol. In addition, we extend the formalism to $ d\n$-dimensional states, reaching an average fidelity of around $80\\% $ in less\nthan $400$ iterations for $d=$ 11, for a variety of genuinely quantum as well\nas semiclassical states. This work paves the way for the development of quantum\nreinforcement learning protocols using quantum data, and the future deployment\nof semi-autonomous quantum systems.\n"]},
{"authors": ["Run Han", "Yilong Yang", "Xiaoshan Li", "Defang Ouyang"], "title": ["Predicting Oral Disintegrating Tablet Formulations by Neural Network\n  Techniques"], "date": ["2018-03-14T15:05:11Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05339v1"], "summary": ["  Oral Disintegrating Tablets (ODTs) is a novel dosage form that can be\ndissolved on the tongue within 3min or less especially for geriatric and\npediatric patients. Current ODT formulation studies usually rely on the\npersonal experience of pharmaceutical experts and trial-and-error in the\nlaboratory, which is inefficient and time-consuming. The aim of current\nresearch was to establish the prediction model of ODT formulations with direct\ncompression process by Artificial Neural Network (ANN) and Deep Neural Network\n(DNN) techniques. 145 formulation data were extracted from Web of Science. All\ndata sets were divided into three parts: training set (105 data), validation\nset (20) and testing set (20). ANN and DNN were compared for the prediction of\nthe disintegrating time. The accuracy of the ANN model has reached 85.60%,\n80.00% and 75.00% on the training set, validation set and testing set\nrespectively, whereas that of the DNN model was 85.60%, 85.00% and 80.00%,\nrespectively. Compared with the ANN, DNN showed the better prediction for ODT\nformulations. It is the first time that deep neural network with the improved\ndataset selection algorithm is applied to formulation prediction on small data.\nThe proposed predictive approach could evaluate the critical parameters about\nquality control of formulation, and guide research and process development. The\nimplementation of this prediction model could effectively reduce drug product\ndevelopment timeline and material usage, and proactively facilitate the\ndevelopment of a robust drug product.\n"]},
{"authors": ["Mehmet Pilanci", "Elif Vural"], "title": ["Domain Adaptation on Graphs by Learning Aligned Graph Bases"], "date": ["2018-03-14T14:04:04Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05288v1"], "summary": ["  We propose a method for domain adaptation on graphs. Given sufficiently many\nobservations of the label function on a source graph, we study the problem of\ntransferring the label information from the source graph to a target graph for\nestimating the target label function. Our assumption about the relation between\nthe two domains is that the frequency content of the label function, regarded\nas a graph signal, has similar characteristics over the source and the target\ngraphs. We propose a method to learn a pair of coherent bases on the two\ngraphs, such that the corresponding source and target graph basis vectors have\nsimilar spectral content, while \"aligning\" the two graphs at the same time so\nthat the reconstructed source and target label functions have similar\ncoefficients over the bases. Experiments on several types of data sets suggest\nthat the proposed method compares quite favorably to reference domain\nadaptation methods. To the best of our knowledge, our treatment is the first to\nstudy the domain adaptation problem in a purely graph-based setting with no\nneed for embedding the data in an ambient space. This feature is particularly\nconvenient for many problems of interest concerning learning on graphs or\nnetworks.\n"]},
{"authors": ["Ilija Bogunovic", "Junyao Zhao", "Volkan Cevher"], "title": ["Robust Maximization of Non-Submodular Objectives"], "date": ["2018-02-20T12:02:01Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.07073v2"], "summary": ["  We study the problem of maximizing a monotone set function subject to a\ncardinality constraint $k$ in the setting where some number of elements $\\tau$\nis deleted from the returned set. The focus of this work is on the worst-case\nadversarial setting. While there exist constant-factor guarantees when the\nfunction is submodular, there are no guarantees for non-submodular objectives.\nIn this work, we present a new algorithm Oblivious-Greedy and prove the first\nconstant-factor approximation guarantees for a wider class of non-submodular\nobjectives. The obtained theoretical bounds are the first constant-factor\nbounds that also hold in the linear regime, i.e. when the number of deletions\n$\\tau$ is linear in $k$. Our bounds depend on established parameters such as\nthe submodularity ratio and some novel ones such as the inverse curvature. We\nbound these parameters for two important objectives including support selection\nand variance reduction. Finally, we numerically demonstrate the robust\nperformance of Oblivious-Greedy for these two objectives on various datasets.\n"]},
{"authors": ["Shuo-Hui Li", "Lei Wang"], "title": ["Neural Network Renormalization Group"], "date": ["2018-02-08T13:16:01Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.02840v2"], "summary": ["  We present a variational renormalization group approach using deep generative\nmodel composed of bijectors. The model can learn hierarchical transformations\nbetween physical variables and renormalized collective variables. It can\ndirectly generate statistically independent physical configurations by\niterative refinement at various length scales. The generative model has an\nexact and tractable likelihood, which provides renormalized energy function of\nthe collective variables and supports unbiased rejection sampling of the\nphysical variables. To train the neural network, we employ probability density\ndistillation, in which the training loss is a variational upper bound of the\nphysical free energy. The approach could be useful for automatically\nidentifying collective variables and effective field theories.\n"]},
{"authors": ["Hongqiao Wang", "Jinglai Li"], "title": ["Adaptive Gaussian process approximation for Bayesian inference with\n  expensive likelihood functions"], "date": ["2017-03-29T08:32:21Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1703.09930v4"], "summary": ["  We consider Bayesian inference problems with computationally intensive\nlikelihood functions. We propose a Gaussian process (GP) based method to\napproximate the joint distribution of the unknown parameters and the data. In\nparticular, we write the joint density approximately as a product of an\napproximate posterior density and an exponentiated GP surrogate. We then\nprovide an adaptive algorithm to construct such an approximation, where an\nactive learning method is used to choose the design points. With numerical\nexamples, we illustrate that the proposed method has competitive performance\nagainst existing approaches for Bayesian computation.\n"]},
{"authors": ["Thomas Wiatowski", "Philipp Grohs", "Helmut B\u00f6lcskei"], "title": ["Topology Reduction in Deep Convolutional Feature Extraction Networks"], "date": ["2017-07-10T06:35:48Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1707.02711v2"], "summary": ["  Deep convolutional neural networks (CNNs) used in practice employ potentially\nhundreds of layers and $10$,$000$s of nodes. Such network sizes entail\nsignificant computational complexity due to the large number of convolutions\nthat need to be carried out; in addition, a large number of parameters needs to\nbe learned and stored. Very deep and wide CNNs may therefore not be well suited\nto applications operating under severe resource constraints as is the case,\ne.g., in low-power embedded and mobile platforms. This paper aims at\nunderstanding the impact of CNN topology, specifically depth and width, on the\nnetwork's feature extraction capabilities. We address this question for the\nclass of scattering networks that employ either Weyl-Heisenberg filters or\nwavelets, the modulus non-linearity, and no pooling. The exponential feature\nmap energy decay results in Wiatowski et al., 2017, are generalized to\n$\\mathcal{O}(a^{-N})$, where an arbitrary decay factor $a>1$ can be realized\nthrough suitable choice of the Weyl-Heisenberg prototype function or the mother\nwavelet. We then show how networks of fixed (possibly small) depth $N$ can be\ndesigned to guarantee that $((1-\\varepsilon)\\cdot 100)\\%$ of the input signal's\nenergy are contained in the feature vector. Based on the notion of\noperationally significant nodes, we characterize, partly rigorously and partly\nheuristically, the topology-reducing effects of (effectively) band-limited\ninput signals, band-limited filters, and feature map symmetries. Finally, for\nnetworks based on Weyl-Heisenberg filters, we determine the prototype function\nbandwidth that minimizes---for fixed network depth $N$---the average number of\noperationally significant nodes per layer.\n"]},
{"authors": ["Pedro J. Villasana T.", "Stanislaw Gorlow", "Arvind T. Hariraman"], "title": ["Multiplicative Updates for Elastic Net Regularized Convolutional NMF\n  Under $\u03b2$-Divergence"], "date": ["2018-03-14T08:11:07Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05159v1"], "summary": ["  We generalize the convolutional NMF by taking the $\\beta$-divergence as the\nloss function, add a regularizer for sparsity in the form of an elastic net,\nand provide multiplicative update rules for its factors in closed form. The new\nupdate rules embed the $\\beta$-NMF, the standard convolutional NMF, and sparse\ncoding alias basis pursuit. We demonstrate that the originally published update\nrules for the convolutional NMF are suboptimal and that their convergence rate\ndepends on the size of the kernel.\n"]},
{"authors": ["Kalyan Ram Ayyalasomayajula", "Filip Malmberg", "Anders Brun"], "title": ["PDNet: Semantic Segmentation integrated with a Primal-Dual Network for\n  Document binarization"], "date": ["2018-01-26T07:07:07Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1801.08694v2"], "summary": ["  Binarization of digital documents is the task of classifying each pixel in an\nimage of the document as belonging to the background (parchment/paper) or\nforeground (text/ink). Historical documents are often subject to degradations,\nthat make the task challenging. In the current work a deep neural network\narchitecture is proposed that combines a fully convolutional network with an\nunrolled primal-dual network that can be trained end-to-end in order to achieve\nstate of the art binarization on four out of seven datasets. Document\nbinarization is formulated as a energy minimization problem. A fully\nconvolutional neural network is trained for semantic labeling of pixels to\nprovide class labeling cost associated with each pixel. This cost estimate is\nrefined along the edges to compensate for any over or under estimation of the\nunder represented fore-ground class using a primal-dual approach. We provide\nnecessary overview on proximal operator that facilitates theoretical\nunderpinning in order to train a primal-dual network using a gradient descent\nalgorithm. Numerical instabilities encountered due to the recurrent nature of\nprimal-dual approach are handled. We provide experimental results on document\nbinarization competition dataset along with network changes and hyperparameter\ntuning required for stability and performance of the network. The network when\npre-trained on synthetic dataset performs better as per the competition\nmetrics.\n"]},
{"authors": ["Yazhen Wang"], "title": ["Asymptotic Analysis via Stochastic Differential Equations of Gradient\n  Descent Algorithms in Statistical and Computational Paradigms"], "date": ["2017-11-27T02:52:29Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.09514v3"], "summary": ["  This paper investigates asymptotic behaviors of gradient descent algorithms\n(particularly accelerated gradient descent and stochastic gradient descent) in\nthe context of stochastic optimization arose in statistics and machine learning\nwhere objective functions are estimated from available data. We show that these\nalgorithms can be modeled by continuous-time ordinary or stochastic\ndifferential equations, and their asymptotic dynamic evolutions and\ndistributions are governed by some linear ordinary or stochastic differential\nequations, as the data size goes to infinity. We illustrate that our study can\nprovide a novel unified framework for a joint computational and statistical\nasymptotic analysis on dynamic behaviors of these algorithms with the time (or\nthe number of iterations in the algorithms) and large sample behaviors of the\nstatistical decision rules (like estimators and classifiers) that the\nalgorithms are applied to compute, where the statistical decision rules are the\nlimits of the random sequences generated from these iterative algorithms as the\nnumber of iterations goes to infinity.\n"]},
{"authors": ["Ikko Yamane", "Florian Yger", "Masashi Sugiyama"], "title": ["Uplift Modeling from Separate Labels"], "date": ["2018-03-14T02:46:17Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05112v1"], "summary": ["  Uplift modeling is aimed at estimating the incremental impact of an action on\nan individual's behavior, which is useful in various application domains such\nas targeted marketing (advertisement campaigns) and personalized medicine\n(medical treatments). Conventional methods of uplift modeling require every\ninstance to be jointly equipped with two types of labels: the taken action and\nits outcome. However, obtaining two labels for each instance at the same time\nis difficult or expensive in many real-world problems. In this paper, we\npropose a novel method of uplift modeling that is applicable to a more\npractical setting where only one type of labels is available for each instance.\nWe demonstrate the effectiveness of the proposed method through experiments.\n"]},
{"authors": ["Muge Li", "Liangyue Li", "Feiping Nie"], "title": ["Ranking with Adaptive Neighbors"], "date": ["2018-03-14T02:23:11Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05105v1"], "summary": ["  Retrieving the most similar objects in a large-scale database for a given\nquery is a fundamental building block in many application domains, ranging from\nweb searches, visual, cross media, and document retrievals. State-of-the-art\napproaches have mainly focused on capturing the underlying geometry of the data\nmanifolds. Graph-based approaches, in particular, define various diffusion\nprocesses on weighted data graphs. Despite success, these approaches rely on\nfixed-weight graphs, making ranking sensitive to the input affinity matrix. In\nthis study, we propose a new ranking algorithm that simultaneously learns the\ndata affinity matrix and the ranking scores. The proposed optimization\nformulation assigns adaptive neighbors to each point in the data based on the\nlocal connectivity, and the smoothness constraint assigns similar ranking\nscores to similar data points. We develop a novel and efficient algorithm to\nsolve the optimization problem. Evaluations using synthetic and real datasets\nsuggest that the proposed algorithm can outperform the existing methods.\n"]},
{"authors": ["Ashok Sundaresan", "Sugumar Murugesan", "Sean Davis", "Karthik Kappaganthu", "ZhongYi Jin", "Divya Jain", "Anurag Maunder"], "title": ["A Multi-Modal Approach to Infer Image Affect"], "date": ["2018-03-13T23:07:45Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05070v1"], "summary": ["  The group affect or emotion in an image of people can be inferred by\nextracting features about both the people in the picture and the overall makeup\nof the scene. The state-of-the-art on this problem investigates a combination\nof facial features, scene extraction and even audio tonality. This paper\ncombines three additional modalities, namely, human pose, text-based tagging\nand CNN extracted features / predictions. To the best of our knowledge, this is\nthe first time all of the modalities were extracted using deep neural networks.\nWe evaluate the performance of our approach against baselines and identify\ninsights throughout this paper.\n"]},
{"authors": ["Zachary C. Lipton", "Kamyar Azizzadenesheli", "Abhishek Kumar", "Lihong Li", "Jianfeng Gao", "Li Deng"], "title": ["Combating Reinforcement Learning's Sisyphean Curse with Intrinsic Fear"], "date": ["2016-11-03T22:30:10Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1611.01211v8"], "summary": ["  Many practical environments contain catastrophic states that an optimal agent\nwould visit infrequently or never. Even on toy problems, Deep Reinforcement\nLearning (DRL) agents tend to periodically revisit these states upon forgetting\ntheir existence under a new policy. We introduce intrinsic fear (IF), a learned\nreward shaping that guards DRL agents against periodic catastrophes. IF agents\npossess a fear model trained to predict the probability of imminent\ncatastrophe. This score is then used to penalize the Q-learning objective. Our\ntheoretical analysis bounds the reduction in average return due to learning on\nthe perturbed objective. We also prove robustness to classification errors. As\na bonus, IF models tend to learn faster, owing to reward shaping. Experiments\ndemonstrate that intrinsic-fear DQNs solve otherwise pathological environments\nand improve on several Atari games.\n"]},
{"authors": ["Adam Roberts", "Jesse Engel", "Colin Raffel", "Curtis Hawthorne", "Douglas Eck"], "title": ["A Hierarchical Latent Vector Model for Learning Long-Term Structure in\n  Music"], "date": ["2018-03-13T21:14:46Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05428v1"], "summary": ["  The Variational Autoencoder (VAE) has proven to be an effective model for\nproducing semantically meaningful latent representations for natural data.\nHowever, it has thus far seen limited application to sequential data, and, as\nwe demonstrate, existing recurrent VAE models have difficulty modeling\nsequences with long-term structure. To address this issue, we propose the use\nof a hierarchical decoder, which first outputs embeddings for subsequences of\nthe input and then uses these embeddings to generate each subsequence\nindependently. This structure encourages the model to utilize its latent code,\nthereby avoiding the \"posterior collapse\" problem which remains an issue for\nrecurrent VAEs. We apply this architecture to modeling sequences of musical\nnotes and find that it exhibits dramatically better sampling, interpolation,\nand reconstruction performance than a \"flat\" baseline model. An implementation\nof our \"MusicVAE\" is available online at http://g.co/magenta/musicvae-colab.\n"]},
{"authors": ["Arash Mehrjou"], "title": ["Analysis of Nonautonomous Adversarial Systems"], "date": ["2018-03-13T21:06:58Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05045v1"], "summary": ["  Generative adversarial networks are used to generate images but still their\nconvergence properties are not well understood. There have been a few studies\nwho intended to investigate the stability properties of GANs as a dynamical\nsystem. This short writing can be seen in that direction. Among the proposed\nmethods for stabilizing training of GANs, {\\ss}-GAN was the first who proposed\na complete annealing strategy to change high-level conditions of the GAN\nobjective. In this note, we show by a simple example how annealing strategy\nworks in GANs. The theoretical analysis is supported by simple simulations.\n"]},
{"authors": ["Pashupati Hegde", "Markus Heinonen", "Samuel Kaski"], "title": ["Variational zero-inflated Gaussian processes with sparse kernels"], "date": ["2018-03-13T20:34:23Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05036v1"], "summary": ["  Zero-inflated datasets, which have an excess of zero outputs, are commonly\nencountered in problems such as climate or rare event modelling. Conventional\nmachine learning approaches tend to overestimate the non-zeros leading to poor\nperformance. We propose a novel model family of zero-inflated Gaussian\nprocesses (ZiGP) for such zero-inflated datasets, produced by sparse kernels\nthrough learning a latent probit Gaussian process that can zero out kernel rows\nand columns whenever the signal is absent. The ZiGPs are particularly useful\nfor making the powerful Gaussian process networks more interpretable. We\nintroduce sparse GP networks where variable-order latent modelling is achieved\nthrough sparse mixing signals. We derive the non-trivial stochastic variational\ninference tractably for scalable learning of the sparse kernels in both models.\nThe novel output-sparse approach improves both prediction of zero-inflated data\nand interpretability of latent mixing models.\n"]},
{"authors": ["Yuting Wei", "Fanny Yang", "Martin J. Wainwright"], "title": ["Early stopping for kernel boosting algorithms: A general analysis with\n  localized complexities"], "date": ["2017-07-05T19:12:12Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1707.01543v2"], "summary": ["  Early stopping of iterative algorithms is a widely-used form of\nregularization in statistics, commonly used in conjunction with boosting and\nrelated gradient-type algorithms. Although consistency results have been\nestablished in some settings, such estimators are less well-understood than\ntheir analogues based on penalized regularization. In this paper, for a\nrelatively broad class of loss functions and boosting algorithms (including\nL2-boost, LogitBoost and AdaBoost, among others), we exhibit a direct\nconnection between the performance of a stopped iterate and the localized\nGaussian complexity of the associated function class. This connection allows us\nto show that local fixed point analysis of Gaussian or Rademacher complexities,\nnow standard in the analysis of penalized estimators, can be used to derive\noptimal stopping rules. We derive such stopping rules in detail for various\nkernel classes, and illustrate the correspondence of our theory with practice\nfor Sobolev kernel classes.\n"]},
{"authors": ["Dougal J. Sutherland", "Heiko Strathmann", "Michael Arbel", "Arthur Gretton"], "title": ["Efficient and principled score estimation with Nystr\u00f6m kernel\n  exponential families"], "date": ["2017-05-23T15:29:00Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1705.08360v5"], "summary": ["  We propose a fast method with statistical guarantees for learning an\nexponential family density model where the natural parameter is in a\nreproducing kernel Hilbert space, and may be infinite-dimensional. The model is\nlearned by fitting the derivative of the log density, the score, thus avoiding\nthe need to compute a normalization constant. Our approach improves the\ncomputational efficiency of an earlier solution by using a low-rank,\nNystr\\\"om-like solution. The new solution retains the consistency and\nconvergence rates of the full-rank solution (exactly in Fisher distance, and\nnearly in other distances), with guarantees on the degree of cost and storage\nreduction. We evaluate the method in experiments on density estimation and in\nthe construction of an adaptive Hamiltonian Monte Carlo sampler. Compared to an\nexisting score learning approach using a denoising autoencoder, our estimator\nis empirically more data-efficient when estimating the score, runs faster, and\nhas fewer parameters (which can be tuned in a principled and interpretable\nway), in addition to providing statistical guarantees.\n"]},
{"authors": ["Yingying Zhu", "Mert R. Sabuncu"], "title": ["A Probabilistic Disease Progression Model for Predicting Future Clinical\n  Outcome"], "date": ["2018-03-13T19:05:08Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05011v1"], "summary": ["  In this work, we consider the problem of predicting the course of a\nprogressive disease, such as cancer or Alzheimer's. Progressive diseases often\nstart with mild symptoms that might precede a diagnosis, and each patient\nfollows their own trajectory. Patient trajectories exhibit wild variability,\nwhich can be associated with many factors such as genotype, age, or sex. An\nadditional layer of complexity is that, in real life, the amount and type of\ndata available for each patient can differ significantly. For example, for one\npatient we might have no prior history, whereas for another patient we might\nhave detailed clinical assessments obtained at multiple prior time-points. This\npaper presents a probabilistic model that can handle multiple modalities\n(including images and clinical assessments) and variable patient histories with\nirregular timings and missing entries, to predict clinical scores at future\ntime-points. We use a sigmoidal function to model latent disease progression,\nwhich gives rise to clinical observations in our generative model. We\nimplemented an approximate Bayesian inference strategy on the proposed model to\nestimate the parameters on data from a large population of subjects.\nFurthermore, the Bayesian framework enables the model to automatically\nfine-tune its predictions based on historical observations that might be\navailable on the test subject. We applied our method to a longitudinal\nAlzheimer's disease dataset with more than 3000 subjects [23] and present a\ndetailed empirical analysis of prediction performance under different\nscenarios, with comparisons against several benchmarks. We also demonstrate how\nthe proposed model can be interrogated to glean insights about temporal\ndynamics in Alzheimer's disease.\n"]},
{"authors": ["Ilias Diakonikolas", "Gautam Kamath", "Daniel M. Kane", "Jerry Li", "Ankur Moitra", "Alistair Stewart"], "title": ["Being Robust (in High Dimensions) Can Be Practical"], "date": ["2017-03-02T18:50:33Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1703.00893v4"], "summary": ["  Robust estimation is much more challenging in high dimensions than it is in\none dimension: Most techniques either lead to intractable optimization problems\nor estimators that can tolerate only a tiny fraction of errors. Recent work in\ntheoretical computer science has shown that, in appropriate distributional\nmodels, it is possible to robustly estimate the mean and covariance with\npolynomial time algorithms that can tolerate a constant fraction of\ncorruptions, independent of the dimension. However, the sample and time\ncomplexity of these algorithms is prohibitively large for high-dimensional\napplications. In this work, we address both of these issues by establishing\nsample complexity bounds that are optimal, up to logarithmic factors, as well\nas giving various refinements that allow the algorithms to tolerate a much\nlarger fraction of corruptions. Finally, we show on both synthetic and real\ndata that our algorithms have state-of-the-art performance and suddenly make\nhigh-dimensional robust estimation a realistic possibility.\n"]},
{"authors": ["David Lopez-Paz", "Maxime Oquab"], "title": ["Revisiting Classifier Two-Sample Tests"], "date": ["2016-10-20T19:16:10Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1610.06545v4"], "summary": ["  The goal of two-sample tests is to assess whether two samples, $S_P \\sim P^n$\nand $S_Q \\sim Q^m$, are drawn from the same distribution. Perhaps intriguingly,\none relatively unexplored method to build two-sample tests is the use of binary\nclassifiers. In particular, construct a dataset by pairing the $n$ examples in\n$S_P$ with a positive label, and by pairing the $m$ examples in $S_Q$ with a\nnegative label. If the null hypothesis \"$P = Q$\" is true, then the\nclassification accuracy of a binary classifier on a held-out subset of this\ndataset should remain near chance-level. As we will show, such Classifier\nTwo-Sample Tests (C2ST) learn a suitable representation of the data on the fly,\nreturn test statistics in interpretable units, have a simple null distribution,\nand their predictive uncertainty allow to interpret where $P$ and $Q$ differ.\nThe goal of this paper is to establish the properties, performance, and uses of\nC2ST. First, we analyze their main theoretical properties. Second, we compare\ntheir performance against a variety of state-of-the-art alternatives. Third, we\npropose their use to evaluate the sample quality of generative models with\nintractable likelihoods, such as Generative Adversarial Networks (GANs).\nFourth, we showcase the novel application of GANs together with C2ST for causal\ndiscovery.\n"]},
{"authors": ["Casey Kneale", "Steven D. Brown"], "title": ["Small Moving Window Calibration Models for Soft Sensing Processes with\n  Limited History"], "date": ["2017-10-31T17:15:37Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.11595v3"], "summary": ["  Five simple soft sensor methodologies with two update conditions were\ncompared on two experimentally-obtained datasets and one simulated dataset. The\nsoft sensors investigated were moving window partial least squares regression\n(and a recursive variant), moving window random forest regression, the mean\nmoving window of $y$, and a novel random forest partial least squares\nregression ensemble (RF-PLS), all of which can be used with small sample sizes\nso that they can be rapidly placed online. It was found that, on two of the\ndatasets studied, small window sizes led to the lowest prediction errors for\nall of the moving window methods studied. On the majority of datasets studied,\nthe RF-PLS calibration method offered the lowest one-step-ahead prediction\nerrors compared to those of the other methods, and it demonstrated greater\npredictive stability at larger time delays than moving window PLS alone. It was\nfound that both the random forest and RF-PLS methods most adequately modeled\nthe datasets that did not feature purely monotonic increases in property\nvalues, but that both methods performed more poorly than moving window PLS\nmodels on one dataset with purely monotonic property values. Other data\ndependent findings are presented and discussed.\n"]},
{"authors": ["R\u00e9mi Pautrat", "Konstantinos Chatzilygeroudis", "Jean-Baptiste Mouret"], "title": ["Bayesian Optimization with Automatic Prior Selection for Data-Efficient\n  Direct Policy Search"], "date": ["2017-09-20T15:04:50Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1709.06919v2"], "summary": ["  One of the most interesting features of Bayesian optimization for direct\npolicy search is that it can leverage priors (e.g., from simulation or from\nprevious tasks) to accelerate learning on a robot. In this paper, we are\ninterested in situations for which several priors exist but we do not know in\nadvance which one fits best the current situation. We tackle this problem by\nintroducing a novel acquisition function, called Most Likely Expected\nImprovement (MLEI), that combines the likelihood of the priors and the expected\nimprovement. We evaluate this new acquisition function on a transfer learning\ntask for a 5-DOF planar arm and on a possibly damaged, 6-legged robot that has\nto learn to walk on flat ground and on stairs, with priors corresponding to\ndifferent stairs and different kinds of damages. Our results show that MLEI\neffectively identifies and exploits the priors, even when there is no obvious\nmatch between the current situations and the priors.\n"]},
{"authors": ["Diviyan Kalainathan", "Olivier Goudet", "Isabelle Guyon", "David Lopez-Paz", "Mich\u00e8le Sebag"], "title": ["SAM: Structural Agnostic Model, Causal Discovery and Penalized\n  Adversarial Learning"], "date": ["2018-03-13T16:40:00Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04929v1"], "summary": ["  We present the Structural Agnostic Model (SAM), a framework to estimate\nend-to-end non-acyclic causal graphs from observational data. In a nutshell,\nSAM implements an adversarial game in which a separate model generates each\nvariable, given real values from all others. In tandem, a discriminator\nattempts to distinguish between the joint distributions of real and generated\nsamples. Finally, a sparsity penalty forces each generator to consider only a\nsmall subset of the variables, yielding a sparse causal graph. SAM scales\neasily to hundreds variables. Our experiments show the state-of-the-art\nperformance of SAM on discovering causal structures and modeling interventions,\nin both acyclic and non-acyclic graphs.\n"]},
{"authors": ["Konstantinos Chatzilygeroudis", "Jean-Baptiste Mouret"], "title": ["Using Parameterized Black-Box Priors to Scale Up Model-Based Policy\n  Search for Robotics"], "date": ["2017-09-20T15:03:47Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1709.06917v2"], "summary": ["  The most data-efficient algorithms for reinforcement learning in robotics are\nmodel-based policy search algorithms, which alternate between learning a\ndynamical model of the robot and optimizing a policy to maximize the expected\nreturn given the model and its uncertainties. Among the few proposed\napproaches, the recently introduced Black-DROPS algorithm exploits a black-box\noptimization algorithm to achieve both high data-efficiency and good\ncomputation times when several cores are used; nevertheless, like all\nmodel-based policy search approaches, Black-DROPS does not scale to high\ndimensional state/action spaces. In this paper, we introduce a new model\nlearning procedure in Black-DROPS that leverages parameterized black-box priors\nto (1) scale up to high-dimensional systems, and (2) be robust to large\ninaccuracies of the prior information. We demonstrate the effectiveness of our\napproach with the \"pendubot\" swing-up task in simulation and with a physical\nhexapod robot (48D state space, 18D action space) that has to walk forward as\nfast as possible. The results show that our new algorithm is more\ndata-efficient than previous model-based policy search algorithms (with and\nwithout priors) and that it can allow a physical 6-legged robot to learn new\ngaits in only 16 to 30 seconds of interaction time.\n"]},
{"authors": ["Roi Naveiro", "Sim\u00f3n Rodr\u00edguez", "David R\u00edos Insua"], "title": ["Large Scale Automated Forecasting for Monitoring Network Safety and\n  Security"], "date": ["2018-02-19T15:50:02Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.06678v2"], "summary": ["  Real time large scale streaming data pose major challenges to forecasting, in\nparticular defying the presence of human experts to perform the corresponding\nanalysis. We present here a class of models and methods used to develop an\nautomated, scalable and versatile system for large scale forecasting oriented\ntowards safety and security monitoring. Our system provides short and long term\nforecasts and uses them to detect safety and security issues in relation with\nmultiple internet connected devices well in advance they might take place.\n"]},
{"authors": ["Micha\u00ebl Defferrard", "Sharada P. Mohanty", "Sean F. Carroll", "Marcel Salath\u00e9"], "title": ["Learning to Recognize Musical Genre from Audio"], "date": ["2018-03-13T15:58:58Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05337v1"], "summary": ["  We here summarize our experience running a challenge with open data for\nmusical genre recognition. Those notes motivate the task and the challenge\ndesign, show some statistics about the submissions, and present the results.\n"]},
{"authors": ["Ievgen Redko", "Nicolas Courty", "R\u00e9mi Flamary", "Devis Tuia"], "title": ["Optimal Transport for Multi-source Domain Adaptation under Target Shift"], "date": ["2018-03-13T15:55:35Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04899v1"], "summary": ["  In this paper, we propose to tackle the problem of reducing discrepancies\nbetween multiple domains referred to as multi-source domain adaptation and\nconsider it under the target shift assumption: in all domains we aim to solve a\nclassification problem with the same output classes, but with labels'\nproportions differing across them. We design a method based on optimal\ntransport, a theory that is gaining momentum to tackle adaptation problems in\nmachine learning due to its efficiency in aligning probability distributions.\nOur method performs multi-source adaptation and target shift correction\nsimultaneously by learning the class probabilities of the unlabeled target\nsample and the coupling allowing to align two (or more) probability\ndistributions. Experiments on both synthetic and real-world data related to\nsatellite image segmentation task show the superiority of the proposed method\nover the state-of-the-art.\n"]},
{"authors": ["Thomas Ryder", "Andrew Golightly", "A. Stephen McGough", "Dennis Prangle"], "title": ["Black-box Variational Inference for Stochastic Differential Equations"], "date": ["2018-02-09T16:36:28Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.03335v2"], "summary": ["  Parameter inference for stochastic differential equations is challenging due\nto the presence of a latent diffusion process. Working with an Euler-Maruyama\ndiscretisation for the diffusion, we use variational inference to jointly learn\nthe parameters and the diffusion paths. We use a standard mean-field\nvariational approximation of the parameter posterior, and introduce a recurrent\nneural network to approximate the posterior for the diffusion paths conditional\non the parameters. This neural network learns how to provide Gaussian state\ntransitions which bridge between observations in a very similar way to the\nconditioned diffusion process. The resulting black-box inference method can be\napplied to any SDE system with light tuning requirements. We illustrate the\nmethod on a Lotka-Volterra system and an epidemic model, producing accurate\nparameter estimates in a few hours.\n"]},
{"authors": ["Reka Kovacs", "Oktay Gunluk", "Raphael Hauser"], "title": ["Low-Rank Boolean Matrix Approximation by Integer Programming"], "date": ["2018-03-13T14:17:00Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04825v1"], "summary": ["  Low-rank approximations of data matrices are an important dimensionality\nreduction tool in machine learning and regression analysis. We consider the\ncase of categorical variables, where it can be formulated as the problem of\nfinding low-rank approximations to Boolean matrices. In this paper we give what\nis to the best of our knowledge the first integer programming formulation that\nrelies on only polynomially many variables and constraints, we discuss how to\nsolve it computationally and report numerical tests on synthetic and real-world\ndata.\n"]},
{"authors": ["Addison Bohannon", "Brian Sadler", "Radu Balan"], "title": ["Learning flexible representations of stochastic processes on graphs"], "date": ["2017-11-03T14:45:50Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.01191v2"], "summary": ["  Graph convolutional networks adapt the architecture of convolutional neural\nnetworks to learn rich representations of data supported on arbitrary graphs by\nreplacing the convolution operations of convolutional neural networks with\ngraph-dependent linear operations. However, these graph-dependent linear\noperations are developed for scalar functions supported on undirected graphs.\nWe propose a class of linear operations for stochastic (time-varying) processes\non directed (or undirected) graphs to be used in graph convolutional networks.\nWe propose a parameterization of such linear operations using functional\ncalculus to achieve arbitrarily low learning complexity. The proposed approach\nis shown to model richer behaviors and display greater flexibility in learning\nrepresentations than product graph methods.\n"]},
{"authors": ["N. Olspert", "J. Pelt", "M. J. K\u00e4pyl\u00e4", "J. Lehtinen"], "title": ["Estimating activity cycles with probabilistic methods I. Bayesian\n  Generalised Lomb-Scargle Periodogram with Trend"], "date": ["2017-12-21T22:16:14Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1712.08235v2"], "summary": ["  Period estimation is one of the central topics in astronomical time series\nanalysis, where data is often unevenly sampled. Especially challenging are\nstudies of stellar magnetic cycles, as there the periods looked for are of the\norder of the same length than the datasets themselves. The datasets often\ncontain trends, the origin of which is either a real long-term cycle or an\ninstrumental effect, but these effects cannot be reliably separated, while they\ncan lead to erroneous period determinations if not properly handled. In this\nstudy we aim at developing a method that can handle the trends properly, and by\nperforming extensive set of testing, we show that this is the optimal procedure\nwhen contrasted with methods that do not include the trend directly to the\nmodel. The effect of the form of the noise (whether constant or\nheteroscedastic) on the results is also investigated. We introduce a Bayesian\nGeneralised Lomb-Scargle Periodogram with Trend (BGLST), which is a\nprobabilistic linear regression model using Gaussian priors for the\ncoefficients and uniform prior for the frequency parameter. We show, using\nsynthetic data, that when there is no prior information on whether and to what\nextent the true model of the data contains a linear trend, the introduced BGLST\nmethod is preferable to the methods which either detrend the data or leave the\ndata untrended before fitting the periodic model. Whether to use noise with\ndifferent than constant variance in the model depends on the density of the\ndata sampling as well as on the true noise type of the process.\n"]},
{"authors": ["Nicolas Papernot", "Patrick McDaniel"], "title": ["Deep k-Nearest Neighbors: Towards Confident, Interpretable and Robust\n  Deep Learning"], "date": ["2018-03-13T13:02:13Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04765v1"], "summary": ["  Deep neural networks (DNNs) enable innovative applications of machine\nlearning like image recognition, machine translation, or malware detection.\nHowever, deep learning is often criticized for its lack of robustness in\nadversarial settings (e.g., vulnerability to adversarial inputs) and general\ninability to rationalize its predictions. In this work, we exploit the\nstructure of deep learning to enable new learning-based inference and decision\nstrategies that achieve desirable properties such as robustness and\ninterpretability. We take a first step in this direction and introduce the Deep\nk-Nearest Neighbors (DkNN). This hybrid classifier combines the k-nearest\nneighbors algorithm with representations of the data learned by each layer of\nthe DNN: a test input is compared to its neighboring training points according\nto the distance that separates them in the representations. We show the labels\nof these neighboring points afford confidence estimates for inputs outside the\nmodel's training manifold, including on malicious inputs like adversarial\nexamples--and therein provides protections against inputs that are outside the\nmodels understanding. This is because the nearest neighbors can be used to\nestimate the nonconformity of, i.e., the lack of support for, a prediction in\nthe training data. The neighbors also constitute human-interpretable\nexplanations of predictions. We evaluate the DkNN algorithm on several\ndatasets, and show the confidence estimates accurately identify inputs outside\nthe model, and that the explanations provided by nearest neighbors are\nintuitive and useful in understanding model failures.\n"]},
{"authors": ["Johannes Lederer", "Lu Yu", "Irina Gaynanova"], "title": ["Oracle Inequalities for High-dimensional Prediction"], "date": ["2016-08-01T21:42:55Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1608.00624v2"], "summary": ["  The abundance of high-dimensional data in the modern sciences has generated\ntremendous interest in penalized estimators such as the lasso, scaled lasso,\nsquare-root lasso, elastic net, and many others. In this paper, we establish a\ngeneral oracle inequality for prediction in high-dimensional linear regression\nwith such methods. Since the proof relies only on convexity and continuity\narguments, the result holds irrespective of the design matrix and applies to a\nwide range of penalized estimators. Overall, the bound demonstrates that\ngeneric estimators can provide consistent prediction with any design matrix.\nFrom a practical point of view, the bound can help to identify the potential of\nspecific estimators, and they can help to get a sense of the prediction\naccuracy in a given application.\n"]},
{"authors": ["Sergey Novoselov", "Oleg Kudashev", "Vadim Schemelinin", "Ivan Kremnev", "Galina Lavrentyeva"], "title": ["Deep CNN based feature extractor for text-prompted speaker recognition"], "date": ["2018-03-13T10:59:24Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.05307v1"], "summary": ["  Deep learning is still not a very common tool in speaker verification field.\nWe study deep convolutional neural network performance in the text-prompted\nspeaker verification task. The prompted passphrase is segmented into word\nstates - i.e. digits -to test each digit utterance separately. We train a\nsingle high-level feature extractor for all states and use cosine similarity\nmetric for scoring. The key feature of our network is the Max-Feature-Map\nactivation function, which acts as an embedded feature selector. By using\nmultitask learning scheme to train the high-level feature extractor we were\nable to surpass the classic baseline systems in terms of quality and achieved\nimpressive results for such a novice approach, getting 2.85% EER on the RSR2015\nevaluation set. Fusion of the proposed and the baseline systems improves this\nresult.\n"]},
{"authors": ["Alexander Jung", "Madelon Hulsebos"], "title": ["The Network Nullspace Property for Compressed Sensing of Big Data over\n  Networks"], "date": ["2017-05-11T21:21:08Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1705.04379v4"], "summary": ["  We present a novel condition, which we term the net- work nullspace property,\nwhich ensures accurate recovery of graph signals representing massive\nnetwork-structured datasets from few signal values. The network nullspace\nproperty couples the cluster structure of the underlying network-structure with\nthe geometry of the sampling set. Our results can be used to design efficient\nsampling strategies based on the network topology.\n"]},
{"authors": ["Tom Zahavy", "Avinatan Hasidim", "Haim Kaplan", "Yishay Mansour"], "title": ["Hierarchical Reinforcement Learning: Approximating Optimal Discounted\n  TSP Using Local Policies"], "date": ["2018-03-13T08:13:11Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04674v1"], "summary": ["  In this work, we provide theoretical guarantees for reward decomposition in\ndeterministic MDPs. Reward decomposition is a special case of Hierarchical\nReinforcement Learning, that allows one to learn many policies in parallel and\ncombine them into a composite solution. Our approach builds on mapping this\nproblem into a Reward Discounted Traveling Salesman Problem, and then deriving\napproximate solutions for it. In particular, we focus on approximate solutions\nthat are local, i.e., solutions that only observe information about the current\nstate. Local policies are easy to implement and do not require substantial\ncomputational resources as they do not perform planning. While local\ndeterministic policies, like Nearest Neighbor, are being used in practice for\nhierarchical reinforcement learning, we propose three stochastic policies that\nguarantee better performance than any deterministic policy.\n"]},
{"authors": ["Andy Brown", "Aaron Tuor", "Brian Hutchinson", "Nicole Nichols"], "title": ["Recurrent Neural Network Attention Mechanisms for Interpretable System\n  Log Anomaly Detection"], "date": ["2018-03-13T08:09:20Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04967v1"], "summary": ["  Deep learning has recently demonstrated state-of-the art performance on key\ntasks related to the maintenance of computer systems, such as intrusion\ndetection, denial of service attack detection, hardware and software system\nfailures, and malware detection. In these contexts, model interpretability is\nvital for administrator and analyst to trust and act on the automated analysis\nof machine learning models. Deep learning methods have been criticized as black\nbox oracles which allow limited insight into decision factors. In this work we\nseek to \"bridge the gap\" between the impressive performance of deep learning\nmodels and the need for interpretable model introspection. To this end we\npresent recurrent neural network (RNN) language models augmented with attention\nfor anomaly detection in system logs. Our methods are generally applicable to\nany computer system and logging source.\n  By incorporating attention variants into our RNN language models we create\nopportunities for model introspection and analysis without sacrificing\nstate-of-the art performance.\n  We demonstrate model performance and illustrate model interpretability on an\nintrusion detection task using the Los Alamos National Laboratory (LANL) cyber\nsecurity dataset, reporting upward of 0.99 area under the receiver operator\ncharacteristic curve despite being trained only on a single day's worth of\ndata.\n"]},
{"authors": ["Maryam Aziz", "Jesse Anderton", "Emilie Kaufmann", "Javed Aslam"], "title": ["Pure Exploration in Infinitely-Armed Bandit Models with Fixed-Confidence"], "date": ["2018-03-13T07:36:31Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04665v1"], "summary": ["  We consider the problem of near-optimal arm identification in the fixed\nconfidence setting of the infinitely armed bandit problem when nothing is known\nabout the arm reservoir distribution. We (1) introduce a PAC-like framework\nwithin which to derive and cast results; (2) derive a sample complexity lower\nbound for near-optimal arm identification; (3) propose an algorithm that\nidentifies a nearly-optimal arm with high probability and derive an upper bound\non its sample complexity which is within a log factor of our lower bound; and\n(4) discuss whether our log^2(1/delta) dependence is inescapable for\n\"two-phase\" (select arms first, identify the best later) algorithms in the\ninfinite setting. This work permits the application of bandit models to a\nbroader class of problems where fewer assumptions hold.\n"]},
{"authors": ["Han Qiu", "Hoang Thanh Lam", "Francesco Fusco", "Mathieu Sinn"], "title": ["Learning Correlation Space for Time Series"], "date": ["2018-02-10T17:59:25Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.03628v2"], "summary": ["  We propose an approximation algorithm for efficient correlation search in\ntime series data. In our method, we use Fourier transform and neural network to\nembed time series into a low-dimensional Euclidean space. The given space is\nlearned such that time series correlation can be effectively approximated from\nEuclidean distance between corresponding embedded vectors. Therefore, search\nfor correlated time series can be done using an index in the embedding space\nfor efficient nearest neighbor search. Our theoretical analysis illustrates\nthat our method's accuracy can be guaranteed under certain regularity\nconditions. We further conduct experiments on real-world datasets and the\nresults show that our method indeed outperforms the baseline solution. In\nparticular, for approximation of correlation, our method reduces the\napproximation loss by a half in most test cases compared to the baseline\nsolution. For top-$k$ highest correlation search, our method improves the\nprecision from 5\\% to 20\\% while the query time is similar to the baseline\napproach query time.\n"]},
{"authors": ["Lilian Besson", "Emilie Kaufmann"], "title": ["Multi-Player Bandits Revisited"], "date": ["2017-11-07T07:10:47Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.02317v3"], "summary": ["  Multi-player Multi-Armed Bandits (MAB) have been extensively studied in the\nliterature, motivated by applications to Cognitive Radio systems. Driven by\nsuch applications as well, we motivate the introduction of several levels of\nfeedback for multi-player MAB algorithms. Most existing work assume that\nsensing information is available to the algorithm. Under this assumption, we\nimprove the state-of-the-art lower bound for the regret of any decentralized\nalgorithms and introduce two algorithms, RandTopM and MCTopM, that are shown to\nempirically outperform existing algorithms. Moreover, we provide strong\ntheoretical guarantees for these algorithms, including a notion of asymptotic\noptimality in terms of the number of selections of bad arms. We then introduce\na promising heuristic, called Selfish, that can operate without sensing\ninformation, which is crucial for emerging applications to Internet of Things\nnetworks. We investigate the empirical performance of this algorithm and\nprovide some first theoretical elements for the understanding of its behavior.\n"]},
{"authors": ["Masayoshi Hayashi", "Tomoya Sakai", "Masashi Sugiyama"], "title": ["Binary Matrix Completion Using Unobserved Entries"], "date": ["2018-03-13T07:26:30Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04663v1"], "summary": ["  A matrix completion problem, which aims to recover a complete matrix from its\npartial observations, is one of the important problems in the machine learning\nfield and has been studied actively. However, there is a discrepancy between\nthe mainstream problem setting, which assumes continuous-valued observations,\nand some practical applications such as recommendation systems and SNS link\npredictions where observations take discrete or even binary values. To cope\nwith this problem, Davenport et al. (2014) proposed a binary matrix completion\n(BMC) problem, where observations are quantized into binary values. Hsieh et\nal. (2015) proposed a PU (Positive and Unlabeled) matrix completion problem,\nwhich is an extension of the BMC problem. This problem targets the setting\nwhere we cannot observe negative values, such as SNS link predictions. In the\nconstruction of their method for this setting, they introduced a methodology of\nthe classification problem, regarding each matrix entry as a sample. Their\nrisk, which defines losses over unobserved entries as well, indicates the\npossibility of the use of unobserved entries. In this paper, motivated by a\nsemi-supervised classification method recently proposed by Sakai et al. (2017),\nwe develop a method for the BMC problem which can use all of positive,\nnegative, and unobserved entries, by combining the risks of Davenport et al.\n(2014) and Hsieh et al. (2015). To the best of our knowledge, this is the first\nBMC method which exploits all kinds of matrix entries. We experimentally show\nthat an appropriate mixture of risks improves the performance.\n"]},
{"authors": ["Kar Wai Lim", "Young Lee", "Leif Hanlen", "Hongbiao Zhao"], "title": ["Simulation and Calibration of a Fully Bayesian Marked Multidimensional\n  Hawkes Process with Dissimilar Decays"], "date": ["2018-03-13T06:44:56Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04654v1"], "summary": ["  We propose a simulation method for multidimensional Hawkes processes based on\nsuperposition theory of point processes. This formulation allows us to design\nefficient simulations for Hawkes processes with differing exponentially\ndecaying intensities. We demonstrate that inter-arrival times can be decomposed\ninto simpler auxiliary variables that can be sampled directly, giving exact\nsimulation with no approximation. We establish that the auxiliary variables\nprovides information on the parent process for each event time. The algorithm\ncorrectness is shown by verifying the simulated intensities with their\ntheoretical moments. A modular inference procedure consisting of Gibbs samplers\nthrough the auxiliary variable augmentation and adaptive rejection sampling is\npresented. Finally, we compare our proposed simulation method against existing\nmethods, and find significant improvement in terms of algorithm speed. Our\ninference algorithm is used to discover the strengths of mutually excitations\nin real dark networks.\n"]},
{"authors": ["George Barmpalias", "Frank Stephan"], "title": ["Algorithmic learning of probability distributions from random data in\n  the limit"], "date": ["2017-10-31T02:35:04Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.11303v3"], "summary": ["  We study the problem of identifying a probability distribution for some given\nrandomly sampled data in the limit, in the context of algorithmic learning\ntheory as proposed recently by Vinanyi and Chater. We show that there exists a\ncomputable partial learner for the computable probability measures, while by\nBienvenu, Monin and Shen it is known that there is no computable learner for\nthe computable probability measures. Our main result is the characterization of\nthe oracles that compute explanatory learners for the computable (continuous)\nprobability measures as the high oracles. This provides an analogue of a\nwell-known result of Adleman and Blum in the context of learning computable\nprobability distributions. We also discuss related learning notions such as\nbehaviorally correct learning and orther variations of explanatory learning, in\nthe context of learning probability distributions from data.\n"]},
{"authors": ["Ayush Jaiswal", "Wael AbdAlmageed", "Yue Wu", "Premkumar Natarajan"], "title": ["CapsuleGAN: Generative Adversarial Capsule Network"], "date": ["2018-02-17T01:04:53Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.06167v3"], "summary": ["  We present Generative Adversarial Capsule Network (CapsuleGAN), a framework\nthat uses capsule networks (CapsNets) instead of the standard convolutional\nneural networks (CNNs) as discriminators within the generative adversarial\nnetwork (GAN) setting, while modeling image data. We provide guidelines for\ndesigning CapsNet discriminators and the updated GAN objective function, which\nincorporates the CapsNet margin loss, for training CapsuleGAN models. We show\nthat CapsuleGAN outperforms convolutional-GAN at modeling image data\ndistribution on MNIST and CIFAR-10 datasets, evaluated on the generative\nadversarial metric and at semi-supervised image classification.\n"]},
{"authors": ["Osbert Bastani", "Carolyn Kim", "Hamsa Bastani"], "title": ["Interpretability via Model Extraction"], "date": ["2017-06-29T14:30:40Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1706.09773v4"], "summary": ["  The ability to interpret machine learning models has become increasingly\nimportant now that machine learning is used to inform consequential decisions.\nWe propose an approach called model extraction for interpreting complex,\nblackbox models. Our approach approximates the complex model using a much more\ninterpretable model; as long as the approximation quality is good, then\nstatistical properties of the complex model are reflected in the interpretable\nmodel. We show how model extraction can be used to understand and debug random\nforests and neural nets trained on several datasets from the UCI Machine\nLearning Repository, as well as control policies learned for several classical\nreinforcement learning problems.\n"]},
{"authors": ["Alistair Shilton", "Sunil Gupta", "Santu Rana", "Pratibha Vellanki", "Cheng Li", "Laurence Park", "Svetha Venkatesh", "Alessandra Sutti", "David Rubin", "Thomas Dorin", "Alireza Vahid", "Murray Height"], "title": ["Covariance Function Pre-Training with m-Kernels for Accelerated Bayesian\n  Optimisation"], "date": ["2018-02-15T00:38:28Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.05370v2"], "summary": ["  The paper presents a novel approach to direct covariance function learning\nfor Bayesian optimisation, with particular emphasis on experimental design\nproblems where an existing corpus of condensed knowledge is present. The method\npresented borrows techniques from reproducing kernel Banach space theory\n(specifically m-kernels) and leverages them to convert (or re-weight) existing\ncovariance functions into new, problem-specific covariance functions. The key\nadvantage of this approach is that rather than relying on the user to manually\nselect (with some hyperparameter tuning and experimentation) an appropriate\ncovariance function it constructs the covariance function to specifically match\nthe problem at hand. The technique is demonstrated on two real-world problems -\nspecifically alloy design and short-polymer fibre manufacturing - as well as a\nselected test function.\n"]},
{"authors": ["Neil Dhir", "Houman Dallali", "Mo Rastgaar"], "title": ["Coregionalised Locomotion Envelopes - A Qualitative Approach"], "date": ["2018-03-13T00:04:40Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04965v1"], "summary": ["  'Sharing of statistical strength' is a phrase often employed in machine\nlearning and signal processing. In sensor networks, for example, missing\nsignals from certain sensors may be predicted by exploiting their correlation\nwith observed signals acquired from other sensors. For humans, our hands move\nsynchronously with our legs, and we can exploit these implicit correlations for\npredicting new poses and for generating new natural-looking walking sequences.\nWe can also go much further and exploit this form of transfer learning, to\ndevelop new control schemas for robust control of rehabilitation robots. In\nthis short paper we introduce coregionalised locomotion envelopes - a method\nfor multi-dimensional manifold regression, on human locomotion variates. Herein\nwe render a qualitative description of this method.\n"]},
{"authors": ["Ardavan Afshar", "Ioakeim Perros", "Evangelos E. Papalexakis", "Elizabeth Searles", "Joyce Ho", "Jimeng Sun"], "title": ["COPA: Constrained PARAFAC2 for Sparse & Large Datasets"], "date": ["2018-03-12T23:27:06Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04572v1"], "summary": ["  PARAFAC2 has demonstrated success in modeling irregular tensors, where the\ntensor dimensions vary across one of the modes. An example scenario is jointly\nmodeling treatments across a set of patients with varying number of medical\nencounters, where the alignment of events in time bears no clinical meaning,\nand it may also be impossible to align them due to their varying length.\nDespite recent improvements on scaling up unconstrained PARAFAC2, its model\nfactors are usually dense and sensitive to noise which limits their\ninterpretability. As a result, the following open challenges remain: a) various\nmodeling constraints, such as temporal smoothness, sparsity and non-negativity,\nare needed to be imposed for interpretable temporal modeling and b) a scalable\napproach is required to support those constraints efficiently for large\ndatasets. To tackle these challenges, we propose a COnstrained PARAFAC2 (COPA)\nmethod, which carefully incorporates optimization constraints such as temporal\nsmoothness, sparsity, and non-negativity in the resulting factors. To\nefficiently support all those constraints, COPA adopts a hybrid optimization\nframework using alternating optimization and alternating direction method of\nmultiplier (AO-ADMM). As evaluated on large electronic health record (EHR)\ndatasets with hundreds of thousands of patients, COPA achieves significant\nspeedups (up to 36x faster) over prior PARAFAC2 approaches that only attempt to\nhandle a subset of the constraints that COPA enables. Overall, our method\noutperforms all the baselines attempting to handle a subset of the constraints\nin terms of speed, while achieving the same level of accuracy.\n"]},
{"authors": ["Nicholas R. Waytowich", "Vernon Lawhern", "Javier O. Garcia", "Jennifer Cummings", "Josef Faller", "Paul Sajda", "Jean M. Vettel"], "title": ["Compact Convolutional Neural Networks for Classification of Asynchronous\n  Steady-state Visual Evoked Potentials"], "date": ["2018-03-12T23:03:44Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04566v1"], "summary": ["  Steady-State Visual Evoked Potentials (SSVEPs) are neural oscillations from\nthe parietal and occipital regions of the brain that are evoked from flickering\nvisual stimuli. SSVEPs are robust signals measurable in the\nelectroencephalogram (EEG) and are commonly used in brain-computer interfaces\n(BCIs). However, methods for high-accuracy decoding of SSVEPs usually require\nhand-crafted approaches that leverage domain-specific knowledge of the stimulus\nsignals, such as specific temporal frequencies in the visual stimuli and their\nrelative spatial arrangement. When this knowledge is unavailable, such as when\nSSVEP signals are acquired asynchronously, such approaches tend to fail. In\nthis paper, we show how a compact convolutional neural network (Compact-CNN),\nwhich only requires raw EEG signals for automatic feature extraction, can be\nused to decode signals from a 12-class SSVEP dataset without the need for any\ndomain-specific knowledge or calibration data. We report across subject mean\naccuracy of approximately 80% (chance being 8.3%) and show this is\nsubstantially better than current state-of-the-art hand-crafted approaches\nusing canonical correlation analysis (CCA) and Combined-CCA. Furthermore, we\nanalyze our Compact-CNN to examine the underlying feature representation,\ndiscovering that the deep learner extracts additional phase and amplitude\nrelated features associated with the structure of the dataset. We discuss how\nour Compact-CNN shows promise for BCI applications that allow users to freely\ngaze/attend to any stimulus at any time (e.g., asynchronous BCI) as well as\nprovides a method for analyzing SSVEP signals in a way that might augment our\nunderstanding about the basic processing in the visual cortex.\n"]},
{"authors": ["Ahmed El Alaoui", "Michael I. Jordan"], "title": ["Detection limits in the high-dimensional spiked rectangular model"], "date": ["2018-02-20T20:19:06Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.07309v2"], "summary": ["  We study the problem of detecting the presence of a single unknown spike in a\nrectangular data matrix, in a high-dimensional regime where the spike has fixed\nstrength and the aspect ratio of the matrix converges to a finite limit. This\nsetup includes Johnstone's spiked covariance model. We analyze the likelihood\nratio of the spiked model against an \"all noise\" null model of reference, and\nshow it has asymptotically Gaussian fluctuations in a region below---but in\ngeneral not up to---the so-called BBP threshold from random matrix theory. Our\nresult parallels earlier findings of Onatski et al.\\ (2013) and\nJohnstone-Onatski (2015) for spherical spikes. We present a probabilistic\napproach capable of treating generic product priors. In particular, sparsity in\nthe spike is allowed. Our approach is based on Talagrand's interpretation of\nthe cavity method from spin-glass theory. The question of the maximal parameter\nregion where asymptotic normality is expected to hold is left open. This region\nis shaped by the prior in a non-trivial way. We conjecture that this is the\nentire paramagnetic phase of an associated spin-glass model, and is defined by\nthe vanishing of the replica-symmetric solution of Lesieur et al.\\ (2015).\n"]},
{"authors": ["Zhixin Zhou", "Arash A. Amini"], "title": ["Analysis of spectral clustering algorithms for community detection: the\n  general bipartite setting"], "date": ["2018-03-12T21:50:58Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04547v1"], "summary": ["  We consider the analysis of spectral clustering algorithms for community\ndetection under a stochastic block model (SBM). A general spectral clustering\nalgorithm consists of three steps: (1) regularization of an appropriate\nadjacency or Laplacian matrix (2) a form of spectral truncation and (3) a\nk-means type algorithm in the reduced spectral domain. By varying each step,\none can obtain different spectral algorithms. In light of the recent\ndevelopments in refining consistency results for the spectral clustering, we\nidentify the necessary bounds at each of these three steps, and then derive and\ncompare consistency results for some existing spectral algorithms as well as a\nnew variant that we propose. The focus of the paper is on providing a better\nunderstanding of the analysis of spectral methods for community detection, with\nan emphasis on the bipartite setting which has received less theoretical\nconsideration. We show how the variations in the spectral truncation step\nreflects in the consistency results under a general SBM. We also investigate\nthe necessary bounds for the k-means step in some detail, allowing one to\nreplace this step with any algorithm (k-means type or otherwise) that\nguarantees the necessary bound. We discuss some of the neglected aspects of the\nbipartite setting, e.g., the role of the mismatch between the communities of\nthe two sides on the performance of spectral methods. Finally, we show how the\nconsistency results can be extended beyond SBMs to the problem of clustering\ninhomogeneous random graph models that can be approximated by SBMs in a certain\nsense.\n"]},
{"authors": ["Binxin Ru", "Mark McLeod", "Diego Granziol", "Michael Osborne"], "title": ["Fast Information-theoretic Bayesian Optimisation"], "date": ["2017-11-02T10:09:09Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.00673v4"], "summary": ["  Information-theoretic Bayesian optimisation techniques have demonstrated\nstate-of-the-art performance in tackling important global optimisation\nproblems. However, current information-theoretic approaches require many\napproximations in implementation, introduce often-prohibitive computational\noverhead and limit the choice of kernels available to model the objective. We\ndevelop a fast information-theoretic Bayesian Optimisation method, FITBO, that\navoids the need for sampling the global minimiser, thus significantly reducing\ncomputational overhead. Moreover, in comparison with existing approaches, our\nmethod faces fewer constraints on kernel choice and enjoys the merits of\ndealing with the output space. We demonstrate empirically that FITBO inherits\nthe performance associated with information-theoretic Bayesian optimisation,\nwhile being even faster than simpler Bayesian optimisation approaches, such as\nExpected Improvement.\n"]},
{"authors": ["Leon Bottou", "Martin Arjovsky", "David Lopez-Paz", "Maxime Oquab"], "title": ["Geometrical Insights for Implicit Generative Modeling"], "date": ["2017-12-21T08:11:44Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1712.07822v2"], "summary": ["  Learning algorithms for implicit generative models can optimize a variety of\ncriteria that measure how the data distribution differs from the implicit model\ndistribution, including the Wasserstein distance, the Energy distance, and the\nMaximum Mean Discrepancy criterion. A careful look at the geometries induced by\nthese distances on the space of probability measures reveals interesting\ndifferences. In particular, we can establish surprising approximate global\nconvergence guarantees for the $1$-Wasserstein distance,even when the\nparametric generator has a nonconvex parametrization.\n"]},
{"authors": ["Tanmay Gangwani", "Jian Peng"], "title": ["Policy Optimization by Genetic Distillation"], "date": ["2017-11-03T03:29:32Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.01012v2"], "summary": ["  Genetic algorithms have been widely used in many practical optimization\nproblems. Inspired by natural selection, operators, including mutation,\ncrossover and selection, provide effective heuristics for search and black-box\noptimization. However, they have not been shown useful for deep reinforcement\nlearning, possibly due to the catastrophic consequence of parameter crossovers\nof neural networks. Here, we present Genetic Policy Optimization (GPO), a new\ngenetic algorithm for sample-efficient deep policy optimization. GPO uses\nimitation learning for policy crossover in the state space and applies policy\ngradient methods for mutation. Our experiments on MuJoCo tasks show that GPO as\na genetic algorithm is able to provide superior performance over the\nstate-of-the-art policy gradient methods and achieves comparable or higher\nsample efficiency.\n"]},
{"authors": ["Sean Billings"], "title": ["Gradient Augmented Information Retrieval with Autoencoders and Semantic\n  Hashing"], "date": ["2018-03-12T19:49:30Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04494v1"], "summary": ["  This paper will explore the use of autoencoders for semantic hashing in the\ncontext of Information Retrieval. This paper will summarize how to efficiently\ntrain an autoencoder in order to create meaningful and low-dimensional\nencodings of data. This paper will demonstrate how computing and storing the\nclosest encodings to an input query can help speed up search time and improve\nthe quality of our search results. The novel contributions of this paper\ninvolve using the representation of the data learned by an auto-encoder in\norder to augment our search query in various ways. I present and evaluate the\nnew gradient search augmentation (GSA) approach, as well as the more well-known\npseudo-relevance-feedback (PRF) adjustment. I find that GSA helps to improve\nthe performance of the TF-IDF based information retrieval system, and PRF\ncombined with GSA works best overall for the systems compared in this paper.\n"]},
{"authors": ["Sean Billings"], "title": ["Probabilistic and Regularized Graph Convolutional Networks"], "date": ["2018-03-12T19:47:16Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04489v1"], "summary": ["  This paper explores the recently proposed Graph Convolutional Network\narchitecture proposed in (Kipf & Welling, 2016) The key points of their work is\nsummarized and their results are reproduced. Graph regularization and\nalternative graph convolution approaches are explored. I find that explicit\ngraph regularization was correctly rejected by (Kipf & Welling, 2016). I\nattempt to improve the performance of GCN by approximating a k-step transition\nmatrix in place of the normalized graph laplacian, but I fail to find positive\nresults. Nonetheless, the performance of several configurations of this GCN\nvariation is shown for the Cora, Citeseer, and Pubmed datasets.\n"]},
{"authors": ["Evan N. Feinberg", "Amir Barati Farimani", "Rajendra Uprety", "Amanda Hunkele", "Gavril W. Pasternak", "Susruta Majumdar", "Vijay S. Pande"], "title": ["Machine Learning Harnesses Molecular Dynamics to Discover New $\u03bc$\n  Opioid Chemotypes"], "date": ["2018-03-12T19:32:21Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04479v1"], "summary": ["  Computational chemists typically assay drug candidates by virtually screening\ncompounds against crystal structures of a protein despite the fact that some\ntargets, like the $\\mu$ Opioid Receptor and other members of the GPCR family,\ntraverse many non-crystallographic states. We discover new conformational\nstates of $\\mu OR$ with molecular dynamics simulation and then machine learn\nligand-structure relationships to predict opioid ligand function. These\nartificial intelligence models identified a novel $\\mu$ opioid chemotype.\n"]},
{"authors": ["Enrico Camporeale"], "title": ["Accuracy-Reliability Cost Function for Empirical Variance Estimation"], "date": ["2018-03-12T19:24:37Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04475v1"], "summary": ["  In this paper we focus on the problem of assigning uncertainties to\nsingle-point predictions. We introduce a cost function that encodes the\ntrade-off between accuracy and reliability in probabilistic forecast. We derive\nanalytic formula for the case of forecasts of continuous scalar variables\nexpressed in terms of Gaussian distributions. The Accuracy-Reliability cost\nfunction can be used to empirically estimate the variance in heteroskedastic\nregression problems (input dependent noise), by solving a two-objective\noptimization problem. The simple philosophy behind this strategy is that\npredictions based on the estimated variances should be both accurate and\nreliable (i.e. statistical consistent with observations). We show several\nexamples with synthetic data, where the underlying hidden noise function can be\naccurately recovered, both in one and multi-dimensional problems. The practical\nimplementation of the method has been done using a Neural Network and, in the\none-dimensional case, with a simple polynomial fit.\n"]},
{"authors": ["Boris Sharchilev", "Yury Ustinovsky", "Pavel Serdyukov", "Maarten de Rijke"], "title": ["Finding Influential Training Samples for Gradient Boosted Decision Trees"], "date": ["2018-02-19T14:19:40Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.06640v2"], "summary": ["  We address the problem of finding influential training samples for a\nparticular case of tree ensemble-based models, e.g., Random Forest (RF) or\nGradient Boosted Decision Trees (GBDT). A natural way of formalizing this\nproblem is studying how the model's predictions change upon leave-one-out\nretraining, leaving out each individual training sample. Recent work has shown\nthat, for parametric models, this analysis can be conducted in a\ncomputationally efficient way. We propose several ways of extending this\nframework to non-parametric GBDT ensembles under the assumption that tree\nstructures remain fixed. Furthermore, we introduce a general scheme of\nobtaining further approximations to our method that balance the trade-off\nbetween performance and computational complexity. We evaluate our approaches on\nvarious experimental setups and use-case scenarios and demonstrate both the\nquality of our approach to finding influential training samples in comparison\nto the baselines and its computational efficiency.\n"]},
{"authors": ["Adel Javanmard", "Hamid Javadi"], "title": ["False Discovery Rate Control via Debiased Lasso"], "date": ["2018-03-12T19:03:33Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04464v1"], "summary": ["  We consider the problem of variable selection in high-dimensional statistical\nmodels where the goal is to report a set of variables, out of many predictors\n$X_1, \\dotsc, X_p$, that are relevant to a response of interest. For linear\nhigh-dimensional model, where the number of parameters exceeds the number of\nsamples $(p>n)$, we propose a procedure for variables selection and prove that\nit controls the \\emph{directional} false discovery rate (FDR) below a\npre-assigned significance level $q\\in [0,1]$. We further analyze the\nstatistical power of our framework and show that for designs with subgaussian\nrows and a common precision matrix $\\Omega\\in\\mathbb{R}^{p\\times p}$, if the\nminimum nonzero parameter $\\theta_{\\min}$ satisfies $$\\sqrt{n} \\theta_{\\min} -\n\\sigma \\sqrt{2(\\max_{i\\in [p]}\\Omega_{ii})\\log\\left(\\frac{2p}{qs_0}\\right)} \\to\n\\infty\\,,$$ then this procedure achieves asymptotic power one.\n  Our framework is built upon the debiasing approach and assumes the standard\ncondition $s_0 = o(\\sqrt{n}/(\\log p)^2)$, where $s_0$ indicates the number of\ntrue positives among the $p$ features. Notably, this framework achieves exact\ndirectional FDR control without any assumption on the amplitude of unknown\nregression parameters, and does not require any knowledge of the distribution\nof covariates or the noise level. We test our method in synthetic and real data\nexperiments to asses its performance and to corroborate our theoretical\nresults.\n"]},
{"authors": ["Zilong Tan", "Kimberly Roche", "Xiang Zhou", "Sayan Mukherjee"], "title": ["Scalable Algorithms for Learning High-Dimensional Linear Mixed Models"], "date": ["2018-03-12T18:07:40Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04431v1"], "summary": ["  Linear mixed models (LMMs) are used extensively to model dependecies of\nobservations in linear regression and are used extensively in many application\nareas. Parameter estimation for LMMs can be computationally prohibitive on big\ndata. State-of-the-art learning algorithms require computational complexity\nwhich depends at least linearly on the dimension $p$ of the covariates, and\noften use heuristics that do not offer theoretical guarantees. We present\nscalable algorithms for learning high-dimensional LMMs with sublinear\ncomputational complexity dependence on $p$. Key to our approach are novel dual\nestimators which use only kernel functions of the data, and fast computational\ntechniques based on the subsampled randomized Hadamard transform. We provide\ntheoretical guarantees for our learning algorithms, demonstrating the\nrobustness of parameter estimation. Finally, we complement the theory with\nexperiments on large synthetic and real data.\n"]},
{"authors": ["Kelly Peterson", "Ognjen Rudovic", "Ricardo Guerrero", "Rosalind W. Picard"], "title": ["Personalized Gaussian Processes for Future Prediction of Alzheimer's\n  Disease Progression"], "date": ["2017-12-01T04:05:27Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1712.00181v3"], "summary": ["  In this paper, we introduce the use of a personalized Gaussian Process model\n(pGP) to predict the key metrics of Alzheimer's Disease progression (MMSE,\nADAS-Cog13, CDRSB and CS) based on each patient's previous visits. We start by\nlearning a population-level model using multi-modal data from previously seen\npatients using the base Gaussian Process (GP) regression. Then, this model is\nadapted sequentially over time to a new patient using domain adaptive GPs to\nform the patient's pGP. We show that this new approach, together with an\nauto-regressive formulation, leads to significant improvements in forecasting\nfuture clinical status and cognitive scores for target patients when compared\nto modeling the population with traditional GPs.\n"]},
{"authors": ["Junhong Lin", "Volkan Cevher"], "title": ["Optimal Rates of Sketched-regularized Algorithms for Least-Squares\n  Regression over Hilbert Spaces"], "date": ["2018-03-12T16:57:48Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04371v1"], "summary": ["  We investigate regularized algorithms combining with projection for\nleast-squares regression problem over a Hilbert space, covering nonparametric\nregression over a reproducing kernel Hilbert space. We prove convergence\nresults with respect to variants of norms, under a capacity assumption on the\nhypothesis space and a regularity condition on the target function. As a\nresult, we obtain optimal rates for regularized algorithms with randomized\nsketches, provided that the sketch dimension is proportional to the effective\ndimension up to a logarithmic factor. As a byproduct, we obtain similar results\nfor Nystr\\\"{o}m regularized algorithms. Our results are the first ones with\noptimal, distribution-dependent rates that do not have any saturation effect\nfor sketched/Nystr\\\"{o}m regularized algorithms, considering both the\nattainable and non-attainable cases.\n"]},
{"authors": ["Fouad Hadj-Selem", "Tommy Lofstedt", "Elvis Dohmatob", "Vincent Frouin", "Mathieu Dubois", "Vincent Guillemot", "Edouard Duchesnay"], "title": ["Continuation of Nesterov's Smoothing for Regression with Structured\n  Sparsity in High-Dimensional Neuroimaging"], "date": ["2016-05-31T15:09:13Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1605.09658v5"], "summary": ["  Predictive models can be used on high-dimensional brain images for diagnosis\nof a clinical condition. Spatial regularization through structured sparsity\noffers new perspectives in this context and reduces the risk of overfitting the\nmodel while providing interpretable neuroimaging signatures by forcing the\nsolution to adhere to domain-specific constraints. Total Variation (TV)\nenforces spatial smoothness of the solution while segmenting predictive regions\nfrom the background. We consider the problem of minimizing the sum of a smooth\nconvex loss, a non-smooth convex penalty (whose proximal operator is known) and\na wide range of possible complex, non-smooth convex structured penalties such\nas TV or overlapping group Lasso. Existing solvers are either limited in the\nfunctions they can minimize or in their practical capacity to scale to\nhigh-dimensional imaging data. Nesterov's smoothing technique can be used to\nminimize a large number of non-smooth convex structured penalties but\nreasonable precision requires a small smoothing parameter, which slows down the\nconvergence speed. To benefit from the versatility of Nesterov's smoothing\ntechnique, we propose a first order continuation algorithm, CONESTA, which\nautomatically generates a sequence of decreasing smoothing parameters. The\ngenerated sequence maintains the optimal convergence speed towards any globally\ndesired precision. Our main contributions are: To propose an expression of the\nduality gap to probe the current distance to the global optimum in order to\nadapt the smoothing parameter and the convergence speed. We provide a\nconvergence rate, which is an improvement over classical proximal gradient\nsmoothing methods. We demonstrate on both simulated and high-dimensional\nstructural neuroimaging data that CONESTA significantly outperforms many\nstate-of-the-art solvers in regard to convergence speed and precision.\n"]},
{"authors": ["Charles F Jekel", "Raphael T. Haftka"], "title": ["Classifying Online Dating Profiles on Tinder using FaceNet Facial\n  Embeddings"], "date": ["2018-03-12T16:14:24Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04347v1"], "summary": ["  A method to produce personalized classification models to automatically\nreview online dating profiles on Tinder is proposed, based on the user's\nhistorical preference. The method takes advantage of a FaceNet facial\nclassification model to extract features which may be related to facial\nattractiveness. The embeddings from a FaceNet model were used as the features\nto describe an individual's face. A user reviewed 8,545 online dating profiles.\nFor each reviewed online dating profile, a feature set was constructed from the\nprofile images which contained just one face. Two approaches are presented to\ngo from the set of features for each face, to a set of profile features. A\nsimple logistic regression trained on the embeddings from just 20 profiles\ncould obtain a 65% validation accuracy. A point of diminishing marginal returns\nwas identified to occur around 80 profiles, at which the model accuracy of 73%\nwould only improve marginally after reviewing a significant number of\nadditional profiles.\n"]},
{"authors": ["Fulton Wang", "Cynthia Rudin"], "title": ["Extreme Dimension Reduction for Handling Covariate Shift"], "date": ["2017-11-29T16:20:06Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.10938v2"], "summary": ["  In the covariate shift learning scenario, the training and test covariate\ndistributions differ, so that a predictor's average loss over the training and\ntest distributions also differ. In this work, we explore the potential of\nextreme dimension reduction, i.e. to very low dimensions, in improving the\nperformance of importance weighting methods for handling covariate shift, which\nfail in high dimensions due to potentially high train/test covariate divergence\nand the inability to accurately estimate the requisite density ratios. We first\nformulate and solve a problem optimizing over linear subspaces a combination of\ntheir predictive utility and train/test divergence within. Applying it to\nsimulated and real data, we show extreme dimension reduction helps sometimes\nbut not always, due to a bias introduced by dimension reduction.\n"]},
{"authors": ["Arya Mazumdar", "Ankit Singh Rawat"], "title": ["Representation Learning and Recovery in the ReLU Model"], "date": ["2018-03-12T15:17:14Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04304v1"], "summary": ["  Rectified linear units, or ReLUs, have become the preferred activation\nfunction for artificial neural networks. In this paper we consider two basic\nlearning problems assuming that the underlying data follow a generative model\nbased on a ReLU-network -- a neural network with ReLU activations. As a\nprimarily theoretical study, we limit ourselves to a single-layer network. The\nfirst problem we study corresponds to dictionary-learning in the presence of\nnonlinearity (modeled by the ReLU functions). Given a set of observation\nvectors $\\mathbf{y}^i \\in \\mathbb{R}^d, i =1, 2, \\dots , n$, we aim to recover\n$d\\times k$ matrix $A$ and the latent vectors $\\{\\mathbf{c}^i\\} \\subset\n\\mathbb{R}^k$ under the model $\\mathbf{y}^i = \\mathrm{ReLU}(A\\mathbf{c}^i\n+\\mathbf{b})$, where $\\mathbf{b}\\in \\mathbb{R}^d$ is a random bias. We show\nthat it is possible to recover the column space of $A$ within an error of\n$O(d)$ (in Frobenius norm) under certain conditions on the probability\ndistribution of $\\mathbf{b}$.\n  The second problem we consider is that of robust recovery of the signal in\nthe presence of outliers, i.e., large but sparse noise. In this setting we are\ninterested in recovering the latent vector $\\mathbf{c}$ from its noisy\nnonlinear sketches of the form $\\mathbf{v} = \\mathrm{ReLU}(A\\mathbf{c}) +\n\\mathbf{e}+\\mathbf{w}$, where $\\mathbf{e} \\in \\mathbb{R}^d$ denotes the\noutliers with sparsity $s$ and $\\mathbf{w} \\in \\mathbb{R}^d$ denote the dense\nbut small noise. This line of work has recently been studied (Soltanolkotabi,\n2017) without the presence of outliers. For this problem, we show that a\ngeneralized LASSO algorithm is able to recover the signal $\\mathbf{c} \\in\n\\mathbb{R}^k$ within an $\\ell_2$ error of $O(\\sqrt{\\frac{(k+s)\\log d}{d}})$\nwhen $A$ is a random Gaussian matrix.\n"]},
{"authors": ["Markus Heinonen", "Cagatay Yildiz", "Henrik Mannerstr\u00f6m", "Jukka Intosalmi", "Harri L\u00e4hdesm\u00e4ki"], "title": ["Learning unknown ODE models with Gaussian processes"], "date": ["2018-03-12T15:13:27Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04303v1"], "summary": ["  In conventional ODE modelling coefficients of an equation driving the system\nstate forward in time are estimated. However, for many complex systems it is\npractically impossible to determine the equations or interactions governing the\nunderlying dynamics. In these settings, parametric ODE model cannot be\nformulated. Here, we overcome this issue by introducing a novel paradigm of\nnonparametric ODE modelling that can learn the underlying dynamics of arbitrary\ncontinuous-time systems without prior knowledge. We propose to learn\nnon-linear, unknown differential functions from state observations using\nGaussian process vector fields within the exact ODE formalism. We demonstrate\nthe model's capabilities to infer dynamics from sparse data and to simulate the\nsystem forward into future.\n"]},
{"authors": ["Patrick Schramowski", "Christian Bauckhage", "Kristian Kersting"], "title": ["Neural Conditional Gradients"], "date": ["2018-03-12T15:10:45Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04300v1"], "summary": ["  The move from hand-designed to learned optimizers in machine learning has\nbeen quite successful for gradient-based and -free optimizers. When facing a\nconstrained problem, however, maintaining feasibility typically requires a\nprojection step, which might be computationally expensive and not\ndifferentiable. We show how the design of projection-free convex optimization\nalgorithms can be cast as a learning problem based on Frank-Wolfe Networks:\nrecurrent networks implementing the Frank-Wolfe algorithm aka. conditional\ngradients. This allows them to learn to exploit structure when, e.g.,\noptimizing over rank-1 matrices. Our LSTM-learned optimizers outperform\nhand-designed as well learned but unconstrained ones. We demonstrate this for\ntraining support vector machines and softmax classifiers.\n"]},
{"authors": ["Ilya Tolstikhin", "Olivier Bousquet", "Sylvain Gelly", "Bernhard Schoelkopf"], "title": ["Wasserstein Auto-Encoders"], "date": ["2017-11-05T10:18:27Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.01558v3"], "summary": ["  We propose the Wasserstein Auto-Encoder (WAE)---a new algorithm for building\na generative model of the data distribution. WAE minimizes a penalized form of\nthe Wasserstein distance between the model distribution and the target\ndistribution, which leads to a different regularizer than the one used by the\nVariational Auto-Encoder (VAE). This regularizer encourages the encoded\ntraining distribution to match the prior. We compare our algorithm with several\nother techniques and show that it is a generalization of adversarial\nauto-encoders (AAE). Our experiments show that WAE shares many of the\nproperties of VAEs (stable training, encoder-decoder architecture, nice latent\nmanifold structure) while generating samples of better quality, as measured by\nthe FID score.\n"]},
{"authors": ["Konstantinos Pitas", "Mike Davies", "Pierre Vandergheynst"], "title": ["FeTa: A DCA Pruning Algorithm with Generalization Error Guarantees"], "date": ["2018-03-12T13:19:33Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04239v1"], "summary": ["  Recent DNN pruning algorithms have succeeded in reducing the number of\nparameters in fully connected layers, often with little or no drop in\nclassification accuracy. However, most of the existing pruning schemes either\nhave to be applied during training or require a costly retraining procedure\nafter pruning to regain classification accuracy. We start by proposing a cheap\npruning algorithm for fully connected DNN layers based on difference of convex\nfunctions (DC) optimisation, that requires little or no retraining. We then\nprovide a theoretical analysis for the growth in the Generalization Error (GE)\nof a DNN for the case of bounded perturbations to the hidden layers, of which\nweight pruning is a special case. Our pruning method is orders of magnitude\nfaster than competing approaches, while our theoretical analysis sheds light to\npreviously observed problems in DNN pruning. Experiments on commnon feedforward\nneural networks validate our results.\n"]},
{"authors": ["Hongyi Ding", "Young Lee", "Issei Sato", "Masashi Sugiyama"], "title": ["Variational Inference for Gaussian Process with Panel Count Data"], "date": ["2018-03-12T13:02:20Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04232v1"], "summary": ["  We present the first framework for Gaussian-process-modulated Poisson\nprocesses when the temporal data appear in the form of panel counts. Panel\ncount data frequently arise when experimental subjects are observed only at\ndiscrete time points and only the numbers of occurrences of the events between\nsubsequent observation times are available. The exact occurrence timestamps of\nthe events are unknown. The method of conducting the efficient variational\ninference is presented, based on the assumption of a Gaussian-process-modulated\nintensity function. We derive a tractable lower bound to alleviate the problems\nof the intractable evidence lower bound inherent in the variational inference\nframework. Our algorithm outperforms classical methods on both synthetic and\nthree real panel count sets.\n"]},
{"authors": ["Jie Yang", "Thomas Drake", "Andreas Damianou", "Yoelle Maarek"], "title": ["Leveraging Crowdsourcing Data For Deep Active Learning - An Application:\n  Learning Intents in Alexa"], "date": ["2018-03-12T12:43:41Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04223v1"], "summary": ["  This paper presents a generic Bayesian framework that enables any deep\nlearning model to actively learn from targeted crowds. Our framework inherits\nfrom recent advances in Bayesian deep learning, and extends existing work by\nconsidering the targeted crowdsourcing approach, where multiple annotators with\nunknown expertise contribute an uncontrolled amount (often limited) of\nannotations. Our framework leverages the low-rank structure in annotations to\nlearn individual annotator expertise, which then helps to infer the true labels\nfrom noisy and sparse annotations. It provides a unified Bayesian model to\nsimultaneously infer the true labels and train the deep learning model in order\nto reach an optimal learning efficacy. Finally, our framework exploits the\nuncertainty of the deep learning model during prediction as well as the\nannotators' estimated expertise to minimize the number of required annotations\nand annotators for optimally training the deep learning model.\n  We evaluate the effectiveness of our framework for intent classification in\nAlexa (Amazon's personal assistant), using both synthetic and real-world\ndatasets. Experiments show that our framework can accurately learn annotator\nexpertise, infer true labels, and effectively reduce the amount of annotations\nin model training as compared to state-of-the-art approaches. We further\ndiscuss the potential of our proposed framework in bridging machine learning\nand crowdsourcing towards improved human-in-the-loop systems.\n"]},
{"authors": ["Michael Teng", "Frank Wood"], "title": ["High Throughput Synchronous Distributed Stochastic Gradient Descent"], "date": ["2018-03-12T11:51:38Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04209v1"], "summary": ["  We introduce a new, high-throughput, synchronous, distributed, data-parallel,\nstochastic-gradient-descent learning algorithm. This algorithm uses amortized\ninference in a compute-cluster-specific, deep, generative, dynamical model to\nperform joint posterior predictive inference of the mini-batch gradient\ncomputation times of all worker-nodes in a parallel computing cluster. We show\nthat a synchronous parameter server can, by utilizing such a model, choose an\noptimal cutoff time beyond which mini-batch gradient messages from slow workers\nare ignored that maximizes overall mini-batch gradient computations per second.\nIn keeping with earlier findings we observe that, under realistic conditions,\neagerly discarding the mini-batch gradient computations of stragglers not only\nincreases throughput but actually increases the overall rate of convergence as\na function of wall-clock time by virtue of eliminating idleness. The principal\nnovel contribution and finding of this work goes beyond this by demonstrating\nthat using the predicted run-times from a generative model of cluster worker\nperformance to dynamically adjust the cutoff improves substantially over the\nstatic-cutoff prior art, leading to, among other things, significantly reduced\ndeep neural net training times on large computer clusters.\n"]},
{"authors": ["Akshay Krishnamurthy", "Zhiwei Steven Wu", "Vasilis Syrgkanis"], "title": ["Semiparametric Contextual Bandits"], "date": ["2018-03-12T11:39:20Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04204v1"], "summary": ["  This paper studies semiparametric contextual bandits, a generalization of the\nlinear stochastic bandit problem where the reward for an action is modeled as a\nlinear function of known action features confounded by an non-linear\naction-independent term. We design new algorithms that achieve\n$\\tilde{O}(d\\sqrt{T})$ regret over $T$ rounds, when the linear function is\n$d$-dimensional, which matches the best known bounds for the simpler\nunconfounded case and improves on a recent result of Greenewald et al. (2017).\nVia an empirical evaluation, we show that our algorithms outperform prior\napproaches when there are non-linear confounding effects on the rewards.\nTechnically, our algorithms use a new reward estimator inspired by\ndoubly-robust approaches and our proofs require new concentration inequalities\nfor self-normalized martingales.\n"]},
{"authors": ["Arun Venkitaraman", "Saikat Chatterjee", "Peter H\u00e4ndel"], "title": ["Multi-kernel Regression For Graph Signal Processing"], "date": ["2018-03-12T11:20:07Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04196v1"], "summary": ["  We develop a multi-kernel based regression method for graph signal processing\nwhere the target signal is assumed to be smooth over a graph. In multi-kernel\nregression, an effective kernel function is expressed as a linear combination\nof many basis kernel functions. We estimate the linear weights to learn the\neffective kernel function by appropriate regularization based on graph\nsmoothness. We show that the resulting optimization problem is shown to be\nconvex and pro- pose an accelerated projected gradient descent based solution.\nSimulation results using real-world graph signals show efficiency of the\nmulti-kernel based approach over a standard kernel based approach.\n"]},
{"authors": ["Arun Venkitaraman", "Saikat Chatterjee", "Peter H\u00e4ndel"], "title": ["Extreme Learning Machine for Graph Signal Processing"], "date": ["2018-03-12T11:12:48Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04193v1"], "summary": ["  In this article, we improve extreme learning machines for regression tasks\nusing a graph signal processing based regularization. We assume that the target\nsignal for prediction or regression is a graph signal. With this assumption, we\nuse the regularization to enforce that the output of an extreme learning\nmachine is smooth over a given graph. Simulation results with real data confirm\nthat such regularization helps significantly when the available training data\nis limited in size and corrupted by noise.\n"]},
{"authors": ["Jaakko Lehtinen", "Jacob Munkberg", "Jon Hasselgren", "Samuli Laine", "Tero Karras", "Miika Aittala", "Timo Aila"], "title": ["Noise2Noise: Learning Image Restoration without Clean Data"], "date": ["2018-03-12T11:07:58Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04189v1"], "summary": ["  We apply basic statistical reasoning to signal reconstruction by machine\nlearning -- learning to map corrupted observations to clean signals -- with a\nsimple and powerful conclusion: under certain common circumstances, it is\npossible to learn to restore signals without ever observing clean ones, at\nperformance close or equal to training using clean exemplars. We show\napplications in photographic noise removal, denoising of synthetic Monte Carlo\nimages, and reconstruction of MRI scans from undersampled inputs, all based on\nonly observing corrupted data.\n"]},
{"authors": ["Arun Venkitaraman", "Alireza M. Javid", "Saikat Chatterjee"], "title": ["R3Net: Random Weights, Rectifier Linear Units and Robustness for\n  Artificial Neural Network"], "date": ["2018-03-12T11:04:17Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04186v1"], "summary": ["  We consider a neural network architecture with randomized features, a\nsign-splitter, followed by rectified linear units (ReLU). We prove that our\narchitecture exhibits robustness to the input perturbation: the output feature\nof the neural network exhibits a Lipschitz continuity in terms of the input\nperturbation. We further show that the network output exhibits a discrimination\nability that inputs that are not arbitrarily close generate output vectors\nwhich maintain distance between each other obeying a certain lower bound. This\nensures that two different inputs remain discriminable while contracting the\ndistance in the output feature space.\n"]},
{"authors": ["Nathalie Peyrard", "Marie-Jos\u00e9e Cros", "Simon de Givry", "Alain Franc", "St\u00e9phane Robin", "R\u00e9gis Sabbadin", "Thomas Schiex", "Matthieu Vignes"], "title": ["Exact and approximate inference in graphical models: variable\n  elimination and beyond"], "date": ["2015-06-29T08:45:11Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1506.08544v2"], "summary": ["  Probabilistic graphical models offer a powerful framework to account for the\ndependence structure between variables, which is represented as a graph.\nHowever, the dependence between variables may render inference tasks\nintractable. In this paper we review techniques exploiting the graph structure\nfor exact inference, borrowed from optimisation and computer science. They are\nbuilt on the principle of variable elimination whose complexity is dictated in\nan intricate way by the order in which variables are eliminated. The so-called\ntreewidth of the graph characterises this algorithmic complexity: low-treewidth\ngraphs can be processed efficiently. The first message that we illustrate is\ntherefore the idea that for inference in graphical model, the number of\nvariables is not the limiting factor, and it is worth checking for the\ntreewidth before turning to approximate methods. We show how algorithms\nproviding an upper bound of the treewidth can be exploited to derive a 'good'\nelimination order enabling to perform exact inference. The second message is\nthat when the treewidth is too large, algorithms for approximate inference\nlinked to the principle of variable elimination, such as loopy belief\npropagation and variational approaches, can lead to accurate results while\nbeing much less time consuming than Monte-Carlo approaches. We illustrate the\ntechniques reviewed in this article on benchmarks of inference problems in\ngenetic linkage analysis and computer vision, as well as on hidden variables\nrestoration in coupled Hidden Markov Models.\n"]},
{"authors": ["Andrew Holbrook", "Thomas Lumley", "Daniel Gillen"], "title": ["Estimating prediction error for complex samples"], "date": ["2017-11-13T22:30:47Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.04877v2"], "summary": ["  Non-uniform random samples are commonly generated in multiple scientific\nfields ranging from economics to medicine. Complex sampling designs afford\nresearch with increased precision for estimating parameters of interest in less\nprevalent sub-populations. With a growing interest in using complex samples to\ngenerate prediction models for numerous outcomes it is necessary to account for\nthe sampling design that gave rise to the data in order to assess the\ngeneralized predictive utility of a proposed prediction rule. Specifically,\nafter learning a prediction rule based on a complex sample, it is of interest\nto estimate the rule's error rate when applied to unobserved members of the\npopulation. Efron proposed a general class of covariance-inflated prediction\nerror estimators that assumed the available training data is representative of\nthe target population for which the prediction rule is to be applied. We extend\nEfron's estimator to the complex sample context by incorporating\nHorvitz-Thompson sampling weights and show that it is consistent for the true\ngeneralization error rate when applied to the underlying superpopulation giving\nrise to the training sample. The resulting Horvitz-Thompson-Efron (HTE)\nestimator is equivalent to dAIC---a recent extension of AIC to survey sampling\ndata---and is more widely applicable. The proposed methodology is assessed via\nempirical simulations and is applied to data predicting renal function that was\nobtained from the National Health and Nutrition Examination Survey (NHANES).\n"]},
{"authors": ["Adarsh Barik", "Jean Honorio"], "title": ["Learning Binary Bayesian Networks in Polynomial Time and Sample\n  Complexity"], "date": ["2018-03-12T01:49:39Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04087v1"], "summary": ["  We consider the problem of structure learning for binary Bayesian networks.\nOur approach is to recover the true parents and children for each node first\nand then combine the results to recover the skeleton. We do not assume any\nspecific probability distribution for the nodes. Rather, we show that if the\nprobability distribution satisfies certain conditions then we can exactly\nrecover the parents and children of a node by performing l1-regularized linear\nregression with sufficient number of samples. The sample complexity of our\nproposed approach depends logarithmically on the number of nodes in the\nBayesian network. Furthermore, our method runs in polynomial time.\n"]},
{"authors": ["Yun-Jhong Wu", "Elizaveta Levina", "Ji Zhu"], "title": ["Link prediction for egocentrically sampled networks"], "date": ["2018-03-12T01:37:53Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04084v1"], "summary": ["  Link prediction in networks is typically accomplished by estimating or\nranking the probabilities of edges for all pairs of nodes. In practice,\nespecially for social networks, the data are often collected by egocentric\nsampling, which means selecting a subset of nodes and recording all of their\nedges. This sampling mechanism requires different prediction tools than the\ntypical assumption of links missing at random. We propose a new computationally\nefficient link prediction algorithm for egocentrically sampled networks, which\nestimates the underlying probability matrix by estimating its row space. For\nnetworks created by sampling rows, our method outperforms many popular link\nprediction and graphon estimation techniques.\n"]},
{"authors": ["Yaohui Zeng", "Patrick Breheny"], "title": ["The biglasso Package: A Memory- and Computation-Efficient Solver for\n  Lasso Model Fitting with Big Data in R"], "date": ["2017-01-20T22:08:49Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1701.05936v2"], "summary": ["  Penalized regression models such as the lasso have been extensively applied\nto analyzing high-dimensional data sets. However, due to memory limitations,\nexisting R packages like glmnet and ncvreg are not capable of fitting\nlasso-type models for ultrahigh-dimensional, multi-gigabyte data sets that are\nincreasingly seen in many areas such as genetics, genomics, biomedical imaging,\nand high-frequency finance. In this research, we implement an R package called\nbiglasso that tackles this challenge. biglasso utilizes memory-mapped files to\nstore the massive data on the disk, only reading data into memory when\nnecessary during model fitting, and is thus able to handle out-of-core\ncomputation seamlessly. Moreover, it's equipped with newly proposed, more\nefficient feature screening rules, which substantially accelerate the\ncomputation. Benchmarking experiments show that our biglasso package, as\ncompared to existing popular ones like glmnet, is much more memory- and\ncomputation-efficient. We further analyze a 31 GB real data set on a laptop\nwith only 16 GB RAM to demonstrate the out-of-core computation capability of\nbiglasso in analyzing massive data sets that cannot be accommodated by existing\nR packages.\n"]},
{"authors": ["Elliot Meyerson", "Risto Miikkulainen"], "title": ["Pseudo-task Augmentation: From Deep Multitask Learning to Intratask\n  Sharing---and Back"], "date": ["2018-03-11T23:06:14Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04062v1"], "summary": ["  Deep multitask learning boosts performance by sharing learned structure\nacross related tasks. This paper adapts ideas from deep multitask learning to\nthe setting where only a single task is available. The method is formalized as\npseudo-task augmentation, in which models are trained with multiple decoders\nfor each task. Pseudo-tasks simulate the effect of training towards\nclosely-related tasks drawn from the same universe. In a suite of experiments,\npseudo-task augmentation is shown to improve performance on single-task\nlearning problems. When combined with multitask learning, further improvements\nare achieved, including state-of-the-art performance on the CelebA dataset,\nshowing that pseudo-task augmentation and multitask learning have complementary\nvalue. All in all, pseudo-task augmentation is a broadly applicable and\nefficient way to boost performance in deep learning systems.\n"]},
{"authors": ["Kai Xu", "Dae Hoon Park", "Chang Yi", "Charles Sutton"], "title": ["Interpreting Deep Classifier by Visual Distillation of Dark Knowledge"], "date": ["2018-03-11T21:17:05Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04042v1"], "summary": ["  Interpreting black box classifiers, such as deep networks, allows an analyst\nto validate a classifier before it is deployed in a high-stakes setting. A\nnatural idea is to visualize the deep network's representations, so as to \"see\nwhat the network sees\". In this paper, we demonstrate that standard dimension\nreduction methods in this setting can yield uninformative or even misleading\nvisualizations. Instead, we present DarkSight, which visually summarizes the\npredictions of a classifier in a way inspired by notion of dark knowledge.\nDarkSight embeds the data points into a low-dimensional space such that it is\neasy to compress the deep classifier into a simpler one, essentially combining\nmodel compression and dimension reduction. We compare DarkSight against t-SNE\nboth qualitatively and quantitatively, demonstrating that DarkSight\nvisualizations are more informative. Our method additionally yields a new\nconfidence measure based on dark knowledge by quantifying how unusual a given\nvector of predictions is.\n"]},
{"authors": ["Nima Dehmamy", "Neda Rohani", "Aggelos Katsaggelos"], "title": ["Separation of time scales and direct computation of weights in deep\n  neural networks"], "date": ["2017-03-14T22:13:41Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1703.04757v3"], "summary": ["  Artificial intelligence is revolutionizing our lives at an ever increasing\npace. At the heart of this revolution is the recent advancements in deep neural\nnetworks (DNN), learning to perform sophisticated, high-level tasks. However,\ntraining DNNs requires massive amounts of data and is very computationally\nintensive. Gaining analytical understanding of the solutions found by DNNs can\nhelp us devise more efficient training algorithms, replacing the commonly used\nmthod of stochastic gradient descent (SGD). We analyze the dynamics of SGD and\nshow that, indeed, direct computation of the solutions is possible in many\ncases. We show that a high performing setup used in DNNs introduces a\nseparation of time-scales in the training dynamics, allowing SGD to train\nlayers from the lowest (closest to input) to the highest. We then show that for\neach layer, the distribution of solutions found by SGD can be estimated using a\nclass-based principal component analysis (PCA) of the layer's input. This\nfinding allows us to forgo SGD entirely and directly derive the DNN parameters\nusing this class-based PCA, which can be well estimated using significantly\nless data than SGD. We implement these results on image datasets MNIST, CIFAR10\nand CIFAR100 and find that, in fact, layers derived using our class-based PCA\nperform comparable or superior to neural networks of the same size and\narchitecture trained using SGD. We also confirm that the class-based PCA often\nconverges using a fraction of the data required for SGD. Thus, using our method\ntraining time can be reduced both by requiring less training data than SGD, and\nby eliminating layers in the costly backpropagation step of the training.\n"]},
{"authors": ["Cem Tekin", "Mihaela van der Schaar"], "title": ["Episodic Multi-armed Bandits"], "date": ["2015-08-04T01:52:42Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1508.00641v4"], "summary": ["  We introduce a new class of reinforcement learning methods referred to as\n{\\em episodic multi-armed bandits} (eMAB). In eMAB the learner proceeds in {\\em\nepisodes}, each composed of several {\\em steps}, in which it chooses an action\nand observes a feedback signal. Moreover, in each step, it can take a special\naction, called the $stop$ action, that ends the current episode. After the\n$stop$ action is taken, the learner collects a terminal reward, and observes\nthe costs and terminal rewards associated with each step of the episode. The\ngoal of the learner is to maximize its cumulative gain (i.e., the terminal\nreward minus costs) over all episodes by learning to choose the best sequence\nof actions based on the feedback. First, we define an {\\em oracle} benchmark,\nwhich sequentially selects the actions that maximize the expected immediate\ngain. Then, we propose our online learning algorithm, named {\\em FeedBack\nAdaptive Learning} (FeedBAL), and prove that its regret with respect to the\nbenchmark is bounded with high probability and increases logarithmically in\nexpectation. Moreover, the regret only has polynomial dependence on the number\nof steps, actions and states. eMAB can be used to model applications that\ninvolve humans in the loop, ranging from personalized medical screening to\npersonalized web-based education, where sequences of actions are taken in each\nepisode, and optimal behavior requires adapting the chosen actions based on the\nfeedback.\n"]},
{"authors": ["Eralp Tur\u011fay", "Doruk \u00d6ner", "Cem Tekin"], "title": ["Multi-objective Contextual Bandit Problem with Similarity Information"], "date": ["2018-03-11T19:04:12Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04015v1"], "summary": ["  In this paper we propose the multi-objective contextual bandit problem with\nsimilarity information. This problem extends the classical contextual bandit\nproblem with similarity information by introducing multiple and possibly\nconflicting objectives. Since the best arm in each objective can be different\ngiven the context, learning the best arm based on a single objective can\njeopardize the rewards obtained from the other objectives. In order to evaluate\nthe performance of the learner in this setup, we use a performance metric\ncalled the contextual Pareto regret. Essentially, the contextual Pareto regret\nis the sum of the distances of the arms chosen by the learner to the context\ndependent Pareto front. For this problem, we develop a new online learning\nalgorithm called Pareto Contextual Zooming (PCZ), which exploits the idea of\ncontextual zooming to learn the arms that are close to the Pareto front for\neach observed context by adaptively partitioning the joint context-arm set\naccording to the observed rewards and locations of the context-arm pairs\nselected in the past. Then, we prove that PCZ achieves $\\tilde O\n(T^{(1+d_p)/(2+d_p)})$ Pareto regret where $d_p$ is the Pareto zooming\ndimension that depends on the size of the set of near-optimal context-arm\npairs. Moreover, we show that this regret bound is nearly optimal by providing\nan almost matching $\\Omega (T^{(1+d_p)/(2+d_p)})$ lower bound.\n"]},
{"authors": ["Pan Li", "Qiang Liu", "Wentao Zhao", "Dongxu Wang", "Siqi Wang"], "title": ["BEBP: An Poisoning Method Against Machine Learning Based IDSs"], "date": ["2018-03-11T14:15:50Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03965v1"], "summary": ["  In big data era, machine learning is one of fundamental techniques in\nintrusion detection systems (IDSs). However, practical IDSs generally update\ntheir decision module by feeding new data then retraining learning models in a\nperiodical way. Hence, some attacks that comprise the data for training or\ntesting classifiers significantly challenge the detecting capability of machine\nlearning-based IDSs. Poisoning attack, which is one of the most recognized\nsecurity threats towards machine learning-based IDSs, injects some adversarial\nsamples into the training phase, inducing data drifting of training data and a\nsignificant performance decrease of target IDSs over testing data. In this\npaper, we adopt the Edge Pattern Detection (EPD) algorithm to design a novel\npoisoning method that attack against several machine learning algorithms used\nin IDSs. Specifically, we propose a boundary pattern detection algorithm to\nefficiently generate the points that are near to abnormal data but considered\nto be normal ones by current classifiers. Then, we introduce a Batch-EPD\nBoundary Pattern (BEBP) detection algorithm to overcome the limitation of the\nnumber of edge pattern points generated by EPD and to obtain more useful\nadversarial samples. Based on BEBP, we further present a moderate but effective\npoisoning method called chronic poisoning attack. Extensive experiments on\nsynthetic and three real network data sets demonstrate the performance of the\nproposed poisoning method against several well-known machine learning\nalgorithms and a practical intrusion detection method named FMIFS-LSSVM-IDS.\n"]},
{"authors": ["Andreas Maurer", "Massimiliano Pontil"], "title": ["Empirical bounds for functions with weak interactions"], "date": ["2018-03-11T10:28:45Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03934v1"], "summary": ["  We provide sharp empirical estimates of expectation, variance and normal\napproximation for a class of statistics whose variation in any argument does\nnot change too much when another argument is modified. Examples of such weak\ninteractions are furnished by U- and V-statistics, Lipschitz L-statistics and\nvarious error functionals of L2-regularized algorithms and Gibbs algorithms.\n"]},
{"authors": ["Esther Derman", "Daniel J. Mankowitz", "Timothy A. Mann", "Shie Mannor"], "title": ["Soft-Robust Actor-Critic Policy-Gradient"], "date": ["2018-03-11T09:43:20Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04848v1"], "summary": ["  Robust Reinforcement Learning aims to derive an optimal behavior that\naccounts for model uncertainty in dynamical systems. However, previous studies\nhave shown that by considering the worst case scenario, robust policies can be\noverly conservative. Our \\textit{soft-robust} framework is an attempt to\novercome this issue. In this paper, we present a novel Soft-Robust Actor-Critic\nalgorithm (SR-AC). It learns an optimal policy with respect to a distribution\nover an uncertainty set and stays robust to model uncertainty but avoids the\nconservativeness of robust strategies. We show convergence of the SR-AC and\ntest the efficiency of our approach on different domains by comparing it\nagainst regular learning methods and their robust formulations.\n"]},
{"authors": ["Yingxiang Yang", "Adams Wei Yu", "Zhaoran Wang", "Tuo Zhao"], "title": ["Detecting Nonlinear Causality in Multivariate Time Series with Sparse\n  Additive Models"], "date": ["2018-03-11T07:46:24Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03919v1"], "summary": ["  We propose a nonparametric method for detecting nonlinear causal relationship\nwithin a set of multidimensional discrete time series, by using sparse additive\nmodels (SpAMs). We show that, when the input to the SpAM is a $\\beta$-mixing\ntime series, the model can be fitted by first approximating each unknown\nfunction with a linear combination of a set of B-spline bases, and then solving\na group-lasso-type optimization problem with nonconvex regularization.\nTheoretically, we characterize the oracle statistical properties of the\nproposed sparse estimator in function estimation and model selection.\nNumerically, we propose an efficient pathwise iterative shrinkage thresholding\nalgorithm (PISTA), which tames the nonconvexity and guarantees linear\nconvergence towards the desired sparse estimator with high probability.\n"]},
{"authors": ["Xiang Gao"], "title": ["Deep reinforcement learning for time series: playing idealized trading\n  games"], "date": ["2018-03-11T06:56:29Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03916v1"], "summary": ["  Deep Q-learning is investigated as an end-to-end solution to estimate the\noptimal strategies for acting on time series input. Experiments are conducted\non two idealized trading games. 1) Univariate: the only input is a wave-like\nprice time series, and 2) Bivariate: the input includes a random stepwise price\ntime series and a noisy signal time series, which is positively correlated with\nfuture price changes. The Univariate game tests whether the agent can capture\nthe underlying dynamics, and the Bivariate game tests whether the agent can\nutilize the hidden relation among the inputs. Stacked Gated Recurrent Unit\n(GRU), Long Short-Term Memory (LSTM) units, Convolutional Neural Network (CNN),\nand multi-layer perceptron (MLP) are used to model Q values. For both games,\nall agents successfully find a profitable strategy. The GRU-based agents show\nbest overall performance in the Univariate game, while the MLP-based agents\noutperform others in the Bivariate game.\n"]},
{"authors": ["Li Zeng", "Zhaolong Yu", "Hongyu Zhao"], "title": ["A pathway-based kernel boosting method for sample classification using\n  genomic data"], "date": ["2018-03-11T05:50:35Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03910v1"], "summary": ["  The analysis of cancer genomic data has long suffered \"the curse of\ndimensionality\". Sample sizes for most cancer genomic studies are a few\nhundreds at most while there are tens of thousands of genomic features studied.\nVarious methods have been proposed to leverage prior biological knowledge, such\nas pathways, to more effectively analyze cancer genomic data. Most of the\nmethods focus on testing marginal significance of the associations between\npathways and clinical phenotypes. They can identify relevant pathways, but do\nnot involve predictive modeling. In this article, we propose a Pathway-based\nKernel Boosting (PKB) method for integrating gene pathway information for\nsample classification, where we use kernel functions calculated from each\npathway as base learners and learn the weights through iterative optimization\nof the classification loss function. We apply PKB and several competing methods\nto three cancer studies with pathological and clinical information, including\ntumor grade, stage, tumor sites, and metastasis status. Our results show that\nPKB outperforms other methods, and identifies pathways relevant to the outcome\nvariables.\n"]},
{"authors": ["Dangna Li", "Kun Yang", "Wing Hung Wong"], "title": ["Density Estimation via Discrepancy Based Adaptive Sequential Partition"], "date": ["2014-04-05T03:43:28Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1404.1425v4"], "summary": ["  Given $iid$ observations from an unknown absolute continuous distribution\ndefined on some domain $\\Omega$, we propose a nonparametric method to learn a\npiecewise constant function to approximate the underlying probability density\nfunction. Our density estimate is a piecewise constant function defined on a\nbinary partition of $\\Omega$. The key ingredient of the algorithm is to use\ndiscrepancy, a concept originates from Quasi Monte Carlo analysis, to control\nthe partition process. The resulting algorithm is simple, efficient, and has a\nprovable convergence rate. We empirically demonstrate its efficiency as a\ndensity estimation method. We present its applications on a wide range of\ntasks, including finding good initializations for k-means.\n"]},
{"authors": ["Yizhen Wang", "Somesh Jha", "Kamalika Chaudhuri"], "title": ["Analyzing the Robustness of Nearest Neighbors to Adversarial Examples"], "date": ["2017-06-13T06:47:50Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1706.03922v3"], "summary": ["  Motivated by safety-critical applications, test-time attacks on classifiers\nvia adversarial examples has recently received a great deal of attention.\nHowever, there is a general lack of understanding on why adversarial examples\narise; whether they originate due to inherent properties of data or due to lack\nof training samples remains ill-understood. In this work, we introduce a\ntheoretical framework analogous to bias-variance theory for understanding these\neffects.\n  We use our framework to analyze the robustness of a canonical non-parametric\nclassifier - the k-nearest neighbors. Our analysis shows that its robustness\nproperties depend critically on the value of k - the classifier may be\ninherently non-robust for small k, but its robustness approaches that of the\nBayes Optimal classifier for fast-growing k. We propose a novel modified\n1-nearest neighbor classifier, and guarantee its robustness in the large sample\nlimit. Our experiments suggest that this classifier may have good robustness\nproperties even for reasonable data set sizes.\n"]},
{"authors": ["Soorya Gopalakrishnan", "Zhinus Marzi", "Upamanyu Madhow", "Ramtin Pedarsani"], "title": ["Combating Adversarial Attacks Using Sparse Representations"], "date": ["2018-03-11T02:02:46Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03880v1"], "summary": ["  It is by now well-known that small adversarial perturbations can induce\nclassification errors in deep neural networks (DNNs). In this paper, we make\nthe case that sparse representations of the input data are a crucial tool for\ncombating such attacks. For linear classifiers, we show that a sparsifying\nfront end is provably effective against $\\ell_{\\infty}$-bounded attacks,\nreducing output distortion due to the attack by a factor of roughly $K / N$\nwhere $N$ is the data dimension and $K$ is the sparsity level. We then extend\nthis concept to DNNs, showing that a \"locally linear\" model can be used to\ndevelop a theoretical foundation for crafting attacks and defenses.\nExperimental results for the MNIST dataset show the efficacy of the proposed\nsparsifying front end.\n"]},
{"authors": ["Rafael M. O. Cruz", "Robert Sabourin", "George D. C. Cavalcanti"], "title": ["On dynamic ensemble selection and data preprocessing for multi-class\n  imbalance learning"], "date": ["2018-03-11T01:46:31Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03877v1"], "summary": ["  Class-imbalance refers to classification problems in which many more\ninstances are available for certain classes than for others. Such imbalanced\ndatasets require special attention because traditional classifiers generally\nfavor the majority class which has a large number of instances. Ensemble of\nclassifiers have been reported to yield promising results. However, the\nmajority of ensemble methods applied too imbalanced learning are static ones.\nMoreover, they only deal with binary imbalanced problems. Hence, this paper\npresents an empirical analysis of dynamic selection techniques and data\npreprocessing methods for dealing with multi-class imbalanced problems. We\nconsidered five variations of preprocessing methods and four dynamic selection\nmethods. Our experiments conducted on 26 multi-class imbalanced problems show\nthat the dynamic ensemble improves the F-measure and the G-mean as compared to\nthe static ensemble. Moreover, data preprocessing plays an important role in\nsuch cases.\n"]},
{"authors": ["Bryon Aragam", "Jiaying Gu", "Qing Zhou"], "title": ["Learning Large-Scale Bayesian Networks with the sparsebn Package"], "date": ["2017-03-11T20:07:06Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1703.04025v2"], "summary": ["  Learning graphical models from data is an important problem with wide\napplications, ranging from genomics to the social sciences. Nowadays datasets\noften have upwards of thousands---sometimes tens or hundreds of thousands---of\nvariables and far fewer samples. To meet this challenge, we have developed a\nnew R package called sparsebn for learning the structure of large, sparse\ngraphical models with a focus on Bayesian networks. While there are many\nexisting software packages for this task, this package focuses on the unique\nsetting of learning large networks from high-dimensional data, possibly with\ninterventions. As such, the methods provided place a premium on scalability and\nconsistency in a high-dimensional setting. Furthermore, in the presence of\ninterventions, the methods implemented here achieve the goal of learning a\ncausal network from data. Additionally, the sparsebn package is fully\ncompatible with existing software packages for network analysis.\n"]},
{"authors": ["Katelyn Gao"], "title": ["Confidence Intervals for Algorithmic Leveraging in Linear Regression"], "date": ["2016-06-05T07:40:08Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1606.01473v4"], "summary": ["  The age of big data has produced data sets that are computationally expensive\nto analyze and store. Algorithmic leveraging proposes that we sample\nobservations from the original data set to generate a representative data set\nand then perform analysis on the representative data set. In this paper, we\npresent efficient algorithms for constructing finite sample confidence\nintervals for each algorithmic leveraging estimated regression coefficient,\nwith asymptotic coverage guarantees. In simulations, we confirm empirically\nthat the confidence intervals have the desired coverage probabilities, while\nbootstrap confidence intervals may not.\n"]},
{"authors": ["Aki Vehtari", "Andrew Gelman", "Tuomas Sivula", "Pasi Jyl\u00e4nki", "Dustin Tran", "Swupnil Sahai", "Paul Blomstedt", "John P. Cunningham", "David Schiminovich", "Christian Robert"], "title": ["Expectation propagation as a way of life: A framework for Bayesian\n  inference on partitioned data"], "date": ["2014-12-16T03:47:38Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1412.4869v3"], "summary": ["  A common approach for Bayesian computation with big data is to partition the\ndata into smaller pieces, perform local inference for each piece separately,\nand finally combine the results to obtain an approximation to the global\nposterior. Looking at this from the bottom up, one can perform separate\nanalyses on individual sources of data and then combine these in a larger\nBayesian model. In either case, the idea of distributed modeling and inference\nhas both conceptual and computational appeal, but from the Bayesian perspective\nthere is no general way of handling the prior distribution: if the prior is\nincluded in each separate inference, it will be multiply-counted when the\ninferences are combined; but if the prior is itself divided into pieces, it may\nnot provide enough regularization for each separate computation, thus\neliminating one of the key advantages of Bayesian methods. To resolve this\ndilemma, we propose expectation propagation (EP) as a general prototype for\ndistributed Bayesian inference. The central idea is to factor the likelihood\naccording to the data partitions, and to iteratively combine each factor with\nan approximate model of the prior and all other parts of the data, thus\nproducing an overall approximation to the global posterior at convergence. In\nthis paper, we give an introduction to EP and an overview of some recent\ndevelopments of the method, with particular emphasis on its use in combining\ninferences from partitioned data. In addition to distributed modeling of large\ndatasets, our unified treatment also includes hierarchical modeling of data\nwith a naturally partitioned structure. The paper describes a general\nalgorithmic framework, rather than a specific algorithm, and presents an\nexample implementation for it.\n"]},
{"authors": ["Boris Hanin", "Mark Sellke"], "title": ["Approximating Continuous Functions by ReLU Nets of Minimal Width"], "date": ["2017-10-31T00:26:56Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.11278v2"], "summary": ["  This article concerns the expressive power of depth in deep feed-forward\nneural nets with ReLU activations. Specifically, we answer the following\nquestion: for a fixed $d_{in}\\geq 1,$ what is the minimal width $w$ so that\nneural nets with ReLU activations, input dimension $d_{in}$, hidden layer\nwidths at most $w,$ and arbitrary depth can approximate any continuous,\nreal-valued function of $d_{in}$ variables arbitrarily well? It turns out that\nthis minimal width is exactly equal to $d_{in}+1.$ That is, if all the hidden\nlayer widths are bounded by $d_{in}$, then even in the infinite depth limit,\nReLU nets can only express a very limited class of functions, and, on the other\nhand, any continuous function on the $d_{in}$-dimensional unit cube can be\napproximated to arbitrary precision by ReLU nets in which all hidden layers\nhave width exactly $d_{in}+1.$ Our construction in fact shows that any\ncontinuous function $f:[0,1]^{d_{in}}\\to\\mathbb R^{d_{out}}$ can be\napproximated by a net of width $d_{in}+d_{out}$. We obtain quantitative depth\nestimates for such an approximation in terms of the modulus of continuity of\n$f$.\n"]},
{"authors": ["Emma Pierson", "Sam Corbett-Davies", "Sharad Goel"], "title": ["Fast Threshold Tests for Detecting Discrimination"], "date": ["2017-02-27T21:18:19Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1702.08536v3"], "summary": ["  Threshold tests have recently been proposed as a useful method for detecting\nbias in lending, hiring, and policing decisions. For example, in the case of\ncredit extensions, these tests aim to estimate the bar for granting loans to\nwhite and minority applicants, with a higher inferred threshold for minorities\nindicative of discrimination. This technique, however, requires fitting a\ncomplex Bayesian latent variable model for which inference is often\ncomputationally challenging. Here we develop a method for fitting threshold\ntests that is two orders of magnitude faster than the existing approach,\nreducing computation from hours to minutes. To achieve these performance gains,\nwe introduce and analyze a flexible family of probability distributions on the\ninterval [0, 1] -- which we call discriminant distributions -- that is\ncomputationally efficient to work with. We demonstrate our technique by\nanalyzing 2.7 million police stops of pedestrians in New York City.\n"]},
{"authors": ["Behzad Tabibian", "Utkarsh Upadhyay", "Abir De", "Ali Zarezade", "Bernhard Schoelkopf", "Manuel Gomez-Rodriguez"], "title": ["Optimizing Human Learning"], "date": ["2017-12-05T19:00:11Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1712.01856v2"], "summary": ["  Spaced repetition is a technique for efficient memorization which uses\nrepeated, spaced review of content to improve long-term retention. Can we find\nthe optimal reviewing schedule to maximize the benefits of spaced repetition?\nIn this paper, we introduce a novel, flexible representation of spaced\nrepetition using the framework of marked temporal point processes and then\naddress the above question as an optimal control problem for stochastic\ndifferential equations with jumps. For two well-known human memory models, we\nshow that the optimal reviewing schedule is given by the recall probability of\nthe content to be learned. As a result, we can then develop a simple, scalable\nonline algorithm, Memorize, to sample the optimal reviewing times. Experiments\non both synthetic and real data gathered from Duolingo, a popular\nlanguage-learning online platform, show that our algorithm may be able to help\nlearners memorize more effectively than alternatives.\n"]},
{"authors": ["Lin Feng", "Shuliang Xu", "Feilong Wang", "Shenglan Liu"], "title": ["Rough extreme learning machine: a new classification method based on\n  uncertainty measure"], "date": ["2017-10-30T09:37:20Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.10824v2"], "summary": ["  Extreme learning machine (ELM) is a new single hidden layer feedback neural\nnetwork. The weights of the input layer and the biases of neurons in hidden\nlayer are randomly generated, the weights of the output layer can be\nanalytically determined. ELM has been achieved good results for a large number\nof classification tasks. In this paper, a new extreme learning machine called\nrough extreme learning machine (RELM) was proposed. RELM uses rough set to\ndivide data into upper approximation set and lower approximation set, and the\ntwo approximation sets are utilized to train upper approximation neurons and\nlower approximation neurons. In addition, an attribute reduction is executed in\nthis algorithm to remove redundant attributes. The experimental results showed,\ncomparing with the comparison algorithms, RELM can get a better accuracy and\nrepeatability in most cases, RELM can not only maintain the advantages of fast\nspeed, but also effectively cope with the classification task for\nhigh-dimensional data.\n"]},
{"authors": ["Siong Thye Goh", "Cynthia Rudin"], "title": ["A Minimax Surrogate Loss Approach to Conditional Difference Estimation"], "date": ["2018-03-10T07:01:52Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03769v1"], "summary": ["  We present a new machine learning approach to estimate personalized treatment\neffects in the classical potential outcomes framework with binary outcomes. To\novercome the problem that both treatment and control outcomes for the same unit\nare required for supervised learning, we propose surrogate loss functions that\nincorporate both treatment and control data. The new surrogates yield tighter\nbounds than the sum of losses for treatment and control groups. A specific\nchoice of loss function, namely a type of hinge loss, yields a minimax support\nvector machine formulation. The resulting optimization problem requires the\nsolution to only a single convex optimization problem, incorporating both\ntreatment and control units, and it enables the kernel trick to be used to\nhandle nonlinear (also non-parametric) estimation. Statistical learning bounds\nare also presented for the framework, and experimental results.\n"]},
{"authors": ["Abien Fred Agarap"], "title": ["A Neural Network Architecture Combining Gated Recurrent Unit (GRU) and\n  Support Vector Machine (SVM) for Intrusion Detection in Network Traffic Data"], "date": ["2017-09-10T10:43:09Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1709.03082v7"], "summary": ["  Gated Recurrent Unit (GRU) is a recently-developed variation of the long\nshort-term memory (LSTM) unit, both of which are types of recurrent neural\nnetwork (RNN). Through empirical evidence, both models have been proven to be\neffective in a wide variety of machine learning tasks such as natural language\nprocessing (Wen et al., 2015), speech recognition (Chorowski et al., 2015), and\ntext classification (Yang et al., 2016). Conventionally, like most neural\nnetworks, both of the aforementioned RNN variants employ the Softmax function\nas its final output layer for its prediction, and the cross-entropy function\nfor computing its loss. In this paper, we present an amendment to this norm by\nintroducing linear support vector machine (SVM) as the replacement for Softmax\nin the final output layer of a GRU model. Furthermore, the cross-entropy\nfunction shall be replaced with a margin-based function. While there have been\nsimilar studies (Alalshekmubarak & Smith, 2013; Tang, 2013), this proposal is\nprimarily intended for binary classification on intrusion detection using the\n2013 network traffic data from the honeypot systems of Kyoto University.\nResults show that the GRU-SVM model performs relatively higher than the\nconventional GRU-Softmax model. The proposed model reached a training accuracy\nof ~81.54% and a testing accuracy of ~84.15%, while the latter was able to\nreach a training accuracy of ~63.07% and a testing accuracy of ~70.75%. In\naddition, the juxtaposition of these two final output layers indicate that the\nSVM would outperform Softmax in prediction time - a theoretical implication\nwhich was supported by the actual training and testing time in the study.\n"]},
{"authors": ["Sanjay Krishna Gouda", "Salil Kanetkar", "David Harrison", "Manfred K Warmuth"], "title": ["Speech Recognition: Keyword Spotting Through Image Recognition"], "date": ["2018-03-10T05:16:18Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03759v1"], "summary": ["  The problem of identifying voice commands has always been a challenge due to\nthe presence of noise and variability in speed, pitch, etc. We will compare the\nefficacies of several neural network architectures for the speech recognition\nproblem. In particular, we will build a model to determine whether a one second\naudio clip contains a particular word (out of a set of 10), an unknown word, or\nsilence. The models to be implemented are a CNN recommended by the Tensorflow\nSpeech Recognition tutorial, a low-latency CNN, and an adversarially trained\nCNN. The result is a demonstration of how to convert a problem in audio\nrecognition to the better-studied domain of image classification, where the\npowerful techniques of convolutional neural networks are fully developed.\nAdditionally, we demonstrate the applicability of the technique of Virtual\nAdversarial Training (VAT) to this problem domain, functioning as a powerful\nregularizer with promising potential future applications.\n"]},
{"authors": ["Lili Zhang", "Jennifer Priestley", "Xuelei Ni"], "title": ["Influence of the Event Rate on Discrimination Abilities of Bankruptcy\n  Prediction Models"], "date": ["2018-03-10T04:51:31Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03756v1"], "summary": ["  In bankruptcy prediction, the proportion of events is very low, which is\noften oversampled to eliminate this bias. In this paper, we study the influence\nof the event rate on discrimination abilities of bankruptcy prediction models.\nFirst the statistical association and significance of public records and\nfirmographics indicators with the bankruptcy were explored. Then the event rate\nwas oversampled from 0.12% to 10%, 20%, 30%, 40%, and 50%, respectively. Seven\nmodels were developed, including Logistic Regression, Decision Tree, Random\nForest, Gradient Boosting, Support Vector Machine, Bayesian Network, and Neural\nNetwork. Under different event rates, models were comprehensively evaluated and\ncompared based on Kolmogorov-Smirnov Statistic, accuracy, F1 score, Type I\nerror, Type II error, and ROC curve on the hold-out dataset with their best\nprobability cut-offs. Results show that Bayesian Network is the most\ninsensitive to the event rate, while Support Vector Machine is the most\nsensitive.\n"]},
{"authors": ["Youngjin Kim", "Minjung Kim", "Gunhee Kim"], "title": ["Memorization Precedes Generation: Learning Unsupervised GANs with Memory\n  Networks"], "date": ["2018-03-05T05:17:42Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.01500v2"], "summary": ["  We propose an approach to address two issues that commonly occur during\ntraining of unsupervised GANs. First, since GANs use only a continuous latent\ndistribution to embed multiple classes or clusters of data, they often do not\ncorrectly handle the structural discontinuity between disparate classes in a\nlatent space. Second, discriminators of GANs easily forget about past generated\nsamples by generators, incurring instability during adversarial training. We\nargue that these two infamous problems of unsupervised GAN training can be\nlargely alleviated by a learnable memory network to which both generators and\ndiscriminators can access. Generators can effectively learn representation of\ntraining samples to understand underlying cluster distributions of data, which\nease the structure discontinuity problem. At the same time, discriminators can\nbetter memorize clusters of previously generated samples, which mitigate the\nforgetting problem. We propose a novel end-to-end GAN model named memoryGAN,\nwhich involves a memory network that is unsupervisedly trainable and integrable\nto many existing GAN models. With evaluations on multiple datasets such as\nFashion-MNIST, CelebA, CIFAR10, and Chairs, we show that our model is\nprobabilistically interpretable, and generates realistic image samples of high\nvisual fidelity. The memoryGAN also achieves the state-of-the-art inception\nscores over unsupervised GAN models on the CIFAR10 dataset, without any\noptimization tricks and weaker divergences.\n"]},
{"authors": ["Kiran K. Thekumparampil", "Chong Wang", "Sewoong Oh", "Li-Jia Li"], "title": ["Attention-based Graph Neural Network for Semi-supervised Learning"], "date": ["2018-03-10T02:01:35Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03735v1"], "summary": ["  Recently popularized graph neural networks achieve the state-of-the-art\naccuracy on a number of standard benchmark datasets for graph-based\nsemi-supervised learning, improving significantly over existing approaches.\nThese architectures alternate between a propagation layer that aggregates the\nhidden states of the local neighborhood and a fully-connected layer. Perhaps\nsurprisingly, we show that a linear model, that removes all the intermediate\nfully-connected layers, is still able to achieve a performance comparable to\nthe state-of-the-art models. This significantly reduces the number of\nparameters, which is critical for semi-supervised learning where number of\nlabeled examples are small. This in turn allows a room for designing more\ninnovative propagation layers. Based on this insight, we propose a novel graph\nneural network that removes all the intermediate fully-connected layers, and\nreplaces the propagation layers with attention mechanisms that respect the\nstructure of the graph. The attention mechanism allows us to learn a dynamic\nand adaptive local summary of the neighborhood to achieve more accurate\npredictions. In a number of experiments on benchmark citation networks\ndatasets, we demonstrate that our approach outperforms competing methods. By\nexamining the attention weights among neighbors, we show that our model\nprovides some interesting insights on how neighbors influence each other.\n"]},
{"authors": ["Wenqi Wang", "Vaneet Aggarwal", "Shuchin Aeron"], "title": ["Tensor Train Neighborhood Preserving Embedding"], "date": ["2017-12-03T20:09:48Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1712.00828v2"], "summary": ["  In this paper, we propose a Tensor Train Neighborhood Preserving Embedding\n(TTNPE) to embed multi-dimensional tensor data into low dimensional tensor\nsubspace. Novel approaches to solve the optimization problem in TTNPE are\nproposed. For this embedding, we evaluate novel trade-off gain among\nclassification, computation, and dimensionality reduction (storage) for\nsupervised learning. It is shown that compared to the state-of-the-arts tensor\nembedding methods, TTNPE achieves superior trade-off in classification,\ncomputation, and dimensionality reduction in MNIST handwritten digits and\nWeizmann face datasets.\n"]},
{"authors": ["Mahmoud Hamandi", "Mike D'Arcy", "Pooyan Fazli"], "title": ["DeepMoTIon: Learning to Navigate Like Humans"], "date": ["2018-03-09T23:36:38Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03719v1"], "summary": ["  We present a novel human-aware navigation approach, where the robot learns to\nmimic humans to navigate safely in crowds. The presented model referred to as\nDeepMoTIon, is trained with pedestrian surveillance data to predict human\nvelocity. The robot processes LiDAR scans via the trained network to navigate\nto the target location. We conduct extensive experiments to assess the\ndifferent components of our network and prove the necessity of each to imitate\nhumans. Our experiments show that DeepMoTIon outperforms state-of-the-art in\nterms of human imitation and reaches the target on 100% of the test cases\nwithout breaching humans' safe distance.\n"]},
{"authors": ["Arnab Ghosh", "Viveka Kulharia", "Vinay Namboodiri", "Philip H. S. Torr", "Puneet K. Dokania"], "title": ["Multi-Agent Diverse Generative Adversarial Networks"], "date": ["2017-04-10T15:26:23Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1704.02906v2"], "summary": ["  We propose an intuitive generalization to the Generative Adversarial Networks\n(GANs) and its conditional variants to address the well known mode collapse\nproblem. Firstly, we propose a multi-agent GAN architecture incorporating\nmultiple generators and one discriminator. Secondly, to enforce different\ngenerators to capture diverse high probability modes, we modify discriminator's\nobjective function where along with finding the real and fake samples, the\ndiscriminator has to identify the generator that generated the fake sample.\nIntuitively, to succeed in this task, the discriminator must learn to push\ndifferent generators towards different identifiable modes. Our framework\n(MAD-GAN) is generalizable in the sense that it can be easily combined with\nother existing variants of GANs to produce diverse samples. We perform\nextensive experiments on synthetic and real datasets and compare MAD-GAN with\ndifferent variants of GAN. We show high quality diverse sample generations for\nthe challenging tasks such as image-to-image translation (known to learn delta\ndistribution) and face generation. In addition, we show that MAD-GAN is able to\ndisentangle different modalities even when trained using highly challenging\nmulti-view dataset (mixture of forests, icebergs, bedrooms etc). In the end, we\nalso show its efficacy for the unsupervised feature representation task. In the\nappendix we introduce a similarity based competing objective which encourages\nthe different generators to generate varied samples judged by a user defined\nsimilarity metric. We show extensive evaluations on a 1-D setting of mixture of\ngaussians for non parametric density estimation. The theoretical proofs back\nthe efficacy of the framework and explains why various generators are pushed\ntowards distinct clusters of modes.\n"]},
{"authors": ["Haizi Yu", "Tianxi Li", "Lav R. Varshney"], "title": ["Probabilistic Rule Realization and Selection"], "date": ["2017-09-06T05:08:00Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1709.01674v3"], "summary": ["  Abstraction and realization are bilateral processes that are key in deriving\nintelligence and creativity. In many domains, the two processes are approached\nthrough rules: high-level principles that reveal invariances within similar yet\ndiverse examples. Under a probabilistic setting for discrete input spaces, we\nfocus on the rule realization problem which generates input sample\ndistributions that follow the given rules. More ambitiously, we go beyond a\nmechanical realization that takes whatever is given, but instead ask for\nproactively selecting reasonable rules to realize. This goal is demanding in\npractice, since the initial rule set may not always be consistent and thus\nintelligent compromises are needed. We formulate both rule realization and\nselection as two strongly connected components within a single and symmetric\nbi-convex problem, and derive an efficient algorithm that works at large scale.\nTaking music compositional rules as the main example throughout the paper, we\ndemonstrate our model's efficiency in not only music realization (composition)\nbut also music interpretation and understanding (analysis).\n"]},
{"authors": ["Briland Hitaj", "Paolo Gasti", "Giuseppe Ateniese", "Fernando Perez-Cruz"], "title": ["PassGAN: A Deep Learning Approach for Password Guessing"], "date": ["2017-09-01T18:42:00Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1709.00440v2"], "summary": ["  State-of-the-art password guessing tools, such as HashCat and John the\nRipper, enable users to check billions of passwords per second against password\nhashes. In addition to performing straightforward dictionary attacks, these\ntools can expand password dictionaries using password generation rules, such as\nconcatenation of words (e.g., \"password123456\") and leet speak (e.g.,\n\"password\" becomes \"p4s5w0rd\"). Although these rules work well in practice,\nexpanding them to model further passwords is a laborious task that requires\nspecialized expertise. To address this issue, in this paper we introduce\nPassGAN, a novel approach that replaces human-generated password rules with\ntheory-grounded machine learning algorithms. Instead of relying on manual\npassword analysis, PassGAN uses a Generative Adversarial Network (GAN) to\nautonomously learn the distribution of real passwords from actual password\nleaks, and to generate high-quality password guesses. Our experiments show that\nthis approach is very promising. When we evaluated PassGAN on two large\npassword datasets, we were able to surpass rule-based and state-of-the-art\nmachine learning password guessing tools. However, in contrast with the other\ntools, PassGAN achieved this result without any a-priori knowledge on passwords\nor common password structures. Additionally, when we combined the output of\nPassGAN with the output of HashCat, we were able to match 51%-73% more\npasswords than with HashCat alone. This is remarkable, because it shows that\nPassGAN can autonomously extract a considerable number of password properties\nthat current state-of-the art rules do not encode.\n"]},
{"authors": ["Jaideep Pathak", "Alexander Wikner", "Rebeckah Fussell", "Sarthak Chandra", "Brian Hunt", "Michelle Girvan", "Edward Ott"], "title": ["Hybrid Forecasting of Chaotic Processes: Using Machine Learning in\n  Conjunction with a Knowledge-Based Model"], "date": ["2018-03-09T21:02:25Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.04779v1"], "summary": ["  A model-based approach to forecasting chaotic dynamical systems utilizes\nknowledge of the physical processes governing the dynamics to build an\napproximate mathematical model of the system. In contrast, machine learning\ntechniques have demonstrated promising results for forecasting chaotic systems\npurely from past time series measurements of system state variables (training\ndata), without prior knowledge of the system dynamics. The motivation for this\npaper is the potential of machine learning for filling in the gaps in our\nunderlying mechanistic knowledge that cause widely-used knowledge-based models\nto be inaccurate. Thus we here propose a general method that leverages the\nadvantages of these two approaches by combining a knowledge-based model and a\nmachine learning technique to build a hybrid forecasting scheme. Potential\napplications for such an approach are numerous (e.g., improving weather\nforecasting). We demonstrate and test the utility of this approach using a\nparticular illustrative version of a machine learning known as reservoir\ncomputing, and we apply the resulting hybrid forecaster to a low-dimensional\nchaotic system, as well as to a high-dimensional spatiotemporal chaotic system.\nThese tests yield extremely promising results in that our hybrid technique is\nable to accurately predict for a much longer period of time than either its\nmachine-learning component or its model-based component alone.\n"]},
{"authors": ["Zhinus Marzi", "Joao Hespanha", "Upamanyu Madhow"], "title": ["On the information in spike timing: neural codes derived from\n  polychronous groups"], "date": ["2018-03-09T20:53:31Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03692v1"], "summary": ["  There is growing evidence regarding the importance of spike timing in neural\ninformation processing, with even a small number of spikes carrying\ninformation, but computational models lag significantly behind those for rate\ncoding. Experimental evidence on neuronal behavior is consistent with the\ndynamical and state dependent behavior provided by recurrent connections. This\nmotivates the minimalistic abstraction investigated in this paper, aimed at\nproviding insight into information encoding in spike timing via recurrent\nconnections. We employ information-theoretic techniques for a simple reservoir\nmodel which encodes input spatiotemporal patterns into a sparse neural code,\ntranslating the polychronous groups introduced by Izhikevich into codewords on\nwhich we can perform standard vector operations. We show that the distance\nproperties of the code are similar to those for (optimal) random codes. In\nparticular, the code meets benchmarks associated with both linear\nclassification and capacity, with the latter scaling exponentially with\nreservoir size.\n"]},
{"authors": ["Luciana Ferrer"], "title": ["Scoring Formulation for Multi-Condition Joint PLDA"], "date": ["2018-03-09T20:29:18Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03684v1"], "summary": ["  The joint PLDA model, is a generalization of PLDA where the nuisance variable\nis no longer considered independent across samples, but potentially shared\n(tied) across samples that correspond to the same nuisance condition. The\noriginal work considered a single nuisance condition, deriving the EM and\nscoring formulas for this scenario. In this document, we show how to obtain\nlikelihood ratios for scoring when multiple nuisance conditions are allowed in\nthe model.\n"]},
{"authors": ["Stefan Feuerriegel", "Julius Gordon"], "title": ["News-based forecasts of macroeconomic indicators: A semantic path model\n  for interpretable predictions"], "date": ["2018-01-22T11:26:30Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1801.07047v2"], "summary": ["  The macroeconomic climate influences operations with regard to, e.g., raw\nmaterial prices, financing, supply chain utilization and demand quotas. In\norder to adapt to the economic environment, decision-makers across the public\nand private sectors require accurate forecasts of the economic outlook.\nExisting predictive frameworks base their forecasts primarily on time series\nanalysis, as well as the judgments of experts. As a consequence, current\napproaches are often biased and prone to error. In order to reduce forecast\nerrors, this paper presents an innovative methodology that extends lag\nvariables with unstructured data in the form of financial news: (1) we apply a\nvariety of models from machine learning to word counts as a high-dimensional\ninput. However, this approach suffers from low interpretability and\noverfitting, motivating the following remedies. (2) We follow the intuition\nthat the economic climate is driven by general sentiments and suggest a\nprojection of words onto latent semantic structures as a means of feature\nengineering. (3) We propose a semantic path model, together with estimation\ntechnique based on regularization, in order to yield full interpretability of\nthe forecasts. We demonstrate the predictive performance of our approach by\nutilizing 80,813 ad hoc announcements in order to make long-term forecasts of\nup to 24 months ahead regarding key macroeconomic indicators. Back-testing\nreveals a considerable reduction in forecast errors.\n"]},
{"authors": ["Soroush Pakniat", "Farzad Eskandari"], "title": ["Nonparametric Risk Assessment and Density Estimation for Persistence\n  Landscapes"], "date": ["2018-03-09T20:04:12Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03677v1"], "summary": ["  This paper presents approximate confidence intervals for each function of\nparameters in a Banach space based on a bootstrap algorithm. We apply kernel\ndensity approach to estimate the persistence landscape. In addition, we\nevaluate the quality distribution function estimator of random variables using\nintegrated mean square error (IMSE). The results of simulation studies show a\nsignificant improvement achieved by our approach compared to the standard\nversion of confidence intervals algorithm. In the next step, we provide several\nalgorithms to solve our model. Finally, real data analysis shows that the\naccuracy of our method compared to that of previous works for computing the\nconfidence interval.\n"]},
{"authors": ["Amin Khajehnejad", "Shima Hajimirza"], "title": ["Competitive Machine Learning: Best Theoretical Prediction vs\n  Optimization"], "date": ["2018-03-09T19:42:54Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03672v1"], "summary": ["  Machine learning is often used in competitive scenarios: Participants learn\nand fit static models, and those models compete in a shared platform. The\ncommon assumption is that in order to win a competition one has to have the\nbest predictive model, i.e., the model with the smallest out-sample error. Is\nthat necessarily true? Does the best theoretical predictive model for a target\nalways yield the best reward in a competition? If not, can one take the best\nmodel and purposefully change it into a theoretically inferior model which in\npractice results in a higher competitive edge? How does that modification look\nlike? And finally, if all participants modify their prediction models towards\nthe best practical performance, who benefits the most? players with inferior\nmodels, or those with theoretical superiority? The main theme of this paper is\nto raise these important questions and propose a theoretical model to answer\nthem. We consider a study case where two linear predictive models compete over\na shared target. The model with the closest estimate gets the whole reward,\nwhich is equal to the absolute value of the target. We characterize the reward\nfunction of each model, and using a basic game theoretic approach, demonstrate\nthat the inferior competitor can significantly improve his performance by\nchoosing optimal model coefficients that are different from the best\ntheoretical prediction. This is a preliminary study that emphasizes the fact\nthat in many applications where predictive machine learning is at the service\nof competition, much can be gained from practical (back-testing) optimization\nof the model compared to static prediction improvement.\n"]},
{"authors": ["Mihai Cucuringu", "Hemant Tyagi"], "title": ["Provably robust estimation of modulo 1 samples of a smooth function with\n  applications to phase unwrapping"], "date": ["2018-03-09T19:31:53Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03669v1"], "summary": ["  Consider an unknown smooth function $f: [0,1]^d \\rightarrow \\mathbb{R}$, and\nsay we are given $n$ noisy mod 1 samples of $f$, i.e., $y_i = (f(x_i) +\n\\eta_i)\\mod 1$, for $x_i \\in [0,1]^d$, where $\\eta_i$ denotes the noise. Given\nthe samples $(x_i,y_i)_{i=1}^{n}$, our goal is to recover smooth, robust\nestimates of the clean samples $f(x_i) \\bmod 1$. We formulate a natural\napproach for solving this problem, which works with angular embeddings of the\nnoisy mod 1 samples over the unit circle, inspired by the angular\nsynchronization framework. This amounts to solving a smoothness regularized\nleast-squares problem -- a quadratically constrained quadratic program (QCQP)\n-- where the variables are constrained to lie on the unit circle. Our approach\nis based on solving its relaxation, which is a trust-region sub-problem and\nhence solvable efficiently. We provide theoretical guarantees demonstrating its\nrobustness to noise for adversarial, and random Gaussian and Bernoulli noise\nmodels. To the best of our knowledge, these are the first such theoretical\nresults for this problem. We demonstrate the robustness and efficiency of our\napproach via extensive numerical simulations on synthetic data, along with a\nsimple least-squares solution for the unwrapping stage, that recovers the\noriginal samples of $f$ (up to a global shift). It is shown to perform well at\nhigh levels of noise, when taking as input the denoised modulo $1$ samples.\n  Finally, we also consider two other approaches for denoising the modulo 1\nsamples that leverage tools from Riemannian optimization on manifolds,\nincluding a Burer-Monteiro approach for a semidefinite programming relaxation\nof our formulation. For the two-dimensional version of the problem, which has\napplications in radar interferometry, we are able to solve instances of\nreal-world data with a million sample points in under 10 seconds, on a personal\nlaptop.\n"]},
{"authors": ["Chi-Ken Lu", "Scott Cheng-Hsin Yang", "Patrick Shafto"], "title": ["Standing Wave Decomposition Gaussian Process"], "date": ["2018-03-09T19:26:11Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03666v1"], "summary": ["  We propose a Standing Wave Decomposition (SWD) approximation to Gaussian\nProcess regression (GP). GP involves a costly matrix inversion operation, which\nlimits applicability to large data analysis. For an input space that can be\napproximated by a grid and when correlations among data are short-ranged, the\nkernel matrix inversion can be replaced by analytic diagonalization using the\nSWD. We show that this approach applies to uni- and multi-dimensional input\ndata, extends to include longer-range correlations, and the grid can be in a\nlatent space and used as inducing points. Through simulations, we show that our\napproximate method outperforms existing methods in predictive accuracy per unit\ntime in the regime where data are plentiful. Our SWD-GP is recommended for\nregression analyses where there is a relatively large amount of data and/or\nthere are constraints on computation time.\n"]},
{"authors": ["Chiwoo Park", "Daniel Apley"], "title": ["Patchwork Kriging for Large-scale Gaussian Process Regression"], "date": ["2017-01-23T22:20:47Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1701.06655v3"], "summary": ["  This paper presents a new approach for Gaussian process (GP) regression for\nlarge datasets. The approach involves partitioning the regression input domain\ninto multiple local regions with a different local GP model fitted in each\nregion. Unlike existing local partitioned GP approaches, we introduce a\ntechnique for patching together the local GP models nearly seamlessly to ensure\nthat the local GP models for two neighboring regions produce nearly the same\nresponse prediction and prediction error variance on the boundary between the\ntwo regions. This effectively solves the well-known discontinuity problem that\ndegrades the boundary accuracy of existing local partitioned GP methods. Our\nmain innovation is to represent the continuity conditions as additional\npseudo-observations that the differences between neighboring GP responses are\nidentically zero at an appropriately chosen set of boundary input locations. To\npredict the response at any input location, we simply augment the actual\nresponse observations with the pseudo-observations and apply standard GP\nprediction methods to the augmented data. In contrast to heuristic continuity\nadjustments, this has an advantage of working within a formal GP framework, so\nthat the GP-based predictive uncertainty quantification remains valid. Our\napproach also inherits a sparse block-like structure for the sample covariance\nmatrix, which results in computationally efficient closed-form expressions for\nthe predictive mean and variance. In addition, we provide a new spatial\npartitioning scheme based on a recursive space partitioning along local\nprincipal component directions, which makes the proposed approach applicable\nfor regression domains having more than two dimensions. Using three spatial\ndatasets and three higher dimensional datasets, we investigate the numerical\nperformance of the approach and compare it to several state-of-the-art\napproaches.\n"]},
{"authors": ["Cong Feng", "Jie Zhang"], "title": ["Hourly-Similarity Based Solar Forecasting Using Multi-Model Machine\n  Learning Blending"], "date": ["2018-03-09T18:17:52Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03623v1"], "summary": ["  With the increasing penetration of solar power into power systems,\nforecasting becomes critical in power system operations. In this paper, an\nhourly-similarity (HS) based method is developed for 1-hour-ahead (1HA) global\nhorizontal irradiance (GHI) forecasting. This developed method utilizes diurnal\npatterns, statistical distinctions between different hours, and hourly\nsimilarities in solar data to improve the forecasting accuracy. The HS-based\nmethod is built by training multiple two-layer multi-model forecasting\nframework (MMFF) models independently with the same-hour subsets. The final\noptimal model is a combination of MMFF models with the best-performed blending\nalgorithm at every hour. At the forecasting stage, the most suitable model is\nselected to perform the forecasting subtask of a certain hour. The HS-based\nmethod is validated by 1-year data with six solar features collected by the\nNational Renewable Energy Laboratory (NREL). Results show that the HS-based\nmethod outperforms the non-HS (all-in-one) method significantly with the same\nMMFF architecture, wherein the optimal HS- based method outperforms the best\nall-in-one method by 10.94% and 7.74% based on the normalized mean absolute\nerror and normalized root mean square error, respectively.\n"]},
{"authors": ["Chun-Hao Chang", "Ladislav Rampasek", "Anna Goldenberg"], "title": ["Dropout Feature Ranking for Deep Learning Models"], "date": ["2017-12-22T20:25:31Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1712.08645v2"], "summary": ["  Deep neural networks (DNNs) achieve state-of-the-art results in a variety of\ndomains. Unfortunately, DNNs are notorious for their non-interpretability, and\nthus limit their applicability in hypothesis-driven domains such as biology and\nhealthcare. Moreover, in the resource-constraint setting, it is critical to\ndesign tests relying on fewer more informative features leading to high\naccuracy performance within reasonable budget. We aim to close this gap by\nproposing a new general feature ranking method for deep learning. We show that\nour simple yet effective method performs on par or compares favorably to eight\nstrawman, classical and deep-learning feature ranking methods in two\nsimulations and five very different datasets on tasks ranging from\nclassification to regression, in both static and time series scenarios. We also\nillustrate the use of our method on a drug response dataset and show that it\nidentifies genes relevant to the drug-response.\n"]},
{"authors": ["Rion Brattig Correia", "Luciana P. de Ara\u00fajo", "Mauro M. Mattos", "David Wild", "Luis M. Rocha"], "title": ["City-wide Analysis of Electronic Health Records Reveals Gender and Age\n  Biases in the Administration of Known Drug-Drug Interactions"], "date": ["2018-03-09T15:45:12Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03571v1"], "summary": ["  From a public-health perspective, the occurrence of drug-drug-interactions\n(DDI) from multiple drug prescriptions is a serious problem, especially in the\nelderly population. This is true both for individuals and the system itself\nsince patients with complications due to DDI will likely re-enter the system at\na costlier level. We conducted an 18-month study of DDI occurrence in Blumenau\n(Brazil; pop. 340,000) using city-wide drug dispensing data from both primary\nand secondary-care level. Our goal is also to identify possible risk factors in\na large population, ultimately characterizing the burden of DDI for patients,\ndoctors and the public system itself. We found 181 distinct DDI being\nprescribed concomitantly to almost 5% of the city population. We also\ndiscovered that women are at a 60% risk increase of DDI when compared to men,\nwhile only having a 6% co-administration risk increase. Analysis of the DDI\nco-occurrence network reveals which DDI pairs are most associated with the\nobserved greater DDI risk for females, demonstrating that contraception and\nhormone therapy are not the main culprits of the gender disparity, which is\nmaximized after the reproductive years. Furthermore, DDI risk increases\ndramatically with age, with patients age 70-79 having a 50-fold risk increase\nin comparison to patients aged 0-19. Interestingly, several null models\ndemonstrate that this risk increase is not due to increased polypharmacy with\nage. Finally, we demonstrate that while the number of drugs and\nco-administrations help predict a patient's number of DDI ($R^2=.413$), they\nare not sufficient to flag these patients accurately, which we achieve by\ntraining classifiers with additional data (MCC=.83,F1=.72). These results\ndemonstrate that accurate warning systems for known DDI can be devised for\npublic and private systems alike, resulting in substantial prevention of\nDDI-related ADR and savings.\n"]},
{"authors": ["Andres C Rodriguez", "Tomasz Kacprzak", "Aurelien Lucchi", "Adam Amara", "Raphael Sgier", "Janis Fluri", "Thomas Hofmann", "Alexandre R\u00e9fr\u00e9gier"], "title": ["Fast Cosmic Web Simulations with Generative Adversarial Networks"], "date": ["2018-01-27T10:52:40Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1801.09070v2"], "summary": ["  Dark matter in the universe evolves through gravity to form a complex network\nof halos, filaments, sheets and voids, that is known as the cosmic web.\nComputational models of the underlying physical processes, such as classical\nN-body simulations, are extremely resource intensive, as they track the action\nof gravity in an expanding universe using billions of particles as tracers of\nthe cosmic matter distribution. Therefore, upcoming cosmology experiments will\nface a computational bottleneck that may limit the exploitation of their full\nscientific potential. To address this challenge, we demonstrate the application\nof a machine learning technique called Generative Adversarial Networks (GAN) to\nlearn models that can efficiently generate new, physically realistic\nrealizations of the cosmic web. Our training set is a small, representative\nsample of 2D image snapshots from N-body simulations of size 500 and 100 Mpc.\nWe show that the GAN-produced results are qualitatively and quantitatively very\nsimilar to the originals. Generation of a new cosmic web realization with a GAN\ntakes a fraction of a second, compared to the many hours needed by the N-body\ntechnique. We anticipate that GANs will therefore play an important role in\nproviding extremely fast and precise simulations of cosmic web in the era of\nlarge cosmological surveys, such as Euclid and LSST.\n"]},
{"authors": ["Marco Melis", "Davide Maiorca", "Battista Biggio", "Giorgio Giacinto", "Fabio Roli"], "title": ["Explaining Black-box Android Malware Detection"], "date": ["2018-03-09T14:56:36Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03544v1"], "summary": ["  Machine-learning models have been recently used for detecting malicious\nAndroid applications, reporting impressive performances on benchmark datasets,\neven when trained only on features statically extracted from the application,\nsuch as system calls and permissions. However, recent findings have highlighted\nthe fragility of such in-vitro evaluations with benchmark datasets, showing\nthat very few changes to the content of Android malware may suffice to evade\ndetection. How can we thus trust that a malware detector performing well on\nbenchmark data will continue to do so when deployed in an operating\nenvironment? To mitigate this issue, the most popular Android malware detectors\nuse linear, explainable machine-learning models to easily identify the most\ninfluential features contributing to each decision. In this work, we generalize\nthis approach to any black-box machine- learning model, by leveraging a\ngradient-based approach to identify the most influential local features. This\nenables using nonlinear models to potentially increase accuracy without\nsacrificing interpretability of decisions. Our approach also highlights the\nglobal characteristics learned by the model to discriminate between benign and\nmalware applications. Finally, as shown by our empirical analysis on a popular\nAndroid malware detection task, it also helps identifying potential\nvulnerabilities of linear and nonlinear models against adversarial\nmanipulations.\n"]},
{"authors": ["Adrien Saumard"], "title": ["A concentration inequality for the excess risk in least-squares\n  regression with random design and heteroscedastic noise"], "date": ["2017-02-16T17:35:06Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1702.05063v2"], "summary": ["  We prove a new and general concentration inequality for the excess risk in\nleast-squares regression with random design and heteroscedastic noise. No\nspecific structure is required on the model, except the existence of a suitable\nfunction that controls the local suprema of the empirical process. So far, only\nthe case of linear contrast estimation was tackled in the literature with this\nlevel of generality on the model. We solve here the case of a quadratic\ncontrast, by separating the behavior of a linearized empirical process and the\nempirical process driven by the squares of functions of models.\n"]},
{"authors": ["Hussain Kazmi", "Johan Suykens", "Johan Driesen"], "title": ["Valuing knowledge, information and agency in Multi-agent Reinforcement\n  Learning: a case study in smart buildings"], "date": ["2018-03-09T12:48:03Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03491v1"], "summary": ["  Increasing energy efficiency in buildings can reduce costs and emissions\nsubstantially. Historically, this has been treated as a local, or single-agent,\noptimization problem. However, many buildings utilize the same types of thermal\nequipment e.g. electric heaters and hot water vessels. During operation,\noccupants in these buildings interact with the equipment differently thereby\ndriving them to diverse regions in the state-space. Reinforcement learning\nagents can learn from these interactions, recorded as sensor data, to optimize\nthe overall energy efficiency. However, if these agents operate individually at\na household level, they can not exploit the replicated structure in the\nproblem. In this paper, we demonstrate that this problem can indeed benefit\nfrom multi-agent collaboration by making use of targeted exploration of the\nstate-space allowing for better generalization. We also investigate trade-offs\nbetween integrating human knowledge and additional sensors. Results show that\nsavings of over 40% are possible with collaborative multi-agent systems making\nuse of either expert knowledge or additional sensors with no loss of occupant\ncomfort. We find that such multi-agent systems comfortably outperform\ncomparable single agent systems.\n"]},
{"authors": ["Hongwei Wang", "Fuzheng Zhang", "Jialin Wang", "Miao Zhao", "Wenjie Li", "Xing Xie", "Minyi Guo"], "title": ["Ripple Network: Propagating User Preferences on the Knowledge Graph for\n  Recommender Systems"], "date": ["2018-03-09T11:12:01Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03467v1"], "summary": ["  To address the sparsity and cold start problem of collaborative filtering,\nresearchers usually make use of side information, such as social networks or\nitem attributes, to improve recommendation performance. This paper considers\nthe knowledge graph as the source of side information. To address the\nlimitations of existing embedding-based and path-based methods for\nknowledge-graph-aware recommendation, we propose Ripple Network, an end-to-end\nframework that naturally incorporates the knowledge graph into recommender\nsystems. Similar to actual ripples propagating on the surface of water, Ripple\nNetwork stimulates the propagation of user preferences over the set of\nknowledge entities by automatically and iteratively extending a user's\npotential interests along links in the knowledge graph. The multiple \"ripples\"\nactivated by a user's historically clicked items are thus superposed to form\nthe preference distribution of the user with respect to a candidate item, which\ncould be used for predicting the final clicking probability. Through extensive\nexperiments on real-world datasets, we demonstrate that Ripple Network achieves\nsubstantial gains in a variety of scenarios, including movie, book and news\nrecommendation, over several state-of-the-art baselines.\n"]},
{"authors": ["Andre Milzarek", "Xiantao Xiao", "Shicong Cen", "Zaiwen Wen", "Michael Ulbrich"], "title": ["A Stochastic Semismooth Newton Method for Nonsmooth Nonconvex\n  Optimization"], "date": ["2018-03-09T11:08:59Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03466v1"], "summary": ["  In this work, we present a globalized stochastic semismooth Newton method for\nsolving stochastic optimization problems involving smooth nonconvex and\nnonsmooth convex terms in the objective function. We assume that only noisy\ngradient and Hessian information of the smooth part of the objective function\nis available via calling stochastic first and second order oracles. The\nproposed method can be seen as a hybrid approach combining stochastic\nsemismooth Newton steps and stochastic proximal gradient steps. Two inexact\ngrowth conditions are incorporated to monitor the convergence and the\nacceptance of the semismooth Newton steps and it is shown that the algorithm\nconverges globally to stationary points in expectation. Moreover, under\nstandard assumptions and utilizing random matrix concentration inequalities, we\nprove that the proposed approach locally turns into a pure stochastic\nsemismooth Newton method and converges r-superlinearly with high probability.\nWe present numerical results and comparisons on $\\ell_1$-regularized logistic\nregression and nonconvex binary classification that demonstrate the efficiency\nof our algorithm.\n"]},
{"authors": ["Favour M. Nyikosa", "Michael A. Osborne", "Stephen J. Roberts"], "title": ["Bayesian Optimization for Dynamic Problems"], "date": ["2018-03-09T09:31:15Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03432v1"], "summary": ["  We propose practical extensions to Bayesian optimization for solving dynamic\nproblems. We model dynamic objective functions using spatiotemporal Gaussian\nprocess priors which capture all the instances of the functions over time. Our\nextensions to Bayesian optimization use the information learnt from this model\nto guide the tracking of a temporally evolving minimum. By exploiting temporal\ncorrelations, the proposed method also determines when to make evaluations, how\nfast to make those evaluations, and it induces an appropriate budget of steps\nbased on the available information. Lastly, we evaluate our technique on\nsynthetic and real-world problems.\n"]},
{"authors": ["Jian Shen", "Yanru Qu", "Weinan Zhang", "Yong Yu"], "title": ["Wasserstein Distance Guided Representation Learning for Domain\n  Adaptation"], "date": ["2017-07-05T05:34:13Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1707.01217v4"], "summary": ["  Domain adaptation aims at generalizing a high-performance learner on a target\ndomain via utilizing the knowledge distilled from a source domain which has a\ndifferent but related data distribution. One solution to domain adaptation is\nto learn domain invariant feature representations while the learned\nrepresentations should also be discriminative in prediction. To learn such\nrepresentations, domain adaptation frameworks usually include a domain\ninvariant representation learning approach to measure and reduce the domain\ndiscrepancy, as well as a discriminator for classification. Inspired by\nWasserstein GAN, in this paper we propose a novel approach to learn domain\ninvariant feature representations, namely Wasserstein Distance Guided\nRepresentation Learning (WDGRL). WDGRL utilizes a neural network, denoted by\nthe domain critic, to estimate empirical Wasserstein distance between the\nsource and target samples and optimizes the feature extractor network to\nminimize the estimated Wasserstein distance in an adversarial manner. The\ntheoretical advantages of Wasserstein distance for domain adaptation lie in its\ngradient property and promising generalization bound. Empirical studies on\ncommon sentiment and image classification adaptation datasets demonstrate that\nour proposed WDGRL outperforms the state-of-the-art domain invariant\nrepresentation learning approaches.\n"]},
{"authors": ["Christopher De Sa", "Megan Leszczynski", "Jian Zhang", "Alana Marzoev", "Christopher R. Aberger", "Kunle Olukotun", "Christopher R\u00e9"], "title": ["High-Accuracy Low-Precision Training"], "date": ["2018-03-09T04:50:27Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03383v1"], "summary": ["  Low-precision computation is often used to lower the time and energy cost of\nmachine learning, and recently hardware accelerators have been developed to\nsupport it. Still, it has been used primarily for inference - not training.\nPrevious low-precision training algorithms suffered from a fundamental\ntradeoff: as the number of bits of precision is lowered, quantization noise is\nadded to the model, which limits statistical accuracy. To address this issue,\nwe describe a simple low-precision stochastic gradient descent variant called\nHALP. HALP converges at the same theoretical rate as full-precision algorithms\ndespite the noise introduced by using low precision throughout execution. The\nkey idea is to use SVRG to reduce gradient variance, and to combine this with a\nnovel technique called bit centering to reduce quantization error. We show that\non the CPU, HALP can run up to $4 \\times$ faster than full-precision SVRG and\ncan match its convergence trajectory. We implemented HALP in TensorQuant, and\nshow that it exceeds the validation performance of plain low-precision SGD on\ntwo deep learning tasks.\n"]},
{"authors": ["Adam Klivans", "Pravesh K. Kothari", "Raghu Meka"], "title": ["Efficient Algorithms for Outlier-Robust Regression"], "date": ["2018-03-08T18:30:31Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03241v2"], "summary": ["  We give the first polynomial-time algorithm for performing linear or\npolynomial regression resilient to adversarial corruptions in both examples and\nlabels.\n  Given a sufficiently large (polynomial-size) training set drawn i.i.d. from\ndistribution D and subsequently corrupted on some fraction of points, our\nalgorithm outputs a linear function whose squared error is close to the squared\nerror of the best-fitting linear function with respect to D, assuming that the\nmarginal distribution of D over the input space is \\emph{certifiably\nhypercontractive}. This natural property is satisfied by many well-studied\ndistributions such as Gaussian, strongly log-concave distributions and, uniform\ndistribution on the hypercube among others. We also give a simple statistical\nlower bound showing that some distributional assumption is necessary to succeed\nin this setting.\n  These results are the first of their kind and were not known to be even\ninformation-theoretically possible prior to our work.\n  Our approach is based on the sum-of-squares (SoS) method and is inspired by\nthe recent applications of the method for parameter recovery problems in\nunsupervised learning. Our algorithm can be seen as a natural convex relaxation\nof the following conceptually simple non-convex optimization problem: find a\nlinear function and a large subset of the input corrupted sample such that the\nleast squares loss of the function over the subset is minimized over all\npossible large subsets.\n"]},
{"authors": ["Lifu Tu", "Kevin Gimpel"], "title": ["Learning Approximate Inference Networks for Structured Prediction"], "date": ["2018-03-09T03:50:24Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03376v1"], "summary": ["  Structured prediction energy networks (SPENs; Belanger & McCallum 2016) use\nneural network architectures to define energy functions that can capture\narbitrary dependencies among parts of structured outputs. Prior work used\ngradient descent for inference, relaxing the structured output to a set of\ncontinuous variables and then optimizing the energy with respect to them. We\nreplace this use of gradient descent with a neural network trained to\napproximate structured argmax inference. This \"inference network\" outputs\ncontinuous values that we treat as the output structure. We develop\nlarge-margin training criteria for joint training of the structured energy\nfunction and inference network. On multi-label classification we report\nspeed-ups of 10-60x compared to (Belanger et al, 2017) while also improving\naccuracy. For sequence labeling with simple structured energies, our approach\nperforms comparably to exact inference while being much faster at test time. We\nthen demonstrate improved accuracy by augmenting the energy with a \"label\nlanguage model\" that scores entire output label sequences, showing it can\nimprove handling of long-distance dependencies in part-of-speech tagging.\nFinally, we show how inference networks can replace dynamic programming for\ntest-time inference in conditional random fields, suggestive for their general\nuse for fast inference in structured settings.\n"]},
{"authors": ["Pedram Daee", "Tomi Peltola", "Aki Vehtari", "Samuel Kaski"], "title": ["User Modelling for Avoiding Overfitting in Interactive Knowledge\n  Elicitation for Prediction"], "date": ["2017-10-13T11:52:19Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.04881v2"], "summary": ["  In human-in-the-loop machine learning, the user provides information beyond\nthat in the training data. Many algorithms and user interfaces have been\ndesigned to optimize and facilitate this human--machine interaction; however,\nfewer studies have addressed the potential defects the designs can cause.\nEffective interaction often requires exposing the user to the training data or\nits statistics. The design of the system is then critical, as this can lead to\ndouble use of data and overfitting, if the user reinforces noisy patterns in\nthe data. We propose a user modelling methodology, by assuming simple rational\nbehaviour, to correct the problem. We show, in a user study with 48\nparticipants, that the method improves predictive performance in a sparse\nlinear regression sentiment analysis task, where graded user knowledge on\nfeature relevance is elicited. We believe that the key idea of inferring user\nknowledge with probabilistic user models has general applicability in guarding\nagainst overfitting and improving interactive machine learning.\n"]},
{"authors": ["Subhabrata Majumdar", "George Michailidis"], "title": ["Joint Estimation and Inference for Data Integration Problems based on\n  Multiple Multi-layered Gaussian Graphical Models"], "date": ["2018-03-09T01:30:04Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03348v1"], "summary": ["  The rapid development of high-throughput technologies has enabled the\ngeneration of data from biological or disease processes that span multiple\nlayers, like genomic, proteomic or metabolomic data, and further pertain to\nmultiple sources, like disease subtypes or experimental conditions. In this\nwork, we propose a general statistical framework based on Gaussian graphical\nmodels for horizontal (i.e. across conditions or subtypes) and vertical (i.e.\nacross different layers containing data on molecular compartments) integration\nof information in such datasets. We start with decomposing the multi-layer\nproblem into a series of two-layer problems. For each two-layer problem, we\nmodel the outcomes at a node in the lower layer as dependent on those of other\nnodes in that layer, as well as all nodes in the upper layer. We use a\ncombination of neighborhood selection and group-penalized regression to obtain\nsparse estimates of all model parameters. Following this, we develop a\ndebiasing technique and asymptotic distributions of inter-layer directed edge\nweights that utilize already computed neighborhood selection coefficients for\nnodes in the upper layer. Subsequently, we establish global and simultaneous\ntesting procedures for these edge weights. Performance of the proposed\nmethodology is evaluated on synthetic data.\n"]},
{"authors": ["Victor Chen", "Matthew M. Dunlop", "Omiros Papaspiliopoulos", "Andrew M. Stuart"], "title": ["Robust MCMC Sampling with Non-Gaussian and Hierarchical Priors in High\n  Dimensions"], "date": ["2018-03-09T01:02:47Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03344v1"], "summary": ["  A key problem in inference for high dimensional unknowns is the design of\nsampling algorithms whose performance scales favourably with the dimension of\nthe unknown. A typical setting in which these problems arise is the area of\nBayesian inverse problems. In such problems, which include graph-based\nlearning, nonparametric regression and PDE-based inversion, the unknown can be\nviewed as an infinite-dimensional parameter (such as a function) that has been\ndiscretised. This results in a high-dimensional space for inference. Here we\nstudy robustness of an MCMC algorithm for posterior inference; this refers to\nMCMC convergence rates that do not deteriorate as the discretisation becomes\nfiner. When a Gaussian prior is employed there is a known methodology for the\ndesign of robust MCMC samplers. However, one often requires more flexibility\nthan a Gaussian prior can provide: hierarchical models are used to enable\ninference of parameters underlying a Gaussian prior; or non-Gaussian priors,\nsuch as Besov, are employed to induce sparse MAP estimators; or deep Gaussian\npriors are used to represent other non-Gaussian phenomena; and piecewise\nconstant functions, which are necessarily non-Gaussian, are required for\nclassification problems. The purpose of this article is to show that the\nsimulation technology available for Gaussian priors can be exported to such\nnon-Gaussian priors. The underlying methodology is based on a white noise\nrepresentation of the unknown. This is exploited both for robust posterior\nsampling and for joint inference of the function and parameters involved in the\nspecification of its prior, in which case our framework borrows strength from\nthe well-developed non-centred methodology for Bayesian hierarchical models.\nThe desired robustness of the proposed sampling algorithms is supported by some\ntheory and by extensive numerical evidence from several challenging problems.\n"]},
{"authors": ["Vernon J. Lawhern", "Amelia J. Solon", "Nicholas R. Waytowich", "Stephen M. Gordon", "Chou P. Hung", "Brent J. Lance"], "title": ["EEGNet: A Compact Convolutional Network for EEG-based Brain-Computer\n  Interfaces"], "date": ["2016-11-23T22:36:58Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1611.08024v3"], "summary": ["  Brain computer interfaces (BCI) enable direct communication with a computer,\nusing neural activity as the control signal. This signal is generally chosen\nfrom a variety of well-studied electroencephalogram (EEG) signals. For a given\nBCI paradigm, feature extractors and classifiers are tailored to the distinct\ncharacteristics of its expected EEG control signal, limiting its application to\nthat specific signal. Convolutional Neural Networks (CNNs), which have been\nused in computer vision and speech recognition to perform automatic feature\nextraction and classification, have successfully been applied to EEG-based\nBCIs; however, they have mainly been applied to single BCI paradigms and thus\nit remains unclear how these architectures generalize to other paradigms. Here,\nwe ask if we can design a single CNN architecture to accurately classify EEG\nsignals from different BCI paradigms, while simultaneously being as compact as\npossible (defined as the number of parameters in the model). In this work we\nintroduce EEGNet, a compact convolutional network for EEG-based BCIs. We\nintroduce the use of depthwise and separable convolutions to more efficiently\nextract relevant features for EEG-based BCIs. We compare EEGNet, both for\nwithin-subject and cross-subject classification, to current state-of-the-art\napproaches across four BCI paradigms: P300 visual-evoked potentials,\nerror-related negativity responses (ERN), movement-related cortical potentials\n(MRCP), and sensory motor rhythms (SMR). We show that EEGNet generalizes across\nparadigms better than, and achieves comparably high performance to, traditional\napproaches, while simultaneously fitting up to two orders of magnitude fewer\nparameters. We also demonstrate ways to visualize the contents of a trained\nEEGNet model to enable interpretation of the learned features.\n"]},
{"authors": ["Son N. Tran", "Srikanth Cherla", "Artur Garcez", "Tillman Weyde"], "title": ["Linear-Time Sequence Classification using Restricted Boltzmann Machines"], "date": ["2017-10-06T00:29:30Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.02245v3"], "summary": ["  Classification of sequence data is the topic of interest for dynamic Bayesian\nmodels and Recurrent Neural Networks (RNNs). While the former can explicitly\nmodel the temporal dependencies between class variables, the latter have a\ncapability of learning representations. Several attempts have been made to\nimprove performance by combining these two approaches or increasing the\nprocessing capability of the hidden units in RNNs. This often results in\ncomplex models with a large number of learning parameters. In this paper, a\ncompact model is proposed which offers both representation learning and\ntemporal inference of class variables by rolling Restricted Boltzmann Machines\n(RBMs) and class variables over time. We address the key issue of\nintractability in this variant of RBMs by optimising a conditional\ndistribution, instead of a joint distribution. Experiments reported in the\npaper on melody modelling and optical character recognition show that the\nproposed model can outperform the state-of-the-art. Also, the experimental\nresults on optical character recognition, part-of-speech tagging and text\nchunking demonstrate that our model is comparable to recurrent neural networks\nwith complex memory gates while requiring far fewer parameters.\n"]},
{"authors": ["Yujia Li", "Oriol Vinyals", "Chris Dyer", "Razvan Pascanu", "Peter Battaglia"], "title": ["Learning Deep Generative Models of Graphs"], "date": ["2018-03-08T22:20:00Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03324v1"], "summary": ["  Graphs are fundamental data structures which concisely capture the relational\nstructure in many important real-world domains, such as knowledge graphs,\nphysical and social interactions, language, and chemistry. Here we introduce a\npowerful new approach for learning generative models over graphs, which can\ncapture both their structure and attributes. Our approach uses graph neural\nnetworks to express probabilistic dependencies among a graph's nodes and edges,\nand can, in principle, learn distributions over any arbitrary graph. In a\nseries of experiments our results show that once trained, our models can\ngenerate good quality samples of both synthetic graphs as well as real\nmolecular graphs, both unconditionally and conditioned on data. Compared to\nbaselines that do not use graph-structured representations, our models often\nperform far better. We also explore key challenges of learning generative\nmodels of graphs, such as how to handle symmetries and ordering of elements\nduring the graph generation process, and offer possible solutions. Our work is\nthe first and most general approach for learning generative models over\narbitrary graphs, and opens new directions for moving away from restrictions of\nvector- and sequence-like knowledge representations, toward more expressive and\nflexible relational data structures.\n"]},
{"authors": ["Itay Evron", "Edward Moroshko", "Koby Crammer"], "title": ["Efficient Loss-Based Decoding On Graphs For Extreme Classification"], "date": ["2018-03-08T21:54:19Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03319v1"], "summary": ["  In extreme classification problems, learning algorithms are required to map\ninstances to labels from an extremely large label set. We build on a recent\nextreme classification framework with logarithmic time and space, and on a\ngeneral approach for error correcting output coding (ECOC), and introduce a\nflexible and efficient approach accompanied by bounds. Our framework employs\noutput codes induced by graphs, and offers a tradeoff between accuracy and\nmodel size. We show how to find the sweet spot of this tradeoff using only the\ntraining data. Our experimental study demonstrates the validity of our\nassumptions and claims, and shows the superiority of our method compared with\nstate-of-the-art algorithms.\n"]},
{"authors": ["Junhong Lin", "Lorenzo Rosasco"], "title": ["Generalization Properties of Doubly Stochastic Learning Algorithms"], "date": ["2017-07-03T14:46:05Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1707.00577v2"], "summary": ["  Doubly stochastic learning algorithms are scalable kernel methods that\nperform very well in practice. However, their generalization properties are not\nwell understood and their analysis is challenging since the corresponding\nlearning sequence may not be in the hypothesis space induced by the kernel. In\nthis paper, we provide an in-depth theoretical analysis for different variants\nof doubly stochastic learning algorithms within the setting of nonparametric\nregression in a reproducing kernel Hilbert space and considering the square\nloss. Particularly, we derive convergence results on the generalization error\nfor the studied algorithms either with or without an explicit penalty term. To\nthe best of our knowledge, the derived results for the unregularized variants\nare the first of this kind, while the results for the regularized variants\nimprove those in the literature. The novelties in our proof are a sample error\nbound that requires controlling the trace norm of a cumulative operator, and a\nrefined analysis of bounding initial error.\n"]},
{"authors": ["Robert Bamler", "Stephan Mandt"], "title": ["Improving Optimization in Models With Continuous Symmetry Breaking"], "date": ["2018-03-08T18:07:40Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03234v1"], "summary": ["  Many loss functions in representation learning are invariant under a\ncontinuous symmetry transformation. As an example, consider word embeddings\n(Mikolov et al., 2013), where the loss remains unchanged if we simultaneously\nrotate all word and context embedding vectors. We show that representation\nlearning models with a continuous symmetry and a quadratic Markovian time\nseries prior possess so-called Goldstone modes. These are low cost deviations\nfrom the optimum which slow down convergence of gradient descent. We use tools\nfrom gauge theory in physics to design an optimization algorithm that solves\nthe slow convergence problem. Our algorithm leads to a fast decay of Goldstone\nmodes, to orders of magnitude faster convergence, and to more interpretable\nrepresentations, as we show for dynamic extensions of matrix factorization and\nword embedding models. We present an example application, translating modern\nwords into historic language using a shared representation space.\n"]},
{"authors": ["Yahav Bechavod", "Katrina Ligett"], "title": ["Penalizing Unfairness in Binary Classification"], "date": ["2017-06-30T20:59:44Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1707.00044v3"], "summary": ["  We present a new approach for mitigating unfairness in learned classifiers.\nIn particular, we focus on binary classification tasks over individuals from\ntwo populations, where, as our criterion for fairness, we wish to achieve\nsimilar false positive rates in both populations, and similar false negative\nrates in both populations. As a proof of concept, we implement our approach and\nempirically evaluate its ability to achieve both fairness and accuracy, using\ndatasets from the fields of criminal risk assessment, credit, lending, and\ncollege admissions.\n"]},
{"authors": ["Gregory Farquhar", "Tim Rockt\u00e4schel", "Maximilian Igl", "Shimon Whiteson"], "title": ["TreeQN and ATreeC: Differentiable Tree-Structured Models for Deep\n  Reinforcement Learning"], "date": ["2017-10-31T11:54:35Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.11417v2"], "summary": ["  Combining deep model-free reinforcement learning with on-line planning is a\npromising approach to building on the successes of deep RL. On-line planning\nwith look-ahead trees has proven successful in environments where transition\nmodels are known a priori. However, in complex environments where transition\nmodels need to be learned from data, the deficiencies of learned models have\nlimited their utility for planning. To address these challenges, we propose\nTreeQN, a differentiable, recursive, tree-structured model that serves as a\ndrop-in replacement for any value function network in deep RL with discrete\nactions. TreeQN dynamically constructs a tree by recursively applying a\ntransition model in a learned abstract state space and then aggregating\npredicted rewards and state-values using a tree backup to estimate Q-values. We\nalso propose ATreeC, an actor-critic variant that augments TreeQN with a\nsoftmax layer to form a stochastic policy network. Both approaches are trained\nend-to-end, such that the learned model is optimised for its actual use in the\ntree. We show that TreeQN and ATreeC outperform n-step DQN and A2C on a\nbox-pushing task, as well as n-step DQN and value prediction networks (Oh et\nal. 2017) on multiple Atari games. Furthermore, we present ablation studies\nthat demonstrate the effect of different auxiliary losses on learning\ntransition models.\n"]},
{"authors": ["Michael P. B. Gallaugher", "Paul D. McNicholas"], "title": ["Mixtures of Matrix Variate Bilinear Factor Analyzers"], "date": ["2017-12-22T21:26:09Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1712.08664v2"], "summary": ["  Over the years data has become increasingly higher dimensional, which has\nprompted an increased need for dimension reduction techniques. This is perhaps\nespecially true for clustering (unsupervised classification) as well as\nsemi-supervised and supervised classification. Although dimension reduction in\nthe area of clustering for multivariate data has been quite thoroughly\ndiscussed in the literature, there is relatively little work in the area of\nthree way, or matrix variate, data. Herein, we develop a mixture of matrix\nvariate bilinear factor analyzers (MMVBFA) model for use in clustering\nhigh-dimensional matrix variate data. This work can be considered both the\nfirst matrix variate bilinear factor analyzers model as well as the first\nMMVBFA model. Parameter estimation is discussed, and the MMVBFA model is\nillustrated using simulated and real data.\n"]},
{"authors": ["Vincent Dorie", "Jennifer Hill", "Uri Shalit", "Marc Scott", "Dan Cervone"], "title": ["Automated versus do-it-yourself methods for causal inference: Lessons\n  learned from a data analysis competition"], "date": ["2017-07-09T21:24:25Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1707.02641v4"], "summary": ["  Statisticians have made great progress in creating methods that reduce our\nreliance on parametric assumptions. However this explosion in research has\nresulted in a breadth of inferential strategies that both create opportunities\nfor more reliable inference as well as complicate the choices that an applied\nresearcher has to make and defend. Relatedly, researchers advocating for new\nmethods typically compare their method to at best 2 or 3 other causal inference\nstrategies and test using simulations that may or may not be designed to\nequally tease out flaws in all the competing methods. The causal inference data\nanalysis challenge, \"Is Your SATT Where It's At?\", launched as part of the 2016\nAtlantic Causal Inference Conference, sought to make progress with respect to\nboth of these issues. The researchers creating the data testing grounds were\ndistinct from the researchers submitting methods whose efficacy would be\nevaluated. Results from 30 competitors across the two versions of the\ncompetition (black box algorithms and do-it-yourself analyses) are presented\nalong with post-hoc analyses that reveal information about the characteristics\nof causal inference strategies and settings that affect performance. The most\nconsistent conclusion was that methods that flexibly model the response surface\nperform better overall than methods that fail to do so. Finally new methods are\nproposed that combine features of several of the top-performing submitted\nmethods.\n"]},
{"authors": ["Trisha Lawrence"], "title": ["A Bayesian and Machine Learning approach to estimating Influence Model\n  parameters for IM-RO"], "date": ["2018-03-08T16:33:09Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03191v1"], "summary": ["  The rise of Online Social Networks (OSNs) has caused an insurmountable amount\nof interest from advertisers and researchers seeking to monopolize on its\nfeatures. Researchers aim to develop strategies for determining how information\nis propagated among users within an OSN that is captured by diffusion or\ninfluence models. We consider the influence models for the IM-RO problem, a\nnovel formulation to the Influence Maximization (IM) problem based on\nimplementing Stochastic Dynamic Programming (SDP). In contrast to existing\napproaches involving influence spread and the theory of submodular functions,\nthe SDP method focuses on optimizing clicks and ultimately revenue to\nadvertisers in OSNs. Existing approaches to influence maximization have been\nactively researched over the past decade, with applications to multiple fields,\nhowever, our approach is a more practical variant to the original IM problem.\nIn this paper, we provide an analysis on the influence models of the IM-RO\nproblem by conducting experiments on synthetic and real-world datasets. We\npropose a Bayesian and Machine Learning approach for estimating the parameters\nof the influence models for the (Influence Maximization- Revenue Optimization)\nIM-RO problem. We present a Bayesian hierarchical model and implement the\nwell-known Naive Bayes classifier (NBC), Decision Trees classifier (DTC) and\nRandom Forest classifier (RFC) on three real-world datasets. Compared to\nprevious approaches to estimating influence model parameters, our strategy has\nthe great advantage of being directly implementable in standard software\npackages such as WinBUGS/OpenBUGS/JAGS and Apache Spark. We demonstrate the\nefficiency and usability of our methods in terms of spreading information and\ngenerating revenue for advertisers in the context of OSNs.\n"]},
{"authors": ["Alyson K. Fletcher", "Philip Schniter"], "title": ["Learning and Free Energies for Vector Approximate Message Passing"], "date": ["2016-02-26T06:06:13Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1602.08207v4"], "summary": ["  Vector approximate message passing (VAMP) is a computationally simple\napproach to the recovery of a signal $\\mathbf{x}$ from noisy linear\nmeasurements $\\mathbf{y}=\\mathbf{Ax}+\\mathbf{w}$. Like the AMP proposed by\nDonoho, Maleki, and Montanari in 2009, VAMP is characterized by a rigorous\nstate evolution (SE) that holds under certain large random matrices and that\nmatches the replica prediction of optimality. But while AMP's SE holds only for\nlarge i.i.d. sub-Gaussian $\\mathbf{A}$, VAMP's SE holds under the much larger\nclass: right-rotationally invariant $\\mathbf{A}$. To run VAMP, however, one\nmust specify the statistical parameters of the signal and noise. This work\ncombines VAMP with Expectation-Maximization to yield an algorithm, EM-VAMP,\nthat can jointly recover $\\mathbf{x}$ while learning those statistical\nparameters. The fixed points of the proposed EM-VAMP algorithm are shown to be\nstationary points of a certain constrained free-energy, providing a variational\ninterpretation of the algorithm. Numerical simulations show that EM-VAMP is\nrobust to highly ill-conditioned $\\mathbf{A}$ with performance nearly matching\noracle-parameter VAMP.\n"]},
{"authors": ["Aur\u00e9lie Fischer", "Mathilde Mougeot"], "title": ["Aggregation using input-output trade-off"], "date": ["2018-03-08T15:43:34Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03166v1"], "summary": ["  In this paper, we introduce a new learning strategy based on a seminal idea\nof Mojirsheibani (1999, 2000, 2002a, 2002b), who proposed a smart method for\ncombining several classifiers, relying on a consensus notion. In many\naggregation methods, the prediction for a new observation x is computed by\nbuilding a linear or convex combination over a collection of basic estimators\nr1(x),. .. , rm(x) previously calibrated using a training data set.\nMojirsheibani proposes to compute the prediction associated to a new\nobservation by combining selected outputs of the training examples. The output\nof a training example is selected if some kind of consensus is observed: the\npredictions computed for the training example with the different machines have\nto be \"similar\" to the prediction for the new observation. This approach has\nbeen recently extended to the context of regression in Biau et al. (2016). In\nthe original scheme, the agreement condition is actually required to hold for\nall individual estimators, which appears inadequate if there is one bad initial\nestimator. In practice, a few disagreements are allowed ; for establishing the\ntheoretical results, the proportion of estimators satisfying the condition is\nrequired to tend to 1. In this paper, we propose an alternative procedure,\nmixing the previous consensus ideas on the predictions with the Euclidean\ndistance computed between entries. This may be seen as an alternative approach\nallowing to reduce the effect of a possibly bad estimator in the initial list,\nusing a constraint on the inputs. We prove the consistency of our strategy in\nclassification and in regression. We also provide some numerical experiments on\nsimulated and real data to illustrate the benefits of this new aggregation\nmethod. On the whole, our practical study shows that our method may perform\nmuch better than the original combination technique, and, in particular,\nexhibit far less variance. We also show on simulated examples that this\nprocedure mixing inputs and outputs is still robust to high dimensional inputs.\n"]},
{"authors": ["Aleksei Triastcyn", "Boi Faltings"], "title": ["Generating Differentially Private Datasets Using GANs"], "date": ["2018-03-08T15:22:37Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03148v1"], "summary": ["  In this paper, we present a technique for generating artificial datasets that\nretain statistical properties of the real data while providing differential\nprivacy guarantees with respect to this data. We include a Gaussian noise layer\nin the discriminator of a generative adversarial network to make the output and\nthe gradients differentially private with respect to the training data, and\nthen use the generator component to synthesise privacy-preserving artificial\ndataset. Our experiments show that under a reasonably small privacy budget we\nare able to generate data of high quality and successfully train machine\nlearning models on this artificial data.\n"]},
{"authors": ["Jade Shi", "Rhiju Das", "Vijay S. Pande"], "title": ["SentRNA: Improving computational RNA design by incorporating a prior of\n  human design strategies"], "date": ["2018-03-08T15:12:16Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03146v1"], "summary": ["  Designing RNA sequences that fold into specific structures and perform\ndesired biological functions is an emerging field in bioengineering with broad\napplications from intracellular chemical catalysis to cancer therapy via\nselective gene silencing. Effective RNA design requires first solving the\ninverse folding problem: given a target structure, propose a sequence that\nfolds into that structure. Although significant progress has been made in\ndeveloping computational algorithms for this purpose, current approaches are\nineffective at designing sequences for complex targets, limiting their utility\nin real-world applications. However, an alternative that has shown\nsignificantly higher performance are human players of the online RNA design\ngame EteRNA. Through many rounds of gameplay, these players have developed a\ncollective library of \"human\" rules and strategies for RNA design that have\nproven to be more effective than current computational approaches, especially\nfor complex targets. Here, we present an RNA design agent, SentRNA, which\nconsists of a fully-connected neural network trained using the $eternasolves$\ndataset, a set of $1.8 x 10^4$ player-submitted sequences across 724 unique\ntargets. The agent first predicts an initial sequence for a target using the\ntrained network, and then refines that solution if necessary using a short\nadaptive walk utilizing a canon of standard design moves. Through this\napproach, we observe SentRNA can learn and apply human-like design strategies\nto solve several complex targets previously unsolvable by any computational\napproach. We thus demonstrate that incorporating a prior of human design\nstrategies into a computational agent can significantly boost its performance,\nand suggests a new paradigm for machine-based RNA design.\n"]},
{"authors": ["Oliver Lauwers", "Bart De Moor"], "title": ["Applicability and interpretation of the deterministic weighted cepstral\n  distance"], "date": ["2018-03-08T14:31:46Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03104v1"], "summary": ["  Quantifying similarity between data objects is an important part of modern\ndata science. Deciding what similarity measure to use is very application\ndependent. In this paper, we combine insights from systems theory and machine\nlearning, and investigate the weighted cepstral distance, which was previously\ndefined for signals coming from ARMA models. We provide an extension of this\ndistance to invertible deterministic linear time invariant single input single\noutput models, and assess its applicability. We show that it can always be\ninterpreted in terms of the poles and zeros of the underlying model, and that,\nin the case of stable, minimum-phase, or unstable, maximum-phase models, a\ngeometrical interpretation in terms of subspace angles can be given. We then\ndevise a method to assess stability and phase-type of the generating models,\nusing only input/output signal information. In this way, we prove a connection\nbetween the extended weighted cepstral distance and a weighted cepstral model\nnorm. In this way, we provide a purely data-driven way to assess different\nunderlying dynamics of input/output signal pairs, without the need for any\nsystem identification step. This can be useful in machine learning tasks such\nas time series clustering. An iPython tutorial is published complementary to\nthis paper, containing implementations of the various methods and algorithms\npresented here, as well as some numerical illustrations of the equivalences\nproven here.\n"]},
{"authors": ["Elad Hoffer", "Ron Banner", "Itay Golan", "Daniel Soudry"], "title": ["Norm matters: efficient and accurate normalization schemes in deep\n  networks"], "date": ["2018-03-05T18:16:43Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.01814v2"], "summary": ["  Over the past few years batch-normalization has been commonly used in deep\nnetworks, allowing faster training and high performance for a wide variety of\napplications. However, the reasons behind its merits remained unanswered, with\nseveral shortcomings that hindered its use for certain tasks. In this work we\npresent a novel view on the purpose and function of normalization methods and\nweight-decay, as tools to decouple weights' norm from the underlying optimized\nobjective. We also improve the use of weight-normalization and show the\nconnection between practices such as normalization, weight decay and\nlearning-rate adjustments. Finally, we suggest several alternatives to the\nwidely used $L^2$ batch-norm, using normalization in $L^1$ and $L^\\infty$\nspaces that can substantially improve numerical stability in low-precision\nimplementations as well as provide computational and memory benefits. We\ndemonstrate that such methods enable the first batch-norm alternative to work\nfor half-precision implementations.\n"]},
{"authors": ["Qianxiao Li", "Long Chen", "Cheng Tai", "Weinan E"], "title": ["Maximum Principle Based Algorithms for Deep Learning"], "date": ["2017-10-26T02:04:33Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.09513v3"], "summary": ["  The continuous dynamical system approach to deep learning is explored in\norder to devise alternative frameworks for training algorithms. Training is\nrecast as a control problem and this allows us to formulate necessary\noptimality conditions in continuous time using the Pontryagin's maximum\nprinciple (PMP). A modification of the method of successive approximations is\nthen used to solve the PMP, giving rise to an alternative training algorithm\nfor deep learning. This approach has the advantage that rigorous error\nestimates and convergence results can be established. We also show that it may\navoid some pitfalls of gradient-based methods, such as slow convergence on flat\nlandscapes near saddle points. Furthermore, we demonstrate that it obtains\nfavorable initial convergence rate per-iteration, provided Hamiltonian\nmaximization can be efficiently carried out - a step which is still in need of\nimprovement. Overall, the approach opens up new avenues to attack problems\nassociated with deep learning, such as trapping in slow manifolds and\ninapplicability of gradient-based methods for discrete trainable variables.\n"]},
{"authors": ["Matt J. Kusner", "Joshua R. Loftus", "Chris Russell", "Ricardo Silva"], "title": ["Counterfactual Fairness"], "date": ["2017-03-20T17:18:57Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1703.06856v3"], "summary": ["  Machine learning can impact people with legal or ethical consequences when it\nis used to automate decisions in areas such as insurance, lending, hiring, and\npredictive policing. In many of these scenarios, previous decisions have been\nmade that are unfairly biased against certain subpopulations, for example those\nof a particular race, gender, or sexual orientation. Since this past data may\nbe biased, machine learning predictors must account for this to avoid\nperpetuating or creating discriminatory practices. In this paper, we develop a\nframework for modeling fairness using tools from causal inference. Our\ndefinition of counterfactual fairness captures the intuition that a decision is\nfair towards an individual if it is the same in (a) the actual world and (b) a\ncounterfactual world where the individual belonged to a different demographic\ngroup. We demonstrate our framework on a real-world problem of fair prediction\nof success in law school.\n"]},
{"authors": ["Jan Chorowski", "Ron J. Weiss", "Rif A. Saurous", "Samy Bengio"], "title": ["On Using Backpropagation for Speech Texture Generation and Voice\n  Conversion"], "date": ["2017-12-22T09:19:23Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1712.08363v2"], "summary": ["  Inspired by recent work on neural network image generation which rely on\nbackpropagation towards the network inputs, we present a proof-of-concept\nsystem for speech texture synthesis and voice conversion based on two\nmechanisms: approximate inversion of the representation learned by a speech\nrecognition neural network, and on matching statistics of neuron activations\nbetween different source and target utterances. Similar to image texture\nsynthesis and neural style transfer, the system works by optimizing a cost\nfunction with respect to the input waveform samples. To this end we use a\ndifferentiable mel-filterbank feature extraction pipeline and train a\nconvolutional CTC speech recognition network. Our system is able to extract\nspeaker characteristics from very limited amounts of target speaker data, as\nlittle as a few seconds, and can be used to generate realistic speech babble or\nreconstruct an utterance in a different voice.\n"]},
{"authors": ["Felix Abramovich", "Vadim Grinshtein"], "title": ["High-dimensional classification by sparse logistic regression"], "date": ["2017-06-26T12:42:42Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1706.08344v2"], "summary": ["  We consider high-dimensional binary classification by sparse logistic\nregression. We propose a model/feature selection procedure based on penalized\nmaximum likelihood with a complexity penalty on the model size and derive the\nnon-asymptotic bounds for the resulting misclassification excess risk. The\nbounds can be reduced under the additional low-noise condition. The proposed\ncomplexity penalty is remarkably related to the VC-dimension of a set of sparse\nlinear classifiers. Implementation of any complexity penalty-based criterion,\nhowever, requires a combinatorial search over all possible models. To find a\nmodel selection procedure computationally feasible for high-dimensional data,\nwe extend the Slope estimator for logistic regression and show that under an\nadditional weighted restricted eigenvalue condition it is rate-optimal in the\nminimax sense.\n"]},
{"authors": ["Isabel Valera", "Melanie F. Pradier", "Maria Lomeli", "Zoubin Ghahramani"], "title": ["General Latent Feature Models for Heterogeneous Datasets"], "date": ["2017-06-12T18:00:03Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1706.03779v2"], "summary": ["  Latent feature modeling allows capturing the latent structure responsible for\ngenerating the observed properties of a set of objects. It is often used to\nmake predictions either for new values of interest or missing information in\nthe original data, as well as to perform data exploratory analysis. However,\nalthough there is an extensive literature on latent feature models for\nhomogeneous datasets, where all the attributes that describe each object are of\nthe same (continuous or discrete) nature, there is a lack of work on latent\nfeature modeling for heterogeneous databases. In this paper, we introduce a\ngeneral Bayesian nonparametric latent feature model suitable for heterogeneous\ndatasets, where the attributes describing each object can be either discrete,\ncontinuous or mixed variables. The proposed model presents several important\nproperties. First, it accounts for heterogeneous data while keeping the\nproperties of conjugate models, which allow us to infer the model in linear\ntime with respect to the number of objects and attributes. Second, its Bayesian\nnonparametric nature allows us to automatically infer the model complexity from\nthe data, i.e., the number of features necessary to capture the latent\nstructure in the data. Third, the latent features in the model are\nbinary-valued variables, easing the interpretability of the obtained latent\nfeatures in data exploratory analysis. We show the flexibility of the proposed\nmodel by solving both prediction and data analysis tasks on several real-world\ndatasets. Moreover, a software package of the GLFM is publicly available for\nother researcher to use and improve it.\n"]},
{"authors": ["Thanh Thi Nguyen"], "title": ["A Multi-Objective Deep Reinforcement Learning Framework"], "date": ["2018-03-08T04:50:21Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02965v1"], "summary": ["  This paper presents a new multi-objective deep reinforcement learning (MODRL)\nframework based on deep Q-networks. We propose linear and non-linear methods to\ndevelop the MODRL framework that includes both single-policy and multi-policy\nstrategies. The experimental results on a deep sea treasure environment\nindicate that the proposed approach is able to converge to the optimal Pareto\nsolutions. The proposed framework is generic, which allows implementation of\ndifferent deep reinforcement learning algorithms in various complex\nenvironments. Details of the framework implementation can be referred to\nhttp://www.deakin.edu.au/~thanhthi/drl.htm.\n"]},
{"authors": ["Ya Ju Fan"], "title": ["Autoencoder Node Saliency: Selecting Relevant Latent Representations"], "date": ["2017-11-21T16:17:14Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.07871v2"], "summary": ["  The autoencoder is an artificial neural network model that learns hidden\nrepresentations of unlabeled data. With a linear transfer function it is\nsimilar to the principal component analysis (PCA). While both methods use\nweight vectors for linear transformations, the autoencoder does not come with\nany indication similar to the eigenvalues in PCA that are paired with the\neigenvectors. We propose a novel supervised node saliency (SNS) method that\nranks the hidden nodes by comparing class distributions of latent\nrepresentations against a fixed reference distribution. The latent\nrepresentations of a hidden node can be described using a one-dimensional\nhistogram. We apply normalized entropy difference (NED) to measure the\n\"interestingness\" of the histograms, and conclude a property for NED values to\nidentify a good classifying node. By applying our methods to real data sets, we\ndemonstrate the ability of SNS to explain what the trained autoencoders have\nlearned.\n"]},
{"authors": ["C\u00e9sar A. Uribe", "Darina Dvinskikh", "Pavel Dvurechensky", "Alexander Gasnikov", "Angelia Nedi\u0107"], "title": ["Distributed Computation of Wasserstein Barycenters over Networks"], "date": ["2018-03-08T01:32:06Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02933v1"], "summary": ["  We propose a new class-optimal algorithm for the distributed computation of\nWasserstein Barycenters over networks. Assuming that each node in a graph has a\nprobability distribution, we prove that every node is able to reach the\nbarycenter of all distributions held in the network by using local interactions\ncompliant with the topology of the graph. We show the minimum number of\ncommunication rounds required for the proposed method to achieve arbitrary\nrelative precision both in the optimality of the solution and the consensus\namong all agents for undirected fixed networks.\n"]},
{"authors": ["Chengliang Yang", "Anand Rangarajan", "Sanjay Ranka"], "title": ["Visual Explanations From Deep 3D Convolutional Neural Networks for\n  Alzheimer's Disease Classification"], "date": ["2018-03-07T07:07:39Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02544v2"], "summary": ["  We develop three efficient approaches for generating visual explanations from\n3D convolutional neural networks (3D-CNNs) for Alzheimer's disease\nclassification. One approach conducts sensitivity analysis on hierarchical 3D\nimage segmentation, and the other two visualize network activations on a\nspatial map. Visual checks and a quantitative localization benchmark indicate\nthat all approaches identify important brain parts for Alzheimer's disease\ndiagnosis. Comparative analysis show that the sensitivity analysis based\napproach has difficulty handling loosely distributed cerebral cortex, and\napproaches based on visualization of activations are constrained by the\nresolution of the convolutional layer. The complementarity of these methods\nimproves the understanding of 3D-CNNs in Alzheimer's disease classification\nfrom different perspectives.\n"]},
{"authors": ["Jason Hartford", "Devon R Graham", "Kevin Leyton-Brown", "Siamak Ravanbakhsh"], "title": ["Deep Models of Interactions Across Sets"], "date": ["2018-03-07T21:18:25Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02879v1"], "summary": ["  We use deep learning to model interactions across two or more sets of\nobjects, such as user-movie ratings or protein-drug bindings. The canonical\nrepresentation of such interactions is a matrix (or tensor) with an\nexchangeability property: the encoding's meaning is not changed by permuting\nrows or columns. We argue that models should hence be Permutation Equivariant\n(PE): constrained to make the same predictions across such permutations. We\npresent a parameter-sharing scheme and prove that it could not be made any more\nexpressive without violating PE. This scheme yields three benefits. First, we\ndemonstrate performance competitive with the state of the art on multiple\nmatrix completion benchmarks. Second, our models require a number of parameters\nindependent of the numbers of objects, and thus scale well to large datasets.\nThird, models can be queried about new objects that were not available at\ntraining time, but for which interactions have since been observed. We observed\nsurprisingly good generalization performance on this matrix extrapolation task,\nboth within domains (e.g., new users and new movies drawn from the same\ndistribution used for training) and even across domains (e.g., predicting music\nratings after training on movie ratings).\n"]},
{"authors": ["Xiaoxia Wu", "Rachel Ward", "L\u00e9on Bottou"], "title": ["WNGrad: Learn the Learning Rate in Gradient Descent"], "date": ["2018-03-07T20:30:35Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02865v1"], "summary": ["  Adjusting the learning rate schedule in stochastic gradient methods is an\nimportant unresolved problem which requires tuning in practice. If certain\nparameters of the loss function such as smoothness or strong convexity\nconstants are known, theoretical learning rate schedules can be applied.\nHowever, in practice, such parameters are not known, and the loss function of\ninterest is not convex in any case. The recently proposed batch normalization\nreparametrization is widely adopted in most neural network architectures today\nbecause, among other advantages, it is robust to the choice of Lipschitz\nconstant of the gradient in loss function, allowing one to set a large learning\nrate without worry. Inspired by batch normalization, we propose a general\nnonlinear update rule for the learning rate in batch and stochastic gradient\ndescent so that the learning rate can be initialized at a high value, and is\nsubsequently decreased according to gradient observations along the way. The\nproposed method is shown to achieve robustness to the relationship between the\nlearning rate and the Lipschitz constant, and near-optimal convergence rates in\nboth the batch and stochastic settings ($O(1/T)$ for smooth loss in the batch\nsetting, and $O(1/\\sqrt{T})$ for convex loss in the stochastic setting). We\nalso show through numerical evidence that such robustness of the proposed\nmethod extends to highly nonconvex and possibly non-smooth loss function in\ndeep learning problems.Our analysis establishes some first theoretical\nunderstanding into the observed robustness for batch normalization and weight\nnormalization.\n"]},
{"authors": ["Brooks Paige", "Frank Wood"], "title": ["Inference Networks for Sequential Monte Carlo in Graphical Models"], "date": ["2016-02-22T09:39:09Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1602.06701v2"], "summary": ["  We introduce a new approach for amortizing inference in directed graphical\nmodels by learning heuristic approximations to stochastic inverses, designed\nspecifically for use as proposal distributions in sequential Monte Carlo\nmethods. We describe a procedure for constructing and learning a structured\nneural network which represents an inverse factorization of the graphical\nmodel, resulting in a conditional density estimator that takes as input\nparticular values of the observed random variables, and returns an\napproximation to the distribution of the latent variables. This recognition\nmodel can be learned offline, independent from any particular dataset, prior to\nperforming inference. The output of these networks can be used as\nautomatically-learned high-quality proposal distributions to accelerate\nsequential Monte Carlo across a diverse range of problem settings.\n"]},
{"authors": ["Sean A. Cantrell"], "title": ["The emergent algebraic structure of RNNs and embeddings in NLP"], "date": ["2018-03-07T19:06:08Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02839v1"], "summary": ["  We examine the algebraic and geometric properties of a uni-directional GRU\nand word embeddings trained end-to-end on a text classification task. A\nhyperparameter search over word embedding dimension, GRU hidden dimension, and\na linear combination of the GRU outputs is performed. We conclude that words\nnaturally embed themselves in a Lie group and that RNNs form a nonlinear\nrepresentation of the group. Appealing to these results, we propose a novel\nclass of recurrent-like neural networks and a word embedding scheme.\n"]},
{"authors": ["Ilias Diakonikolas", "Gautam Kamath", "Daniel M. Kane", "Jerry Li", "Jacob Steinhardt", "Alistair Stewart"], "title": ["Sever: A Robust Meta-Algorithm for Stochastic Optimization"], "date": ["2018-03-07T18:47:48Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02815v1"], "summary": ["  In high dimensions, most machine learning methods are brittle to even a small\nfraction of structured outliers. To address this, we introduce a new\nmeta-algorithm that can take in a base learner such as least squares or\nstochastic gradient descent, and harden the learner to be resistant to\noutliers. Our method, Sever, possesses strong theoretical guarantees yet is\nalso highly scalable -- beyond running the base learner itself, it only\nrequires computing the top singular vector of a certain $n \\times d$ matrix. We\napply Sever on a drug design dataset and a spam classification dataset, and\nfind that in both cases it has substantially greater robustness than several\nbaselines. On the spam dataset, with $1\\%$ corruptions, we achieved $7.4\\%$\ntest error, compared to $13.4\\%-20.5\\%$ for the baselines, and $3\\%$ error on\nthe uncorrupted dataset. Similarly, on the drug design dataset, with $10\\%$\ncorruptions, we achieved $1.42$ mean-squared error test error, compared to\n$1.51$-$2.33$ for the baselines, and $1.23$ error on the uncorrupted dataset.\n"]},
{"authors": ["Marwa El Halabi", "Francis Bach", "Volkan Cevher"], "title": ["Combinatorial Penalties: Which structures are preserved by convex\n  relaxations?"], "date": ["2017-10-17T13:41:21Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.06273v2"], "summary": ["  We consider the homogeneous and the non-homogeneous convex relaxations for\ncombinatorial penalty functions defined on support sets. Our study identifies\nkey differences in the tightness of the resulting relaxations through the\nnotion of the lower combinatorial envelope of a set-function along with new\nnecessary conditions for support identification. We then propose a general\nadaptive estimator for convex monotone regularizers, and derive new sufficient\nconditions for support recovery in the asymptotic setting.\n"]},
{"authors": ["Kajsa M\u00f8llersen", "Jon Yngve Hardeberg", "Fred Godtliebsen"], "title": ["A bag-to-class divergence approach to multiple-instance learning"], "date": ["2018-03-07T17:33:29Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02782v1"], "summary": ["  In multi-instance (MI) learning, each object (bag) consists of multiple\nfeature vectors (instances), and is most commonly regarded as a set of points\nin a multidimensional space. A different viewpoint is that the instances are\nrealisations of random vectors with corresponding probability distribution, and\nthat a bag is the distribution, not the realisations. In MI classification,\neach bag in the training set has a class label, but the instances are\nunlabelled. By introducing the probability distribution space to bag-level\nclassification problems, dissimilarities between probability distributions\n(divergences) can be applied. The bag-to-bag Kullback-Leibler information is\nasymptotically the best classifier, but the typical sparseness of MI training\nsets is an obstacle. We introduce bag-to-class divergence to MI learning,\nemphasising the hierarchical nature of the random vectors that makes bags from\nthe same class different. We propose two properties for bag-to-class\ndivergences, and an additional property for sparse training sets.\n"]},
{"authors": ["Vaibhav Sinha", "Sukrut Rao", "Vineeth N Balasubramanian"], "title": ["Fast Dawid-Skene"], "date": ["2018-03-07T17:31:20Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02781v1"], "summary": ["  Many real world problems can now be effectively solved using supervised\nmachine learning. A major roadblock is often the lack of an adequate quantity\nof labeled data for training. A possible solution is to assign the task of\nlabeling data to a crowd, and then infer the true label using aggregation\nmethods. A well-known approach for aggregation is the Dawid-Skene (DS)\nalgorithm, which is based on the principle of Expectation-Maximization (EM). We\npropose a new simple, yet effective, EM-based algorithm, which can be\ninterpreted as a 'hard' version of DS, that allows much faster convergence\nwhile maintaining similar accuracy in aggregation. We also show how the\nproposed method can be extended to settings when there are multiple labels as\nwell as for online vote aggregation. Our experiments on standard vote\naggregation datasets show a significant speedup in time taken for convergence -\nupto $\\sim$8x over Dawid-Skene and $\\sim$6x over other fast EM methods, at\ncompetitive accuracy performance.\n"]},
{"authors": ["HaiYing Wang", "Rong Zhu", "Ping Ma"], "title": ["Optimal Subsampling for Large Sample Logistic Regression"], "date": ["2017-02-03T21:23:46Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1702.01166v2"], "summary": ["  For massive data, the family of subsampling algorithms is popular to downsize\nthe data volume and reduce computational burden. Existing studies focus on\napproximating the ordinary least squares estimate in linear regression, where\nstatistical leverage scores are often used to define subsampling probabilities.\nIn this paper, we propose fast subsampling algorithms to efficiently\napproximate the maximum likelihood estimate in logistic regression. We first\nestablish consistency and asymptotic normality of the estimator from a general\nsubsampling algorithm, and then derive optimal subsampling probabilities that\nminimize the asymptotic mean squared error of the resultant estimator. An\nalternative minimization criterion is also proposed to further reduce the\ncomputational cost. The optimal subsampling probabilities depend on the full\ndata estimate, so we develop a two-step algorithm to approximate the optimal\nsubsampling procedure. This algorithm is computationally efficient and has a\nsignificant reduction in computing time compared to the full data approach.\nConsistency and asymptotic normality of the estimator from a two-step algorithm\nare also established. Synthetic and real data sets are used to evaluate the\npractical performance of the proposed method.\n"]},
{"authors": ["Lukas Bruder", "Phaedon-Stelios Koutsourelakis"], "title": ["Beyond black-boxes in Bayesian inverse problems and model validation:\n  applications in solid mechanics of elastography"], "date": ["2018-03-02T16:15:11Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.00930v3"], "summary": ["  The present paper is motivated by one of the most fundamental challenges in\ninverse problems, that of quantifying model discrepancies and errors. While\nsignificant strides have been made in calibrating model parameters, the\noverwhelming majority of pertinent methods is based on the assumption of a\nperfect model. Motivated by problems in solid mechanics which, as all problems\nin continuum thermodynamics, are described by conservation laws and\nphenomenological constitutive closures, we argue that in order to quantify\nmodel uncertainty in a physically meaningful manner, one should break open the\nblack-box forward model. In particular we propose formulating an undirected\nprobabilistic model that explicitly accounts for the governing equations and\ntheir validity. This recasts the solution of both forward and inverse problems\nas probabilistic inference tasks where the problem's state variables should not\nonly be compatible with the data but also with the governing equations as well.\nEven though the probability densities involved do not contain any black-box\nterms, they live in much higher-dimensional spaces. In combination with the\nintractability of the normalization constant of the undirected model employed,\nthis poses significant challenges which we propose to address with a\nlinearly-scaling, double-layer of Stochastic Variational Inference. We\ndemonstrate the capabilities and efficacy of the proposed model in synthetic\nforward and inverse problems (with and without model error) in elastography.\n"]},
{"authors": ["Tatsuro Kawamoto"], "title": ["Algorithmic detectability threshold of the stochastic block model"], "date": ["2017-10-24T15:18:13Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.08841v2"], "summary": ["  The assumption that the values of model parameters are known or correctly\nlearned, i.e., the Nishimori condition, is one of the requirements for the\ndetectability analysis of the stochastic block model in statistical inference.\nIn practice, however, there is no example demonstrating that we can know the\nmodel parameters beforehand, and there is no guarantee that the model\nparameters can be learned accurately. In this study, we consider the\nexpectation--maximization (EM) algorithm with belief propagation (BP) and\nderive its algorithmic detectability threshold. Our analysis is not restricted\nto the community structure, but includes general modular structures. Because\nthe algorithm cannot always learn the planted model parameters correctly, the\nalgorithmic detectability threshold is qualitatively different from the one\nwith the Nishimori condition.\n"]},
{"authors": ["Natalie Stanley", "Thomas Bonacci", "Roland Kwitt", "Marc Niethammer", "Peter J. Mucha"], "title": ["Stochastic Block Models with Multiple Continuous Attributes"], "date": ["2018-03-07T15:50:09Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02726v1"], "summary": ["  The stochastic block model (SBM) is a probabilistic model for community\nstructure in networks. Typically, only the adjacency matrix is used to perform\nSBM parameter inference. In this paper, we consider circumstances in which\nnodes have an associated vector of continuous attributes that are also used to\nlearn the node-to-community assignments and corresponding SBM parameters. While\nthis assumption is not realistic for every application, our model assumes that\nthe attributes associated with the nodes in a network's community can be\ndescribed by a common multivariate Gaussian model. In this augmented,\nattributed SBM, the objective is to simultaneously learn the SBM connectivity\nprobabilities with the multivariate Gaussian parameters describing each\ncommunity. While there are recent examples in the literature that combine\nconnectivity and attribute information to inform community detection, our model\nis the first augmented stochastic block model to handle multiple continuous\nattributes. This provides the flexibility in biological data to, for example,\naugment connectivity information with continuous measurements from multiple\nexperimental modalities. Because the lack of labeled network data often makes\ncommunity detection results difficult to validate, we highlight the usefulness\nof our model for two network prediction tasks: link prediction and\ncollaborative filtering. As a result of fitting this attributed stochastic\nblock model, one can predict the attribute vector or connectivity patterns for\na new node in the event of the complementary source of information\n(connectivity or attributes, respectively). We also highlight two biological\nexamples where the attributed stochastic block model provides satisfactory\nperformance in the link prediction and collaborative filtering tasks.\n"]},
{"authors": ["Tsendsuren Munkhdalai", "Xingdi Yuan", "Soroush Mehri", "Adam Trischler"], "title": ["Rapid Adaptation with Conditionally Shifted Neurons"], "date": ["2017-12-28T16:47:13Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1712.09926v2"], "summary": ["  We describe a mechanism by which artificial neural networks can learn rapid\nadaptation - the ability to adapt on the fly, with little data, to new tasks -\nthat we call conditionally shifted neurons. We apply this mechanism in the\nframework of metalearning, where the aim is to replicate some of the\nflexibility of human learning in machines. Conditionally shifted neurons modify\ntheir activation values with task-specific shifts retrieved from a memory\nmodule, which is populated rapidly based on limited task experience. On\nmetalearning benchmarks from the vision and language domains, models augmented\nwith conditionally shifted neurons achieve state-of-the-art results.\n"]},
{"authors": ["Xiaoyue Xi", "Fran\u00e7ois-Xavier Briol", "Mark Girolami"], "title": ["Bayesian Quadrature for Multiple Related Integrals"], "date": ["2018-01-12T12:49:32Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1801.04153v4"], "summary": ["  Bayesian probabilistic numerical methods are a set of tools providing\nposterior distributions on the output of numerical methods. The use of these\nmethods is usually motivated by the fact that they can represent our\nuncertainty due to incomplete/finite information about the continuous\nmathematical problem being approximated. In this paper, we demonstrate that\nthis paradigm can provide additional advantages, such as the possibility of\ntransferring information between several numerical methods. This allows users\nto represent uncertainty in a more faithful manner and, as a by-product,\nprovide increased numerical efficiency. We propose the first such numerical\nmethod by extending the well-known Bayesian quadrature algorithm to the case\nwhere we are interested in computing the integral of several related functions.\nWe then prove convergence rates for the method in the well-specified and\nmisspecified cases, and demonstrate its efficiency in the context of\nmulti-fidelity models for complex engineering systems and a problem of global\nillumination in computer graphics.\n"]},
{"authors": ["Ming-Yen Wu", "Chi-Hua Chen", "Chi-Chun Lo"], "title": ["An Exercise Fatigue Detection Model Based on Machine Learning Methods"], "date": ["2018-03-07T13:23:42Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.07952v1"], "summary": ["  This study proposes an exercise fatigue detection model based on real-time\nclinical data which includes time domain analysis, frequency domain analysis,\ndetrended fluctuation analysis, approximate entropy, and sample entropy.\nFurthermore, this study proposed a feature extraction method which is combined\nwith an analytical hierarchy process to analyze and extract critical features.\nFinally, machine learning algorithms were adopted to analyze the data of each\nfeature for the detection of exercise fatigue. The practical experimental\nresults showed that the proposed exercise fatigue detection model and feature\nextraction method could precisely detect the level of exercise fatigue, and the\naccuracy of exercise fatigue detection could be improved up to 98.65%.\n"]},
{"authors": ["Francesco Locatello", "Rajiv Khanna", "Joydeep Ghosh", "Gunnar R\u00e4tsch"], "title": ["Boosting Variational Inference: an Optimization Perspective"], "date": ["2017-08-05T08:42:11Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1708.01733v2"], "summary": ["  Variational inference is a popular technique to approximate a possibly\nintractable Bayesian posterior with a more tractable one. Recently, boosting\nvariational inference has been proposed as a new paradigm to approximate the\nposterior by a mixture of densities by greedily adding components to the\nmixture. However, as is the case with many other variational inference\nalgorithms, its theoretical properties have not been studied. In the present\nwork, we study the convergence properties of this approach from a modern\noptimization viewpoint by establishing connections to the classic Frank-Wolfe\nalgorithm. Our analyses yields novel theoretical insights regarding the\nsufficient conditions for convergence, explicit rates, and algorithmic\nsimplifications. Since a lot of focus in previous works for variational\ninference has been on tractability, our work is especially important as a much\nneeded attempt to bridge the gap between probabilistic models and their\ncorresponding theoretical properties.\n"]},
{"authors": ["Ieva Kazlauskaite", "Carl Henrik Ek", "Neill D. F. Campbell"], "title": ["Gaussian Process Latent Variable Alignment Learning"], "date": ["2018-03-07T11:30:05Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02603v1"], "summary": ["  We present a model that can automatically learn alignments between\nhigh-dimensional data in an unsupervised manner. Learning alignments is an\nill-constrained problem as there are many different ways of defining a good\nalignment. Our proposed method casts alignment learning in a framework where\nboth alignment and data are modelled simultaneously. We derive a probabilistic\nmodel built on non-parametric priors that allows for flexible warps while at\nthe same time providing means to specify interpretable constraints. We show\nresults on several datasets, including different motion capture sequences and\nshow that the suggested model outperform the classical algorithmic approaches\nto the alignment task.\n"]},
{"authors": ["Adrien Wohrer"], "title": ["The Ising distribution as a latent variable model"], "date": ["2018-03-07T11:20:29Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02598v1"], "summary": ["  We show that the Ising distribution can be treated as a latent variable\nmodel, where a set of N real-valued, correlated random variables are drawn and\nused to generate N binary spins independently. This allows to approximate the\nIsing distribution by a simpler model where the latent variables follow a\nmultivariate normal distribution. The resulting approximation bears\nsimilarities with the Thouless Anderson Palmer (TAP) solution from mean field\ntheory, but retains a broader range of applicability when the coupling weights\nare not independently distributed. Moreover, unlike classic mean field\napproaches, the approximation can be used to generate correlated spin patterns.\n"]},
{"authors": ["Yu-Xiang Wang"], "title": ["Revisiting differentially private linear regression: optimal and\n  adaptive prediction & estimation in unbounded domain"], "date": ["2018-03-07T11:03:36Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02596v1"], "summary": ["  We revisit the problem of linear regression under a differential privacy\nconstraint. By consolidating existing pieces in the literature, we clarify the\ncorrect dependence of the feature, label and coefficient domain in the\noptimization error and estimation error, hence revealing the delicate price of\ndifferential privacy in statistical estimation and statistical learning.\nMoreover, we propose simple modifications of two existing DP algorithms: (a)\nposterior sampling, (b) sufficient statistics perturbation, and show that they\ncan be upgraded into **adaptive** algorithms that are able to exploit\ndata-dependent quantities and behave nearly optimally for every instance.\nExtensive experiments are conducted on both simulated data and real data, which\nconclude that both AdaOPS and AdaSSP outperform the existing techniques on\nnearly all 36 data sets that we test on.\n"]},
{"authors": ["Marco Ancona", "Enea Ceolini", "Cengiz \u00d6ztireli", "Markus Gross"], "title": ["Towards better understanding of gradient-based attribution methods for\n  Deep Neural Networks"], "date": ["2017-11-16T14:19:29Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.06104v4"], "summary": ["  Understanding the flow of information in Deep Neural Networks (DNNs) is a\nchallenging problem that has gain increasing attention over the last few years.\nWhile several methods have been proposed to explain network predictions, there\nhave been only a few attempts to compare them from a theoretical perspective.\nWhat is more, no exhaustive empirical comparison has been performed in the\npast. In this work, we analyze four gradient-based attribution methods and\nformally prove conditions of equivalence and approximation between them. By\nreformulating two of these methods, we construct a unified framework which\nenables a direct comparison, as well as an easier implementation. Finally, we\npropose a novel evaluation metric, called Sensitivity-n and test the\ngradient-based attribution methods alongside with a simple perturbation-based\nattribution method on several datasets in the domains of image and text\nclassification, using various network architectures.\n"]},
{"authors": ["Ivan Glasser", "Nicola Pancotti", "Moritz August", "Ivan D. Rodriguez", "J. Ignacio Cirac"], "title": ["Neural-Network Quantum States, String-Bond States, and Chiral\n  Topological States"], "date": ["2017-10-11T13:03:19Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1710.04045v3"], "summary": ["  Neural-Network Quantum States have been recently introduced as an Ansatz for\ndescribing the wave function of quantum many-body systems. We show that there\nare strong connections between Neural-Network Quantum States in the form of\nRestricted Boltzmann Machines and some classes of Tensor-Network states in\narbitrary dimensions. In particular we demonstrate that short-range Restricted\nBoltzmann Machines are Entangled Plaquette States, while fully connected\nRestricted Boltzmann Machines are String-Bond States with a nonlocal geometry\nand low bond dimension. These results shed light on the underlying architecture\nof Restricted Boltzmann Machines and their efficiency at representing many-body\nquantum states. String-Bond States also provide a generic way of enhancing the\npower of Neural-Network Quantum States and a natural generalization to systems\nwith larger local Hilbert space. We compare the advantages and drawbacks of\nthese different classes of states and present a method to combine them\ntogether. This allows us to benefit from both the entanglement structure of\nTensor Networks and the efficiency of Neural-Network Quantum States into a\nsingle Ansatz capable of targeting the wave function of strongly correlated\nsystems. While it remains a challenge to describe states with chiral\ntopological order using traditional Tensor Networks, we show that\nNeural-Network Quantum States and their String-Bond States extension can\ndescribe a lattice Fractional Quantum Hall state exactly. In addition, we\nprovide numerical evidence that Neural-Network Quantum States can approximate a\nchiral spin liquid with better accuracy than Entangled Plaquette States and\nlocal String-Bond States. Our results demonstrate the efficiency of neural\nnetworks to describe complex quantum wave functions and pave the way towards\nthe use of String-Bond States as a tool in more traditional machine-learning\napplications.\n"]},
{"authors": ["Zhanxing Zhu", "Jingfeng Wu", "Bing Yu", "Lei Wu", "Jinwen Ma"], "title": ["The Regularization Effects of Anisotropic Noise in Stochastic Gradient\n  Descent"], "date": ["2018-03-01T03:46:36Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.00195v3"], "summary": ["  Understanding the generalization of deep learning has raised lots of concerns\nrecently, where the learning algorithms play an important role in\ngeneralization performance, such as stochastic gradient descent (SGD). Along\nthis line, we particularly study the anisotropic noise introduced by SGD, and\ninvestigate its importance for the generalization in deep neural networks.\nThrough a thorough empirical analysis, it is shown that the anisotropic\ndiffusion of SGD tends to follow the curvature information of the loss\nlandscape, and thus is beneficial for escaping from sharp and poor minima\neffectively, towards more stable and flat minima. We verify our understanding\nthrough comparing this anisotropic diffusion with full gradient descent plus\nisotropic diffusion (i.e. Langevin dynamics) and other types of\nposition-dependent noise.\n"]},
{"authors": ["Hilmi E. Egilmez", "Eduardo Pavez", "Antonio Ortega"], "title": ["Graph Learning from Filtered Signals: Graph System and Diffusion Kernel\n  Identification"], "date": ["2018-03-07T07:37:44Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02553v1"], "summary": ["  This paper introduces a novel graph signal processing framework for building\ngraph-based models from classes of filtered signals. In our framework,\ngraph-based modeling is formulated as a graph system identification problem,\nwhere the goal is to learn a weighted graph (a graph Laplacian matrix) and a\ngraph-based filter (a function of graph Laplacian matrices). In order to solve\nthe proposed problem, an algorithm is developed to jointly identify a graph and\na graph-based filter (GBF) from multiple signal/data observations. Our\nalgorithm is valid under the assumption that GBFs are one-to-one functions. The\nproposed approach can be applied to learn diffusion (heat) kernels, which are\npopular in various fields for modeling diffusion processes. In addition, for\nspecific choices of graph-based filters, the proposed problem reduces to a\ngraph Laplacian estimation problem. Our experimental results demonstrate that\nthe proposed algorithm outperforms the current state-of-the-art methods. We\nalso implement our framework on a real climate dataset for modeling of\ntemperature signals.\n"]},
{"authors": ["Wei-Ning Hsu", "James Glass"], "title": ["Extracting Domain Invariant Features by Unsupervised Learning for Robust\n  Automatic Speech Recognition"], "date": ["2018-03-07T07:30:36Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02551v1"], "summary": ["  The performance of automatic speech recognition (ASR) systems can be\nsignificantly compromised by previously unseen conditions, which is typically\ndue to a mismatch between training and testing distributions. In this paper, we\naddress robustness by studying domain invariant features, such that domain\ninformation becomes transparent to ASR systems, resolving the mismatch problem.\nSpecifically, we investigate a recent model, called the Factorized Hierarchical\nVariational Autoencoder (FHVAE). FHVAEs learn to factorize sequence-level and\nsegment-level attributes into different latent variables without supervision.\nWe argue that the set of latent variables that contain segment-level\ninformation is our desired domain invariant feature for ASR. Experiments are\nconducted on Aurora-4 and CHiME-4, which demonstrate 41% and 27% absolute word\nerror rate reductions respectively on mismatched domains.\n"]},
{"authors": ["Ehsan Hajiramezanali", "Siamak Zamani Dadaneh", "Paul de Figueiredo", "Sing-Hoi Sze", "Mingyuan Zhou", "Xiaoning Qian"], "title": ["Differential Expression Analysis of Dynamical Sequencing Count Data with\n  a Gamma Markov Chain"], "date": ["2018-03-07T05:31:55Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02527v1"], "summary": ["  Next-generation sequencing (NGS) to profile temporal changes in living\nsystems is gaining more attention for deriving better insights into the\nunderlying biological mechanisms compared to traditional static sequencing\nexperiments. Nonetheless, the majority of existing statistical tools for\nanalyzing NGS data lack the capability of exploiting the richer information\nembedded in temporal data. Several recent tools have been developed to analyze\nsuch data but they typically impose strict model assumptions, such as\nsmoothness on gene expression dynamic changes. To capture a broader range of\ngene expression dynamic patterns, we develop the gamma Markov negative binomial\n(GMNB) model that integrates a gamma Markov chain into a negative binomial\ndistribution model, allowing flexible temporal variation in NGS count data.\nUsing Bayes factors, GMNB enables more powerful temporal gene differential\nexpression analysis across different phenotypes or treatment conditions. In\naddition, it naturally handles the heterogeneity of sequencing depth in\ndifferent samples, removing the need for ad-hoc normalization. Efficient Gibbs\nsampling inference of the GMNB model parameters is achieved by exploiting novel\ndata augmentation techniques. Extensive experiments on both simulated and\nreal-world RNA-seq data show that GMNB outperforms existing methods in both\nreceiver operating characteristic (ROC) and precision-recall (PR) curves of\ndifferential expression analysis results.\n"]},
{"authors": ["Jonathan Jonker", "Aleksandr Y. Aravkin", "James V. Burke", "Gianluigi Pillonetto", "Sarah Webster"], "title": ["Fast Robust Methods for Singular State-Space Models"], "date": ["2018-03-07T05:10:26Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02525v1"], "summary": ["  State-space models are used in a wide range of time series analysis\nformulations. Kalman filtering and smoothing are work-horse algorithms in these\nsettings. While classic algorithms assume Gaussian errors to simplify\nestimation, recent advances use a broader range of optimization formulations to\nallow outlier-robust estimation, as well as constraints to capture prior\ninformation.\n  Here we develop methods on state-space models where either innovations or\nerror covariances may be singular. These models frequently arise in navigation\n(e.g. for `colored noise' models or deterministic integrals) and are ubiquitous\nin auto-correlated time series models such as ARMA. We reformulate all\nstate-space models (singular as well as nonsinguar) as constrained convex\noptimization problems, and develop an efficient algorithm for this\nreformulation. The convergence rate is {\\it locally linear}, with constants\nthat do not depend on the conditioning of the problem.\n  Numerical comparisons show that the new approach outperforms competing\napproaches for {\\it nonsingular} models, including state of the art interior\npoint (IP) methods. IP methods converge at superlinear rates; we expect them to\ndominate. However, the steep rate of the proposed approach (independent of\nproblem conditioning) combined with cheap iterations wins against IP in a\nrun-time comparison. We therefore suggest that the proposed approach be the\n{\\it default choice} for estimating state space models outside of the Gaussian\ncontext, regardless of whether the error covariances are singular or not.\n"]},
{"authors": ["Elizabeth Hou", "Alfred O. Hero"], "title": ["Sequential Maximum Margin Classifiers for Partially Labeled Data"], "date": ["2018-03-07T03:55:18Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02517v1"], "summary": ["  In many real-world applications, data is not collected as one batch, but\nsequentially over time, and often it is not possible or desirable to wait until\nthe data is completely gathered before analyzing it. Thus, we propose a\nframework to sequentially update a maximum margin classifier by taking\nadvantage of the Maximum Entropy Discrimination principle. Our maximum margin\nclassifier allows for a kernel representation to represent large numbers of\nfeatures and can also be regularized with respect to a smooth sub-manifold,\nallowing it to incorporate unlabeled observations. We compare the performance\nof our classifier to its non-sequential equivalents in both simulated and real\ndatasets.\n"]},
{"authors": ["Tse-Yu Lin", "Yen-Lung Tsai"], "title": ["An Application of HodgeRank to Online Peer Assessment"], "date": ["2018-03-07T02:53:54Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02509v1"], "summary": ["  Bias and heterogeneity in peer assessment can lead to the issue of unfair\nscoring in the educational field. To deal with this problem, we propose a\nreference ranking method for an online peer assessment system using HodgeRank.\nSuch a scheme provides instructors with an objective scoring reference based on\nmathematics.\n"]},
{"authors": ["Bowen Wu", "Zhangling Chen", "Jun Wang", "Huaming Wu"], "title": ["Exponential Discriminative Metric Embedding in Deep Learning"], "date": ["2018-03-07T02:39:34Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02504v1"], "summary": ["  With the remarkable success achieved by the Convolutional Neural Networks\n(CNNs) in object recognition recently, deep learning is being widely used in\nthe computer vision community. Deep Metric Learning (DML), integrating deep\nlearning with conventional metric learning, has set new records in many fields,\nespecially in classification task. In this paper, we propose a replicable DML\nmethod, called Include and Exclude (IE) loss, to force the distance between a\nsample and its designated class center away from the mean distance of this\nsample to other class centers with a large margin in the exponential feature\nprojection space. With the supervision of IE loss, we can train CNNs to enhance\nthe intra-class compactness and inter-class separability, leading to great\nimprovements on several public datasets ranging from object recognition to face\nverification. We conduct a comparative study of our algorithm with several\ntypical DML methods on three kinds of networks with different capacity.\nExtensive experiments on three object recognition datasets and two face\nrecognition datasets demonstrate that IE loss is always superior to other\nmainstream DML methods and approach the state-of-the-art results.\n"]},
{"authors": ["Alexandr A. Kalinin", "Gerald A. Higgins", "Narathip Reamaroon", "S. M. Reza Soroushmehr", "Ari Allyn-Feuer", "Ivo D. Dinov", "Kayvan Najarian", "Brian D. Athey"], "title": ["Deep Learning in Pharmacogenomics: From Gene Regulation to Patient\n  Stratification"], "date": ["2018-01-25T19:21:15Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1801.08570v2"], "summary": ["  This Perspective provides examples of current and future applications of deep\nlearning in pharmacogenomics, including: (1) identification of novel regulatory\nvariants located in noncoding domains and their function as applied to\npharmacoepigenomics; (2) patient stratification from medical records; and (3)\nprediction of drugs, targets, and their interactions. Deep learning\nencapsulates a family of machine learning algorithms that over the last decade\nhas transformed many important subfields of artificial intelligence (AI) and\nhas demonstrated breakthrough performance improvements on a wide range of tasks\nin biomedicine. We anticipate that in the future deep learning will be widely\nused to predict personalized drug response and optimize medication selection\nand dosing, using knowledge extracted from large and complex molecular,\nepidemiological, clinical, and demographic datasets.\n"]},
{"authors": ["Daniel Ting", "Michael I. Jordan"], "title": ["On Nonlinear Dimensionality Reduction, Linear Smoothing and Autoencoding"], "date": ["2018-03-06T21:35:16Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02432v1"], "summary": ["  We develop theory for nonlinear dimensionality reduction (NLDR). A number of\nNLDR methods have been developed, but there is limited understanding of how\nthese methods work and the relationships between them. There is limited basis\nfor using existing NLDR theory for deriving new algorithms. We provide a novel\nframework for analysis of NLDR via a connection to the statistical theory of\nlinear smoothers. This allows us to both understand existing methods and derive\nnew ones. We use this connection to smoothing to show that asymptotically,\nexisting NLDR methods correspond to discrete approximations of the solutions of\nsets of differential equations given a boundary condition. In particular, we\ncan characterize many existing methods in terms of just three limiting\ndifferential operators and boundary conditions. Our theory also provides a way\nto assert that one method is preferable to another; indeed, we show Local\nTangent Space Alignment is superior within a class of methods that assume a\nglobal coordinate chart defines an isometric embedding of the manifold.\n"]},
{"authors": ["Daniel L. Sussman", "Vince Lyzinski", "Youngser Park", "Carey E. Priebe"], "title": ["Matched Filters for Noisy Induced Subgraph Detection"], "date": ["2018-03-06T20:55:17Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02423v1"], "summary": ["  We consider the problem of finding the vertex correspondence between two\ngraphs with different number of vertices where the smaller graph is still\npotentially large. We propose a solution to this problem via a graph matching\nmatched filter: padding the smaller graph in different ways and then using\ngraph matching methods to align it to the larger network. Under a statistical\nmodel for correlated pairs of graphs, which yields a noisy copy of the small\ngraph within the larger graph, the resulting optimization problem can be\nguaranteed to recover the true vertex correspondence between the networks,\nthough there are currently no efficient algorithms for solving this problem. We\nconsider an approach that exploits a partially known correspondence and show\nvia varied simulations and applications to the Drosophila connectome that in\npractice this approach can achieve good performance.\n"]},
{"authors": ["Fady Medhat", "David Chesmore", "John Robinson"], "title": ["Masked Conditional Neural Networks for Audio Classification"], "date": ["2018-03-06T20:54:00Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02421v1"], "summary": ["  We present the ConditionaL Neural Network (CLNN) and the Masked ConditionaL\nNeural Network (MCLNN) designed for temporal signal recognition. The CLNN takes\ninto consideration the temporal nature of the sound signal and the MCLNN\nextends upon the CLNN through a binary mask to preserve the spatial locality of\nthe features and allows an automated exploration of the features combination\nanalogous to hand-crafting the most relevant features for the recognition task.\nMCLNN has achieved competitive recognition accuracies on the GTZAN and the\nISMIR2004 music datasets that surpass several state-of-the-art neural network\nbased architectures and hand-crafted methods applied on both datasets.\n"]},
{"authors": ["Mijung Park", "James Foulds", "Kamalika Chaudhuri", "Max Welling"], "title": ["Variational Bayes In Private Settings (VIPS)"], "date": ["2016-11-01T19:19:49Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1611.00340v4"], "summary": ["  Many applications of Bayesian data analysis involve sensitive information,\nmotivating methods which ensure that privacy is protected. We introduce a\ngeneral privacy-preserving framework for Variational Bayes (VB), a widely used\noptimization-based Bayesian inference method. Our framework respects\ndifferential privacy, the gold-standard privacy criterion, and encompasses a\nlarge class of probabilistic models, called the Conjugate Exponential (CE)\nfamily. We observe that we can straightforwardly privatise VB's approximate\nposterior distributions for models in the CE family, by perturbing the expected\nsufficient statistics of the complete-data likelihood. For a broadly-used class\nof non-CE models, those with binomial likelihoods, we show how to bring such\nmodels into the CE family, such that inferences in the modified model resemble\nthe private variational Bayes algorithm as closely as possible, using the\nPolya-Gamma data augmentation scheme. The iterative nature of variational Bayes\npresents a further challenge since iterations increase the amount of noise\nneeded. We overcome this by combining: (1) an improved composition method for\ndifferential privacy, called the moments accountant, which provides a tight\nbound on the privacy cost of multiple VB iterations and thus significantly\ndecreases the amount of additive noise; and (2) the privacy amplification\neffect of subsampling mini-batches from large-scale data in stochastic\nlearning. We empirically demonstrate the effectiveness of our method in CE and\nnon-CE models including latent Dirichlet allocation, Bayesian logistic\nregression, and sigmoid belief networks, evaluated on real-world datasets.\n"]},
{"authors": ["Joshua Hochuli", "Alec Helbling", "Tamar Skaist", "Matthew Ragoza", "David Ryan Koes"], "title": ["Visualizing Convolutional Neural Network Protein-Ligand Scoring"], "date": ["2018-03-06T19:40:51Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02398v1"], "summary": ["  Protein-ligand scoring is an important step in a structure-based drug design\npipeline. Selecting a correct binding pose and predicting the binding affinity\nof a protein-ligand complex enables effective virtual screening. Machine\nlearning techniques can make use of the increasing amounts of structural data\nthat are becoming publicly available. Convolutional neural network (CNN)\nscoring functions in particular have shown promise in pose selection and\naffinity prediction for protein-ligand complexes. Neural networks are known for\nbeing difficult to interpret. Understanding the decisions of a particular\nnetwork can help tune parameters and training data to maximize performance.\nVisualization of neural networks helps decompose complex scoring functions into\npictures that are more easily parsed by humans. Here we present three methods\nfor visualizing how individual protein-ligand complexes are interpreted by 3D\nconvolutional neural networks. We also present a visualization of the\nconvolutional filters and their weights. We describe how the intuition provided\nby these visualizations aids in network design.\n"]},
{"authors": ["Milad Hashemi", "Kevin Swersky", "Jamie A. Smith", "Grant Ayers", "Heiner Litz", "Jichuan Chang", "Christos Kozyrakis", "Parthasarathy Ranganathan"], "title": ["Learning Memory Access Patterns"], "date": ["2018-03-06T18:41:04Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02329v1"], "summary": ["  The explosion in workload complexity and the recent slow-down in Moore's law\nscaling call for new approaches towards efficient computing. Researchers are\nnow beginning to use recent advances in machine learning in software\noptimizations, augmenting or replacing traditional heuristics and data\nstructures. However, the space of machine learning for computer hardware\narchitecture is only lightly explored. In this paper, we demonstrate the\npotential of deep learning to address the von Neumann bottleneck of memory\nperformance. We focus on the critical problem of learning memory access\npatterns, with the goal of constructing accurate and efficient memory\nprefetchers. We relate contemporary prefetching strategies to n-gram models in\nnatural language processing, and show how recurrent neural networks can serve\nas a drop-in replacement. On a suite of challenging benchmark datasets, we find\nthat neural networks consistently demonstrate superior performance in terms of\nprecision and recall. This work represents the first step towards practical\nneural-network based prefetching, and opens a wide range of exciting directions\nfor machine learning in computer architecture research.\n"]},
{"authors": ["Steven Young", "Tamer Abdou", "Ayse Bener"], "title": ["Deep Super Learner: A Deep Ensemble for Classification Problems"], "date": ["2018-03-06T18:19:55Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02323v1"], "summary": ["  Deep learning has become very popular for tasks such as predictive modeling\nand pattern recognition in handling big data. Deep learning is a powerful\nmachine learning method that extracts lower level features and feeds them\nforward for the next layer to identify higher level features that improve\nperformance. However, deep neural networks have drawbacks, which include many\nhyper-parameters and infinite architectures, opaqueness into results, and\nrelatively slower convergence on smaller datasets. While traditional machine\nlearning algorithms can address these drawbacks, they are not typically capable\nof the performance levels achieved by deep neural networks. To improve\nperformance, ensemble methods are used to combine multiple base learners. Super\nlearning is an ensemble that finds the optimal combination of diverse learning\nalgorithms. This paper proposes deep super learning as an approach which\nachieves log loss and accuracy results competitive to deep neural networks\nwhile employing traditional machine learning algorithms in a hierarchical\nstructure. The deep super learner is flexible, adaptable, and easy to train\nwith good performance across different tasks using identical hyper-parameter\nvalues. Using traditional machine learning requires fewer hyper-parameters,\nallows transparency into results, and has relatively fast convergence on\nsmaller datasets. Experimental results show that the deep super learner has\nsuperior performance compared to the individual base learners, single-layer\nensembles, and in some cases deep neural networks. Performance of the deep\nsuper learner may further be improved with task-specific tuning.\n"]},
{"authors": ["Xiao-Lei Zhang"], "title": ["Multilayer bootstrap networks"], "date": ["2014-08-05T02:13:50Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1408.0848v8"], "summary": ["  Multilayer bootstrap network builds a gradually narrowed multilayer nonlinear\nnetwork from bottom up for unsupervised nonlinear dimensionality reduction.\nEach layer of the network is a nonparametric density estimator. It consists of\na group of k-centroids clusterings. Each clustering randomly selects data\npoints with randomly selected features as its centroids, and learns a one-hot\nencoder by one-nearest-neighbor optimization. Geometrically, the nonparametric\ndensity estimator at each layer projects the input data space to a\nuniformly-distributed discrete feature space, where the similarity of two data\npoints in the discrete feature space is measured by the number of the nearest\ncentroids they share in common. The multilayer network gradually reduces the\nnonlinear variations of data from bottom up by building a vast number of\nhierarchical trees implicitly on the original data space. Theoretically, the\nestimation error caused by the nonparametric density estimator is proportional\nto the correlation between the clusterings, both of which are reduced by the\nrandomization steps.\n"]},
{"authors": ["Fernando Gama", "Antonio G. Marques", "Alejandro Ribeiro", "Geert Leus"], "title": ["MIMO Graph Filters for Convolutional Neural Networks"], "date": ["2018-03-06T15:18:56Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02247v1"], "summary": ["  Superior performance and ease of implementation have fostered the adoption of\nConvolutional Neural Networks (CNNs) for a wide array of inference and\nreconstruction tasks. CNNs implement three basic blocks: convolution, pooling\nand pointwise nonlinearity. Since the two first operations are well-defined\nonly on regular-structured data such as audio or images, application of CNNs to\ncontemporary datasets where the information is defined in irregular domains is\nchallenging. This paper investigates CNNs architectures to operate on signals\nwhose support can be modeled using a graph. Architectures that replace the\nregular convolution with a so-called linear shift-invariant graph filter have\nbeen recently proposed. This paper goes one step further and, under the\nframework of multiple-input multiple-output (MIMO) graph filters, imposes\nadditional structure on the adopted graph filters, to obtain three new (more\nparsimonious) architectures. The proposed architectures result in a lower\nnumber of model parameters, reducing the computational complexity, facilitating\nthe training, and mitigating the risk of overfitting. Simulations show that the\nproposed simpler architectures achieve similar performance as more complex\nmodels.\n"]},
{"authors": ["Xi Fang", "Zengmao Wang", "Xinyao Tang", "Chen Wu"], "title": ["Multi-class Active Learning: A Hybrid Informative and Representative\n  Criterion Inspired Approach"], "date": ["2018-03-06T14:32:15Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02222v1"], "summary": ["  Labeling each instance in a large dataset is extremely labor- and time-\nconsuming . One way to alleviate this problem is active learning, which aims to\nwhich discover the most valuable instances for labeling to construct a powerful\nclassifier. Considering both informativeness and representativeness provides a\npromising way to design a practical active learning. However, most existing\nactive learning methods select instances favoring either informativeness or\nrepresentativeness. Meanwhile, many are designed based on the binary class, so\nthat they may present suboptimal solutions on the datasets with multiple\nclasses. In this paper, a hybrid informative and representative criterion based\nmulti-class active learning approach is proposed. We combine the informative\ninformativeness and representativeness into one formula, which can be solved\nunder a unified framework. The informativeness is measured by the margin\nminimum while the representative information is measured by the maximum mean\ndiscrepancy. By minimizing the upper bound for the true risk, we generalize the\nempirical risk minimization principle to the active learning setting.\nSimultaneously, our proposed method makes full use of the label information,\nand the proposed active learning is designed based on multiple classes. So the\nproposed method is not suitable to the binary class but also the multiple\nclasses. We conduct our experiments on twelve benchmark UCI data sets, and the\nexperimental results demonstrate that the proposed method performs better than\nsome state-of-the-art methods.\n"]},
{"authors": ["Abien Fred Agarap"], "title": ["On Breast Cancer Detection: An Application of Machine Learning\n  Algorithms on the Wisconsin Diagnostic Dataset"], "date": ["2017-11-20T06:33:34Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.07831v3"], "summary": ["  This paper presents a comparison of six machine learning (ML) algorithms:\nGRU-SVM (Agarap, 2017), Linear Regression, Multilayer Perceptron (MLP), Nearest\nNeighbor (NN) search, Softmax Regression, and Support Vector Machine (SVM) on\nthe Wisconsin Diagnostic Breast Cancer (WDBC) dataset (Wolberg, Street, &\nMangasarian, 1992) by measuring their classification test accuracy and their\nsensitivity and specificity values. The said dataset consists of features which\nwere computed from digitized images of FNA tests on a breast mass (Wolberg,\nStreet, & Mangasarian, 1992). For the implementation of the ML algorithms, the\ndataset was partitioned in the following fashion: 70% for training phase, and\n30% for the testing phase. The hyper-parameters used for all the classifiers\nwere manually assigned. Results show that all the presented ML algorithms\nperformed well (all exceeded 90% test accuracy) on the classification task. The\nMLP algorithm stands out among the implemented algorithms with a test accuracy\nof ~99.04%.\n"]},
{"authors": ["Christian Grussler", "Anders Rantzer", "Pontus Giselsson"], "title": ["Low-rank Optimization with Convex Constraints"], "date": ["2016-06-06T15:46:08Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1606.01793v3"], "summary": ["  The problem of low-rank approximation with convex constraints, which appears\nin data analysis, system identification, model order reduction, low-order\ncontroller design and low-complexity modelling is considered. Given a matrix,\nthe objective is to find a low-rank approximation that meets rank and convex\nconstraints, while minimizing the distance to the matrix in the squared\nFrobenius norm. In many situations, this non-convex problem is convexified by\nnuclear norm regularization. However, we will see that the approximations\nobtained by this method may be far from optimal. In this paper, we propose an\nalternative convex relaxation that uses the convex envelope of the squared\nFrobenius norm and the rank constraint. With this approach, easily verifiable\nconditions are obtained under which the solutions to the convex relaxation and\nthe original non-convex problem coincide. An SDP representation of the convex\nenvelope is derived, which allows us to apply this approach to several known\nproblems. Our example on optimal low-rank Hankel approximation/model reduction\nillustrates that the proposed convex relaxation performs consistently better\nthan nuclear norm regularization and may outperform balanced truncation.\n"]},
{"authors": ["Emiel Hoogeboom", "Jorn W. T. Peters", "Taco S. Cohen", "Max Welling"], "title": ["HexaConv"], "date": ["2018-03-06T11:05:39Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02108v1"], "summary": ["  The effectiveness of Convolutional Neural Networks stems in large part from\ntheir ability to exploit the translation invariance that is inherent in many\nlearning problems. Recently, it was shown that CNNs can exploit other\ninvariances, such as rotation invariance, by using group convolutions instead\nof planar convolutions. However, for reasons of performance and ease of\nimplementation, it has been necessary to limit the group convolution to\ntransformations that can be applied to the filters without interpolation. Thus,\nfor images with square pixels, only integer translations, rotations by\nmultiples of 90 degrees, and reflections are admissible.\n  Whereas the square tiling provides a 4-fold rotational symmetry, a hexagonal\ntiling of the plane has a 6-fold rotational symmetry. In this paper we show how\none can efficiently implement planar convolution and group convolution over\nhexagonal lattices, by re-using existing highly optimized convolution routines.\nWe find that, due to the reduced anisotropy of hexagonal filters, planar\nHexaConv provides better accuracy than planar convolution with square filters,\ngiven a fixed parameter budget. Furthermore, we find that the increased degree\nof symmetry of the hexagonal grid increases the effectiveness of group\nconvolutions, by allowing for more parameter sharing. We show that our method\nsignificantly outperforms conventional CNNs on the AID aerial scene\nclassification dataset, even outperforming ImageNet pre-trained models.\n"]},
{"authors": ["Savitha Ramasamy", "Kanagasabai Rajaraman", "Pavitra Krishnaswamy", "Vijay Chandrasekhar"], "title": ["Online Deep Learning: Growing RBM on the fly"], "date": ["2018-03-06T07:24:21Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02043v1"], "summary": ["  We propose a novel online learning algorithm for Restricted Boltzmann\nMachines (RBM), namely, the Online Generative Discriminative Restricted\nBoltzmann Machine (OGD-RBM), that provides the ability to build and adapt the\nnetwork architecture of RBM according to the statistics of streaming data. The\nOGD-RBM is trained in two phases: (1) an online generative phase for\nunsupervised feature representation at the hidden layer and (2) a\ndiscriminative phase for classification. The online generative training begins\nwith zero neurons in the hidden layer, adds and updates the neurons to adapt to\nstatistics of streaming data in a single pass unsupervised manner, resulting in\na feature representation best suited to the data. The discriminative phase is\nbased on stochastic gradient descent and associates the represented features to\nthe class labels. We demonstrate the OGD-RBM on a set of multi-category and\nbinary classification problems for data sets having varying degrees of\nclass-imbalance. We first apply the OGD-RBM algorithm on the multi-class MNIST\ndataset to characterize the network evolution. We demonstrate that the online\ngenerative phase converges to a stable, concise network architecture, wherein\nindividual neurons are inherently discriminative to the class labels despite\nunsupervised training. We then benchmark OGD-RBM performance to other machine\nlearning, neural network and ClassRBM techniques for credit scoring\napplications using 3 public non-stationary two-class credit datasets with\nvarying degrees of class-imbalance. We report that OGD-RBM improves accuracy by\n2.5-3% over batch learning techniques while requiring at least 24%-70% fewer\nneurons and fewer training samples. This online generative training approach\ncan be extended greedily to multiple layers for training Deep Belief Networks\nin non-stationary data mining applications without the need for a priori fixed\narchitectures.\n"]},
{"authors": ["G\u00e9rard Biau", "Beno\u00eet Cadre", "Laurent Rouv\u00ec\u00e8re"], "title": ["Accelerated Gradient Boosting"], "date": ["2018-03-06T07:23:17Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02042v1"], "summary": ["  Gradient tree boosting is a prediction algorithm that sequentially produces a\nmodel in the form of linear combinations of decision trees, by solving an\ninfinite-dimensional optimization problem. We combine gradient boosting and\nNesterov's accelerated descent to design a new algorithm, which we call AGB\n(for Accelerated Gradient Boosting). Substantial numerical evidence is provided\non both synthetic and real-life data sets to assess the excellent performance\nof the method in a large variety of prediction problems. It is empirically\nshown that AGB is much less sensitive to the shrinkage parameter and outputs\npredictors that are considerably more sparse in the number of trees, while\nretaining the exceptional performance of gradient boosting.\n"]},
{"authors": ["Adam Gustafson", "Hariharan Narayanan"], "title": ["John's Walk"], "date": ["2018-03-06T07:01:51Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02032v1"], "summary": ["  We present an affine-invariant random walk for drawing uniform random samples\nfrom a convex body $\\mathcal{K} \\subset \\mathbb{R}^n$ for which the maximum\nvolume inscribed ellipsoid, known as John's ellipsoid, may be computed. We\nconsider a polytope $\\mathcal{P} = \\{x \\in \\mathbb{R}^n \\mid Ax \\leq 1\\}$ where\n$A \\in \\mathbb{R}^{m \\times n}$ as a special case. Our algorithm makes steps\nusing uniform sampling from the John's ellipsoid of the symmetrization of\n$\\mathcal{K}$ at the current point. We show that from a warm start, the random\nwalk mixes in $\\widetilde{O}(n^7)$ steps where the log factors depend only on\nconstants determined by the warm start and error parameters (and not on the\ndimension or number of constraints defining the body). This sampling algorithm\nthus offers improvement over the affine-invariant Dikin Walk for polytopes\n(which mixes in $\\widetilde{O}(mn)$ steps from a warm start) for applications\nin which $m \\gg n$. Furthermore, we describe an $\\widetilde{O}(mn^{\\omega+1} +\nn^{2\\omega+2})$ algorithm for finding a suitably approximate John's ellipsoid\nfor a symmetric polytope based on Vaidya's algorithm, and show the mixing time\nis retained using these approximate ellipsoids (where $\\omega < 2.373$ is the\ncurrent value of the fast matrix multiplication constant).\n"]},
{"authors": ["James W. Kay", "Robin A. A. Ince"], "title": ["Exact partial information decompositions for Gaussian systems based on\n  dependency constraints"], "date": ["2018-03-06T06:42:38Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02030v1"], "summary": ["  The Partial Information Decomposition (PID) [arXiv:1004.2515] provides a\ntheoretical framework to characterize and quantify the structure of\nmultivariate information sharing. A new method (Idep) has recently been\nproposed for computing a two-predictor PID over discrete spaces.\n[arXiv:1709.06653] A lattice of maximum entropy probability models is\nconstructed based on marginal dependency constraints, and the unique\ninformation that a particular predictor has about the target is defined as the\nminimum increase in joint predictor-target mutual information when that\nparticular predictor-target marginal dependency is constrained. Here, we apply\nthe Idep approach to Gaussian systems, for which the marginally constrained\nmaximum entropy models are Gaussian graphical models. Closed form solutions for\nthe Idep PID are derived for both univariate and multivariate Gaussian systems.\nNumerical and graphical illustrations are provided, together with practical and\ntheoretical comparisons of the Idep PID with the minimum mutual information PID\n(Immi). [arXiv:1411.2832] In particular, it is proved that the Immi method\ngenerally produces larger estimates of redundancy and synergy than does the\nIdep method. In discussion of the practical examples, the PIDs are complemented\nby the use of deviance tests for the comparison of Gaussian graphical models.\n"]},
{"authors": ["Yuhuai Wu", "Mengye Ren", "Renjie Liao", "Roger Grosse"], "title": ["Understanding Short-Horizon Bias in Stochastic Meta-Optimization"], "date": ["2018-03-06T05:01:37Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.02021v1"], "summary": ["  Careful tuning of the learning rate, or even schedules thereof, can be\ncrucial to effective neural net training. There has been much recent interest\nin gradient-based meta-optimization, where one tunes hyperparameters, or even\nlearns an optimizer, in order to minimize the expected loss when the training\nprocedure is unrolled. But because the training procedure must be unrolled\nthousands of times, the meta-objective must be defined with an\norders-of-magnitude shorter time horizon than is typical for neural net\ntraining. We show that such short-horizon meta-objectives cause a serious bias\ntowards small step sizes, an effect we term short-horizon bias. We introduce a\ntoy problem, a noisy quadratic cost function, on which we analyze short-horizon\nbias by deriving and comparing the optimal schedules for short and long time\nhorizons. We then run meta-optimization experiments (both offline and online)\non standard benchmark datasets, showing that meta-optimization chooses too\nsmall a learning rate by multiple orders of magnitude, even when run with a\nmoderately long time horizon (100 steps) typical of work in the area. We\nbelieve short-horizon bias is a fundamental problem that needs to be addressed\nif meta-optimization is to scale to practical neural net training regimes.\n"]},
{"authors": ["Hussein Hazimeh", "Rahul Mazumder"], "title": ["Fast Best Subset Selection: Coordinate Descent and Local Combinatorial\n  Optimization Algorithms"], "date": ["2018-03-05T01:41:12Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.01454v2"], "summary": ["  We consider the canonical $L_0$-regularized least squares problem (aka best\nsubsets) which is generally perceived as a `gold-standard' for many sparse\nlearning regimes. In spite of worst-case computational intractability results,\nrecent work has shown that advances in mixed integer optimization can be used\nto obtain near-optimal solutions to this problem for instances where the number\nof features $p \\approx 10^3$. While these methods lead to estimators with\nexcellent statistical properties, often there is a price to pay in terms of a\nsteep increase in computation times, especially when compared to highly\nefficient popular algorithms for sparse learning (e.g., based on\n$L_1$-regularization) that scale to much larger problem sizes. Bridging this\ngap is a main goal of this paper. We study the computational aspects of a\nfamily of $L_0$-regularized least squares problems with additional convex\npenalties. We propose a hierarchy of necessary optimality conditions for these\nproblems. We develop new algorithms, based on coordinate descent and local\ncombinatorial optimization schemes, and study their convergence properties. We\ndemonstrate that the choice of an algorithm determines the quality of solutions\nobtained; and local combinatorial optimization-based algorithms generally\nresult in solutions of superior quality. We show empirically that our proposed\nframework is relatively fast for problem instances with $p\\approx 10^6$ and\nworks well, in terms of both optimization and statistical properties (e.g.,\nprediction, estimation, and variable selection), compared to simpler heuristic\nalgorithms. A version of our algorithm reaches up to a three-fold speedup (with\n$p$ up to $10^6$) when compared to state-of-the-art schemes for sparse learning\nsuch as glmnet and ncvreg.\n"]},
{"authors": ["Tao Sun", "Hao Jiang", "Lizhi Cheng", "Wei Zhu"], "title": ["A convergence frame for inexact nonconvex and nonsmooth algorithms and\n  its applications to several iterations"], "date": ["2017-09-12T22:28:18Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1709.04072v3"], "summary": ["  In this paper, we consider the convergence of an abstract inexact nonconvex\nand nonsmooth algorithm. We promise a pseudo sufficient descent condition and a\npseudo relative error condition, which both are related to an auxiliary\nsequence, for the algorithm; and a continuity condition is assumed to hold. In\nfact, a wide of classical inexact nonconvex and nonsmooth algorithms allow\nthese three conditions. Under the finite energy assumption on the auxiliary\nsequence, we prove the sequence generated by the general algorithm converges to\na critical point of the objective function if being assumed Kurdyka-\nLojasiewicz property. The core of the proofs lies on building a new Lyapunov\nfunction, whose successive difference provides a bound for the successive\ndifference of the points generated by the algorithm. And then, we apply our\nfindings to several classical nonconvex iterative algorithms and derive\ncorresponding convergence results.\n"]},
{"authors": ["Fan Zhou"], "title": ["Nonparametric Estimation of Low Rank Matrix Valued Function"], "date": ["2018-02-17T20:56:33Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1802.06292v2"], "summary": ["  Let $A:[0,1]\\rightarrow\\mathbb{H}_m$ (the space of Hermitian matrices) be a\nmatrix valued function which is low rank with entries in H\\\"{o}lder class\n$\\Sigma(\\beta,L)$. The goal of this paper is to study statistical estimation of\n$A$ based on the regression model $\\mathbb{E}(Y_j|\\tau_j,X_j) = \\langle\nA(\\tau_j), X_j \\rangle,$ where $\\tau_j$ are i.i.d. uniformly distributed in\n$[0,1]$, $X_j$ are i.i.d. matrix completion sampling matrices, $Y_j$ are\nindependent bounded responses. We propose an innovative nuclear norm penalized\nlocal polynomial estimator and establish an upper bound on its point-wise risk\nmeasured by Frobenius norm. Then we extend this estimator globally and prove an\nupper bound on its integrated risk measured by $L_2$-norm. We also propose\nanother new estimator based on bias-reducing kernels to study the case when $A$\nis not necessarily low rank and establish an upper bound on its risk measured\nby $L_{\\infty}$-norm. We show that the obtained rates are all optimal up to\nsome logarithmic factor in minimax sense. Finally, we propose an adaptive\nestimation procedure based on Lepski's method and the penalized data splitting\ntechnique which is computationally efficient and can be easily implemented and\nparallelized.\n"]},
{"authors": ["Yuhui Xu", "Yongzhuang Wang", "Aojun Zhou", "Weiyao Lin", "Hongkai Xiong"], "title": ["Deep Neural Network Compression with Single and Multiple Level\n  Quantization"], "date": ["2018-03-06T01:47:52Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.03289v1"], "summary": ["  Network quantization is an effective solution to compress deep neural\nnetworks for practical usage. Existing network quantization methods cannot\nsufficiently exploit the depth information to generate low-bit compressed\nnetwork. In this paper, we propose two novel network quantization approaches,\nsingle-level network quantization (SLQ) for high-bit quantization and\nmulti-level network quantization (MLQ) for extremely low-bit quantization\n(ternary).We are the first to consider the network quantization from both width\nand depth level. In the width level, parameters are divided into two parts: one\nfor quantization and the other for re-training to eliminate the quantization\nloss. SLQ leverages the distribution of the parameters to improve the width\nlevel. In the depth level, we introduce incremental layer compensation to\nquantize layers iteratively which decreases the quantization loss in each\niteration. The proposed approaches are validated with extensive experiments\nbased on the state-of-the-art neural networks including AlexNet, VGG-16,\nGoogleNet and ResNet-18. Both SLQ and MLQ achieve impressive results.\n"]},
{"authors": ["Luke Pfister", "Yoram Bresler"], "title": ["Learning Filter Bank Sparsifying Transforms"], "date": ["2018-03-06T01:35:01Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.01980v1"], "summary": ["  Data is said to follow the transform (or analysis) sparsity model if it\nbecomes sparse when acted on by a linear operator called a sparsifying\ntransform. Several algorithms have been designed to learn such a transform\ndirectly from data, and data-adaptive sparsifying transforms have demonstrated\nexcellent performance in signal restoration tasks. Sparsifying transforms are\ntypically learned using small sub-regions of data called patches, but these\nalgorithms often ignore redundant information shared between neighboring\npatches.\n  We show that many existing transform and analysis sparse representations can\nbe viewed as filter banks, thus linking the local properties of patch-based\nmodel to the global properties of a convolutional model. We propose a new\ntransform learning framework where the sparsifying transform is an undecimated\nperfect reconstruction filter bank. Unlike previous transform learning\nalgorithms, the filter length can be chosen independently of the number of\nfilter bank channels. Numerical results indicate filter bank sparsifying\ntransforms outperform existing patch-based transform learning for image\ndenoising while benefiting from additional flexibility in the design process.\n"]},
{"authors": ["Debjyoti Saharoy", "Theja Tulabandhula"], "title": ["An Online Algorithm for Learning Buyer Behavior under Realistic Pricing\n  Restrictions"], "date": ["2018-03-06T00:48:02Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.01968v1"], "summary": ["  We propose a new efficient online algorithm to learn the parameters governing\nthe purchasing behavior of a utility maximizing buyer, who responds to prices,\nin a repeated interaction setting. The key feature of our algorithm is that it\ncan learn even non-linear buyer utility while working with arbitrary price\nconstraints that the seller may impose. This overcomes a major shortcoming of\nprevious approaches, which use unrealistic prices to learn these parameters\nmaking them unsuitable in practice.\n"]},
{"authors": ["Yao Zhang", "Andrew M. Saxe", "Madhu S. Advani", "Alpha A. Lee"], "title": ["Energy-entropy competition and the effectiveness of stochastic gradient\n  descent in machine learning"], "date": ["2018-03-05T21:12:04Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.01927v1"], "summary": ["  Finding parameters that minimise a loss function is at the core of many\nmachine learning methods. The Stochastic Gradient Descent algorithm is widely\nused and delivers state of the art results for many problems. Nonetheless,\nStochastic Gradient Descent typically cannot find the global minimum, thus its\nempirical effectiveness is hitherto mysterious. We derive a correspondence\nbetween parameter inference and free energy minimisation in statistical\nphysics. The degree of undersampling plays the role of temperature. Analogous\nto the energy-entropy competition in statistical physics, wide but shallow\nminima can be optimal if the system is undersampled, as is typical in many\napplications. Moreover, we show that the stochasticity in the algorithm has a\nnon-trivial correlation structure which systematically biases it towards wide\nminima. We illustrate our argument with two prototypical models: image\nclassification using deep learning, and a linear neural network where we can\nanalytically reveal the relationship between entropy and out-of-sample error.\n"]},
{"authors": ["Maithra Raghu", "Alex Irpan", "Jacob Andreas", "Robert Kleinberg", "Quoc V. Le", "Jon Kleinberg"], "title": ["Can Deep Reinforcement Learning Solve Erdos-Selfridge-Spencer Games?"], "date": ["2017-11-07T06:16:56Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1711.02301v3"], "summary": ["  Deep reinforcement learning has achieved many recent successes, but our\nunderstanding of its strengths and limitations is hampered by the lack of rich\nenvironments in which we can fully characterize optimal behavior, and\ncorrespondingly diagnose individual actions against such a characterization.\nHere we consider a family of combinatorial games, arising from work of Erdos,\nSelfridge, and Spencer, and we propose their use as environments for evaluating\nand comparing different approaches to reinforcement learning. These games have\na number of appealing features: they are challenging for current learning\napproaches, but they form (i) a low-dimensional, simply parametrized\nenvironment where (ii) there is a linear closed form solution for optimal\nbehavior from any state, and (iii) the difficulty of the game can be tuned by\nchanging environment parameters in an interpretable way. We use these\nErdos-Selfridge-Spencer games not only to compare different algorithms, but\ntest for generalization, make comparisons to supervised learning, analyse\nmultiagent play, and even develop a self play algorithm.\n"]},
{"authors": ["Mor Shpigel Nacson", "Jason Lee", "Suriya Gunasekar", "Nathan Srebro", "Daniel Soudry"], "title": ["Convergence of Gradient Descent on Separable Data"], "date": ["2018-03-05T20:03:46Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.01905v1"], "summary": ["  The implicit bias of gradient descent is not fully understood even in simple\nlinear classification tasks (e.g., logistic regression). Soudry et al. (2018)\nstudied this bias on separable data, where there are multiple solutions that\ncorrectly classify the data. It was found that, when optimizing monotonically\ndecreasing loss functions with exponential tails using gradient descent, the\nlinear classifier specified by the gradient descent iterates converge to the\n$L_2$ max margin separator. However, the convergence rate to the maximum margin\nsolution with fixed step size was found to be extremely slow: $1/\\log(t)$.\n  Here we examine how the convergence is influenced by using different loss\nfunctions and by using variable step sizes. First, we calculate the convergence\nrate for loss functions with poly-exponential tails near $\\exp(-u^{\\nu})$. We\nprove that $\\nu=1$ yields the optimal convergence rate in the range $\\nu>0.25$.\nBased on further analysis we conjecture that this remains the optimal rate for\n$\\nu \\leq 0.25$, and even for sub-poly-exponential tails --- until loss\nfunctions with polynomial tails no longer converge to the max margin. Second,\nwe prove the convergence rate could be improved to $(\\log t) /\\sqrt{t}$ for the\nexponential loss, by using aggressive step sizes which compensate for the\nrapidly vanishing gradients.\n"]},
{"authors": ["Yongkai Wu", "Lu Zhang", "Xintao Wu"], "title": ["On Discrimination Discovery and Removal in Ranked Data using Causal\n  Graph"], "date": ["2018-03-05T19:53:40Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.01901v1"], "summary": ["  Predictive models learned from historical data are widely used to help\ncompanies and organizations make decisions. However, they may digitally\nunfairly treat unwanted groups, raising concerns about fairness and\ndiscrimination. In this paper, we study the fairness-aware ranking problem\nwhich aims to discover discrimination in ranked datasets and reconstruct the\nfair ranking. Existing methods in fairness-aware ranking are mainly based on\nstatistical parity that cannot measure the true discriminatory effect since\ndiscrimination is causal. On the other hand, existing methods in causal-based\nanti-discrimination learning focus on classification problems and cannot be\ndirectly applied to handle the ranked data. To address these limitations, we\npropose to map the rank position to a continuous score variable that represents\nthe qualification of the candidates. Then, we build a causal graph that\nconsists of both the discrete profile attributes and the continuous score. The\npath-specific effect technique is extended to the mixed-variable causal graph\nto identify both direct and indirect discrimination. The relationship between\nthe path-specific effects for the ranked data and those for the binary decision\nis theoretically analyzed. Finally, algorithms for discovering and removing\ndiscrimination from a ranked dataset are developed. Experiments using the real\ndataset show the effectiveness of our approaches.\n"]},
{"authors": ["Alexander G. Ororbia", "Ankur Mali", "Daniel Kifer", "C. Lee Giles"], "title": ["Conducting Credit Assignment by Aligning Local Representations"], "date": ["2018-03-05T18:54:02Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.01834v1"], "summary": ["  The use of back-propagation and its variants to train deep networks is often\nproblematic for new users, with issues such as exploding gradients, vanishing\ngradients, and high sensitivity to weight initialization strategies often\nmaking networks difficult to train. In this paper, we present Local\nRepresentation Alignment (LRA), a training procedure that is much less\nsensitive to bad initializations, does not require modifications to the network\narchitecture, and can be adapted to networks with highly nonlinear and\ndiscrete-valued activation functions. Furthermore, we show that one variation\nof LRA can start with a null initialization of network weights and still\nsuccessfully train networks with a wide variety of nonlinearities, including\ntanh, ReLU-6, softplus, signum and others that are more biologically plausible.\n  Experiments on MNIST and Fashion MNIST validate the performance of the\nalgorithm and show that LRA can train networks robustly and effectively,\nsucceeding even when back-propagation fails and outperforming other alternative\nlearning algorithms, such as target propagation and feedback alignment.\n"]},
{"authors": ["Samory Kpotufe", "Guillaume Martinet"], "title": ["Marginal Singularity, and the Benefits of Labels in Covariate-Shift"], "date": ["2018-03-05T18:52:08Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.01833v1"], "summary": ["  We present new minimax results that concisely capture the relative benefits\nof source and target labeled data, under covariate-shift. Namely, we show that\nthe benefits of target labels are controlled by a transfer-exponent $\\gamma$\nthat encodes how singular Q is locally w.r.t. P, and interestingly allows\nsituations where transfer did not seem possible under previous insights. In\nfact, our new minimax analysis - in terms of $\\gamma$ - reveals a continuum of\nregimes ranging from situations where target labels have little benefit, to\nregimes where target labels dramatically improve classification. We then show\nthat a recently proposed semi-supervised procedure can be extended to adapt to\nunknown $\\gamma$, and therefore requests labels only when beneficial, while\nachieving minimax transfer rates.\n"]},
{"authors": ["Hao Li", "Zheng Xu", "Gavin Taylor", "Christoph Studer", "Tom Goldstein"], "title": ["Visualizing the Loss Landscape of Neural Nets"], "date": ["2017-12-28T16:15:42Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1712.09913v2"], "summary": ["  Neural network training relies on our ability to find \"good\" minimizers of\nhighly non-convex loss functions. It is well known that certain network\narchitecture designs (e.g., skip connections) produce loss functions that train\neasier, and well-chosen training parameters (batch size, learning rate,\noptimizer) produce minimizers that generalize better. However, the reasons for\nthese differences, and their effect on the underlying loss landscape, is not\nwell understood. In this paper, we explore the structure of neural loss\nfunctions, and the effect of loss landscapes on generalization, using a range\nof visualization methods. First, we introduce a simple \"filter normalization\"\nmethod that helps us visualize loss function curvature, and make meaningful\nside-by-side comp arisons between loss functions. Then, using a variety of\nvisualizations, we explore how network architecture affects the loss landscape,\nand how training parameters affect the shape of minimizers.\n"]},
{"authors": ["Shiyu Liang", "Ruoyu Sun", "Yixuan Li", "R. Srikant"], "title": ["Understanding the Loss Surface of Neural Networks for Binary\n  Classification"], "date": ["2018-02-19T02:13:38Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.00909v2"], "summary": ["  It is widely conjectured that the reason that training algorithms for neural\nnetworks are successful because all local minima lead to similar performance,\nfor example, see (LeCun et al., 2015, Choromanska et al., 2015, Dauphin et al.,\n2014). Performance is typically measured in terms of two metrics: training\nperformance and generalization performance. Here we focus on the training\nperformance of single-layered neural networks for binary classification, and\nprovide conditions under which the training error is zero at all local minima\nof a smooth hinge loss function. Our conditions are roughly in the following\nform: the neurons have to be strictly convex and the surrogate loss function\nshould be a smooth version of hinge loss. We also provide counterexamples to\nshow that when the loss function is replaced with quadratic loss or logistic\nloss, the result may not hold.\n"]},
{"authors": ["Friedrich Solowjow", "Dominik Baumann", "Jochen Garcke", "Sebastian Trimpe"], "title": ["Event-triggered Learning for Resource-efficient Networked Control"], "date": ["2018-03-05T17:48:43Z"], "category": "stat.ML", "url": ["http://arxiv.org/abs/1803.01802v1"], "summary": ["  Common event-triggered state estimation (ETSE) algorithms save communication\nin networked control systems by predicting agents' behavior, and transmitting\nupdates only when the predictions deviate significantly. The effectiveness in\nreducing communication thus heavily depends on the quality of the dynamics\nmodels used to predict the agents' states or measurements. Event-triggered\nlearning is proposed herein as a novel concept to further reduce communication:\nwhenever poor communication performance is detected, an identification\nexperiment is triggered and an improved prediction model learned from data.\nEffective learning triggers are obtained by comparing the actual communication\nrate with the one that is expected based on the current model. By analyzing\nstatistical properties of the inter-communication times and leveraging powerful\nconvergence results, the proposed trigger is proven to limit learning\nexperiments to the necessary instants. Numerical and physical experiments\ndemonstrate that event-triggered learning improves robustness toward changing\nenvironments and yields lower communication rates than common ETSE.\n"]}
]