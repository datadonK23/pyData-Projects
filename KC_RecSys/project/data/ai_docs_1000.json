[
{"authors": ["Colin Lockard", "Xin Luna Dong", "Arash Einolghozati", "Prashant Shiralkar"], "title": ["CERES: Distantly Supervised Relation Extraction from the Semi-Structured\n  Web"], "date": ["2018-04-12T17:19:36Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.04635v1"], "summary": ["  The web contains countless semi-structured websites, which can be a rich\nsource of information for populating knowledge bases. Existing methods for\nextracting relations from the DOM trees of semi-structured webpages can achieve\nhigh precision and recall only when manual annotations for each website are\navailable. Although there have been efforts to learn extractors from\nautomatically-generated labels, these methods are not sufficiently robust to\nsucceed in settings with complex schemas and information-rich websites.\n  In this paper we present a new method for automatic extraction from\nsemi-structured websites based on distant supervision. We automatically\ngenerate training labels by aligning an existing knowledge base with a web page\nand leveraging the unique structural characteristics of semi-structured\nwebsites. We then train a classifier based on the potentially noisy and\nincomplete labels to predict new relation instances. Our method can compete\nwith annotation-based techniques in the literature in terms of extraction\nquality. A large-scale experiment on over 400,000 pages from dozens of\nmulti-lingual long-tail websites harvested 1.25 million facts at a precision of\n90%.\n"]},
{"authors": ["Jan-Peter Calliess"], "title": ["Lazily Adapted Constant Kinky Inference for Nonparametric Regression and\n  Model-Reference Adaptive Control"], "date": ["2016-12-31T23:25:59Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1701.00178v2"], "summary": ["  Techniques known as Nonlinear Set Membership prediction, Lipschitz\nInterpolation or Kinky Inference are approaches to machine learning that\nutilise presupposed Lipschitz properties to compute inferences over unobserved\nfunction values. Provided a bound on the true best Lipschitz constant of the\ntarget function is known a priori they offer convergence guarantees as well as\nbounds around the predictions. Considering a more general setting that builds\non Hoelder continuity relative to pseudo-metrics, we propose an online method\nfor estimating the Hoelder constant online from function value observations\nthat possibly are corrupted by bounded observational errors. Utilising this to\ncompute adaptive parameters within a kinky inference rule gives rise to a\nnonparametric machine learning method, for which we establish strong universal\napproximation guarantees. That is, we show that our prediction rule can learn\nany continuous function in the limit of increasingly dense data to within a\nworst-case error bound that depends on the level of observational uncertainty.\nWe apply our method in the context of nonparametric model-reference adaptive\ncontrol (MRAC). Across a range of simulated aircraft roll-dynamics and\nperformance metrics our approach outperforms recently proposed alternatives\nthat were based on Gaussian processes and RBF-neural networks. For\ndiscrete-time systems, we provide guarantees on the tracking success of our\nlearning-based controllers both for the batch and the online learning setting.\n"]},
{"authors": ["Daniel Worrall", "Gabriel Brostow"], "title": ["CubeNet: Equivariance to 3D Rotation and Translation"], "date": ["2018-04-12T12:14:18Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.04458v1"], "summary": ["  3D Convolutional Neural Networks are sensitive to transformations applied to\ntheir input. This is a problem because a voxelized version of a 3D object, and\nits rotated clone, will look unrelated to each other after passing through to\nthe last layer of a network. Instead, an idealized model would preserve a\nmeaningful representation of the voxelized object, while explaining the\npose-difference between the two inputs. An equivariant representation vector\nhas two components: the invariant identity part, and a discernable encoding of\nthe transformation. Models that can't explain pose-differences risk \"diluting\"\nthe representation, in pursuit of optimizing a classification or regression\nloss function.\n  We introduce a Group Convolutional Neural Network with linear equivariance to\ntranslations and right angle rotations in three dimensions. We call this\nnetwork CubeNet, reflecting its cube-like symmetry. By construction, this\nnetwork helps preserve a 3D shape's global and local signature, as it is\ntransformed through successive layers. We apply this network to a variety of 3D\ninference problems, achieving state-of-the-art on the ModelNet10 classification\nchallenge, and comparable performance on the ISBI 2012 Connectome Segmentation\nBenchmark. To the best of our knowledge, this is the first 3D rotation\nequivariant CNN for voxel representations.\n"]},
{"authors": ["Stefan Depeweg", "Constantin A. Rothkopf", "Frank J\u00e4kel"], "title": ["Solving Bongard Problems with a Visual Language and Pragmatic Reasoning"], "date": ["2018-04-12T12:05:28Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.04452v1"], "summary": ["  More than 50 years ago Bongard introduced 100 visual concept learning\nproblems as a testbed for intelligent vision systems. These problems are now\nknown as Bongard problems. Although they are well known in the cognitive\nscience and AI communities only moderate progress has been made towards\nbuilding systems that can solve a substantial subset of them. In the system\npresented here, visual features are extracted through image processing and then\ntranslated into a symbolic visual vocabulary. We introduce a formal language\nthat allows representing complex visual concepts based on this vocabulary.\nUsing this language and Bayesian inference, complex visual concepts can be\ninduced from the examples that are provided in each Bongard problem. Contrary\nto other concept learning problems the examples from which concepts are induced\nare not random in Bongard problems, instead they are carefully chosen to\ncommunicate the concept, hence requiring pragmatic reasoning. Taking pragmatic\nreasoning into account we find good agreement between the concepts with high\nposterior probability and the solutions formulated by Bongard himself. While\nthis approach is far from solving all Bongard problems, it solves the biggest\nfraction yet.\n"]},
{"authors": ["Andr\u00e9 Barreto", "Will Dabney", "R\u00e9mi Munos", "Jonathan J. Hunt", "Tom Schaul", "Hado van Hasselt", "David Silver"], "title": ["Successor Features for Transfer in Reinforcement Learning"], "date": ["2016-06-16T18:45:32Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1606.05312v2"], "summary": ["  Transfer in reinforcement learning refers to the notion that generalization\nshould occur not only within a task but also across tasks. We propose a\ntransfer framework for the scenario where the reward function changes between\ntasks but the environment's dynamics remain the same. Our approach rests on two\nkey ideas: \"successor features\", a value function representation that decouples\nthe dynamics of the environment from the rewards, and \"generalized policy\nimprovement\", a generalization of dynamic programming's policy improvement\noperation that considers a set of policies rather than a single one. Put\ntogether, the two ideas lead to an approach that integrates seamlessly within\nthe reinforcement learning framework and allows the free exchange of\ninformation across tasks. The proposed method also provides performance\nguarantees for the transferred policy even before any learning has taken place.\nWe derive two theorems that set our approach in firm theoretical ground and\npresent experiments that show that it successfully promotes transfer in\npractice, significantly outperforming alternative methods in a sequence of\nnavigation tasks and in the control of a simulated robotic arm.\n"]},
{"authors": ["Bruno Ordozgoiti", "Alberto Mozo", "Jes\u00fas Garc\u00eda L\u00f3pez de Lacalle"], "title": ["Regularized Greedy Column Subset Selection"], "date": ["2018-04-12T10:56:44Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.04421v1"], "summary": ["  The Column Subset Selection Problem provides a natural framework for\nunsupervised feature selection. Despite being a hard combinatorial optimization\nproblem, there exist efficient algorithms that provide good approximations. The\ndrawback of the problem formulation is that it incorporates no form of\nregularization, and is therefore very sensitive to noise when presented with\nscarce data. In this paper we propose a regularized formulation of this\nproblem, and derive a correct greedy algorithm that is similar in efficiency to\nexisting greedy methods for the unregularized problem. We study its adequacy\nfor feature selection and propose suitable formulations. Additionally, we\nderive a lower bound for the error of the proposed problems. Through various\nnumerical experiments on real and synthetic data, we demonstrate the\nsignificantly increased robustness and stability of our method, as well as the\nimproved conditioning of its output, all while remaining efficient for\npractical use.\n"]},
{"authors": ["Stefano Cresci", "Fabrizio Lillo", "Daniele Regoli", "Serena Tardelli", "Maurizio Tesconi"], "title": ["Cashtag piggybacking: uncovering spam and bot activity in stock\n  microblogs on Twitter"], "date": ["2018-04-12T10:04:36Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.04406v1"], "summary": ["  Microblogs are increasingly exploited for predicting prices and traded\nvolumes of stocks in financial markets. However, it has been demonstrated that\nmuch of the content shared in microblogging platforms is created and publicized\nby bots and spammers. Yet, the presence (or lack thereof) and the impact of\nfake stock microblogs has never systematically been investigated before. Here,\nwe study 9M tweets related to stocks of the 5 main financial markets in the US.\nBy comparing tweets with financial data from Google Finance, we highlight\nimportant characteristics of Twitter stock microblogs. More importantly, we\nuncover a malicious practice perpetrated by coordinated groups of bots and\nlikely aimed at promoting low-value stocks by exploiting the popularity of\nhigh-value ones. Our results call for the adoption of spam and bot detection\ntechniques in all studies and applications that exploit user-generated content\nfor predicting the stock market.\n"]},
{"authors": ["Xiangnan Ren", "Olivier Cur\u00e9", "Hubert Naacke", "Guohui Xiao"], "title": ["BigSR: an empirical study of real-time expressive RDF stream reasoning\n  on modern Big Data platforms"], "date": ["2018-04-12T08:15:17Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.04367v1"], "summary": ["  The trade-off between language expressiveness and system scalability (E&S) is\na well-known problem in RDF stream reasoning. Higher expressiveness supports\nmore complex reasoning logic, however, it may also hinder system scalability.\nCurrent research mainly focuses on logical frameworks suitable for stream\nreasoning as well as the implementation and the evaluation of prototype\nsystems. These systems are normally developed in a centralized setting which\nsuffer from inherent limited scalability, while an in-depth study of applying\ndistributed solutions to cover E&S is still missing. In this paper, we aim to\nexplore the feasibility of applying modern distributed computing frameworks to\nmeet E&S all together. To do so, we first propose BigSR, a technical\ndemonstrator that supports a positive fragment of the LARS framework. For the\nsake of generality and to cover a wide variety of use cases, BigSR relies on\nthe two main execution models adopted by major distributed execution\nframeworks: Bulk Synchronous Processing (BSP) and Record-at-A-Time (RAT).\nAccordingly, we implement BigSR on top of Apache Spark Streaming (BSP model)\nand Apache Flink (RAT model). In order to conclude on the impacts of BSP and\nRAT on E&S, we analyze the ability of the two models to support distributed\nstream reasoning and identify several types of use cases characterized by their\nlevels of support. This classification allows for quantifying the E&S trade-off\nby assessing the scalability of each type of use case \\wrt its level of\nexpressiveness. Then, we conduct a series of experiments with 15 queries from 4\ndifferent datasets. Our experiments show that BigSR over both BSP and RAT\ngenerally scales up to high throughput beyond million-triples per second (with\nor without recursion), and RAT attains sub-millisecond delay for stateless\nquery operators.\n"]},
{"authors": ["Rohith Aralikatti", "Dilip Margam", "Tanay Sharma", "Thanda Abhinav", "Shankar M Venkatesan"], "title": ["Global SNR Estimation of Speech Signals using Entropy and Uncertainty\n  Estimates from Dropout Networks"], "date": ["2018-04-12T07:15:20Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.04353v1"], "summary": ["  This paper demonstrates two novel methods to estimate the global SNR of\nspeech signals. In both methods, Deep Neural Network-Hidden Markov Model\n(DNN-HMM) acoustic model used in speech recognition systems is leveraged for\nthe additional task of SNR estimation. In the first method, the entropy of the\nDNN-HMM output is computed. Recent work on bayesian deep learning has shown\nthat a DNN-HMM trained with dropout can be used to estimate model uncertainty\nby approximating it as a deep Gaussian process. In the second method, this\napproximation is used to obtain model uncertainty estimates. Noise specific\nregressors are used to predict the SNR from the entropy and model uncertainty.\nThe DNN-HMM is trained on GRID corpus and tested on different noise profiles\nfrom the DEMAND noise database at SNR levels ranging from -10 dB to 30 dB.\n"]},
{"authors": ["Tom Everitt", "Marcus Hutter"], "title": ["A Topological Approach to Meta-heuristics: Analytical Results on the BFS\n  vs. DFS Algorithm Selection Problem"], "date": ["2015-09-09T10:30:48Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1509.02709v2"], "summary": ["  Search is a central problem in artificial intelligence, and breadth-first\nsearch (BFS) and depth-first search (DFS) are the two most fundamental ways to\nsearch. In this paper we derive estimates for average BFS and DFS runtime. The\naverage runtime estimates can be used to allocate resources or judge the\nhardness of a problem. They can also be used for selecting the best graph\nrepresentation, and for selecting the faster algorithm out of BFS and DFS. They\nmay also form the basis for an analysis of more advanced search methods. The\npaper treats both tree search and graph search. For tree search, we employ a\nprobabilistic model of goal distribution; for graph search, the analysis\ndepends on an additional statistic of path redundancy and average branching\nfactor. As an application, we use the results to predict BFS and DFS runtime on\ntwo concrete grammar problems and on the N-puzzle. Experimental verification\nshows that our analytical approximations come close to empirical reality.\n"]},
{"authors": ["Yookoon Park", "Jaemin Cho", "Gunhee Kim"], "title": ["A Hierarchical Latent Structure for Variational Conversation Modeling"], "date": ["2018-04-10T10:00:36Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.03424v2"], "summary": ["  Variational autoencoders (VAE) combined with hierarchical RNNs have emerged\nas a powerful framework for conversation modeling. However, they suffer from\nthe notorious degeneration problem, where the decoders learn to ignore latent\nvariables and reduce to vanilla RNNs. We empirically show that this degeneracy\noccurs mostly due to two reasons. First, the expressive power of hierarchical\nRNN decoders is often high enough to model the data using only its decoding\ndistributions without relying on the latent variables. Second, the conditional\nVAE structure whose generation process is conditioned on a context, makes the\nrange of training targets very sparse; that is, the RNN decoders can easily\noverfit to the training data ignoring the latent variables. To solve the\ndegeneration problem, we propose a novel model named Variational Hierarchical\nConversation RNNs (VHCR), involving two key ideas of (1) using a hierarchical\nstructure of latent variables, and (2) exploiting an utterance drop\nregularization. With evaluations on two datasets of Cornell Movie Dialog and\nUbuntu Dialog Corpus, we show that our VHCR successfully utilizes latent\nvariables and outperforms state-of-the-art models for conversation generation.\nMoreover, it can perform several new utterance control tasks, thanks to its\nhierarchical latent structure.\n"]},
{"authors": ["Tran Dang Quang Vinh", "Tuan-Anh Nguyen Pham", "Gao Cong", "Xiao-Li Li"], "title": ["Attention-based Group Recommendation"], "date": ["2018-04-12T05:54:13Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.04327v1"], "summary": ["  Recommender systems are widely used in big information-based companies such\nas Google, Twitter, LinkedIn, and Netflix. A recommender system deals with the\nproblem of information overload by filtering important information fragments\naccording to users' preferences. However, most traditional recommendation\ntechniques have limitations. In light of the increasing success of deep\nlearning, recent studies have proved the benefits of using deep learning in\nvarious recommendation tasks. Recommendation architectures have been utilizing\ndeep learning in order to overcome limitations of traditional recommendation\ntechniques. We propose an extension of deep learning to solve the group\nrecommendation problem. On the one hand, as different individual preferences in\na group necessitate preference trade-offs in making group recommendations, it\nis essential that the recommendation model can discover substitutes among user\nbehaviors. On the other hand, it has been observed that a user as an individual\nand as a group member behaves differently. To tackle such problems, we propose\nusing an attention mechanism to capture the impact of each user in a group.\nSpecifically, our model automatically learns the influence weight of each user\nin a group and recommends items to the group based on its members' weighted\npreferences. We conduct extensive experiments on four datasets. Our model\nsignificantly outperforms baseline methods and shows promising results in\napplying deep learning to the group recommendation problem.\n"]},
{"authors": ["Yuya Yoshikawa", "Jiaqing Lin", "Akikazu Takeuchi"], "title": ["STAIR Actions: A Video Dataset of Everyday Home Actions"], "date": ["2018-04-12T05:48:06Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.04326v1"], "summary": ["  A new large-scale video dataset for human action recognition, called STAIR\nActions is introduced. STAIR Actions contains 100 categories of action labels\nrepresenting fine-grained everyday home actions so that it can be applied to\nresearch in various home tasks such as nursing, caring, and security. In STAIR\nActions, each video has a single action label. Moreover, for each action\ncategory, there are around 1,000 videos that were obtained from YouTube or\nproduced by crowdsource workers. The duration of each video is mostly five to\nsix seconds. The total number of videos is 102,462. We explain how we\nconstructed STAIR Actions and show the characteristics of STAIR Actions\ncompared to existing datasets for human action recognition. Experiments with\nthree major models for action recognition show that STAIR Actions can train\nlarge models and achieve good performance. STAIR Actions can be downloaded from\nhttps://actions.stair.center.\n"]},
{"authors": ["Yale Song", "Mohammed Soleymani"], "title": ["Cross-Modal Retrieval with Implicit Concept Association"], "date": ["2018-04-12T05:10:33Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.04318v1"], "summary": ["  Traditional cross-modal retrieval assumes explicit association of concepts\nacross modalities, where there is no ambiguity in how the concepts are linked\nto each other, e.g., when we do the image search with a query \"dogs\", we expect\nto see dog images. In this paper, we consider a different setting for\ncross-modal retrieval where data from different modalities are implicitly\nlinked via concepts that must be inferred by high-level reasoning; we call this\nsetting implicit concept association. To foster future research in this\nsetting, we present a new dataset containing 47K pairs of animated GIFs and\nsentences crawled from the web, in which the GIFs depict physical or emotional\nreactions to the scenarios described in the text (called \"reaction GIFs\"). We\nreport on a user study showing that, despite the presence of implicit concept\nassociation, humans are able to identify video-sentence pairs with matching\nconcepts, suggesting the feasibility of our task. Furthermore, we propose a\nnovel visual-semantic embedding network based on multiple instance learning.\nUnlike traditional approaches, we compute multiple embeddings from each\nmodality, each representing different concepts, and measure their similarity by\nconsidering all possible combinations of visual-semantic embeddings in the\nframework of multiple instance learning. We evaluate our approach on two\nvideo-sentence datasets with explicit and implicit concept association and\nreport competitive results compared to existing approaches on cross-modal\nretrieval.\n"]},
{"authors": ["Makoto Naruse", "Nicolas Chauvet", "David Jegouso", "Benoit Boulanger", "Hayato Saigo", "Kazuya Okamura", "Hirokazu Hori", "Aurelien Drezet", "Serge Huant", "Guillaume Bachelier"], "title": ["Entangled photons for competitive multi-armed bandit problem:\n  achievement of maximum social reward, equality, and deception prevention"], "date": ["2018-04-12T05:04:34Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.04316v1"], "summary": ["  The competitive multi-armed bandit (CMAB) problem is related to social issues\nsuch as maximizing total social benefits while preserving equality among\nindividuals by overcoming conflicts between individual decisions, which could\nseriously decrease social benefits. The study described herein provides\nexperimental evidence that entangled photons physically resolve the CMAB,\nmaximizing the social rewards while ensuring equality. Moreover, by exploiting\nthe requirement that entangled photons share a common polarization basis, we\ndemonstrated that deception, or delaying the other player receiving a greater\nreward, cannot be accomplished in a polarization-entangled-photon-based system,\nwhile deception is achievable in systems based on classical or\npolarization-correlated photons. Autonomous alignment schemes for polarization\nbases were also experimentally demonstrated based on decision conflict\ninformation. This study provides the foundation for collective decision making\nbased on polarization-entangled photons and their polarization and value\nalignment, which is essential for utilizing quantum light for intelligent\nfunctionalities.\n"]},
{"authors": ["Glen Berseth", "Michiel van de Panne"], "title": ["Model-Based Action Exploration for Learning Dynamic Motion Skills"], "date": ["2018-01-11T19:05:38Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.03954v2"], "summary": ["  Deep reinforcement learning has achieved great strides in solving challenging\nmotion control tasks. Recently, there has been significant work on methods for\nexploiting the data gathered during training, but there has been less work on\nhow to best generate the data to learn from. For continuous action domains, the\nmost common method for generating exploratory actions involves sampling from a\nGaussian distribution centred around the mean action output by a policy.\nAlthough these methods can be quite capable, they do not scale well with the\ndimensionality of the action space, and can be dangerous to apply on hardware.\nWe consider learning a forward dynamics model to predict the result,\n($x_{t+1}$), of taking a particular action, ($u$), given a specific observation\nof the state, ($x_{t}$). With this model we perform internal look-ahead\npredictions of outcomes and seek actions we believe have a reasonable chance of\nsuccess. This method alters the exploratory action space, thereby increasing\nlearning speed and enables higher quality solutions to difficult problems, such\nas robotic locomotion and juggling.\n"]},
{"authors": ["Shawn L. E. Beaulieu", "Sam Kriegman", "Josh C. Bongard"], "title": ["Combating catastrophic forgetting with developmental compression"], "date": ["2018-04-12T02:20:47Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.04286v1"], "summary": ["  Generally intelligent agents exhibit successful behavior across problems in\nseveral settings. Endemic in approaches to realize such intelligence in\nmachines is catastrophic forgetting: sequential learning corrupts knowledge\nobtained earlier in the sequence, or tasks antagonistically compete for system\nresources. Methods for obviating catastrophic forgetting have sought to\nidentify and preserve features of the system necessary to solve one problem\nwhen learning to solve another, or to enforce modularity such that minimally\noverlapping sub-functions contain task specific knowledge. While successful,\nboth approaches scale poorly because they require larger architectures as the\nnumber of training instances grows, causing different parts of the system to\nspecialize for separate subsets of the data. Here we present a method for\naddressing catastrophic forgetting called developmental compression. It\nexploits the mild impacts of developmental mutations to lessen adverse changes\nto previously-evolved capabilities and `compresses' specialized neural networks\ninto a generalized one. In the absence of domain knowledge, developmental\ncompression produces systems that avoid overt specialization, alleviating the\nneed to engineer a bespoke system for every task permutation and suggesting\nbetter scalability than existing approaches. We validate this method on a robot\ncontrol problem and hope to extend this approach to other machine learning\ndomains in the future.\n"]},
{"authors": ["Dylan Hadfield-Menell", "Gillian Hadfield"], "title": ["Incomplete Contracting and AI Alignment"], "date": ["2018-04-12T01:22:50Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.04268v1"], "summary": ["  We suggest that the analysis of incomplete contracting developed by law and\neconomics researchers can provide a useful framework for understanding the AI\nalignment problem and help to generate a systematic approach to finding\nsolutions. We first provide an overview of the incomplete contracting\nliterature and explore parallels between this work and the problem of AI\nalignment. As we emphasize, misalignment between principal and agent is a core\nfocus of economic analysis. We highlight some technical results from the\neconomics literature on incomplete contracts that may provide insights for AI\nalignment researchers. Our core contribution, however, is to bring to bear an\ninsight that economists have been urged to absorb from legal scholars and other\nbehavioral scientists: the fact that human contracting is supported by\nsubstantial amounts of external structure, such as generally available\ninstitutions (culture, law) that can supply implied terms to fill the gaps in\nincomplete contracts. We propose a research agenda for AI alignment work that\nfocuses on the problem of how to build AI that can replicate the human\ncognitive processes that connect individual incomplete contracts with this\nsupporting external structure.\n"]},
{"authors": ["Noam Shazeer", "Mitchell Stern"], "title": ["Adafactor: Adaptive Learning Rates with Sublinear Memory Cost"], "date": ["2018-04-11T21:42:32Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.04235v1"], "summary": ["  In several recently proposed stochastic optimization methods (e.g. RMSProp,\nAdam, Adadelta), parameter updates are scaled by the inverse square roots of\nexponential moving averages of squared past gradients. Maintaining these\nper-parameter second-moment estimators requires memory equal to the number of\nparameters. For the case of neural network weight matrices, we propose\nmaintaining only the per-row and per-column sums of these moving averages, and\nestimating the per-parameter second moments based on these sums. We demonstrate\nempirically that this method produces similar results to the baseline.\nSecondly, we show that adaptive methods can produce larger-than-desired updates\nwhen the decay rate of the second moment accumulator is too slow. We propose\nupdate clipping and a gradually increasing decay rate scheme as remedies.\nCombining these methods and dropping momentum, we achieve comparable results to\nthe published Adam regime in training the Transformer model on the WMT 2014\nEnglish-German machine translation task, while using very little auxiliary\nstorage in the optimizer. Finally, we propose scaling the parameter updates\nbased on the scale of the parameters themselves.\n"]},
{"authors": ["Yue Liu", "Tao Ge", "Kusum S. Mathews", "Heng Ji", "Deborah L. McGuinness"], "title": ["Exploiting Task-Oriented Resources to Learn Word Embeddings for Clinical\n  Abbreviation Expansion"], "date": ["2018-04-11T21:16:39Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.04225v1"], "summary": ["  In the medical domain, identifying and expanding abbreviations in clinical\ntexts is a vital task for both better human and machine understanding. It is a\nchallenging task because many abbreviations are ambiguous especially for\nintensive care medicine texts, in which phrase abbreviations are frequently\nused. Besides the fact that there is no universal dictionary of clinical\nabbreviations and no universal rules for abbreviation writing, such texts are\ndifficult to acquire, expensive to annotate and even sometimes, confusing to\ndomain experts. This paper proposes a novel and effective approach --\nexploiting task-oriented resources to learn word embeddings for expanding\nabbreviations in clinical notes. We achieved 82.27\\% accuracy, close to expert\nhuman performance.\n"]},
{"authors": ["Thomas Spooner", "John Fearnley", "Rahul Savani", "Andreas Koukorinis"], "title": ["Market Making via Reinforcement Learning"], "date": ["2018-04-11T20:46:33Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.04216v1"], "summary": ["  Market making is a fundamental trading problem in which an agent provides\nliquidity by continually offering to buy and sell a security. The problem is\nchallenging due to inventory risk, the risk of accumulating an unfavourable\nposition and ultimately losing money. In this paper, we develop a high-fidelity\nsimulation of limit order book markets, and use it to design a market making\nagent using temporal-difference reinforcement learning. We use a linear\ncombination of tile codings as a value function approximator, and design a\ncustom reward function that controls inventory risk. We demonstrate the\neffectiveness of our approach by showing that our agent outperforms both simple\nbenchmark strategies and a recent online learning approach from the literature.\n"]},
{"authors": ["Nikolaos Aletras", "Benjamin Paul Chamberlain"], "title": ["Predicting Twitter User Socioeconomic Attributes with Network and\n  Language Information"], "date": ["2018-04-11T17:00:27Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.04095v1"], "summary": ["  Inferring socioeconomic attributes of social media users such as occupation\nand income is an important problem in computational social science. Automated\ninference of such characteristics has applications in personalised recommender\nsystems, targeted computational advertising and online political campaigning.\nWhile previous work has shown that language features can reliably predict\nsocioeconomic attributes on Twitter, employing information coming from users'\nsocial networks has not yet been explored for such complex user\ncharacteristics. In this paper, we describe a method for predicting the\noccupational class and the income of Twitter users given information extracted\nfrom their extended networks by learning a low-dimensional vector\nrepresentation of users, i.e. graph embeddings. We use this representation to\ntrain predictive models for occupational class and income. Results on two\npublicly available datasets show that our method consistently outperforms the\nstate-of-the-art methods in both tasks. We also obtain further significant\nimprovements when we combine graph embeddings with textual features,\ndemonstrating that social network and language information are complementary.\n"]},
{"authors": ["Fay\u00e7al Ait Aoudia", "Jakob Hoydis"], "title": ["End-to-End Learning of Communications Systems Without a Channel Model"], "date": ["2018-04-06T14:01:00Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.02276v2"], "summary": ["  The idea of end-to-end learning of communications systems through neural\nnetwork -based autoencoders has the shortcoming that it requires a\ndifferentiable channel model. We present in this paper a novel learning\nalgorithm which alleviates this problem. The algorithm iterates between\nsupervised training of the receiver and reinforcement learning -based training\nof the transmitter. We demonstrate that this approach works as well as fully\nsupervised methods on additive white Gaussian noise (AWGN) and Rayleigh\nblock-fading (RBF) channels. Surprisingly, while our method converges slower on\nAWGN channels than supervised training, it converges faster on RBF channels.\nOur results are a first step towards learning of communications systems over\nany type of channel without prior assumptions.\n"]},
{"authors": ["Ole-Christoffer Granmo"], "title": ["The Tsetlin Machine - A Game Theoretic Bandit Driven Approach to Optimal\n  Pattern Recognition with Propositional Logic"], "date": ["2018-04-04T16:52:34Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.01508v5"], "summary": ["  Although simple individually, artificial neurons provide state-of-the-art\nperformance when interconnected in deep networks. Unknown to many, there exists\nan arguably even simpler and more versatile learning mechanism, namely, the\nTsetlin Automaton. Merely by means of a single integer as memory, it learns the\noptimal action in stochastic environments. In this paper, we introduce the\nTsetlin Machine, which solves complex pattern recognition problems with\neasy-to-interpret propositional formulas, composed by a collective of Tsetlin\nAutomata. To eliminate the longstanding problem of vanishing signal-to-noise\nratio, the Tsetlin Machine orchestrates the automata using a novel game. Our\ntheoretical analysis establishes that the Nash equilibria of the game are\naligned with the propositional formulas that provide optimal pattern\nrecognition accuracy. This translates to learning without local optima, only\nglobal ones. We argue that the Tsetlin Machine finds the propositional formula\nthat provides optimal accuracy, with probability arbitrarily close to unity. In\nfour distinct benchmarks, the Tsetlin Machine outperforms both Neural Networks,\nSVMs, Random Forests, the Naive Bayes Classifier and Logistic Regression. It\nfurther turns out that the accuracy advantage of the Tsetlin Machine increases\nwith lack of data. The Tsetlin Machine has a significant computational\nperformance advantage since both inputs, patterns, and outputs are expressed as\nbits, while recognition of patterns relies on bit manipulation. The combination\nof accuracy, interpretability, and computational simplicity makes the Tsetlin\nMachine a promising tool for a wide range of domains, including safety-critical\nmedicine. Being the first of its kind, we believe the Tsetlin Machine will\nkick-start completely new paths of research, with a potentially significant\nimpact on the AI field and the applications of AI.\n"]},
{"authors": ["Leshem Choshen", "Lior Fox", "Yonatan Loewenstein"], "title": ["DORA The Explorer: Directed Outreaching Reinforcement Action-Selection"], "date": ["2018-04-11T14:21:53Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.04012v1"], "summary": ["  Exploration is a fundamental aspect of Reinforcement Learning, typically\nimplemented using stochastic action-selection. Exploration, however, can be\nmore efficient if directed toward gaining new world knowledge. Visit-counters\nhave been proven useful both in practice and in theory for directed\nexploration. However, a major limitation of counters is their locality. While\nthere are a few model-based solutions to this shortcoming, a model-free\napproach is still missing. We propose $E$-values, a generalization of counters\nthat can be used to evaluate the propagating exploratory value over\nstate-action trajectories. We compare our approach to commonly used RL\ntechniques, and show that using $E$-values improves learning and performance\nover traditional counters. We also show how our method can be implemented with\nfunction approximation to efficiently learn continuous MDPs. We demonstrate\nthis by showing that our approach surpasses state of the art performance in the\nFreeway Atari 2600 game.\n"]},
{"authors": ["Angeliki Lazaridou", "Karl Moritz Hermann", "Karl Tuyls", "Stephen Clark"], "title": ["Emergence of Linguistic Communication from Referential Games with\n  Symbolic and Pixel Input"], "date": ["2018-04-11T13:51:19Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.03984v1"], "summary": ["  The ability of algorithms to evolve or learn (compositional) communication\nprotocols has traditionally been studied in the language evolution literature\nthrough the use of emergent communication tasks. Here we scale up this research\nby using contemporary deep learning methods and by training\nreinforcement-learning neural network agents on referential communication\ngames. We extend previous work, in which agents were trained in symbolic\nenvironments, by developing agents which are able to learn from raw pixel data,\na more challenging and realistic input representation. We find that the degree\nof structure found in the input data affects the nature of the emerged\nprotocols, and thereby corroborate the hypothesis that structured compositional\nlanguage is most likely to emerge when agents perceive the world as being\nstructured.\n"]},
{"authors": ["Kris Cao", "Angeliki Lazaridou", "Marc Lanctot", "Joel Z Leibo", "Karl Tuyls", "Stephen Clark"], "title": ["Emergent Communication through Negotiation"], "date": ["2018-04-11T13:48:08Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.03980v1"], "summary": ["  Multi-agent reinforcement learning offers a way to study how communication\ncould emerge in communities of agents needing to solve specific problems. In\nthis paper, we study the emergence of communication in the negotiation\nenvironment, a semi-cooperative model of agent interaction. We introduce two\ncommunication protocols -- one grounded in the semantics of the game, and one\nwhich is \\textit{a priori} ungrounded and is a form of cheap talk. We show that\nself-interested agents can use the pre-grounded communication channel to\nnegotiate fairly, but are unable to effectively use the ungrounded channel.\nHowever, prosocial agents do learn to use cheap talk to find an optimal\nnegotiating strategy, suggesting that cooperation is necessary for language to\nemerge. We also study communication behaviour in a setting where one agent\ninteracts with agents in a community with different levels of prosociality and\nshow how agent identifiability can aid negotiation.\n"]},
{"authors": ["Cumhur Erkan Tuncali", "James Kapinski", "Hisahiro Ito", "Jyotirmoy V. Deshmukh"], "title": ["Reasoning about Safety of Learning-Enabled Components in Autonomous\n  Cyber-physical Systems"], "date": ["2018-04-11T13:28:07Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.03973v1"], "summary": ["  We present a simulation-based approach for generating barrier certificate\nfunctions for safety verification of cyber-physical systems (CPS) that contain\nneural network-based controllers. A linear programming solver is utilized to\nfind a candidate generator function from a set of simulation traces obtained by\nrandomly selecting initial states for the CPS model. A level set of the\ngenerator function is then selected to act as a barrier certificate for the\nsystem, meaning it demonstrates that no unsafe system states are reachable from\na given set of initial states. The barrier certificate properties are verified\nwith an SMT solver. This approach is demonstrated on a case study in which a\nDubins car model of an autonomous vehicle is controlled by a neural network to\nfollow a given path.\n"]},
{"authors": ["Chiara Di Francescomarino", "Chiara Ghidini", "Fabrizio Maria Maggi", "Williams Rizzi", "Cosimo Damiano Persia"], "title": ["Incremental Predictive Process Monitoring: How to Deal with the\n  Variability of Real Environments"], "date": ["2018-04-11T13:08:26Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.03967v1"], "summary": ["  A characteristic of existing predictive process monitoring techniques is to\nfirst construct a predictive model based on past process executions, and then\nuse it to predict the future of new ongoing cases, without the possibility of\nupdating it with new cases when they complete their execution. This can make\npredictive process monitoring too rigid to deal with the variability of\nprocesses working in real environments that continuously evolve and/or exhibit\nnew variant behaviors over time. As a solution to this problem, we propose the\nuse of algorithms that allow the incremental construction of the predictive\nmodel. These incremental learning algorithms update the model whenever new\ncases become available so that the predictive model evolves over time to fit\nthe current circumstances. The algorithms have been implemented using different\ncase encoding strategies and evaluated on a number of real and synthetic\ndatasets. The results provide a first evidence of the potential of incremental\nlearning strategies for predicting process monitoring in real environments, and\nof the impact of different case encoding strategies in this setting.\n"]},
{"authors": ["Julia C. Freitas", "Puca Huachi V. Penna"], "title": ["A Variable Neighborhood Search for Flying Sidekick Traveling Salesman\n  Problem"], "date": ["2018-04-11T12:21:18Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.03954v1"], "summary": ["  An innovative model of parcel distribution is emerging from the accelerated\nevolution of drones and the effort of logistic companies to proceed faster\ndeliveries at a reduced cost. This new modality originated the Flying Sidekick\nTraveling Salesman Problem (FSTSP) in which customers are served either by a\ntruck or a drone. Additionally, this variant of the Traveling Salesman Problem\n(TSP) presents several new restrictions concerning the drone such as endurance\nand payload capacity. This work proposes a hybrid heuristic that the initial\nsolution is created from the optimal TSP solution reached by a Mixed-Integer\nProgramming (MIP) solver. Next, an implementation of the General Variable\nNeighborhood Search is used to obtain the delivery routes of truck and drone.\nComputational experiments show the potential of the algorithm to improve the\ntotal delivery time up to 67.79%. New best-known solutions (BKS) are\nestablished for all FSTSP instances that results are reported in the\nliterature. Furthermore, a new set of instances based on well-known TSPLIB\ninstances is provided.\n"]},
{"authors": ["Joose Rajam\u00e4ki", "Perttu H\u00e4m\u00e4l\u00e4inen"], "title": ["An Iterative Closest Points Approach to Neural Generative Models"], "date": ["2017-11-16T08:07:47Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.06562v2"], "summary": ["  We present a simple way to learn a transformation that maps samples of one\ndistribution to the samples of another distribution. Our algorithm comprises an\niteration of 1) drawing samples from some simple distribution and transforming\nthem using a neural network, 2) determining pairwise correspondences between\nthe transformed samples and training data (or a minibatch), and 3) optimizing\nthe weights of the neural network being trained to minimize the distances\nbetween the corresponding vectors. This can be considered as a variant of the\nIterative Closest Points (ICP) algorithm, common in geometric computer vision,\nalthough ICP typically operates on sensor point clouds and linear transforms\ninstead of random sample sets and neural nonlinear transforms. We demonstrate\nthe algorithm on simple synthetic data and MNIST data. We furthermore\ndemonstrate that the algorithm is capable of handling distributions with both\ncontinuous and discrete variables.\n"]},
{"authors": ["Kien Do", "Truyen Tran", "Thin Nguyen", "Svetha Venkatesh"], "title": ["Attentional Multilabel Learning over Graphs: A Message Passing Approach"], "date": ["2018-04-01T13:01:24Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.00293v2"], "summary": ["  We address a largely open problem of multilabel classification over graphs.\nUnlike traditional vector input, a graph has rich variable-size substructures\nwhich are related to the labels in some ways. We believe that uncovering these\nrelations might hold the key to classification performance and explainability.\nWe introduce GAML (Graph Attentional Multi-Label learning), a novel graph\nneural network that can handle this problem effectively. GAML regards labels as\nauxiliary nodes and models them in conjunction with the input graph. By\napplying message passing and attention mechanisms to both the label nodes and\nthe input nodes iteratively, GAML can capture the relations between the labels\nand the input subgraphs at various resolution scales. Moreover, our model can\ntake advantage of explicit label dependencies. It also scales linearly with the\nnumber of labels and graph size thanks to our proposed hierarchical attention.\nWe evaluate GAML on an extensive set of experiments with both graph-structured\ninputs and classical unstructured inputs. The results show that GAML\nsignificantly outperforms other competing methods. Importantly, GAML enables\nintuitive visualizations for better understanding of the label-substructure\nrelations and explanation of the model behaviors.\n"]},
{"authors": ["Leshem Choshen", "Omri Abend"], "title": ["Reference-less Measure of Faithfulness for Grammatical Error Correction"], "date": ["2018-04-11T06:10:48Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.03824v1"], "summary": ["  We propose {\\sc USim}, a semantic measure for Grammatical Error Correction\n(GEC) that measures the semantic faithfulness of the output to the source,\nthereby complementing existing reference-less measures (RLMs) for measuring the\noutput's grammaticality. {\\sc USim} operates by comparing the semantic symbolic\nstructure of the source and the correction, without relying on manually-curated\nreferences. Our experiments establish the validity of {\\sc USim}, by showing\nthat (1) semantic annotation can be consistently applied to ungrammatical text;\n(2) valid corrections obtain a high {\\sc USim} similarity score to the source;\nand (3) invalid corrections obtain a lower score.\\footnote{Our code is\navailable in \\url{https://github.com/borgr/USim}.\n"]},
{"authors": ["Rashmi Gangadharaiah", "Balakrishnan Narayanaswamy", "Charles Elkan"], "title": ["Achieving Fluency and Coherency in Task-oriented Dialog"], "date": ["2018-04-11T03:49:22Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.03799v1"], "summary": ["  We consider real world task-oriented dialog settings, where agents need to\ngenerate both fluent natural language responses and correct external actions\nlike database queries and updates. We demonstrate that, when applied to\ncustomer support chat transcripts, Sequence to Sequence (Seq2Seq) models often\ngenerate short, incoherent and ungrammatical natural language responses that\nare dominated by words that occur with high frequency in the training data.\nThese phenomena do not arise in synthetic datasets such as bAbI, where we show\nSeq2Seq models are nearly perfect. We develop techniques to learn embeddings\nthat succinctly capture relevant information from the dialog history, and\ndemonstrate that nearest neighbor based approaches in this learned neural\nembedding space generate more fluent responses. However, we see that these\nmethods are not able to accurately predict when to execute an external action.\nWe show how to combine nearest neighbor and Seq2Seq methods in a hybrid model,\nwhere nearest neighbor is used to generate fluent responses and Seq2Seq type\nmodels ensure dialog coherency and generate accurate external actions. We show\nthat this approach is well suited for customer support scenarios, where agents'\nresponses are typically script-driven, and correct external actions are\ncritically important. The hybrid model on the customer support data achieves a\n78% relative improvement in fluency scores, and a 130% improvement in accuracy\nof external calls.\n"]},
{"authors": ["Jason Lee", "Kyunghyun Cho", "Jason Weston", "Douwe Kiela"], "title": ["Emergent Translation in Multi-Agent Communication"], "date": ["2017-10-12T00:37:27Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.06922v2"], "summary": ["  While most machine translation systems to date are trained on large parallel\ncorpora, humans learn language in a different way: by being grounded in an\nenvironment and interacting with other humans. In this work, we propose a\ncommunication game where two agents, native speakers of their own respective\nlanguages, jointly learn to solve a visual referential task. We find that the\nability to understand and translate a foreign language emerges as a means to\nachieve shared goals. The emergent translation is interactive and multimodal,\nand crucially does not require parallel corpora, but only monolingual,\nindependent text and corresponding images. Our proposed translation model\nachieves this by grounding the source and target languages into a shared visual\nmodality, and outperforms several baselines on both word-level and\nsentence-level translation tasks. Furthermore, we show that agents in a\nmultilingual community learn to translate better and faster than in a bilingual\ncommunication setting.\n"]},
{"authors": ["Sidi Lu", "Lantao Yu", "Weinan Zhang", "Yong Yu"], "title": ["CoT: Cooperative Training for Generative Modeling"], "date": ["2018-04-11T02:10:55Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.03782v1"], "summary": ["  We propose Cooperative Training (CoT) for training generative models that\nmeasure a tractable density function for target data. CoT coordinately trains a\ngenerator $G$ and an auxiliary predictive mediator $M$. The training target of\n$M$ is to estimate a mixture density of the learned distribution $G$ and the\ntarget distribution $P$, and that of $G$ is to minimize the Jensen-Shannon\ndivergence estimated through $M$. CoT achieves independent success without the\nnecessity of pre-training via Maximum Likelihood Estimation or involving\nhigh-variance algorithms like REINFORCE. This low-variance algorithm is\ntheoretically proved to be unbiased for both generative and predictive tasks.\nWe also theoretically and empirically show the superiority of CoT over most\nprevious algorithms, in terms of generative quality and diversity, predictive\ngeneralization ability and computational cost.\n"]},
{"authors": ["Zhongang Qi", "Saeed Khorram", "Fuxin Li"], "title": ["Embedding Deep Networks into Visual Explanations"], "date": ["2017-09-15T18:16:34Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1709.05360v2"], "summary": ["  In this paper, we propose a novel explanation module to explain the\npredictions made by a deep network. The explanation module works by embedding a\nhigh-dimensional deep network layer nonlinearly into a low-dimensional\nexplanation space while retaining faithfulness, so that the original deep\nlearning predictions can be constructed from the few concepts extracted by the\nexplanation module. We then visualize such concepts for human to learn about\nthe high-level concepts that deep learning is using to make decisions. We\npropose an algorithm called Sparse Reconstruction Autoencoder (SRAE) for\nlearning the embedding to the explanation space. SRAE aims to reconstruct part\nof the original feature space while retaining faithfulness. A pull-away term is\napplied to SRAE to make the explanation space more orthogonal. A visualization\nsystem is then introduced for human understanding of the features in the\nexplanation space. The proposed method is applied to explain CNN models in\nimage classification tasks, and several novel metrics are introduced to\nevaluate the performance of explanations quantitatively without human\ninvolvement. Experiments show that the proposed approach generates interesting\nexplanations of the mechanisms CNN use for making predictions.\n"]},
{"authors": ["Ping Chen", "Fei Wu", "Tong Wang", "Wei Ding"], "title": ["A Semantic QA-Based Approach for Text Summarization Evaluation"], "date": ["2017-04-21T15:32:01Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1704.06259v2"], "summary": ["  Many Natural Language Processing and Computational Linguistics applications\ninvolves the generation of new texts based on some existing texts, such as\nsummarization, text simplification and machine translation. However, there has\nbeen a serious problem haunting these applications for decades, that is, how to\nautomatically and accurately assess quality of these applications. In this\npaper, we will present some preliminary results on one especially useful and\nchallenging problem in NLP system evaluation: how to pinpoint content\ndifferences of two text passages (especially for large pas-sages such as\narticles and books). Our idea is intuitive and very different from existing\napproaches. We treat one text passage as a small knowledge base, and ask it a\nlarge number of questions to exhaustively identify all content points in it. By\ncomparing the correctly answered questions from two text passages, we will be\nable to compare their content precisely. The experiment using 2007 DUC\nsummarization corpus clearly shows promising results.\n"]},
{"authors": ["Chen Ma", "Junfeng Wen", "Yoshua Bengio"], "title": ["Universal Successor Representations for Transfer Reinforcement Learning"], "date": ["2018-04-11T00:06:36Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.03758v1"], "summary": ["  The objective of transfer reinforcement learning is to generalize from a set\nof previous tasks to unseen new tasks. In this work, we focus on the transfer\nscenario where the dynamics among tasks are the same, but their goals differ.\nAlthough general value function (Sutton et al., 2011) has been shown to be\nuseful for knowledge transfer, learning a universal value function can be\nchallenging in practice. To attack this, we propose (1) to use universal\nsuccessor representations (USR) to represent the transferable knowledge and (2)\na USR approximator (USRA) that can be trained by interacting with the\nenvironment. Our experiments show that USR can be effectively applied to new\ntasks, and the agent initialized by the trained USRA can achieve the goal\nconsiderably faster than random initialization.\n"]},
{"authors": ["Diptangshu Pandit"], "title": ["3D Pathfinding and Collision Avoidance Using Uneven Search-space\n  Quantization and Visual Cone Search"], "date": ["2017-06-05T13:49:49Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1706.01320v2"], "summary": ["  Pathfinding is a very popular area in computer game development. While\ntwo-dimensional (2D) pathfinding is widely applied in most of the popular game\nengines, little implementation of real three-dimensional (3D) pathfinding can\nbe found. This research presents a dynamic search space optimization algorithm\nwhich can be applied to tessellate 3D search space unevenly, significantly\nreducing the total number of resulting nodes. The algorithm can be used with\npopular pathfinding algorithms in 3D game engines. Furthermore, a simplified\nstandalone 3D pathfinding algorithm is proposed in this paper. The proposed\nalgorithm relies on ray-casting or line vision to generate a feasible path\nduring runtime without requiring division of the search space into a 3D grid.\nBoth of the proposed algorithms are simulated on Unreal Engine to show\ninnerworkings and resultant path comparison with A*. The advantages and\nshortcomings of the proposed algorithms are also discussed along with future\ndirections.\n"]},
{"authors": ["Wojciech Skaba"], "title": ["Binary Space Partitioning as Intrinsic Reward"], "date": ["2018-04-10T16:03:16Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.03611v1"], "summary": ["  An autonomous agent embodied in a humanoid robot, in order to learn from the\noverwhelming flow of raw and noisy sensory, has to effectively reduce the high\nspatial-temporal data dimensionality. In this paper we propose a novel method\nof unsupervised feature extraction and selection with binary space\npartitioning, followed by a computation of information gain that is interpreted\nas intrinsic reward, then applied as immediate-reward signal for the\nreinforcement-learning. The space partitioning is executed by tiny codelets\nrunning on a simulated Turing Machine. The features are represented by concept\nnodes arranged in a hierarchy, in which those of a lower level become the input\nvectors of a higher level.\n"]},
{"authors": ["Christopher P. Burgess", "Irina Higgins", "Arka Pal", "Loic Matthey", "Nick Watters", "Guillaume Desjardins", "Alexander Lerchner"], "title": ["Understanding disentangling in $\u03b2$-VAE"], "date": ["2018-04-10T15:48:18Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.03599v1"], "summary": ["  We present new intuitions and theoretical assessments of the emergence of\ndisentangled representation in variational autoencoders. Taking a\nrate-distortion theory perspective, we show the circumstances under which\nrepresentations aligned with the underlying generative factors of variation of\ndata emerge when optimising the modified ELBO bound in $\\beta$-VAE, as training\nprogresses. From these insights, we propose a modification to the training\nregime of $\\beta$-VAE, that progressively increases the information capacity of\nthe latent code during training. This modification facilitates the robust\nlearning of disentangled representations in $\\beta$-VAE, without the previous\ntrade-off in reconstruction accuracy.\n"]},
{"authors": ["Simone Silvetti", "Laura Nenzi", "Ezio Bartocci", "Luca Bortolussi"], "title": ["A Robust Genetic Algorithm for Learning Temporal Specifications from\n  Data"], "date": ["2017-11-13T17:31:08Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.06202v2"], "summary": ["  We consider the problem of mining signal temporal logical requirements from a\ndataset of regular (good) and anomalous (bad) trajectories of a dynamical\nsystem. We assume the training set to be labeled by human experts and that we\nhave access only to a limited amount of data, typically noisy. We provide a\nsystematic approach to synthesize both the syntactical structure and the\nparameters of the temporal logic formula using a two-steps procedure: first, we\nleverage a novel evolutionary algorithm for learning the structure of the\nformula; second, we perform the parameter synthesis operating on the\nstatistical emulation of the average robustness for a candidate formula w.r.t.\nits parameters. We compare our results with our previous work [{BufoBSBLB14]\nand with a recently proposed decision-tree [bombara_decision_2016] based\nmethod. We present experimental results on two case studies: an anomalous\ntrajectory detection problem of a naval surveillance system and the\ncharacterization of an Ineffective Respiratory effort, showing the usefulness\nof our work.\n"]},
{"authors": ["Ali el Hassouni", "Mark Hoogendoorn", "Martijn van Otterlo", "Eduardo Barbaro"], "title": ["Personalization of Health Interventions using Cluster-Based\n  Reinforcement Learning"], "date": ["2018-04-10T15:38:59Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.03592v1"], "summary": ["  Research has shown that personalization of health interventions can\ncontribute to an improved effectiveness. Reinforcement learning algorithms can\nbe used to perform such tailoring using data that is collected about users.\nLearning is however very fragile for health interventions as only limited time\nis available to learn from the user before disengagement takes place, or before\nthe opportunity to intervene passes. In this paper, we present a cluster-based\nreinforcement learning approach which learns across groups of users. Such an\napproach can speed up the learning process while still giving a level of\npersonalization. The clustering algorithm uses a distance metric over traces of\nstates and rewards. We apply both online and batch learning to learn policies\nover the clusters and introduce a publicly available simulator which we have\ndeveloped to evaluate the approach. The results show batch learning clearly\noutperforms online learning. Furthermore, clustering can be beneficial provided\nthat a proper clustering is found.\n"]},
{"authors": ["Zihao Xiao", "Jianfei Chen", "Jun Zhu"], "title": ["Towards Training Probabilistic Topic Models on Neuromorphic Multi-chip\n  Systems"], "date": ["2018-04-10T15:01:50Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.03578v1"], "summary": ["  Probabilistic topic models are popular unsupervised learning methods,\nincluding probabilistic latent semantic indexing (pLSI) and latent Dirichlet\nallocation (LDA). By now, their training is implemented on general purpose\ncomputers (GPCs), which are flexible in programming but energy-consuming.\nTowards low-energy implementations, this paper investigates their training on\nan emerging hardware technology called the neuromorphic multi-chip systems\n(NMSs). NMSs are very effective for a family of algorithms called spiking\nneural networks (SNNs). We present three SNNs to train topic models. The first\nSNN is a batch algorithm combining the conventional collapsed Gibbs sampling\n(CGS) algorithm and an inference SNN to train LDA. The other two SNNs are\nonline algorithms targeting at both energy- and storage-limited environments.\nThe two online algorithms are equivalent with training LDA by using\nmaximum-a-posterior estimation and maximizing the semi-collapsed likelihood,\nrespectively. They use novel, tailored ordinary differential equations for\nstochastic optimization. We simulate the new algorithms and show that they are\ncomparable with the GPC algorithms, while being suitable for NMS\nimplementation. We also propose an extension to train pLSI and a method to\nprune the network to obey the limited fan-in of some NMSs.\n"]},
{"authors": ["Zhongxiang Wang", "Ali Shafahi", "Ali Haghani"], "title": ["SCDA: School Compatibility Decomposition Algorithm for Solving the\n  Multi-School Bus Routing and Scheduling Problem"], "date": ["2017-11-01T20:29:15Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.00532v3"], "summary": ["  Safely serving the school transportation demand with the minimum number of\nbuses is one of the highest financial goals of school transportation directors.\nTo achieve that objective, a good and efficient way to solve the routing and\nscheduling problem is required. Due to the growth of the computing power, the\nspotlight has been shed on solving the combined problem of the school bus\nrouting and scheduling problem. We show that an integrated multi-school bus\nrouting and scheduling can be formulated with the help of trip compatibility. A\nnovel decomposition algorithm is proposed to solve the integrated model. The\nmerit of this integrated model and the decomposition method is that with the\nconsideration of the trip compatibility, the interrelationship between the\nrouting and scheduling sub-problems will not be lost in the process of\ndecomposition. Results show the proposed decomposed problem could provide the\nsolutions using the same number of buses as the integrated model in much\nshorter time (as little as 0.6%) and that the proposed method can save up to\n26% number of buses from existing research.\n"]},
{"authors": ["Yu Liu", "Fangyin Wei", "Jing Shao", "Lu Sheng", "Junjie Yan", "Xiaogang Wang"], "title": ["Exploring Disentangled Feature Representation Beyond Face Identification"], "date": ["2018-04-10T12:59:53Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.03487v1"], "summary": ["  This paper proposes learning disentangled but complementary face features\nwith minimal supervision by face identification. Specifically, we construct an\nidentity Distilling and Dispelling Autoencoder (D2AE) framework that\nadversarially learns the identity-distilled features for identity verification\nand the identity-dispelled features to fool the verification system. Thanks to\nthe design of two-stream cues, the learned disentangled features represent not\nonly the identity or attribute but the complete input image. Comprehensive\nevaluations further demonstrate that the proposed features not only maintain\nstate-of-the-art identity verification performance on LFW, but also acquire\ncompetitive discriminative power for face attribute recognition on CelebA and\nLFWA. Moreover, the proposed system is ready to semantically control the face\ngeneration/editing based on various identities and attributes in an\nunsupervised manner.\n"]},
{"authors": ["Florian Sikora"], "title": ["The shortest way to visit all metro lines in a city"], "date": ["2017-09-13T13:41:59Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1709.05948v3"], "summary": ["  What if $\\{$a tourist, a train addict, Dr. Sheldon Cooper, somebody who likes\nto waste time$\\}$ wants to visit all metro lines or carriages in a given\nnetwork in a minimum number of steps? We study this problem with an application\nto the metro network of Paris and Tokyo, proposing optimal solutions thanks to\nmathematical programming tools. Quite surprisingly, it appears that you can\nvisit all 16 Parisian metro lines in only 26 steps (we denote by a step the act\nof taking the metro from one station to an adjacent one). Perhaps even more\nsurprisingly, adding the 5 RER lines to these 16 lines does not increase the\nsize of the best solution. It is also possible to visit the 13 lines of (the\ndense network of) Tokyo with only 15 steps.\n"]},
{"authors": ["Wojciech Skaba"], "title": ["Evaluating Actuators in a Purely Information-Theory Based Reward Model"], "date": ["2018-04-10T10:34:36Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.03439v1"], "summary": ["  AGINAO builds its cognitive engine by applying self-programming techniques to\ncreate a hierarchy of interconnected codelets - the tiny pieces of code\nexecuted on a virtual machine. These basic processing units are evaluated for\ntheir applicability and fitness with a notion of reward calculated from\nself-information gain of binary partitioning of the codelet's input\nstate-space. This approach, however, is useless for the evaluation of\nactuators. Instead, a model is proposed in which actuators are evaluated by\nmeasuring the impact that an activation of an effector, and consequently the\nfeedback from the robot sensors, has on average reward received by the\nprocessing units.\n"]},
{"authors": ["Wojciech Skaba"], "title": ["The AGINAO Self-Programming Engine"], "date": ["2018-04-10T10:29:14Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.03437v1"], "summary": ["  The AGINAO is a project to create a human-level artificial general\nintelligence system (HL AGI) embodied in the Aldebaran Robotics' NAO humanoid\nrobot. The dynamical and open-ended cognitive engine of the robot is\nrepresented by an embedded and multi-threaded control program, that is\nself-crafted rather than hand-crafted, and is executed on a simulated Universal\nTuring Machine (UTM). The actual structure of the cognitive engine emerges as a\nresult of placing the robot in a natural preschool-like environment and running\na core start-up system that executes self-programming of the cognitive layer on\ntop of the core layer. The data from the robot's sensory devices supplies the\ntraining samples for the machine learning methods, while the commands sent to\nactuators enable testing hypotheses and getting a feedback. The individual\nself-created subroutines are supposed to reflect the patterns and concepts of\nthe real world, while the overall program structure reflects the spatial and\ntemporal hierarchy of the world dependencies. This paper focuses on the details\nof the self-programming approach, limiting the discussion of the applied\ncognitive architecture to a necessary minimum.\n"]},
{"authors": ["Lin Qiu", "Hao Zhou", "Yanru Qu", "Weinan Zhang", "Suoheng Li", "Shu Rong", "Dongyu Ru", "Lihua Qian", "Kewei Tu", "Yong Yu"], "title": ["QA4IE: A Question Answering based Framework for Information Extraction"], "date": ["2018-04-10T08:31:03Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.03396v1"], "summary": ["  Information Extraction (IE) refers to automatically extracting structured\nrelation tuples from unstructured texts. Common IE solutions, including\nRelation Extraction (RE) and open IE systems, can hardly handle cross-sentence\ntuples, and are severely restricted by limited relation types as well as\ninformal relation specifications (e.g., free-text based relation tuples). In\norder to overcome these weaknesses, we propose a novel IE framework named\nQA4IE, which leverages the flexible question answering (QA) approaches to\nproduce high quality relation triples across sentences. Based on the framework,\nwe develop a large IE benchmark with high quality human evaluation. This\nbenchmark contains 293K documents, 2M golden relation triples, and 636 relation\ntypes. We compare our system with some IE baselines on our benchmark and the\nresults show that our system achieves great improvements.\n"]},
{"authors": ["Daniel Harari", "Joshua B. Tenenbaum", "Shimon Ullman"], "title": ["Discovery and usage of joint attention in images"], "date": ["2018-04-10T07:04:19Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.04604v1"], "summary": ["  Joint visual attention is characterized by two or more individuals looking at\na common target at the same time. The ability to identify joint attention in\nscenes, the people involved, and their common target, is fundamental to the\nunderstanding of social interactions, including others' intentions and goals.\nIn this work we deal with the extraction of joint attention events, and the use\nof such events for image descriptions. The work makes two novel contributions.\nFirst, our extraction algorithm is the first which identifies joint visual\nattention in single static images. It computes 3D gaze direction, identifies\nthe gaze target by combining gaze direction with a 3D depth map computed for\nthe image, and identifies the common gaze target. Second, we use a human study\nto demonstrate the sensitivity of humans to joint attention, suggesting that\nthe detection of such a configuration in an image can be useful for\nunderstanding the image, including the goals of the agents and their joint\nactivity, and therefore can contribute to image captioning and related tasks.\n"]},
{"authors": ["Tom\u00e1\u0161 Kliegr", "\u0160t\u011bp\u00e1n Bahn\u00edk", "Johannes F\u00fcrnkranz"], "title": ["A review of possible effects of cognitive biases on interpretation of\n  rule-based machine learning models"], "date": ["2018-04-09T13:28:56Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.02969v2"], "summary": ["  This paper investigates to what extent do cognitive biases affect human\nunderstanding of interpretable machine learning models, in particular of rules\ndiscovered from data. Twenty cognitive biases (illusions, effects) are covered,\nas are possibly effective debiasing techniques that can be adopted by designers\nof machine learning algorithms and software. While there seems no universal\napproach for eliminating all the identified cognitive biases, it follows from\nour analysis that the effect of most biases can be ameliorated by making\nrule-based models more concise. Due to lack of previous research, our review\ntransfers general results obtained in cognitive psychology to the domain of\nmachine learning. It needs to be succeeded by empirical studies specifically\naimed at the machine learning domain.\n"]},
{"authors": ["John Angel", "Naveen Sundar Govindarajulu", "Selmer Bringsjord"], "title": ["Toward Formalizing Teleportation of Pedagogical Artificial Agents"], "date": ["2018-04-10T05:27:49Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.03342v1"], "summary": ["  Our paradigm for the use of artificial agents to teach requires among other\nthings that they persist through time in their interaction with human students,\nin such a way that they \"teleport\" or \"migrate\" from an embodiment at one time\nt to a different embodiment at later time t'. In this short paper, we report on\ninitial steps toward the formalization of such teleportation, in order to\nenable an overseeing AI system to establish, mechanically, and verifiably, that\nthe human students in question will likely believe that the very same\nartificial agent has persisted across such times despite the different\nembodiments.\n"]},
{"authors": ["Saba Heidari Gheshlaghi", "Abolfazl Madani", "AmirAbolfazl Suratgar", "Fardin Faraji"], "title": ["Segmentation of Multiple Sclerosis lesion in brain MR images using Fuzzy\n  C-Means"], "date": ["2018-04-10T04:36:58Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.03282v1"], "summary": ["  Magnetic resonance images (MRI) play an important role in supporting and\nsubstituting clinical information in the diagnosis of multiple sclerosis (MS)\ndisease by presenting lesion in brain MR images. In this paper, an algorithm\nfor MS lesion segmentation from Brain MR Images has been presented. We revisit\nthe modification of properties of fuzzy -c means algorithms and the canny edge\ndetection. By changing and reformed fuzzy c-means clustering algorithms, and\napplying canny contraction principle, a relationship between MS lesions and\nedge detection is established. For the special case of FCM, we derive a\nsufficient condition and clustering parameters, allowing identification of them\nas (local) minima of the objective function.\n"]},
{"authors": ["Zhenxin Wang", "Sayan Sarcar", "Jingxin Liu", "Yilin Zheng", "Xiangshi Ren"], "title": ["Outline Objects using Deep Reinforcement Learning"], "date": ["2018-04-10T03:25:31Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.04603v1"], "summary": ["  Image segmentation needs both local boundary position information and global\nobject context information. The performance of the recent state-of-the-art\nmethod, fully convolutional networks, reaches a bottleneck due to the neural\nnetwork limit after balancing between the two types of information\nsimultaneously in an end-to-end training style. To overcome this problem, we\ndivide the semantic image segmentation into temporal subtasks. First, we find a\npossible pixel position of some object boundary; then trace the boundary at\nsteps within a limited length until the whole object is outlined. We present\nthe first deep reinforcement learning approach to semantic image segmentation,\ncalled DeepOutline, which outperforms other algorithms in Coco detection\nleaderboard in the middle and large size person category in Coco val2017\ndataset. Meanwhile, it provides an insight into a divide and conquer way by\nreinforcement learning on computer vision problems.\n"]},
{"authors": ["Takumi Ichimura", "Kousuke Tanabe"], "title": ["An Estimation of Favorite Value in Emotion Generating Calculation by\n  Fuzzy Petri Net"], "date": ["2018-04-10T02:43:35Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.03994v1"], "summary": ["  Emotion Generating Calculations (EGC) method based on the Emotion Eliciting\nCondition Theory can decide whether an event arouses pleasure or not and\nquantify the degree under the event. An event in the form of Case Frame\nrepresentation is classified into 12 types of calculations. However, the weak\npoint in EGC is Favorite Value (FV) as the personal taste information. In order\nto improve the problem, this paper challenges to establish a learning method to\nlearn speaker's taste information from dialog. Especially, the learning method\nemploys Fuzzy Petri Net to find an appropriate FV to a word which has the\nunknown FV. This paper discusses the effective learning method to improve a\nweak point of EGC when a missing value of FV exists.\n"]},
{"authors": ["Yingqi Qu", "Jie Liu", "Liangyi Kang", "Qinfeng Shi", "Dan Ye"], "title": ["Question Answering over Freebase via Attentive RNN with Similarity\n  Matrix based CNN"], "date": ["2018-04-10T02:39:41Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.03317v1"], "summary": ["  With the rapid growth of knowledge bases (KBs), question answering over\nknowledge base, a.k.a. KBQA has drawn huge attention in recent years. Most of\nthe existing KBQA methods follow so called encoder-compare framework. They map\nthe question and the KB facts to a common embedding space, in which the\nsimilarity between the question vector and the fact vectors can be conveniently\ncomputed. This, however, inevitably loses original words interaction\ninformation. To preserve more original information, we propose an attentive\nrecurrent neural network with similarity matrix based convolutional neural\nnetwork (AR-SMCNN) model, which is able to capture comprehensive hierarchical\ninformation utilizing the advantages of both RNN and CNN. We use RNN to capture\nsemantic-level correlation by its sequential modeling nature, and use an\nattention mechanism to keep track of the entities and relations simultaneously.\nMeanwhile, we use a similarity matrix based CNN with two-directions pooling to\nextract literal-level words interaction matching utilizing CNNs strength of\nmodeling spatial correlation among data. Moreover, we have developed a new\nheuristic extension method for entity detection, which significantly decreases\nthe effect of noise. Our method has outperformed the state-of-the-arts on\nSimpleQuestion benchmark in both accuracy and efficiency.\n"]},
{"authors": ["Daniel J. Buehrer"], "title": ["A Mathematical Framework for Superintelligent Machines"], "date": ["2018-04-10T01:26:00Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.03301v1"], "summary": ["  We describe a class calculus that is expressive enough to describe and\nimprove its own learning process. It can design and debug programs that satisfy\ngiven input/output constraints, based on its ontology of previously learned\nprograms. It can improve its own model of the world by checking the actual\nresults of the actions of its robotic activators. For instance, it could check\nthe black box of a car crash to determine if it was probably caused by electric\nfailure, a stuck electronic gate, dark ice, or some other condition that it\nmust add to its ontology in order to meet its sub-goal of preventing such\ncrashes in the future. Class algebra basically defines the eval/eval-1 Galois\nconnection between the residuated Boolean algebras of 1. equivalence classes\nand super/sub classes of class algebra type expressions, and 2. a residual\nBoolean algebra of biclique relationships. It distinguishes which formulas are\nequivalent, entailed, or unrelated, based on a simplification algorithm that\nmay be thought of as producing a unique pair of Karnaugh maps that describe the\nrough sets of maximal bicliques of relations. Such maps divide the\nn-dimensional space of up to 2n-1 conjunctions of up to n propositions into\nclopen (i.e. a closed set of regions and their boundaries) causal sets. This\nclass algebra is generalized to type-2 fuzzy class algebra by using relative\nfrequencies as probabilities. It is also generalized to a class calculus\ninvolving assignments that change the states of programs.\n  INDEX TERMS 4-valued Boolean Logic, Artificial Intelligence, causal sets,\nclass algebra, consciousness, intelligent design, IS-A hierarchy, mathematical\nlogic, meta-theory, pointless topological space, residuated lattices, rough\nsets, type-2 fuzzy sets\n"]},
{"authors": ["Rohan Anil", "Gabriel Pereyra", "Alexandre Passos", "Robert Ormandi", "George E. Dahl", "Geoffrey E. Hinton"], "title": ["Large scale distributed neural network training through online\n  distillation"], "date": ["2018-04-09T20:56:03Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.03235v1"], "summary": ["  Techniques such as ensembling and distillation promise model quality\nimprovements when paired with almost any base model. However, due to increased\ntest-time cost (for ensembles) and increased complexity of the training\npipeline (for distillation), these techniques are challenging to use in\nindustrial settings. In this paper we explore a variant of distillation which\nis relatively straightforward to use as it does not require a complicated\nmulti-stage setup or many new hyperparameters. Our first claim is that online\ndistillation enables us to use extra parallelism to fit very large datasets\nabout twice as fast. Crucially, we can still speed up training even after we\nhave already reached the point at which additional parallelism provides no\nbenefit for synchronous or asynchronous stochastic gradient descent. Two neural\nnetworks trained on disjoint subsets of the data can share knowledge by\nencouraging each model to agree with the predictions the other model would have\nmade. These predictions can come from a stale version of the other model so\nthey can be safely computed using weights that only rarely get transmitted. Our\nsecond claim is that online distillation is a cost-effective way to make the\nexact predictions of a model dramatically more reproducible. We support our\nclaims using experiments on the Criteo Display Ad Challenge dataset, ImageNet,\nand the largest to-date dataset used for neural language modeling, containing\n$6\\times 10^{11}$ tokens and based on the Common Crawl repository of web data.\n"]},
{"authors": ["Victor Dibia", "\u00c7a\u011fatay Demiralp"], "title": ["Data2Vis: Automatic Generation of Data Visualizations Using\n  Sequence-to-Sequence Recurrent Neural Networks"], "date": ["2018-04-09T17:48:23Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.03126v1"], "summary": ["  Rapidly creating effective visualizations using expressive grammars is\nchallenging for users who have limited time and limited skills in statistics\nand data visualization. Even high-level, dedicated visualization tools often\nrequire users to manually select among data attributes, decide which\ntransformations to apply, and specify mappings between visual encoding\nvariables and raw or transformed attributes. In this paper, we introduce\nData2Vis, a neural translation model, for automatically generating\nvisualizations from given datasets. We formulate visualization generation as a\nsequence to sequence translation problem where data specification is mapped to\na visualization specification in a declarative language (Vega-Lite). To this\nend, we train a multilayered Long Short-Term Memory (LSTM) model with attention\non a corpus of visualization specifications. Qualitative results show that our\nmodel learns the vocabulary and syntax for a valid visualization specification,\nappropriate transformations (count, bins, mean) and how to use common data\nselection patterns that occur within data visualizations. Our model generates\nvisualizations that are comparable to manually-created visualizations in a\nfraction of the time, with potential to learn more complex visualization\nstrategies at scale.\n"]},
{"authors": ["Jing Qian", "Mai ElSherief", "Elizabeth M. Belding", "William Yang Wang"], "title": ["Leveraging Intra-User and Inter-User Representation Learning for\n  Automated Hate Speech Detection"], "date": ["2018-04-09T17:46:33Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.03124v1"], "summary": ["  Hate speech detection is a critical, yet challenging problem in Natural\nLanguage Processing (NLP). Despite the existence of numerous studies dedicated\nto the development of NLP hate speech detection approaches, the accuracy is\nstill poor. The central problem is that social media posts are short and noisy,\nand most existing hate speech detection solutions take each post as an isolated\ninput instance, which is likely to yield high false positive and negative\nrates. In this paper, we radically improve automated hate speech detection by\npresenting a novel model that leverages intra-user and inter-user\nrepresentation learning for robust hate speech detection on Twitter. In\naddition to the target Tweet, we collect and analyze the user's historical\nposts to model intra-user Tweet representations. To suppress the noise in a\nsingle Tweet, we also model the similar Tweets posted by all other users with\nreinforced inter-user representation learning techniques. Experimentally, we\nshow that leveraging these two representations can significantly improve the\nf-score of a strong bidirectional LSTM baseline model by 10.1%.\n"]},
{"authors": ["Jiri Fajtl", "Vasileios Argyriou", "Dorothy Monekosso", "Paolo Remagnino"], "title": ["AMNet: Memorability Estimation with Attention"], "date": ["2018-04-09T17:28:00Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.03115v1"], "summary": ["  In this paper we present the design and evaluation of an end-to-end\ntrainable, deep neural network with a visual attention mechanism for\nmemorability estimation in still images. We analyze the suitability of transfer\nlearning of deep models from image classification to the memorability task.\nFurther on we study the impact of the attention mechanism on the memorability\nestimation and evaluate our network on the SUN Memorability and the LaMem\ndatasets. Our network outperforms the existing state of the art models on both\ndatasets in terms of the Spearman's rank correlation as well as the mean\nsquared error, closely matching human consistency.\n"]},
{"authors": ["Parikshit Gopalan", "Vatsal Sharan", "Udi Wieder"], "title": ["Faster Anomaly Detection via Matrix Sketching"], "date": ["2018-04-09T15:47:36Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.03065v1"], "summary": ["  We present efficient streaming algorithms to compute two commonly used\nanomaly measures: the rank-$k$ leverage scores (aka Mahalanobis distance) and\nthe rank-$k$ projection distance, in the row-streaming model. We show that\ncommonly used matrix sketching techniques such as the Frequent Directions\nsketch and random projections can be used to approximate these measures. Our\nmain technical contribution is to prove matrix perturbation inequalities for\noperators arising in the computation of these measures.\n"]},
{"authors": ["Igor Adamski", "Robert Adamski", "Tomasz Grel", "Adam J\u0119drych", "Kamil Kaczmarek", "Henryk Michalewski"], "title": ["Distributed Deep Reinforcement Learning: Learn how to play Atari games\n  in 21 minutes"], "date": ["2018-01-09T09:39:29Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.02852v2"], "summary": ["  We present a study in Distributed Deep Reinforcement Learning (DDRL) focused\non scalability of a state-of-the-art Deep Reinforcement Learning algorithm\nknown as Batch Asynchronous Advantage ActorCritic (BA3C). We show that using\nthe Adam optimization algorithm with a batch size of up to 2048 is a viable\nchoice for carrying out large scale machine learning computations. This,\ncombined with careful reexamination of the optimizer's hyperparameters, using\nsynchronous training on the node level (while keeping the local, single node\npart of the algorithm asynchronous) and minimizing the memory footprint of the\nmodel, allowed us to achieve linear scaling for up to 64 CPU nodes. This\ncorresponds to a training time of 21 minutes on 768 CPU cores, as opposed to 10\nhours when using a single node with 24 cores achieved by a baseline single-node\nimplementation.\n"]},
{"authors": ["Marco Cavallo", "\u00c7a\u011fatay Demiralp"], "title": ["Clustrophile 2: Guided Visual Clustering Analysis"], "date": ["2018-04-09T15:05:56Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.03048v1"], "summary": ["  Data clustering is a common unsupervised learning method frequently used in\nexploratory data analysis. However, identifying relevant structures in\nunlabeled, high-dimensional data is nontrivial, requiring iterative\nexperimentation with clustering parameters as well as data features and\ninstances. The space of possible clusterings for a typical dataset is vast, and\nnavigating in this vast space is also challenging. The absence of ground-truth\nlabels makes it impossible to define an optimal solution, thus requiring user\njudgment to establish what can be considered a satisfiable clustering result.\nData scientists need adequate interactive tools to effectively explore and\nnavigate the large space of clusterings so as to improve the effectiveness of\nexploratory clustering analysis. We introduce \\textit{Clustrophile 2}, a new\ninteractive tool for guided clustering analysis. \\textit{Clustrophile 2} guides\nusers in clustering-based exploratory analysis, adapts user feedback to improve\nuser guidance, facilitates the interpretation of clusters, and helps quickly\nreason about differences between clusterings. To this end, \\textit{Clustrophile\n2} contributes a novel feature, the clustering tour, to help users choose\nclustering parameters and assess the quality of different clustering results in\nrelation to current analysis goals and user expectations. We evaluate\n\\textit{Clustrophile 2} through a user study with 12 data scientists, who used\nour tool to explore and interpret sub-cohorts in a dataset of Parkinson's\ndisease patients. Results suggest that \\textit{Clustrophile 2} improves the\nspeed and effectiveness of exploratory clustering analysis for both experts and\nnon-experts.\n"]},
{"authors": ["Giovanni Saponaro", "Pedro Vicente", "Atabak Dehban", "Lorenzo Jamone", "Alexandre Bernardino", "Jos\u00e9 Santos-Victor"], "title": ["Learning at the Ends: From Hand to Tool Affordances in Humanoid Robots"], "date": ["2018-04-09T14:28:15Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.03022v1"], "summary": ["  One of the open challenges in designing robots that operate successfully in\nthe unpredictable human environment is how to make them able to predict what\nactions they can perform on objects, and what their effects will be, i.e., the\nability to perceive object affordances. Since modeling all the possible world\ninteractions is unfeasible, learning from experience is required, posing the\nchallenge of collecting a large amount of experiences (i.e., training data).\nTypically, a manipulative robot operates on external objects by using its own\nhands (or similar end-effectors), but in some cases the use of tools may be\ndesirable, nevertheless, it is reasonable to assume that while a robot can\ncollect many sensorimotor experiences using its own hands, this cannot happen\nfor all possible human-made tools.\n  Therefore, in this paper we investigate the developmental transition from\nhand to tool affordances: what sensorimotor skills that a robot has acquired\nwith its bare hands can be employed for tool use? By employing a visual and\nmotor imagination mechanism to represent different hand postures compactly, we\npropose a probabilistic model to learn hand affordances, and we show how this\nmodel can generalize to estimate the affordances of previously unseen tools,\nultimately supporting planning, decision-making and tool selection tasks in\nhumanoid robots. We present experimental results with the iCub humanoid robot,\nand we publicly release the collected sensorimotor data in the form of a hand\nposture affordances dataset.\n"]},
{"authors": ["Yang Yu", "Kazi Saidul Hasan", "Mo Yu", "Wei Zhang", "Zhiguo Wang"], "title": ["Knowledge Base Relation Detection via Multi-View Matching"], "date": ["2018-03-01T20:17:02Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.00612v2"], "summary": ["  Relation detection is a core component for Knowledge Base Question Answering\n(KBQA). In this paper, we propose a KB relation detection model via multi-view\nmatching which utilizes more useful information extracted from question and KB.\nThe matching inside each view is through multiple perspectives to compare two\ninput texts thoroughly. All these components are designed in an end-to-end\ntrainable neural network model. Experiments on SimpleQuestions and WebQSP yield\nstate-of-the-art results.\n"]},
{"authors": ["David Manheim", "Scott Garrabrant"], "title": ["Categorizing Variants of Goodhart's Law"], "date": ["2018-03-13T01:15:39Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.04585v3"], "summary": ["  There are several distinct failure modes for overoptimization of systems on\nthe basis of metrics. This occurs when a metric which can be used to improve a\nsystem is used to an extent that further optimization is ineffective or\nharmful, and is sometimes termed Goodhart's Law. This class of failure is often\npoorly understood, partly because terminology for discussing them is ambiguous,\nand partly because discussion using this ambiguous terminology ignores\ndistinctions between different failure modes of this general type. This paper\nexpands on an earlier discussion by Garrabrant, which notes there are \"(at\nleast) four different mechanisms\" that relate to Goodhart's Law. This paper is\nintended to explore these mechanisms further, and specify more clearly how they\noccur. This discussion should be helpful in better understanding these types of\nfailures in economic regulation, in public policy, in machine learning, and in\nArtificial Intelligence alignment. The importance of Goodhart effects depends\non the amount of power directed towards optimizing the proxy, and so the\nincreased optimization power offered by artificial intelligence makes it\nespecially critical for that field.\n"]},
{"authors": ["J. H. van Hateren"], "title": ["A theory of consciousness: computation, algorithm, and neurobiological\n  realization"], "date": ["2018-04-09T13:02:35Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.02952v1"], "summary": ["  The most enigmatic aspect of consciousness is the fact that it is felt, as a\nsubjective sensation. This particular aspect is explained by the theory\nproposed here. The theory encompasses both the computation that is presumably\ninvolved and the way in which that computation may be realized in the brain's\nneurobiology. It is assumed that the brain makes an internal estimate of an\nindividual's own evolutionary fitness, which can be shown to produce an\nirreducible, distinct cause. Communicating components of the fitness estimate\n(either for external or internal use) requires inverting them. Such inversion\ncan be performed by the thalamocortical feedback loop in the mammalian brain,\nif that loop is operating in a switched, dual-stage mode. A first\n(nonconscious) stage produces forward estimates, whereas the second (conscious)\nstage inverts those estimates. It is argued that inversion produces\nirreducible, distinct, and spatially localized causes, which are plausibly\nsensed as the feeling of consciousness.\n"]},
{"authors": ["Christoph Benzm\u00fcller", "Xavier Parent"], "title": ["First Experiments with a Flexible Infrastructure for Normative Reasoning"], "date": ["2018-04-09T11:55:22Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.02929v1"], "summary": ["  A flexible infrastructure for normative reasoning is outlined. A small-scale\ndemonstrator version of the envisioned system has been implemented in the proof\nassistant Isabelle/HOL by utilising the first authors universal logical\nreasoning approach based on shallow semantical embeddings in meta-logic HOL.\nThe need for such a flexible reasoning infrastructure is motivated and\nillustrated with a contrary-to-duty example scenario selected from the General\nData Protection Regulation.\n"]},
{"authors": ["Seunghyun Yoon", "Joongbo Shin", "Kyomin Jung"], "title": ["Learning to Rank Question-Answer Pairs using Hierarchical Recurrent\n  Encoder with Latent Topic Clustering"], "date": ["2017-10-10T07:26:50Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.03430v3"], "summary": ["  In this paper, we propose a novel end-to-end neural architecture for ranking\ncandidate answers, that adapts a hierarchical recurrent neural network and a\nlatent topic clustering module. With our proposed model, a text is encoded to a\nvector representation from an word-level to a chunk-level to effectively\ncapture the entire meaning. In particular, by adapting the hierarchical\nstructure, our model shows very small performance degradations in longer text\ncomprehension while other state-of-the-art recurrent neural network models\nsuffer from it. Additionally, the latent topic clustering module extracts\nsemantic information from target samples. This clustering module is useful for\nany text related tasks by allowing each data sample to find its nearest topic\ncluster, thus helping the neural network model analyze the entire data. We\nevaluate our models on the Ubuntu Dialogue Corpus and consumer electronic\ndomain question answering dataset, which is related to Samsung products. The\nproposed model shows state-of-the-art results for ranking question-answer\npairs.\n"]},
{"authors": ["Duc Thien Nguyen", "Akshat Kumar", "Hoong Chuin Lau"], "title": ["Policy Gradient With Value Function Approximation For Collective\n  Multiagent Planning"], "date": ["2018-04-09T09:45:29Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.02884v1"], "summary": ["  Decentralized (PO)MDPs provide an expressive framework for sequential\ndecision making in a multiagent system. Given their computational complexity,\nrecent research has focused on tractable yet practical subclasses of\nDec-POMDPs. We address such a subclass called CDEC-POMDP where the collective\nbehavior of a population of agents affects the joint-reward and environment\ndynamics. Our main contribution is an actor-critic (AC) reinforcement learning\nmethod for optimizing CDEC-POMDP policies. Vanilla AC has slow convergence for\nlarger problems. To address this, we show how a particular decomposition of the\napproximate action-value function over agents leads to effective updates, and\nalso derive a new way to train the critic based on local reward signals.\nComparisons on a synthetic benchmark and a real-world taxi fleet optimization\nproblem show that our new AC approach provides better quality solutions than\nprevious best approaches.\n"]},
{"authors": ["Bing Zeng", "Xinyu Li", "Liang Gao", "Yuyan Zhang"], "title": ["Whale swarm algorithm with iterative counter for multimodal function\n  optimization"], "date": ["2018-04-09T07:29:33Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.02851v1"], "summary": ["  Most real-world optimization problems often come with multiple global optima\nor local optima. Therefore, increasing niching metaheuristic algorithms, which\ndevote to finding multiple optima in a single run, are developed to solve these\nmultimodal optimization problems. However, there are two difficulties urgently\nto be solved for most existing niching metaheuristic algorithms: how to set the\noptimal values of niching parameters for different optimization problems, and\nhow to jump out of the local optima efficiently. These two difficulties limited\ntheir practicality largely. Based on Whale Swarm Algorithm (WSA) we proposed\npreviously, this paper presents a new multimodal optimizer named WSA with\nIterative Counter (WSA-IC) to address these two difficulties. In the one hand,\nWSA-IC improves the iteration rule of the original WSA for multimodal\noptimization, which removes the need of specifying different values of\nattenuation coefficient for different problems to form multiple subpopulations,\nwithout introducing any niching parameter. In the other hand, WSA-IC enables\nthe identification of extreme point during iterations relying on two new\nparameters (i.e., stability threshold Ts and fitness threshold Tf), to jump out\nof the located extreme point. The proposed WSA-IC is compared with several\nstate-of-the-art niching metaheuristic algorithms on CEC2015 niching benchmark\ntest functions and five additional classical multimodal functions with high\ndimensions. The experimental results demonstrate that WSA-IC statistically\noutperforms other niching metaheuristic algorithms on most test functions.\n"]},
{"authors": ["Zhang-Wei Hong", "Shih-Yang Su", "Tzu-Yun Shann", "Yi-Hsiang Chang", "Chun-Yi Lee"], "title": ["A Deep Policy Inference Q-Network for Multi-Agent Systems"], "date": ["2017-12-21T11:53:35Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1712.07893v2"], "summary": ["  We present DPIQN, a deep policy inference Q-network that targets multi-agent\nsystems composed of controllable agents, collaborators, and opponents that\ninteract with each other. We focus on one challenging issue in such\nsystems---modeling agents with varying strategies---and propose to employ\n\"policy features\" learned from raw observations (e.g., raw images) of\ncollaborators and opponents by inferring their policies. DPIQN incorporates the\nlearned policy features as a hidden vector into its own deep Q-network (DQN),\nsuch that it is able to predict better Q values for the controllable agents\nthan the state-of-the-art deep reinforcement learning models. We further\npropose an enhanced version of DPIQN, called deep recurrent policy inference\nQ-network (DRPIQN), for handling partial observability. Both DPIQN and DRPIQN\nare trained by an adaptive training procedure, which adjusts the network's\nattention to learn the policy features and its own Q-values at different phases\nof the training process. We present a comprehensive analysis of DPIQN and\nDRPIQN, and highlight their effectiveness and generalizability in various\nmulti-agent settings. Our models are evaluated in a classic soccer game\ninvolving both competitive and collaborative scenarios. Experimental results\nperformed on 1 vs. 1 and 2 vs. 2 games show that DPIQN and DRPIQN demonstrate\nsuperior performance to the baseline DQN and deep recurrent Q-network (DRQN)\nmodels. We also explore scenarios in which collaborators or opponents\ndynamically change their policies, and show that DPIQN and DRPIQN do lead to\nbetter overall performance in terms of stability and mean scores.\n"]},
{"authors": ["Shin Kamada", "Takumi Ichimura"], "title": ["A Generation Method of Immunological Memory in Clonal Selection\n  Algorithm by using Restricted Boltzmann Machines"], "date": ["2018-04-09T05:14:26Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.02816v1"], "summary": ["  Recently, a high technique of image processing is required to extract the\nimage features in real time. In our research, the tourist subject data are\ncollected from the Mobile Phone based Participatory Sensing (MPPS) system. Each\nrecord consists of image files with GPS, geographic location name, user's\nnumerical evaluation, and comments written in natural language at sightseeing\nspots where a user really visits. In our previous research, the famous\nlandmarks in sightseeing spot can be detected by Clonal Selection Algorithm\nwith Immunological Memory Cell (CSAIM). However, some landmarks was not\ndetected correctly by the previous method because they didn't have enough\namount of information for the feature extraction. In order to improve the\nweakness, we propose the generation method of immunological memory by\nRestricted Boltzmann Machines. To verify the effectiveness of the method, some\nexperiments for classification of the subjective data are executed by using\nmachine learning tools for Deep Learning.\n"]},
{"authors": ["Tuomas Haarnoja", "Kristian Hartikainen", "Pieter Abbeel", "Sergey Levine"], "title": ["Latent Space Policies for Hierarchical Reinforcement Learning"], "date": ["2018-04-09T04:00:30Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.02808v1"], "summary": ["  We address the problem of learning hierarchical deep neural network policies\nfor reinforcement learning. Our aim is to design a hierarchical reinforcement\nlearning algorithm that can construct hierarchical representations in bottom-up\nlayerwise fashion. In contrast to methods that explicitly restrict or cripple\nlower layers of a hierarchy to force them to use higher-level modulating\nsignals, each layer in our framework is trained to directly solve the task, but\nacquires a range of diverse strategies via a maximum entropy reinforcement\nlearning objective. Each layer is also augmented with latent random variables,\nwhich are sampled from a prior distribution during the training of that layer.\nThe maximum entropy objective causes these latent variables to be incorporated\ninto the layer's policy, and the higher level layer can directly control the\nbehavior of the lower layer through this latent space. Furthermore, by\nconstraining the mapping from latent variables to actions to be invertible,\nhigher layers retain full expressivity: neither the higher layers nor the lower\nlayers are constrained in their behavior. Our experimental evaluation\ndemonstrates that we can improve on the performance of single-layer policies on\nstandard benchmark tasks simply by adding additional layers, and that our\nmethod can solve more complex sparse-reward tasks by learning higher-level\npolicies on top of high-entropy skills optimized for simple low-level\nobjectives.\n"]},
{"authors": ["Lei Tai", "Jingwei Zhang", "Ming Liu", "Joschka Boedecker", "Wolfram Burgard"], "title": ["A Survey of Deep Network Solutions for Learning Control in Robotics:\n  From Reinforcement to Imitation"], "date": ["2016-12-21T14:31:47Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1612.07139v4"], "summary": ["  Deep learning techniques have been widely applied, achieving state-of-the-art\nresults in various fields of study. This survey focuses on deep learning\nsolutions that target learning control policies for robotics applications. We\ncarry out our discussions on the two main paradigms for learning control with\ndeep networks: deep reinforcement learning and imitation learning. For deep\nreinforcement learning (DRL), we begin from traditional reinforcement learning\nalgorithms, showing how they are extended to the deep context and effective\nmechanisms that could be added on top of the DRL algorithms. We then introduce\nrepresentative works that utilize DRL to solve navigation and manipulation\ntasks in robotics. We continue our discussion on methods addressing the\nchallenge of the reality gap for transferring DRL policies trained in\nsimulation to real-world scenarios, and summarize robotics simulation platforms\nfor conducting DRL research. For imitation leaning, we go through its three\nmain categories, behavior cloning, inverse reinforcement learning and\ngenerative adversarial imitation learning, by introducing their formulations\nand their corresponding robotics applications. Finally, we discuss the open\nchallenges and research frontiers.\n"]},
{"authors": ["Jiaxuan Zhuo", "Zeyu Chen", "Jianhuang Lai", "Guangcong Wang"], "title": ["Occluded Person Re-identification"], "date": ["2018-04-09T01:56:53Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.02792v1"], "summary": ["  Person re-identification (re-id) suffers from a serious occlusion problem\nwhen applied to crowded public places. In this paper, we propose to retrieve a\nfull-body person image by using a person image with occlusions. This differs\nsignificantly from the conventional person re-id problem where it is assumed\nthat person images are detected without any occlusion. We thus call this new\nproblem the occluded person re-identitification. To address this new problem,\nwe propose a novel Attention Framework of Person Body (AFPB) based on deep\nlearning, consisting of 1) an Occlusion Simulator (OS) which automatically\ngenerates artificial occlusions for full-body person images, and 2) multi-task\nlosses that force the neural network not only to discriminate a person's\nidentity but also to determine whether a sample is from the occluded data\ndistribution or the full-body data distribution. Experiments on a new occluded\nperson re-id dataset and three existing benchmarks modified to include\nfull-body person images and occluded person images show the superiority of the\nproposed method.\n"]},
{"authors": ["Cheng Zhang", "Cengiz \u00d6ztireli", "Stephan Mandt", "Giampiero Salvi"], "title": ["Active Mini-Batch Sampling using Repulsive Point Processes"], "date": ["2018-04-08T22:48:20Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.02772v1"], "summary": ["  The convergence speed of stochastic gradient descent (SGD) can be improved by\nactively selecting mini-batches. We explore sampling schemes where similar data\npoints are less likely to be selected in the same mini-batch. In particular, we\nprove that such repulsive sampling schemes lowers the variance of the gradient\nestimator. This generalizes recent work on using Determinantal Point Processes\n(DPPs) for mini-batch diversification (Zhang et al., 2017) to the broader class\nof repulsive point processes. We first show that the phenomenon of variance\nreduction by diversified sampling generalizes in particular to non-stationary\npoint processes. We then show that other point processes may be computationally\nmuch more efficient than DPPs. In particular, we propose and investigate\nPoisson Disk sampling---frequently encountered in the computer graphics\ncommunity---for this task. We show empirically that our approach improves over\nstandard SGD both in terms of convergence speed as well as final model\nperformance.\n"]},
{"authors": ["Yi Wu", "Yuxin Wu", "Georgia Gkioxari", "Yuandong Tian"], "title": ["Building Generalizable Agents with a Realistic and Rich 3D Environment"], "date": ["2018-01-07T16:34:41Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.02209v2"], "summary": ["  Teaching an agent to navigate in an unseen 3D environment is a challenging\ntask, even in the event of simulated environments. To generalize to unseen\nenvironments, an agent needs to be robust to low-level variations (e.g. color,\ntexture, object changes), and also high-level variations (e.g. layout changes\nof the environment). To improve overall generalization, all types of variations\nin the environment have to be taken under consideration via different level of\ndata augmentation steps. To this end, we propose House3D, a rich, extensible\nand efficient environment that contains 45,622 human-designed 3D scenes of\nvisually realistic houses, ranging from single-room studios to multi-storied\nhouses, equipped with a diverse set of fully labeled 3D objects, textures and\nscene layouts, based on the SUNCG dataset (Song et.al.). The diversity in\nHouse3D opens the door towards scene-level augmentation, while the label-rich\nnature of House3D enables us to inject pixel- & task-level augmentations such\nas domain randomization (Toubin et. al.) and multi-task training. Using a\nsubset of houses in House3D, we show that reinforcement learning agents trained\nwith an enhancement of different levels of augmentations perform much better in\nunseen environments than our baselines with raw RGB input by over 8% in terms\nof navigation success rate. House3D is publicly available at\nhttp://github.com/facebookresearch/House3D.\n"]},
{"authors": ["Subhash Kak"], "title": ["Order Effects for Queries in Intelligent Systems"], "date": ["2018-04-08T21:18:55Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.02759v1"], "summary": ["  This paper examines common assumptions regarding the decision-making internal\nenvironment for intelligent agents and investigates issues related to\nprocessing of memory and belief states to help obtain better understanding of\nthe responses. In specific, we consider order effects and discuss both\nclassical and non-classical explanations for them. We also consider implicit\ncognition and explore if certain inaccessible states may be best modeled as\nquantum states. We propose that the hypothesis that quantum states are at the\nbasis of order effects be tested on large databases such as those related to\nmedical treatment and drug efficacy. A problem involving a maze network is\nconsidered and comparisons made between classical and quantum decision\nscenarios for it.\n"]},
{"authors": ["Krzysztof Chalupka", "Pietro Perona", "Frederick Eberhardt"], "title": ["Fast Conditional Independence Test for Vector Variables with Large\n  Sample Sizes"], "date": ["2018-04-08T20:03:07Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.02747v1"], "summary": ["  We present and evaluate the Fast (conditional) Independence Test (FIT) -- a\nnonparametric conditional independence test. The test is based on the idea that\nwhen $P(X \\mid Y, Z) = P(X \\mid Y)$, $Z$ is not useful as a feature to predict\n$X$, as long as $Y$ is also a regressor. On the contrary, if $P(X \\mid Y, Z)\n\\neq P(X \\mid Y)$, $Z$ might improve prediction results. FIT applies to\nthousand-dimensional random variables with a hundred thousand samples in a\nfraction of the time required by alternative methods. We provide an extensive\nevaluation that compares FIT to six extant nonparametric independence tests.\nThe evaluation shows that FIT has low probability of making both Type I and\nType II errors compared to other tests, especially as the number of available\nsamples grows. Our implementation of FIT is publicly available.\n"]},
{"authors": ["Xue Bin Peng", "Pieter Abbeel", "Sergey Levine", "Michiel van de Panne"], "title": ["DeepMimic: Example-Guided Deep Reinforcement Learning of Physics-Based\n  Character Skills"], "date": ["2018-04-08T17:04:58Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.02717v1"], "summary": ["  A longstanding goal in character animation is to combine data-driven\nspecification of behavior with a system that can execute a similar behavior in\na physical simulation, thus enabling realistic responses to perturbations and\nenvironmental variation. We show that well-known reinforcement learning (RL)\nmethods can be adapted to learn robust control policies capable of imitating a\nbroad range of example motion clips, while also learning complex recoveries,\nadapting to changes in morphology, and accomplishing user-specified goals. Our\nmethod handles keyframed motions, highly-dynamic actions such as\nmotion-captured flips and spins, and retargeted motions. By combining a\nmotion-imitation objective with a task objective, we can train characters that\nreact intelligently in interactive settings, e.g., by walking in a desired\ndirection or throwing a ball at a user-specified target. This approach thus\ncombines the convenience and motion quality of using motion clips to define the\ndesired style and appearance, with the flexibility and generality afforded by\nRL methods and physics-based animation. We further explore a number of methods\nfor integrating multiple clips into the learning process to develop\nmulti-skilled agents capable of performing a rich repertoire of diverse skills.\nWe demonstrate results using multiple characters (human, Atlas robot, bipedal\ndinosaur, dragon) and a large variety of skills, including locomotion,\nacrobatics, and martial arts.\n"]},
{"authors": ["Takumi Ichimura", "Daisuke Igaue"], "title": ["Hierarchical Modular Reinforcement Learning Method and Knowledge\n  Acquisition of State-Action Rule for Multi-target Problem"], "date": ["2018-04-08T14:39:13Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.02698v1"], "summary": ["  Hierarchical Modular Reinforcement Learning (HMRL), consists of 2 layered\nlearning where Profit Sharing works to plan a prey position in the higher layer\nand Q-learning method trains the state-actions to the target in the lower\nlayer. In this paper, we expanded HMRL to multi-target problem to take the\ndistance between targets to the consideration. The function, called `AT field',\ncan estimate the interests for an agent according to the distance between 2\nagents and the advantage/disadvantage of the other agent. Moreover, the\nknowledge related to state-action rules is extracted by C4.5. The action under\nthe situation is decided by using the acquired knowledge. To verify the\neffectiveness of proposed method, some experimental results are reported.\n"]},
{"authors": ["Takumi Ichimura", "Issei Tachibana"], "title": ["Emotion Orientated Recommendation System for Hiroshima Tourist by Fuzzy\n  Petri Net"], "date": ["2018-04-08T09:18:56Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.02657v1"], "summary": ["  We developed an Android Smartophone application software for tourist\ninformation system. Especially, the agent system recommends the sightseeing\nspot and local hospitality corresponding to the current feelings. The system\nsuch as concierge can estimate user's emotion and mood by Emotion Generating\nCalculations and Mental State Transition Network. In this paper, the system\ndecides the next candidates for spots and foods by the reasoning of fuzzy Petri\nNet in order to make more smooth communication between human and smartphone.\nThe system was developed for Hiroshima Tourist Information and described some\nhospitality about the concierge system.\n"]},
{"authors": ["Takumi Ichimura", "Shin Kamada"], "title": ["Clustering and Retrieval Method of Immunological Memory Cell in Clonal\n  Selection Algorithm"], "date": ["2018-04-08T04:27:09Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.02628v1"], "summary": ["  The clonal selection principle explains the basic features of an adaptive\nimmune response to a antigenic stimulus. It established the idea that only\nthose cells that recognize the antigens are selected to proliferate and\ndifferentiate. This paper explains a computational implementation of the clonal\nselection principle that explicitly takes into account the affinity maturation\nof the immune response. Antibodies generated by the clonal selection algorithm\nare clustered in some categories according to the affinity maturation, so that\nimmunological memory cells which respond to the specified pathogen are created.\nExperimental results to classify the medical database of Coronary Heart Disease\ndatabases are reported. For the dataset, our proposed method shows the 99.6\\%\nclassification capability of training data.\n"]},
{"authors": ["Takumi Ichimura", "Takashi Yamaguchi"], "title": ["A Proposal of Interactive Growing Hierarchical SOM"], "date": ["2018-04-08T03:37:36Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.02620v1"], "summary": ["  Self Organizing Map is trained using unsupervised learning to produce a\ntwo-dimensional discretized representation of input space of the training\ncases. Growing Hierarchical SOM is an architecture which grows both in a\nhierarchical way representing the structure of data distribution and in a\nhorizontal way representation the size of each individual maps. The control\nmethod of the growing degree of GHSOM by pruning off the redundant branch of\nhierarchy in SOM is proposed in this paper. Moreover, the interface tool for\nthe proposed method called interactive GHSOM is developed. We discuss the\ncomputation results of Iris data by using the developed tool.\n"]},
{"authors": ["Vivek Kulkarni", "William Yang Wang"], "title": ["Simple Models for Word Formation in English Slang"], "date": ["2018-04-07T21:59:46Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.02596v1"], "summary": ["  We propose generative models for three types of extra-grammatical word\nformation phenomena abounding in English slang: Blends, Clippings, and\nReduplicatives. Adopting a data-driven approach coupled with linguistic\nknowledge, we propose simple models with state of the art performance on human\nannotated gold standard datasets. Overall, our models reveal insights into the\ngenerative processes of word formation in slang -- insights which are\nincreasingly relevant in the context of the rising prevalence of slang and\nnon-standard varieties on the Internet.\n"]},
{"authors": ["Sankalp Arora", "Sanjiban Choudhury", "Sebastian Scherer"], "title": ["Hindsight is Only 50/50: Unsuitability of MDP based Approximate POMDP\n  Solvers for Multi-resolution Information Gathering"], "date": ["2018-04-07T16:27:33Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.02573v1"], "summary": ["  Partially Observable Markov Decision Processes (POMDPs) offer an elegant\nframework to model sequential decision making in uncertain environments.\nSolving POMDPs online is an active area of research and given the size of\nreal-world problems approximate solvers are used. Recently, a few approaches\nhave been suggested for solving POMDPs by using MDP solvers in conjunction with\nimitation learning. MDP based POMDP solvers work well for some cases, while\ncatastrophically failing for others. The main failure point of such solvers is\nthe lack of motivation for MDP solvers to gain information, since under their\nassumption the environment is either already known as much as it can be or the\nuncertainty will disappear after the next step. However for solving POMDP\nproblems gaining information can lead to efficient solutions. In this paper we\nderive a set of conditions where MDP based POMDP solvers are provably\nsub-optimal. We then use the well-known tiger problem to demonstrate such\nsub-optimality. We show that multi-resolution, budgeted information gathering\ncannot be addressed using MDP based POMDP solvers. The contribution of the\npaper helps identify the properties of a POMDP problem for which the use of MDP\nbased POMDP solvers is inappropriate, enabling better design choices.\n"]},
{"authors": ["Iraklis A. Klampanos", "Athanasios Davvetas", "Antonis Koukourikos", "Vangelis Karkaletsis"], "title": ["ANNETT-O: An Ontology for Describing Artificial Neural Network\n  Evaluation, Topology and Training"], "date": ["2018-04-07T07:56:29Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.02528v1"], "summary": ["  Deep learning models, while effective and versatile, are becoming\nincreasingly complex, often including multiple overlapping networks of\narbitrary depths, multiple objectives and non-intuitive training methodologies.\nThis makes it increasingly difficult for researchers and practitioners to\ndesign, train and understand them. In this paper we present ANNETT-O, a\nmuch-needed, generic and computer-actionable vocabulary for researchers and\npractitioners to describe their deep learning configurations, training\nprocedures and experiments. The proposed ontology focuses on topological,\ntraining and evaluation aspects of complex deep neural configurations, while\nkeeping peripheral entities more succinct. Knowledge bases implementing\nANNETT-O can support a wide variety of queries, providing relevant insights to\nusers. In addition to a detailed description of the ontology, we demonstrate\nits suitability to the task via a number of hypothetical use-cases of\nincreasing complexity.\n"]},
{"authors": ["Yuexin Ma", "Dinesh Manocha", "Wenping Wang"], "title": ["Efficient Reciprocal Collision Avoidance between Heterogeneous Agents\n  Using CTMAT"], "date": ["2018-04-07T05:44:19Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.02512v1"], "summary": ["  We present a novel algorithm for reciprocal collision avoidance between\nheterogeneous agents of different shapes and sizes. We present a novel CTMAT\nrepresentation based on medial axis transform to compute a tight fitting\nbounding shape for each agent. Each CTMAT is represented using tuples, which\nare composed of circular arcs and line segments. Based on the reciprocal\nvelocity obstacle formulation, we reduce the problem to solving a\nlow-dimensional linear programming between each pair of tuples belonging to\nadjacent agents. We precompute the Minkowski Sums of tuples to accelerate the\nruntime performance. Finally, we provide an efficient method to update the\norientation of each agent in a local manner. We have implemented the algorithm\nand highlight its performance on benchmarks corresponding to road traffic\nscenarios and different vehicles. The overall runtime performance is comparable\nto prior multi-agent collision avoidance algorithms that use circular or\nelliptical agents. Our approach is less conservative and results in fewer false\ncollisions.\n"]},
{"authors": ["Ho-Pun Lam", "Mustafa Hashmi"], "title": ["Enabling Reasoning with LegalRuleML"], "date": ["2017-11-11T05:00:58Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.06128v2"], "summary": ["  In order to automate verification process, regulatory rules written in\nnatural language need to be translated into a format that machines can\nunderstand. However, none of the existing formalisms can fully represent the\nelements that appear in legal norms. For instance, most of these formalisms do\nnot provide features to capture the behavior of deontic effects, which is an\nimportant aspect in automated compliance checking. This paper presents an\napproach for transforming legal norms represented using LegalRuleML to a\nvariant of Modal Defeasible Logic (and vice versa) such that a legal statement\nrepresented using LegalRuleML can be transformed into a machine-readable format\nthat can be understood and reasoned about depending upon the client's\npreferences.\n"]},
{"authors": ["Xinpeng Chen", "Lin Ma", "Wenhao Jiang", "Jian Yao", "Wei Liu"], "title": ["Regularizing RNNs for Caption Generation by Reconstructing The Past with\n  The Present"], "date": ["2018-03-30T13:15:56Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.11439v2"], "summary": ["  Recently, caption generation with an encoder-decoder framework has been\nextensively studied and applied in different domains, such as image captioning,\ncode captioning, and so on. In this paper, we propose a novel architecture,\nnamely Auto-Reconstructor Network (ARNet), which, coupling with the\nconventional encoder-decoder framework, works in an end-to-end fashion to\ngenerate captions. ARNet aims at reconstructing the previous hidden state with\nthe present one, besides behaving as the input-dependent transition operator.\nTherefore, ARNet encourages the current hidden state to embed more information\nfrom the previous one, which can help regularize the transition dynamics of\nrecurrent neural networks (RNNs). Extensive experimental results show that our\nproposed ARNet boosts the performance over the existing encoder-decoder models\non both image captioning and source code captioning tasks. Additionally, ARNet\nremarkably reduces the discrepancy between training and inference processes for\ncaption generation. Furthermore, the performance on permuted sequential MNIST\ndemonstrates that ARNet can effectively regularize RNN, especially on modeling\nlong-term dependencies. Our code is available at:\nhttps://github.com/chenxinpeng/ARNet\n"]},
{"authors": ["Abhinav Verma", "Vijayaraghavan Murali", "Rishabh Singh", "Pushmeet Kohli", "Swarat Chaudhuri"], "title": ["Programmatically Interpretable Reinforcement Learning"], "date": ["2018-04-06T22:17:18Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.02477v1"], "summary": ["  We study the problem of generating interpretable and verifiable policies\nthrough reinforcement learning. Unlike the popular Deep Reinforcement Learning\n(DRL) paradigm, in which the policy is represented by a neural network, the aim\nin Programmatically Interpretable Reinforcement Learning is to find a policy\nthat can be represented in a high-level programming language. Such programmatic\npolicies have the benefits of being more easily interpreted than neural\nnetworks, and being amenable to verification by symbolic methods. We propose a\nnew method, called Neurally Directed Program Search (NDPS), for solving the\nchallenging nonsmooth optimization problem of finding a programmatic policy\nwith maxima reward. NDPS works by first learning a neural policy network using\nDRL, and then performing a local search over programmatic policies that seeks\nto minimize a distance from this neural \"oracle\". We evaluate NDPS on the task\nof learning to drive a simulated car in the TORCS car-racing environment. We\ndemonstrate that NDPS is able to discover human-readable policies that pass\nsome significant performance bars. We also find that a well-designed policy\nlanguage can serve as a regularizer, and result in the discovery of policies\nthat lead to smoother trajectories and are more easily transferred to\nenvironments not encountered during training.\n"]},
{"authors": ["Chiara Di Francescomarino", "Chiara Ghidini", "Fabrizio Maria Maggi", "Fredrik Milani"], "title": ["Predictive Process Monitoring Methods: Which One Suits Me Best?"], "date": ["2018-04-06T18:45:54Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.02422v1"], "summary": ["  Predictive process monitoring has recently gained traction in academia and is\nmaturing also in companies. However, with the growing body of research, it\nmight be daunting for companies to navigate in this domain in order to find,\nprovided certain data, what can be predicted and what methods to use. The main\nobjective of this paper is developing a value-driven framework for classifying\nexisting work on predictive process monitoring. This objective is achieved by\nsystematically identifying, categorizing, and analyzing existing approaches for\npredictive process monitoring. The review is then used to develop a\nvalue-driven framework that can support organizations to navigate in the\npredictive process monitoring field and help them to find value and exploit the\nopportunities enabled by these analysis techniques.\n"]},
{"authors": ["Edward Choi", "Angeliki Lazaridou", "Nando de Freitas"], "title": ["Compositional Obverter Communication Learning From Raw Visual Input"], "date": ["2018-04-06T16:12:51Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.02341v1"], "summary": ["  One of the distinguishing aspects of human language is its compositionality,\nwhich allows us to describe complex environments with limited vocabulary.\nPreviously, it has been shown that neural network agents can learn to\ncommunicate in a highly structured, possibly compositional language based on\ndisentangled input (e.g. hand- engineered features). Humans, however, do not\nlearn to communicate based on well-summarized features. In this work, we train\nneural agents to simultaneously develop visual perception from raw image\npixels, and learn to communicate with a sequence of discrete symbols. The\nagents play an image description game where the image contains factors such as\ncolors and shapes. We train the agents using the obverter technique where an\nagent introspects to generate messages that maximize its own understanding.\nThrough qualitative analysis, visualization and a zero-shot test, we show that\nthe agents can develop, out of raw image pixels, a language with compositional\nproperties, given a proper pressure from the environment.\n"]},
{"authors": ["A Mani"], "title": ["Comparing Dependencies in Probability Theory and General Rough Sets:\n  Part-A"], "date": ["2018-04-06T15:26:36Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.02322v1"], "summary": ["  The problem of comparing concepts of dependence in general rough sets with\nthose in probability theory had been initiated by the present author in some of\nher recent papers. This problem relates to the identification of the\nlimitations of translating between the methodologies and possibilities in the\nidentification of concepts. Comparison of ideas of dependence in the approaches\nhad been attempted from a set-valuation based minimalist perspective by the\npresent author. The deviant probability framework has been the result of such\nan approach. Other Bayesian reasoning perspectives (involving numeric\nvaluations) and frequentist approaches are also known. In this research,\nduality results are adapted to demonstrate the possibility of improved\ncomparisons across implications between ontologically distinct concepts in a\ncommon logic-based framework by the present author. Both positive and negative\nresults are proved that delimit possible comparisons in a clearer way by her.\n"]},
{"authors": ["Sam Kriegman", "Nick Cheney", "Francesco Corucci", "Josh C. Bongard"], "title": ["Interoceptive robustness through environment-mediated morphological\n  development"], "date": ["2018-04-06T13:33:37Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.02257v1"], "summary": ["  Typically, AI researchers and roboticists try to realize intelligent behavior\nin machines by tuning parameters of a predefined structure (body plan and/or\nneural network architecture) using evolutionary or learning algorithms. Another\nbut not unrelated longstanding property of these systems is their brittleness\nto slight aberrations, as highlighted by the growing deep learning literature\non adversarial examples. Here we show robustness can be achieved by evolving\nthe geometry of soft robots, their control systems, and how their material\nproperties develop in response to one particular interoceptive stimulus\n(engineering stress) during their lifetimes. By doing so we realized robots\nthat were equally fit but more robust to extreme material defects (such as\nmight occur during fabrication or by damage thereafter) than robots that did\nnot develop during their lifetimes, or developed in response to a different\ninteroceptive stimulus (pressure). This suggests that the interplay between\nchanges in the containing systems of agents (body plan and/or neural\narchitecture) at different temporal scales (evolutionary and developmental)\nalong different modalities (geometry, material properties, synaptic weights)\nand in response to different signals (interoceptive and external perception)\nall dictate those agents' abilities to evolve or learn capable and robust\nstrategies.\n"]},
{"authors": ["Boyi Li", "Wenqi Ren", "Dengpan Fu", "Dacheng Tao", "Dan Feng", "Wenjun Zeng", "Zhangyang Wang"], "title": ["Benchmarking Single Image Dehazing and Beyond"], "date": ["2017-12-12T06:33:20Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1712.04143v2"], "summary": ["  In this paper, we present a comprehensive study and evaluation of existing\nsingle image dehazing algorithms, using a new large-scale benchmark consisting\nof both synthetic and real-world hazy images, called REalistic Single Image\nDEhazing (RESIDE). RESIDE highlights diverse data sources and image contents,\nand is divided into five subsets, each serving different training or evaluation\npurposes. We further provide a rich variety of criteria for dehazing algorithm\nevaluation, ranging from full-reference metrics, to no-reference metrics, to\nsubjective evaluation and the novel task-driven evaluation. Experiments on\nRESIDE shed light on the comparisons and limitations of state-of-the-art\ndehazing algorithms, and suggest promising future directions.\n"]},
{"authors": ["Lucas Bechberger", "Kai-Uwe K\u00fchnberger"], "title": ["Formal Ways for Measuring Relations between Concepts in Conceptual\n  Spaces"], "date": ["2018-04-06T13:06:01Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.02393v1"], "summary": ["  The highly influential framework of conceptual spaces provides a geometric\nway of representing knowledge. Instances are represented by points in a\nhigh-dimensional space and concepts are represented by regions in this space.\nIn this article, we extend our recent mathematical formalization of this\nframework by providing quantitative mathematical definitions for measuring\nrelations between concepts: We develop formal ways for computing concept size,\nsubsethood, implication, similarity, and betweenness. This considerably\nincreases the representational capabilities of our formalization and makes it\nthe most thorough and comprehensive formalization of conceptual spaces\ndeveloped so far.\n"]},
{"authors": ["Hanlin Tang", "Martin Schrimpf", "Bill Lotter", "Charlotte Moerman", "Ana Paredes", "Josue Ortega Caro", "Walter Hardesty", "David Cox", "Gabriel Kreiman"], "title": ["Recurrent computations for visual pattern completion"], "date": ["2017-06-07T16:23:28Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1706.02240v2"], "summary": ["  Making inferences from partial information constitutes a critical aspect of\ncognition. During visual perception, pattern completion enables recognition of\npoorly visible or occluded objects. We combined psychophysics, physiology and\ncomputational models to test the hypothesis that pattern completion is\nimplemented by recurrent computations and present three pieces of evidence that\nare consistent with this hypothesis. First, subjects robustly recognized\nobjects even when rendered <15% visible, but recognition was largely impaired\nwhen processing was interrupted by backward masking. Second, invasive\nphysiological responses along the human ventral cortex exhibited visually\nselective responses to partially visible objects that were delayed compared to\nwhole objects, suggesting the need for additional computations. These\nphysiological delays were correlated with the effects of backward masking.\nThird, state-of-the-art feed-forward computational architectures were not\nrobust to partial visibility. However, recognition performance was recovered\nwhen the model was augmented with attractor-based recurrent connectivity. These\nresults provide a strong argument of plausibility for the role of recurrent\ncomputations in making visual inferences from partial information.\n"]},
{"authors": ["Saumya Jetley", "Nicholas A. Lord", "Namhoon Lee", "Philip H. S. Torr"], "title": ["Learn To Pay Attention"], "date": ["2018-04-06T10:47:26Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.02391v1"], "summary": ["  We propose an end-to-end-trainable attention module for convolutional neural\nnetwork (CNN) architectures built for image classification. The module takes as\ninput the 2D feature vector maps which form the intermediate representations of\nthe input image at different stages in the CNN pipeline, and outputs a 2D\nmatrix of scores for each map. Standard CNN architectures are modified through\nthe incorporation of this module, and trained under the constraint that a\nconvex combination of the intermediate 2D feature vectors, as parameterised by\nthe score matrices, must \\textit{alone} be used for classification.\nIncentivised to amplify the relevant and suppress the irrelevant or misleading,\nthe scores thus assume the role of attention values. Our experimental\nobservations provide clear evidence to this effect: the learned attention maps\nneatly highlight the regions of interest while suppressing background clutter.\nConsequently, the proposed function is able to bootstrap standard CNN\narchitectures for the task of image classification, demonstrating superior\ngeneralisation over 6 unseen benchmark datasets. When binarised, our attention\nmaps outperform other CNN-based attention maps, traditional saliency maps, and\ntop object proposals for weakly supervised segmentation as demonstrated on the\nObject Discovery dataset. We also demonstrate improved robustness against the\nfast gradient sign method of adversarial attack.\n"]},
{"authors": ["Frederic Boussemart", "Christophe Lecoutre", "Gilles Audemard", "C\u00e9dric Piette"], "title": ["XCSP3: An Integrated Format for Benchmarking Combinatorial Constrained\n  Problems"], "date": ["2016-11-10T17:00:56Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1611.03398v2"], "summary": ["  We propose a major revision of the format XCSP 2.1, called XCSP3, to build\nintegrated representations of combinatorial constrained problems. This new\nformat is able to deal with mono/multi optimization, many types of variables,\ncost functions, reification, views, annotations, variable quantification,\ndistributed, probabilistic and qualitative reasoning. The new format is made\ncompact, highly readable, and rather easy to parse. Interestingly, it captures\nthe structure of the problem models, through the possibilities of declaring\narrays of variables, and identifying syntactic and semantic groups of\nconstraints. The number of constraints is kept under control by introducing a\nlimited set of basic constraint forms, and producing almost automatically some\nof their variations through lifting, restriction, sliding, logical combination\nand relaxation mechanisms. As a result, XCSP3 encompasses practically all\nconstraints that can be found in major constraint solvers developed by the CP\ncommunity. A website, which is developed conjointly with the format, contains\nmany models and series of instances. The user can make sophisticated queries\nfor selecting instances from very precise criteria. The objective of XCSP3 is\nto ease the effort required to test and compare different algorithms by\nproviding a common test-bed of combinatorial constrained instances.\n"]},
{"authors": ["Xiaojun Xu", "Xinyun Chen", "Chang Liu", "Anna Rohrbach", "Trevor Darrell", "Dawn Song"], "title": ["Fooling Vision and Language Models Despite Localization and Attention\n  Mechanism"], "date": ["2017-09-25T19:32:49Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1709.08693v2"], "summary": ["  Adversarial attacks are known to succeed on classifiers, but it has been an\nopen question whether more complex vision systems are vulnerable. In this\npaper, we study adversarial examples for vision and language models, which\nincorporate natural language understanding and complex structures such as\nattention, localization, and modular architectures. In particular, we\ninvestigate attacks on a dense captioning model and on two visual question\nanswering (VQA) models. Our evaluation shows that we can generate adversarial\nexamples with a high success rate (i.e., > 90%) for these models. Our work\nsheds new light on understanding adversarial attacks on vision systems which\nhave a language component and shows that attention, bounding box localization,\nand compositional internal structures are vulnerable to adversarial attacks.\nThese observations will inform future work towards building effective defenses.\n"]},
{"authors": ["Xi Chen", "Zonghang Li", "Yupeng Zhang", "Ruiming Long", "Hongfang Yu", "Xiaojiang Du", "Mohsen Guizani"], "title": ["Reinforcement Learning based QoS/QoE-aware Service Function Chaining in\n  Software-Driven 5G Slices"], "date": ["2018-04-06T01:07:53Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.02099v1"], "summary": ["  With the ever growing diversity of devices and applications that will be\nconnected to 5G networks, flexible and agile service orchestration with\nacknowledged QoE that satisfies end-user's functional and QoS requirements is\nnecessary. SDN (Software-Defined Networking) and NFV (Network Function\nVirtualization) are considered key enabling technologies for 5G core networks.\nIn this regard, this paper proposes a reinforcement learning based\nQoS/QoE-aware Service Function Chaining (SFC) in SDN/NFV-enabled 5G slices.\nFirst, it implements a lightweight QoS information collector based on LLDP,\nwhich works in a piggyback fashion on the southbound interface of the SDN\ncontroller, to enable QoS-awareness. Then, a DQN (Deep Q Network) based agent\nframework is designed to support SFC in the context of NFV. The agent takes\ninto account the QoE and QoS as key aspects to formulate the reward so that it\nis expected to maximize QoE while respecting QoS constraints. The experiment\nresults show that this framework exhibits good performance in QoE provisioning\nand QoS requirements maintenance for SFC in dynamic network environments.\n"]},
{"authors": ["Dmytro Bobkov", "Sili Chen", "Ruiqing Jian", "Muhammad Iqbal", "Eckehard Steinbach"], "title": ["Noise-resistant Deep Learning for Object Classification in 3D Point\n  Clouds Using a Point Pair Descriptor"], "date": ["2018-04-05T23:19:55Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.02077v1"], "summary": ["  Object retrieval and classification in point cloud data is challenged by\nnoise, irregular sampling density and occlusion. To address this issue, we\npropose a point pair descriptor that is robust to noise and occlusion and\nachieves high retrieval accuracy. We further show how the proposed descriptor\ncan be used in a 4D convolutional neural network for the task of object\nclassification. We propose a novel 4D convolutional layer that is able to learn\nclass-specific clusters in the descriptor histograms. Finally, we provide\nexperimental validation on 3 benchmark datasets, which confirms the superiority\nof the proposed approach.\n"]},
{"authors": ["Peter Anderson", "Qi Wu", "Damien Teney", "Jake Bruce", "Mark Johnson", "Niko S\u00fcnderhauf", "Ian Reid", "Stephen Gould", "Anton van den Hengel"], "title": ["Vision-and-Language Navigation: Interpreting visually-grounded\n  navigation instructions in real environments"], "date": ["2017-11-20T12:17:47Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.07280v3"], "summary": ["  A robot that can carry out a natural-language instruction has been a dream\nsince before the Jetsons cartoon series imagined a life of leisure mediated by\na fleet of attentive robot helpers. It is a dream that remains stubbornly\ndistant. However, recent advances in vision and language methods have made\nincredible progress in closely related areas. This is significant because a\nrobot interpreting a natural-language navigation instruction on the basis of\nwhat it sees is carrying out a vision and language process that is similar to\nVisual Question Answering. Both tasks can be interpreted as visually grounded\nsequence-to-sequence translation problems, and many of the same methods are\napplicable. To enable and encourage the application of vision and language\nmethods to the problem of interpreting visually-grounded navigation\ninstructions, we present the Matterport3D Simulator -- a large-scale\nreinforcement learning environment based on real imagery. Using this simulator,\nwhich can in future support a range of embodied vision and language tasks, we\nprovide the first benchmark dataset for visually-grounded natural language\nnavigation in real buildings -- the Room-to-Room (R2R) dataset.\n"]},
{"authors": ["Xi Ouyang", "Yu Cheng", "Yifan Jiang", "Chun-Liang Li", "Pan Zhou"], "title": ["Pedestrian-Synthesis-GAN: Generating Pedestrian Data in Real Scene and\n  Beyond"], "date": ["2018-04-05T20:22:01Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.02047v1"], "summary": ["  State-of-the-art pedestrian detection models have achieved great success in\nmany benchmarks. However, these models require lots of annotation information\nand the labeling process usually takes much time and efforts. In this paper, we\npropose a method to generate labeled pedestrian data and adapt them to support\nthe training of pedestrian detectors. The proposed framework is built on the\nGenerative Adversarial Network (GAN) with multiple discriminators, trying to\nsynthesize realistic pedestrians and learn the background context\nsimultaneously. To handle the pedestrians of different sizes, we adopt the\nSpatial Pyramid Pooling (SPP) layer in the discriminator. We conduct\nexperiments on two benchmarks. The results show that our framework can smoothly\nsynthesize pedestrians on background images of variations and different levels\nof details. To quantitatively evaluate our approach, we add the generated\nsamples into training data of the baseline pedestrian detectors and show the\nsynthetic images are able to improve the detectors' performance.\n"]},
{"authors": ["Wenhu Chen", "Wenhan Xiong", "Xifeng Yan", "William Wang"], "title": ["Variational Knowledge Graph Reasoning"], "date": ["2018-03-17T22:08:10Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.06581v2"], "summary": ["  Inferring missing links in knowledge graphs (KG) has attracted a lot of\nattention from the research community. In this paper, we tackle a practical\nquery answering task involving predicting the relation of a given entity pair.\nWe frame this prediction problem as an inference problem in a probabilistic\ngraphical model and aim at resolving it from a variational inference\nperspective. In order to model the relation between the query entity pair, we\nassume that there exists an underlying latent variable (paths connecting two\nnodes) in the KG, which carries the equivalent semantics of their relations.\nHowever, due to the intractability of connections in large KGs, we propose to\nuse variation inference to maximize the evidence lower bound. More\nspecifically, our framework (\\textsc{Diva}) is composed of three modules, i.e.\na posterior approximator, a prior (path finder), and a likelihood (path\nreasoner). By using variational inference, we are able to incorporate them\nclosely into a unified architecture and jointly optimize them to perform KG\nreasoning. With active interactions among these sub-modules, \\textsc{Diva} is\nbetter at handling noise and coping with more complex reasoning scenarios. In\norder to evaluate our method, we conduct the experiment of the link prediction\ntask on multiple datasets and achieve state-of-the-art performances on both\ndatasets.\n"]},
{"authors": ["Hector Zenil", "Narsis A. Kiani", "Allan A. Zea", "Jesper Tegn\u00e9r"], "title": ["Ab initio Algorithmic Causal Deconvolution of Intertwined Programs and\n  Networks by Generative Mechanism"], "date": ["2018-02-18T08:06:13Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.09904v4"], "summary": ["  Complex data is usually produced by interacting sources with different\nmechanisms. Here we introduce a parameter-free model-based approach, based upon\nthe seminal concept of Algorithmic Probability, that decomposes an observation\nand signal into its most likely algorithmic generative sources. Our methods use\na causal calculus to infer model representations. We demonstrate the method\nability to distinguish interacting mechanisms and deconvolve them, regardless\nof whether the objects produce strings, space-time evolution diagrams, images\nor networks. We numerically test and evaluate our causal separation methods and\nfind that it can disentangle examples of observations from discrete dynamical\nsystems, and complex networks. We think that these causal separating techniques\ncan contribute to tackle the challenge of causation for estimations of better\nrooted probability distributions thereby complementing more limited\nstatistical-oriented techniques that otherwise would lack model inference\ncapabilities.\n"]},
{"authors": ["Mehmet Emin Aydin", "Ryan Fellows"], "title": ["A reinforcement learning algorithm for building collaboration in\n  multi-agent systems"], "date": ["2017-11-28T21:46:42Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.10574v2"], "summary": ["  This paper presents a proof-of concept study for demonstrating the viability\nof building collaboration among multiple agents through standard Q learning\nalgorithm embedded in particle swarm optimisation. Collaboration is formulated\nto be achieved among the agents via some sort competition, where the agents are\nexpected to balance their action in such a way that none of them drifts away of\nthe team and none intervene any fellow neighbours territory. Particles are\ndevised with Q learning algorithm for self training to learn how to act as\nmembers of a swarm and how to produce collaborative/collective behaviours. The\nproduced results are supportive to the algorithmic structures suggesting that a\nsubstantive collaboration can be build via proposed learning algorithm.\n"]},
{"authors": ["Paul Azunre", "Craig Corcoran", "David Sullivan", "Garrett Honke", "Rebecca Ruppel", "Sandeep Verma", "Jonathon Morgan"], "title": ["Abstractive Tabular Dataset Summarization via Knowledge Base Semantic\n  Embeddings"], "date": ["2018-04-04T16:45:04Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.01503v2"], "summary": ["  This paper describes an abstractive summarization method for tabular data\nwhich employs a knowledge base semantic embedding to generate the summary.\nAssuming the dataset contains descriptive text in headers, columns and/or some\naugmenting metadata, the system employs the embedding to recommend a\nsubject/type for each text segment. Recommendations are aggregated into a small\ncollection of super types considered to be descriptive of the dataset by\nexploiting the hierarchy of types in a pre-specified ontology. Using February\n2015 Wikipedia as the knowledge base, and a corresponding DBpedia ontology as\ntypes, we present experimental results on open data taken from several\nsources--OpenML, CKAN and data.world--to illustrate the effectiveness of the\napproach.\n"]},
{"authors": ["Ngoc Duy Nguyen", "Saeid Nahavandi", "Thanh Nguyen"], "title": ["A Human Mixed Strategy Approach to Deep Reinforcement Learning"], "date": ["2018-04-05T14:24:42Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.01874v1"], "summary": ["  In 2015, Google's DeepMind announced an advancement in creating an autonomous\nagent based on deep reinforcement learning (DRL) that could beat a professional\nplayer in a series of 49 Atari games. However, the current manifestation of DRL\nis still immature, and has significant drawbacks. One of DRL's imperfections is\nits lack of \"exploration\" during the training process, especially when working\nwith high-dimensional problems. In this paper, we propose a mixed strategy\napproach that mimics behaviors of human when interacting with environment, and\ncreate a \"thinking\" agent that allows for more efficient exploration in the DRL\ntraining process. The simulation results based on the Breakout game show that\nour scheme achieves a higher probability of obtaining a maximum score than does\nthe baseline DRL algorithm, i.e., the asynchronous advantage actor-critic\nmethod. The proposed scheme therefore can be applied effectively to solving a\ncomplicated task in a real-world application.\n"]},
{"authors": ["Saumya Jetley", "Naila Murray", "Eleonora Vig"], "title": ["End-to-End Saliency Mapping via Probability Distribution Prediction"], "date": ["2018-04-05T11:59:01Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.01793v1"], "summary": ["  Most saliency estimation methods aim to explicitly model low-level\nconspicuity cues such as edges or blobs and may additionally incorporate\ntop-down cues using face or text detection. Data-driven methods for training\nsaliency models using eye-fixation data are increasingly popular, particularly\nwith the introduction of large-scale datasets and deep architectures. However,\ncurrent methods in this latter paradigm use loss functions designed for\nclassification or regression tasks whereas saliency estimation is evaluated on\ntopographical maps. In this work, we introduce a new saliency map model which\nformulates a map as a generalized Bernoulli distribution. We then train a deep\narchitecture to predict such maps using novel loss functions which pair the\nsoftmax activation function with measures designed to compute distances between\nprobability distributions. We show in extensive experiments the effectiveness\nof such loss functions over standard ones on four public benchmark datasets,\nand demonstrate improved performance over state-of-the-art saliency methods.\n"]},
{"authors": ["Yan Wu", "Greg Wayne", "Alex Graves", "Timothy Lillicrap"], "title": ["The Kanerva Machine: A Generative Distributed Memory"], "date": ["2018-04-05T10:07:05Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.01756v1"], "summary": ["  We present an end-to-end trained memory system that quickly adapts to new\ndata and generates samples like them. Inspired by Kanerva's sparse distributed\nmemory, it has a robust distributed reading and writing mechanism. The memory\nis analytically tractable, which enables optimal on-line compression via a\nBayesian update-rule. We formulate it as a hierarchical conditional generative\nmodel, where memory provides a rich data-dependent prior distribution.\nConsequently, the top-down memory and bottom-up perception are combined to\nproduce the code representing an observation. Empirically, we demonstrate that\nthe adaptive memory significantly improves generative models trained on both\nthe Omniglot and CIFAR datasets. Compared with the Differentiable Neural\nComputer (DNC) and its variants, our memory model has greater capacity and is\nsignificantly easier to train.\n"]},
{"authors": ["Takuma Yoneda", "Koki Mori", "Makoto Miwa", "Yutaka Sasaki"], "title": ["Bib2vec: An Embedding-based Search System for Bibliographic Information"], "date": ["2017-06-16T00:53:28Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1706.05122v3"], "summary": ["  We propose a novel embedding model that represents relationships among\nseveral elements in bibliographic information with high representation ability\nand flexibility. Based on this model, we present a novel search system that\nshows the relationships among the elements in the ACL Anthology Reference\nCorpus. The evaluation results show that our model can achieve a high\nprediction ability and produce reasonable search results.\n"]},
{"authors": ["Aditya Grover", "Ramki Gummadi", "Miguel Lazaro-Gredilla", "Dale Schuurmans", "Stefano Ermon"], "title": ["Variational Rejection Sampling"], "date": ["2018-04-05T07:53:41Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.01712v1"], "summary": ["  Learning latent variable models with stochastic variational inference is\nchallenging when the approximate posterior is far from the true posterior, due\nto high variance in the gradient estimates. We propose a novel rejection\nsampling step that discards samples from the variational posterior which are\nassigned low likelihoods by the model. Our approach provides an arbitrarily\naccurate approximation of the true posterior at the expense of extra\ncomputation. Using a new gradient estimator for the resulting unnormalized\nproposal distribution, we achieve average improvements of 3.71 nats and 0.21\nnats over state-of-the-art single-sample and multi-sample alternatives\nrespectively for estimating marginal log-likelihoods using sigmoid belief\nnetworks on the MNIST dataset.\n"]},
{"authors": ["Arend Hintze", "Douglas Kirkpatrick", "Christoph Adami"], "title": ["The structure of evolved representations across different substrates for\n  artificial intelligence"], "date": ["2018-04-05T03:10:37Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.01660v1"], "summary": ["  Artificial neural networks (ANNs), while exceptionally useful for\nclassification, are vulnerable to misdirection. Small amounts of noise can\nsignificantly affect their ability to correctly complete a task. Instead of\ngeneralizing concepts, ANNs seem to focus on surface statistical regularities\nin a given task. Here we compare how recurrent artificial neural networks, long\nshort-term memory units, and Markov Brains sense and remember their\nenvironments. We show that information in Markov Brains is localized and\nsparsely distributed, while the other neural network substrates \"smear\"\ninformation about the environment across all nodes, which makes them vulnerable\nto noise.\n"]},
{"authors": ["Aarthy Shivram Arun", "Sai Vikneshwar Mani Jayaraman", "Christopher R\u00e9", "Atri Rudra"], "title": ["Hypertree Decompositions Revisited for PGMs"], "date": ["2018-04-05T01:05:34Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.01640v1"], "summary": ["  We revisit the classical problem of exact inference on probabilistic\ngraphical models (PGMs). Our algorithm is based on recent worst-case optimal\ndatabase join algorithms, which can be asymptotically faster than traditional\ndata processing methods. We present the first empirical evaluation of these new\nalgorithms via JoinInfer, a new exact inference engine. We empirically explore\nthe properties of the data for which our engine can be expected to outperform\ntraditional inference engines refining current theoretical notions. Further,\nJoinInfer outperforms existing state-of-the-art inference engines (ACE, IJGP\nand libDAI) on some standard benchmark datasets by up to a factor of 630x.\nFinally, we propose a promising data-driven heuristic that extends JoinInfer to\nautomatically tailor its parameters and/or switch to the traditional inference\nalgorithms.\n"]},
{"authors": ["Leopoldo Bertossi"], "title": ["Characterizing and Computing Causes for Query Answers in Databases from\n  Database Repairs and Repair Programs"], "date": ["2017-12-04T11:00:38Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1712.01001v3"], "summary": ["  A correspondence between database tuples as causes for query answers in\ndatabases and tuple-based repairs of inconsistent databases with respect to\ndenial constraints has already been established. In this work, answer-set\nprograms that specify repairs of databases are used as a basis for solving\ncomputational and reasoning problems about causes. Here, causes are also\nintroduced at the attribute level by appealing to a both null-based and\nattribute-based repair semantics. The corresponding repair programs are\npresented, and they are used as a basis for computation and reasoning about\nattribute-level causes.\n"]},
{"authors": ["Alex X. Lee", "Richard Zhang", "Frederik Ebert", "Pieter Abbeel", "Chelsea Finn", "Sergey Levine"], "title": ["Stochastic Adversarial Video Prediction"], "date": ["2018-04-04T17:55:40Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.01523v1"], "summary": ["  Being able to predict what may happen in the future requires an in-depth\nunderstanding of the physical and causal rules that govern the world. A model\nthat is able to do so has a number of appealing applications, from robotic\nplanning to representation learning. However, learning to predict raw future\nobservations, such as frames in a video, is exceedingly challenging -- the\nambiguous nature of the problem can cause a naively designed model to average\ntogether possible futures into a single, blurry prediction. Recently, this has\nbeen addressed by two distinct approaches: (a) latent variational variable\nmodels that explicitly model underlying stochasticity and (b)\nadversarially-trained models that aim to produce naturalistic images. However,\na standard latent variable model can struggle to produce realistic results, and\na standard adversarially-trained model underutilizes latent variables and fails\nto produce diverse predictions. We show that these distinct methods are in fact\ncomplementary. Combining the two produces predictions that look more realistic\nto human raters and better cover the range of possible futures. Our method\noutperforms prior and concurrent work in these aspects.\n"]},
{"authors": ["Aravind Srinivas", "Allan Jabri", "Pieter Abbeel", "Sergey Levine", "Chelsea Finn"], "title": ["Universal Planning Networks"], "date": ["2018-04-02T17:51:53Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.00645v2"], "summary": ["  A key challenge in complex visuomotor control is learning abstract\nrepresentations that are effective for specifying goals, planning, and\ngeneralization. To this end, we introduce universal planning networks (UPN).\nUPNs embed differentiable planning within a goal-directed policy. This planning\ncomputation unrolls a forward model in a latent space and infers an optimal\naction plan through gradient descent trajectory optimization. The\nplan-by-gradient-descent process and its underlying representations are learned\nend-to-end to directly optimize a supervised imitation learning objective. We\nfind that the representations learned are not only effective for goal-directed\nvisual imitation via gradient-based trajectory optimization, but can also\nprovide a metric for specifying goals using images. The learned representations\ncan be leveraged to specify distance-based rewards to reach new target states\nfor model-free reinforcement learning, resulting in substantially more\neffective learning when solving new tasks described via image-based goals. We\nwere able to achieve successful transfer of visuomotor planning strategies\nacross robots with significantly different morphologies and actuation\ncapabilities.\n"]},
{"authors": ["Andrew L. Beam", "Benjamin Kompa", "Inbar Fried", "Nathan P. Palmer", "Xu Shi", "Tianxi Cai", "Isaac S. Kohane"], "title": ["Clinical Concept Embeddings Learned from Massive Sources of Medical Data"], "date": ["2018-04-04T16:02:54Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.01486v1"], "summary": ["  Word embeddings have emerged as a popular approach to unsupervised learning\nof word relationships in machine learning and natural language processing. In\nthis article, we benchmark two of the most popular algorithms, GloVe and\nword2vec, to assess their suitability for capturing medical relationships in\nlarge sources of biomedical data. Leaning on recent theoretical insights, we\nprovide a unified view of these algorithms and demonstrate how different\nsources of data can be combined to construct the largest ever set of embeddings\nfor 108,477 medical concepts using an insurance claims database of 60 million\nmembers, 20 million clinical notes, and 1.7 million full text biomedical\njournal articles. We evaluate our approach, called cui2vec, on a set of\nclinically relevant benchmarks and in many instances demonstrate state of the\nart performance relative to previous results. Finally, we provide a\ndownloadable set of pre-trained embeddings for other researchers to use, as\nwell as an online tool for interactive exploration of the cui2vec embeddings.\n"]},
{"authors": ["Rohan Badlani", "Ankit Shah", "Benjamin Elizalde", "Anurag Kumar", "Bhiksha Raj"], "title": ["Framework for evaluation of sound event detection in web videos"], "date": ["2017-11-02T16:32:23Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.00804v2"], "summary": ["  The largest source of sound events is web videos. Most videos lack sound\nevent labels at segment level, however, a significant number of them do respond\nto text queries, from a match found using metadata by search engines. In this\npaper we explore the extent to which a search query can be used as the true\nlabel for detection of sound events in videos. We present a framework for\nlarge-scale sound event recognition on web videos. The framework crawls videos\nusing search queries corresponding to 78 sound event labels drawn from three\ndatasets. The datasets are used to train three classifiers, and we obtain a\nprediction on 3.7 million web video segments. We evaluated performance using\nthe search query as true label and compare it with human labeling. Both types\nof ground truth exhibited close performance, to within 10%, and similar\nperformance trend with increasing number of evaluated segments. Hence, our\nexperiments show potential for using search query as a preliminary true label\nfor sound event recognition in web videos.\n"]},
{"authors": ["Manuel Namici"], "title": ["R2RML Mappings in OBDA Systems: Enabling Comparison among OBDA Tools"], "date": ["2018-04-04T13:43:21Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.01405v1"], "summary": ["  In today's large enterprises there is a significant increasing trend in the\namount of data that has to be stored and processed. To complicate this scenario\nthe complexity of organizing and managing a large collection of data,\nstructured according to a single, unified schema, makes so that there is almost\nnever a single place where to look to satisfy an information need.\n  The Ontology-Based Data Access (OBDA) paradigm aims at mitigating this\nphenomenon by providing to the users of the system a unified and shared\nconceptual view of the domain of interest (ontology), while still enabling the\ndata to be stored in different data sources, which are managed by a relational\ndatabase. In an OBDA system the link between the data stored at the sources and\nthe ontology is provided through a declarative specification given in terms of\na set of mappings.\n  In this work we focus on comparing two of the available systems for OBDA,\nnamely, Mastro and Ontop, by adopting OBDA specifications based on W3C\nrecommendations. We first show how support for R2RML mappings has been\nintegrated in Mastro, which was the last feature missing in order to enable the\nsystem to use specifications based solely on W3C recommendations relevant to\nOBDA. We then proceed in performing a comparison between these systems over two\nOBDA specifications, the NPD Benchmark and the ACI specification.\n"]},
{"authors": ["Kun Xu", "Lingfei Wu", "Zhiguo Wang", "Yansong Feng", "Vadim Sheinin"], "title": ["Graph2Seq: Graph to Sequence Learning with Attention-based Neural\n  Networks"], "date": ["2018-04-03T04:47:22Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.00823v2"], "summary": ["  Celebrated \\emph{Sequence to Sequence learning (Seq2Seq)} and its fruitful\nvariants are powerful models to achieve excellent performance on the tasks that\nmap sequences to sequences. However, these are many machine learning tasks with\ninputs naturally represented in a form of graphs, which imposes significant\nchallenges to existing Seq2Seq models for lossless conversion from its graph\nform to the sequence. In this work, we present a general end-to-end approach to\nmap the input graph to a sequence of vectors, and then another attention-based\nLSTM to decode the target sequence from these vectors. Specifically, to address\ninevitable information loss for data conversion, we introduce a novel\ngraph-to-sequence neural network model that follows the encoder-decoder\narchitecture. Our method first uses an improved graph-based neural network to\ngenerate the node and graph embeddings by a novel aggregation strategy to\nincorporate the edge direction information into the node embeddings. We also\npropose an attention based mechanism that aligns node embeddings and decoding\nsequence to better cope with large graphs. Experimental results on bAbI task,\nShortest Path Task, and Natural Language Generation Task demonstrate that our\nmodel achieves the state-of-the-art performance and significantly outperforms\nother baselines. We also show that with the proposed aggregation strategy, our\nproposed model is able to quickly converge to good performance.\n"]},
{"authors": ["Rasoul Kheiri"], "title": ["A Projective Simulation Scheme for a Partially-Observable Multi-Agent\n  Game"], "date": ["2016-10-29T10:35:53Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1610.09372v3"], "summary": ["  We introduce a kind of partial observability to the projective simulation\n(PS) learning method via Dirac notation. It is done by adding a projection\noperator and an observability parameter to the original formulation of the\nefficiency in PS model. Our examples are from invasion toy problem regarding a\nmulti-agent setting.\n"]},
{"authors": ["Boris Belousov", "Jan Peters"], "title": ["f-Divergence constrained policy improvement"], "date": ["2017-12-29T23:07:26Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.00056v2"], "summary": ["  To ensure stability of learning, state-of-the-art generalized policy\niteration algorithms augment the policy improvement step with a trust region\nconstraint bounding the information loss. The size of the trust region is\ncommonly determined by the Kullback-Leibler (KL) divergence, which not only\ncaptures the notion of distance well but also yields closed-form solutions. In\nthis paper, we consider a more general class of f-divergences and derive the\ncorresponding policy update rules. The generic solution is expressed through\nthe derivative of the convex conjugate function to f and includes the KL\nsolution as a special case. Within the class of f-divergences, we further focus\non a one-parameter family of $\\alpha$-divergences to study effects of the\nchoice of divergence on policy improvement. Previously known as well as new\npolicy updates emerge for different values of $\\alpha$. We show that every type\nof policy update comes with a compatible policy evaluation resulting from the\nchosen f-divergence. Interestingly, the mean-squared Bellman error minimization\nis closely related to policy evaluation with the Pearson $\\chi^2$-divergence\npenalty, while the KL divergence results in the soft-max policy update and a\nlog-sum-exp critic. We carry out asymptotic analysis of the solutions for\ndifferent values of $\\alpha$ and demonstrate the effects of using different\ndivergence functions on a multi-armed bandit problem and on common standard\nreinforcement learning problems.\n"]},
{"authors": ["Wei Zhao", "Jianbo Ye", "Min Yang", "Zeyang Lei", "Suofei Zhang", "Zhou Zhao"], "title": ["Investigating Capsule Networks with Dynamic Routing for Text\n  Classification"], "date": ["2018-03-29T02:27:42Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.00538v2"], "summary": ["  In this study, we explore capsule networks with dynamic routing for text\nclassification. We propose three strategies to stabilize the dynamic routing\nprocess to alleviate the disturbance of some noise capsules which may contain\n\"background\" information or have not been successfully trained. A series of\nexperiments are conducted with capsule networks on six text classification\nbenchmarks. Capsule networks achieve state of the art on 4 out of 6 datasets,\nwhich shows the effectiveness of capsule networks for text classification. We\nadditionally show that capsule networks exhibit significant improvement when\ntransfer single-label to multi-label text classification over strong baseline\nmethods. To the best of our knowledge, this is the first work that capsule\nnetworks have been empirically investigated for text modeling.\n"]},
{"authors": ["Daniel Hein", "Steffen Udluft", "Thomas A. Runkler"], "title": ["Interpretable Policies for Reinforcement Learning by Genetic Programming"], "date": ["2017-12-12T08:31:51Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1712.04170v2"], "summary": ["  The search for interpretable reinforcement learning policies is of high\nacademic and industrial interest. Especially for industrial systems, domain\nexperts are more likely to deploy autonomously learned controllers if they are\nunderstandable and convenient to evaluate. Basic algebraic equations are\nsupposed to meet these requirements, as long as they are restricted to an\nadequate complexity. Here we introduce the genetic programming for\nreinforcement learning (GPRL) approach based on model-based batch reinforcement\nlearning and genetic programming, which autonomously learns policy equations\nfrom pre-existing default state-action trajectory samples. GPRL is compared to\na straight-forward method which utilizes genetic programming for symbolic\nregression, yielding policies imitating an existing well-performing, but\nnon-interpretable policy. Experiments on three reinforcement learning\nbenchmarks, i.e., mountain car, cart-pole balancing, and industrial benchmark,\ndemonstrate the superiority of our GPRL approach compared to the symbolic\nregression method. GPRL is capable of producing well-performing interpretable\nreinforcement learning policies from pre-existing default trajectory data.\n"]},
{"authors": ["Thomas Guyet", "Ren\u00e9 Quiniou"], "title": ["NegPSpan: efficient extraction of negative sequential patterns with\n  embedding constraints"], "date": ["2018-04-04T06:47:32Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.01256v1"], "summary": ["  Mining frequent sequential patterns consists in extracting recurrent\nbehaviors, modeled as patterns, in a big sequence dataset. Such patterns inform\nabout which events are frequently observed in sequences, i.e. what does really\nhappen. Sometimes, knowing that some specific event does not happen is more\ninformative than extracting a lot of observed events. Negative sequential\npatterns (NSP) formulate recurrent behaviors by patterns containing both\nobserved events and absent events. Few approaches have been proposed to mine\nsuch NSPs. In addition, the syntax and semantics of NSPs differ in the\ndifferent methods which makes it difficult to compare them. This article\nprovides a unified framework for the formulation of the syntax and the\nsemantics of NSPs. Then, we introduce a new algorithm, NegPSpan, that extracts\nNSPs using a PrefixSpan depth-first scheme and enabling maxgap constraints that\nother approaches do not take into account. The formal framework allows for\nhighlighting the differences between the proposed approach wrt to the methods\nfrom the literature, especially wrt the state of the art approach eNSP.\nIntensive experiments on synthetic and real datasets show that NegPSpan can\nextract meaningful NSPs and that it can process bigger datasets than eNSP\nthanks to significantly lower memory requirements and better computation times.\n"]},
{"authors": ["Mikael Henaff", "William F. Whitney", "Yann LeCun"], "title": ["Model-Based Planning with Discrete and Continuous Actions"], "date": ["2017-05-19T20:38:49Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1705.07177v2"], "summary": ["  Action planning using learned and differentiable forward models of the world\nis a general approach which has a number of desirable properties, including\nimproved sample complexity over model-free RL methods, reuse of learned models\nacross different tasks, and the ability to perform efficient gradient-based\noptimization in continuous action spaces. However, this approach does not apply\nstraightforwardly when the action space is discrete. In this work, we show that\nit is in fact possible to effectively perform planning via backprop in discrete\naction spaces, using a simple paramaterization of the actions vectors on the\nsimplex combined with input noise when training the forward model. Our\nexperiments show that this approach can match or outperform model-free RL and\ndiscrete planning methods on gridworld navigation tasks in terms of performance\nand/or planning time while using limited environment interactions, and can\nadditionally be used to perform model-based control in a challenging new task\nwhere the action space combines discrete and continuous actions. We furthermore\npropose a policy distillation approach which yields a fast policy network which\ncan be used at inference time, removing the need for an iterative planning\nprocedure.\n"]},
{"authors": ["Bart Jacobs", "Fabio Zanasi"], "title": ["The Logical Essentials of Bayesian Reasoning"], "date": ["2018-04-03T23:55:41Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.01193v1"], "summary": ["  This chapter offers an accessible introduction to the channel-based approach\nto Bayesian probability theory. This framework rests on algebraic and logical\nfoundations, inspired by the methodologies of programming language semantics.\nIt offers a uniform, structured and expressive language for describing Bayesian\nphenomena in terms of familiar programming concepts, like channel, predicate\ntransformation and state transformation. The introduction also covers inference\nin Bayesian networks, which will be modelled by a suitable calculus of string\ndiagrams.\n"]},
{"authors": ["Ashwin J. Vijayakumar", "Abhishek Mohta", "Oleksandr Polozov", "Dhruv Batra", "Prateek Jain", "Sumit Gulwani"], "title": ["Neural-Guided Deductive Search for Real-Time Program Synthesis from\n  Examples"], "date": ["2018-04-03T22:37:08Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.01186v1"], "summary": ["  Synthesizing user-intended programs from a small number of input-output\nexamples is a challenging problem with several important applications like\nspreadsheet manipulation, data wrangling and code refactoring. Existing\nsynthesis systems either completely rely on deductive logic techniques that are\nextensively hand-engineered or on purely statistical models that need massive\namounts of data, and in general fail to provide real-time synthesis on\nchallenging benchmarks. In this work, we propose Neural Guided Deductive Search\n(NGDS), a hybrid synthesis technique that combines the best of both symbolic\nlogic techniques and statistical models. Thus, it produces programs that\nsatisfy the provided specifications by construction and generalize well on\nunseen examples, similar to data-driven systems. Our technique effectively\nutilizes the deductive search framework to reduce the learning problem of the\nneural component to a simple supervised learning setup. Further, this allows us\nto both train on sparingly available real-world data and still leverage\npowerful recurrent neural network encoders. We demonstrate the effectiveness of\nour method by evaluating on real-world customer scenarios by synthesizing\naccurate programs with up to 12x speed-up compared to state-of-the-art systems.\n"]},
{"authors": ["Priya L. Donti", "Brandon Amos", "J. Zico Kolter"], "title": ["Task-based End-to-end Model Learning in Stochastic Optimization"], "date": ["2017-03-13T17:58:36Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1703.04529v3"], "summary": ["  With the increasing popularity of machine learning techniques, it has become\ncommon to see prediction algorithms operating within some larger process.\nHowever, the criteria by which we train these algorithms often differ from the\nultimate criteria on which we evaluate them. This paper proposes an end-to-end\napproach for learning probabilistic machine learning models in a manner that\ndirectly captures the ultimate task-based objective for which they will be\nused, within the context of stochastic programming. We present three\nexperimental evaluations of the proposed approach: a classical inventory stock\nproblem, a real-world electrical grid scheduling task, and a real-world energy\nstorage arbitrage task. We show that the proposed approach can outperform both\ntraditional modeling and purely black-box policy optimization approaches in\nthese applications.\n"]},
{"authors": ["Carlos Gershenson", "Vito Trianni", "Justin Werfel", "Hiroki Sayama"], "title": ["Self-Organization and Artificial Life: A Review"], "date": ["2018-04-03T19:44:09Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.01144v1"], "summary": ["  Self-organization has been an important concept within a number of\ndisciplines, which Artificial Life (ALife) also has heavily utilized since its\ninception. The term and its implications, however, are often confusing or\nmisinterpreted. In this work, we provide a mini-review of self-organization and\nits relationship with ALife, aiming at initiating discussions on this important\ntopic with the interested audience. We first articulate some fundamental\naspects of self-organization, outline its usage, and review its applications to\nALife within its soft, hard, and wet domains. We also provide perspectives for\nfurther research.\n"]},
{"authors": ["Luis Piloto", "Ari Weinstein", "Dhruva TB", "Arun Ahuja", "Mehdi Mirza", "Greg Wayne", "David Amos", "Chia-chun Hung", "Matt Botvinick"], "title": ["Probing Physics Knowledge Using Tools from Developmental Psychology"], "date": ["2018-04-03T18:47:46Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.01128v1"], "summary": ["  In order to build agents with a rich understanding of their environment, one\nkey objective is to endow them with a grasp of intuitive physics; an ability to\nreason about three-dimensional objects, their dynamic interactions, and\nresponses to forces. While some work on this problem has taken the approach of\nbuilding in components such as ready-made physics engines, other research aims\nto extract general physical concepts directly from sensory data. In the latter\ncase, one challenge that arises is evaluating the learning system. Research on\nintuitive physics knowledge in children has long employed a violation of\nexpectations (VOE) method to assess children's mastery of specific physical\nconcepts. We take the novel step of applying this method to artificial learning\nsystems. In addition to introducing the VOE technique, we describe a set of\nprobe datasets inspired by classic test stimuli from developmental psychology.\nWe test a baseline deep learning system on this battery, as well as on a\nphysics learning dataset (\"IntPhys\") recently posed by another research group.\nOur results show how the VOE technique may provide a useful tool for tracking\nphysics knowledge in future research.\n"]},
{"authors": ["Helge Rhodin", "Mathieu Salzmann", "Pascal Fua"], "title": ["Unsupervised Geometry-Aware Representation for 3D Human Pose Estimation"], "date": ["2018-04-03T18:01:54Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.01110v1"], "summary": ["  Modern 3D human pose estimation techniques rely on deep networks, which\nrequire large amounts of training data. While weakly-supervised methods require\nless supervision, by utilizing 2D poses or multi-view imagery without\nannotations, they still need a sufficiently large set of samples with 3D\nannotations for learning to succeed.\n  In this paper, we propose to overcome this problem by learning a\ngeometry-aware body representation from multi-view images without annotations.\nTo this end, we use an encoder-decoder that predicts an image from one\nviewpoint given an image from another viewpoint. Because this representation\nencodes 3D geometry, using it in a semi-supervised setting makes it easier to\nlearn a mapping from it to 3D human pose. As evidenced by our experiments, our\napproach significantly outperforms fully-supervised methods given the same\namount of labeled data, and improves over other semi-supervised methods while\nusing as little as 1% of the labeled data.\n"]},
{"authors": ["Krishna Kumar Singh", "Santosh Divvala", "Ali Farhadi", "Yong Jae Lee"], "title": ["Transferring Common-Sense Knowledge for Object Detection"], "date": ["2018-04-03T17:41:53Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.01077v1"], "summary": ["  We propose the idea of transferring common-sense knowledge from source\ncategories to target categories for scalable object detection. In our setting,\nthe training data for the source categories have bounding box annotations,\nwhile those for the target categories only have image-level annotations.\nCurrent state-of-the-art approaches focus on image-level visual or semantic\nsimilarity to adapt a detector trained on the source categories to the new\ntarget categories. In contrast, our key idea is to (i) use similarity not at\nimage-level, but rather at region-level, as well as (ii) leverage richer\ncommon-sense (based on attribute, spatial, etc.,) to guide the algorithm\ntowards learning the correct detections. We acquire such common-sense cues\nautomatically from readily-available knowledge bases without any extra human\neffort. On the challenging MS COCO dataset, we find that using common-sense\nknowledge substantially improves detection performance over existing\ntransfer-learning baselines.\n"]},
{"authors": ["Haque Ishfaq", "Assaf Hoogi", "Daniel Rubin"], "title": ["TVAE: Triplet-Based Variational Autoencoder using Metric Learning"], "date": ["2018-02-13T00:05:19Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04403v2"], "summary": ["  Deep metric learning has been demonstrated to be highly effective in learning\nsemantic representation and encoding information that can be used to measure\ndata similarity, by relying on the embedding learned from metric learning. At\nthe same time, variational autoencoder (VAE) has widely been used to\napproximate inference and proved to have a good performance for directed\nprobabilistic models. However, for traditional VAE, the data label or feature\ninformation are intractable. Similarly, traditional representation learning\napproaches fail to represent many salient aspects of the data. In this project,\nwe propose a novel integrated framework to learn latent embedding in VAE by\nincorporating deep metric learning. The features are learned by optimizing a\ntriplet loss on the mean vectors of VAE in conjunction with standard evidence\nlower bound (ELBO) of VAE. This approach, which we call Triplet based\nVariational Autoencoder (TVAE), allows us to capture more fine-grained\ninformation in the latent embedding. Our model is tested on MNIST data set and\nachieves a high triplet accuracy of 95.60% while the traditional VAE (Kingma &\nWelling, 2013) achieves triplet accuracy of 75.08%.\n"]},
{"authors": ["Patrick Klose", "Rudolf Mester"], "title": ["Simulated Autonomous Driving on Realistic Road Networks using Deep\n  Reinforcement Learning"], "date": ["2017-12-12T15:55:53Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1712.04363v2"], "summary": ["  Using Deep Reinforcement Learning (DRL) can be a promising approach to handle\nvarious tasks in the field of (simulated) autonomous driving. However, recent\npublications mainly consider learning in unusual driving environments. This\npaper presents Driving School for Autonomous Agents (DSA^2), a software for\nvalidating DRL algorithms in more usual driving environments based on\nartificial and realistic road networks. We also present the results of applying\nDSA^2 for handling the task of driving on a straight road while regulating the\nvelocity of one vehicle according to different speed limits.\n"]},
{"authors": ["Wenjie Pei", "David M. J. Tax"], "title": ["Unsupervised Learning of Sequence Representations by Autoencoders"], "date": ["2018-04-03T13:12:45Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.00946v1"], "summary": ["  Traditional machine learning models have problems with handling sequence\ndata, because the lengths of sequences may vary between samples. In this paper,\nwe present an unsupervised learning model for sequence data, called the\nIntegrated Sequence Autoencoder (ISA), to learn a fixed-length vectorial\nrepresentation by minimizing the reconstruction error. Specifically, we propose\nto integrate two classical mechanisms for sequence reconstruction which takes\ninto account both the global silhouette information and the local temporal\ndependencies. Furthermore, we propose a stop feature that serves as a temporal\nstamp to guide the reconstruction process, and which results in a\nhigher-quality representation. Extensive validation on real-world datasets\nshows that the learned representation is able to effectively summarize not only\nthe apparent features, but also the underlying and high-level style\ninformation. Take for example a speech sequence sample: our ISA model can not\nonly recognize the spoken text (apparent feature), but can also discriminate\nthe speaker who utters the audio (more high-level style).\n"]},
{"authors": ["Tao Shen", "Tianyi Zhou", "Guodong Long", "Jing Jiang", "Chengqi Zhang"], "title": ["Bi-Directional Block Self-Attention for Fast and Memory-Efficient\n  Sequence Modeling"], "date": ["2018-04-03T07:41:10Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.00857v1"], "summary": ["  Recurrent neural networks (RNN), convolutional neural networks (CNN) and\nself-attention networks (SAN) are commonly used to produce context-aware\nrepresentations. RNN can capture long-range dependency but is hard to\nparallelize and not time-efficient. CNN focuses on local dependency but does\nnot perform well on some tasks. SAN can model both such dependencies via highly\nparallelizable computation, but memory requirement grows rapidly in line with\nsequence length. In this paper, we propose a model, called \"bi-directional\nblock self-attention network (Bi-BloSAN)\", for RNN/CNN-free sequence encoding.\nIt requires as little memory as RNN but with all the merits of SAN. Bi-BloSAN\nsplits the entire sequence into blocks, and applies an intra-block SAN to each\nblock for modeling local context, then applies an inter-block SAN to the\noutputs for all blocks to capture long-range dependency. Thus, each SAN only\nneeds to process a short sequence, and only a small amount of memory is\nrequired. Additionally, we use feature-level attention to handle the variation\nof contexts around the same word, and use forward/backward masks to encode\ntemporal order information. On nine benchmark datasets for different NLP tasks,\nBi-BloSAN achieves or improves upon state-of-the-art accuracy, and shows better\nefficiency-memory trade-off than existing RNN/CNN/SAN.\n"]},
{"authors": ["Changmao Cheng", "Yanwei Fu", "Yu-Gang Jiang", "Wei Liu", "Wenlian Lu", "Jianfeng Feng", "Xiangyang Xue"], "title": ["Dual Skipping Networks"], "date": ["2017-10-28T04:18:11Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.10386v2"], "summary": ["  Inspired by the recent neuroscience studies on the left-right asymmetry of\nthe human brain in processing low and high spatial frequency information, this\npaper introduces a dual skipping network which carries out coarse-to-fine\nobject categorization. Such a network has two branches to simultaneously deal\nwith both coarse and fine-grained classification tasks. Specifically, we\npropose a layer-skipping mechanism that learns a gating network to predict\nwhich layers to skip in the testing stage. This layer-skipping mechanism endows\nthe network with good flexibility and capability in practice. Evaluations are\nconducted on several widely used coarse-to-fine object categorization\nbenchmarks, and promising results are achieved by our proposed network model.\n"]},
{"authors": ["Jialin Song", "Ravi Lanka", "Albert Zhao", "Yisong Yue", "Masahiro Ono"], "title": ["Learning to Search via Self-Imitation"], "date": ["2018-04-03T06:52:09Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.00846v1"], "summary": ["  We study the problem of learning a good search policy. To do so, we propose\nthe self-imitation learning setting, which builds upon imitation learning in\ntwo ways. First, self-imitation uses feedback provided by retrospective\nanalysis of demonstrated search traces. Second, the policy can learn from its\nown decisions and mistakes without requiring repeated feedback from an external\nexpert. Combined, these two properties allow our approach to iteratively scale\nup to larger problem sizes than the initial problem size for which expert\ndemonstrations were provided. We showcase the effectiveness of our approach on\na synthetic maze solving task and the problem of risk-aware path planning.\n"]},
{"authors": ["Kun Shao", "Yuanheng Zhu", "Dongbin Zhao"], "title": ["StarCraft Micromanagement with Reinforcement Learning and Curriculum\n  Transfer Learning"], "date": ["2018-04-03T03:57:02Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.00810v1"], "summary": ["  Real-time strategy games have been an important field of game artificial\nintelligence in recent years. This paper presents a reinforcement learning and\ncurriculum transfer learning method to control multiple units in StarCraft\nmicromanagement. We define an efficient state representation, which breaks down\nthe complexity caused by the large state space in the game environment. Then a\nparameter sharing multi-agent gradientdescent Sarsa({\\lambda}) (PS-MAGDS)\nalgorithm is proposed to train the units. The learning policy is shared among\nour units to encourage cooperative behaviors. We use a neural network as a\nfunction approximator to estimate the action-value function, and propose a\nreward function to help units balance their move and attack. In addition, a\ntransfer learning method is used to extend our model to more difficult\nscenarios, which accelerates the training process and improves the learning\nperformance. In small scale scenarios, our units successfully learn to combat\nand defeat the built-in AI with 100% win rates. In large scale scenarios,\ncurriculum transfer learning method is used to progressively train a group of\nunits, and shows superior performance over some baseline methods in target\nscenarios. With reinforcement learning and curriculum transfer learning, our\nunits are able to learn appropriate strategies in StarCraft micromanagement\nscenarios.\n"]},
{"authors": ["Mohammad Hasanzadeh Mofrad", "S. K. Chang"], "title": ["A Bi-population Particle Swarm Optimizer for Learning Automata based\n  Slow Intelligent System"], "date": ["2018-04-03T00:12:07Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.00768v1"], "summary": ["  Particle Swarm Optimization (PSO) is an Evolutionary Algorithm (EA) that\nutilizes a swarm of particles to solve an optimization problem. Slow\nIntelligence System (SIS) is a learning framework which slowly learns the\nsolution to a problem performing a series of operations. Moreover, Learning\nAutomata (LA) are minuscule but effective decision making entities which are\nbest suited to act as a controller component. In this paper, we combine two\nisolate populations of PSO to forge the Adaptive Intelligence Optimizer (AIO)\nwhich harnesses the advantages of a bi-population PSO to escape from the local\nminimum and avoid premature convergence. Furthermore, using the rich framework\nof SIS and the nifty control theory that LA derived from, we find the perfect\nmatching between SIS and LA where acting slowly is the pillar of both of them.\nBoth SIS and LA need time to converge to the optimal decision where this\nenables AIO to outperform standard PSO having an incomparable performance on\nevolutionary optimization benchmark functions.\n"]},
{"authors": ["Zhong Meng", "Jinyu Li", "Zhuo Chen", "Yong Zhao", "Vadim Mazalov", "Yifan Gong", " Biing-Hwang", " Juang"], "title": ["Speaker-Invariant Training via Adversarial Learning"], "date": ["2018-04-02T21:09:30Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.00732v1"], "summary": ["  We propose a novel adversarial multi-task learning scheme, aiming at actively\ncurtailing the inter-talker feature variability while maximizing its senone\ndiscriminability so as to enhance the performance of a deep neural network\n(DNN) based ASR system. We call the scheme speaker-invariant training (SIT). In\nSIT, a DNN acoustic model and a speaker classifier network are jointly\noptimized to minimize the senone (tied triphone state) classification loss, and\nsimultaneously mini-maximize the speaker classification loss. A\nspeaker-invariant and senone-discriminative deep feature is learned through\nthis adversarial multi-task learning. With SIT, a canonical DNN acoustic model\nwith significantly reduced variance in its output probabilities is learned with\nno explicit speaker-independent (SI) transformations or speaker-specific\nrepresentations used in training or testing. Evaluated on the CHiME-3 dataset,\nthe SIT achieves 4.99% relative word error rate (WER) improvement over the\nconventional SI acoustic model. With additional unsupervised speaker\nadaptation, the speaker-adapted (SA) SIT model achieves 4.86% relative WER gain\nover the SA SI acoustic model.\n"]},
{"authors": ["Ario Santoso"], "title": ["Specification-Driven Multi-Perspective Predictive Business Process\n  Monitoring (Extended Version)"], "date": ["2018-04-02T16:26:35Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.00617v1"], "summary": ["  Predictive analysis in business process monitoring aims at forecasting the\nfuture information of a running business process. The prediction is typically\nmade based on the model extracted from historical process execution logs (event\nlogs). In practice, different business domains might require different kinds of\npredictions. Hence, it is important to have a means for properly specifying the\ndesired prediction tasks, and a mechanism to deal with these various prediction\ntasks. Although there have been many studies in this area, they mostly focus on\na specific prediction task. This work introduces a language for specifying the\ndesired prediction tasks, and this language allows us to express various kinds\nof prediction tasks. This work also presents a mechanism for automatically\ncreating the corresponding prediction model based on the given specification.\nThus, different from previous studies, our approach enables us to deal with\nvarious kinds of prediction tasks based on the given specification. A prototype\nimplementing our approach has been developed and experiments using a real-life\nevent log have been conducted.\n"]},
{"authors": ["Thibault Gauthier", "Cezary Kaliszyk", "Josef Urban", "Ramana Kumar", "Michael Norrish"], "title": ["Learning to Prove with Tactics"], "date": ["2018-04-02T15:43:17Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.00596v1"], "summary": ["  We implement a automated tactical prover TacticToe on top of the HOL4\ninteractive theorem prover. TacticToe learns from human proofs which\nmathematical technique is suitable in each proof situation. This knowledge is\nthen used in a Monte Carlo tree search algorithm to explore promising\ntactic-level proof paths. On a single CPU, with a time limit of 60 seconds,\nTacticToe proves 66.4 percent of the 7164 theorems in HOL4's standard library,\nwhereas E prover with auto-schedule solves 34.5 percent. The success rate rises\nto 69.0 percent by combining the results of TacticToe and E prover.\n"]},
{"authors": ["Thibault Gauthier", "Cezary Kaliszyk", "Josef Urban"], "title": ["Learning to Reason with HOL4 tactics"], "date": ["2018-04-02T15:41:09Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.00595v1"], "summary": ["  Techniques combining machine learning with translation to automated reasoning\nhave recently become an important component of formal proof assistants. Such\n\"hammer\" tech- niques complement traditional proof assistant automation as\nimplemented by tactics and decision procedures. In this paper we present a\nunified proof assistant automation approach which attempts to automate the\nselection of appropriate tactics and tactic-sequences com- bined with an\noptimized small-scale hammering approach. We implement the technique as a\ntactic-level automation for HOL4: TacticToe. It implements a modified\nA*-algorithm directly in HOL4 that explores different tactic-level proof paths,\nguiding their selection by learning from a large number of previous\ntactic-level proofs. Unlike the existing hammer methods, TacticToe avoids\ntranslation to FOL, working directly on the HOL level. By combining tactic\nprediction and premise selection, TacticToe is able to re-prove 39 percent of\n7902 HOL4 theorems in 5 seconds whereas the best single HOL(y)Hammer strategy\nsolves 32 percent in the same amount of time.\n"]},
{"authors": ["Shruti Mittal", "Dattaraj Rao"], "title": ["Regional Priority Based Anomaly Detection using Autoencoders"], "date": ["2018-04-02T13:49:01Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.00492v1"], "summary": ["  In the recent times, autoencoders, besides being used for compression, have\nbeen proven quite useful even for regenerating similar images or help in image\ndenoising. They have also been explored for anomaly detection in a few cases.\nHowever, due to location invariance property of convolutional neural network,\nautoencoders tend to learn from or search for learned features in the complete\nimage. This creates issues when all the items in the image are not equally\nimportant and their location matters. For such cases, a semi supervised\nsolution - regional priority based autoencoder (RPAE) has been proposed. In\nthis model, similar to object detection models, a region proposal network\nidentifies the relevant areas in the images as belonging to one of the\npredefined categories and then those bounding boxes are fed into appropriate\ndecoder based on the category they belong to. Finally, the error scores from\nall the decoders are combined based on their importance to provide total\nreconstruction error.\n"]},
{"authors": ["Oleksii Zhelo", "Jingwei Zhang", "Lei Tai", "Ming Liu", "Wolfram Burgard"], "title": ["Curiosity-driven Exploration for Mapless Navigation with Deep\n  Reinforcement Learning"], "date": ["2018-04-02T11:40:00Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.00456v1"], "summary": ["  This paper investigates exploration strategies of Deep Reinforcement Learning\n(DRL) methods to learn navigation policies for mobile robots. In particular, we\naugment the normal external reward for training DRL algorithms with intrinsic\nreward signals measured by curiosity. We test our approach in a mapless\nnavigation setting, where the autonomous agent is required to navigate without\nthe occupancy map of the environment, to targets whose relative locations can\nbe easily acquired through low-cost solutions (e.g., visible light\nlocalization, Wi-Fi signal localization). We validate that the intrinsic\nmotivation is crucial for improving DRL performance in tasks with challenging\nexploration requirements. Our experimental results show that our proposed\nmethod is able to more effectively learn navigation policies, and has better\ngeneralization capabilities in previously unseen environments. A video of our\nexperimental results can be found at https://goo.gl/pWbpcF.\n"]},
{"authors": ["Dongwook Lee", "Jaejun Yoo", "Sungho Tak", "Jong Chul Ye"], "title": ["Deep Residual Learning for Accelerated MRI using Magnitude and Phase\n  Networks"], "date": ["2018-04-02T09:08:02Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.00432v1"], "summary": ["  Accelerated magnetic resonance (MR) scan acquisition with compressed sensing\n(CS) and parallel imaging is a powerful method to reduce MR imaging scan time.\nHowever, many reconstruction algorithms have high computational costs. To\naddress this, we investigate deep residual learning networks to remove aliasing\nartifacts from artifact corrupted images. The proposed deep residual learning\nnetworks are composed of magnitude and phase networks that are separately\ntrained. If both phase and magnitude information are available, the proposed\nalgorithm can work as an iterative k-space interpolation algorithm using\nframelet representation. When only magnitude data is available, the proposed\napproach works as an image domain post-processing algorithm. Even with strong\ncoherent aliasing artifacts, the proposed network successfully learned and\nremoved the aliasing artifacts, whereas current parallel and CS reconstruction\nmethods were unable to remove these artifacts. Comparisons using single and\nmultiple coil show that the proposed residual network provides good\nreconstruction results with orders of magnitude faster computational time than\nexisting compressed sensing methods. The proposed deep learning framework may\nhave a great potential for accelerated MR reconstruction by generating accurate\nresults immediately.\n"]},
{"authors": ["Michael Gr. Voskoglou", "Yiannis Theodorou"], "title": ["Application of Grey Numbers to Assessment Processes"], "date": ["2018-04-02T07:45:55Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.00423v1"], "summary": ["  The theory of grey systems plays an important role in science,engineering and\nin the everyday life in general for handling approximate data. In the present\npaper grey numbers are used as a tool for assessing with linguistic expressions\nthe mean performance of a group of objects participating in a certain activity.\nTwo applications to student and football player assessment are also presented\nillustrating our results.\n"]},
{"authors": ["Michael Gr. Voskoglou"], "title": ["A Study of Student Learning Skills Using Fuzzy Relation Equations"], "date": ["2018-04-02T07:31:34Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.00421v1"], "summary": ["  Fuzzy relation equations (FRE)are associated with the composition of binary\nfuzzy relations. In the present work FRE are used as a tool for studying the\nprocess of learning a new subject matter by a student class. A classroom\napplication and other csuitable examples connected to the student learning of\nthe derivative are also presented illustrating our results and useful\nconclusions are obtained.\n"]},
{"authors": ["Shiyu Duan", "Yunmei Chen", "Jose Principe"], "title": ["Learning Multiple Levels of Representations with Kernel Machines"], "date": ["2018-02-11T17:18:28Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.03774v2"], "summary": ["  We propose a connectionist-inspired kernel machine model with three key\nadvantages over traditional kernel machines. First, it is capable of learning\ndistributed and hierarchical representations. Second, its performance is highly\nrobust to the choice of kernel function. Third, the solution space is not\nlimited to the span of images of training data in reproducing kernel Hilbert\nspace (RKHS). Together with the architecture, we propose a greedy learning\nalgorithm that allows the proposed multilayer network to be trained layer-wise\nwithout backpropagation by optimizing the geometric properties of images in\nRKHS. With a single fixed generic kernel for each layer and two layers in\ntotal, our model compares favorably with state-of-the-art multiple kernel\nlearning algorithms using significantly more kernels and popular deep\narchitectures on widely used classification benchmarks.\n"]},
{"authors": ["Saksham Sharma", "Pallav Agarwal", "Parv Mor", "Amey Karkare"], "title": ["TipsC: Tips and Corrections for programming MOOCs"], "date": ["2018-04-02T02:17:53Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.00373v1"], "summary": ["  With the widespread adoption of MOOCs in academic institutions, it has become\nimperative to come up with better techniques to solve the tutoring and grading\nproblems posed by programming courses. Programming being the new 'writing', it\nbecomes a challenge to ensure that a large section of the society is exposed to\nprogramming. Due to the gradient in learning abilities of students, the course\ninstructor must ensure that everyone can cope up with the material, and receive\nadequate help in completing assignments while learning along the way. We\nintroduce TipsC for this task. By analyzing a large number of correct\nsubmissions, TipsC can search for correct codes resembling a given incorrect\nsolution. Without revealing the actual code, TipsC then suggests changes in the\nincorrect code to help the student fix logical runtime errors. In addition,\nthis also serves as a cluster visualization tool for the instructor, revealing\ndifferent patterns in user submissions. We evaluated the effectiveness of\nTipsC's clustering algorithm on data collected from previous offerings of an\nintroductory programming course conducted at IIT Kanpur where the grades were\ngiven by human TAs. The results show the weighted average variance of marks for\nclusters when similar submissions are grouped together is 47% less compared to\nthe case when all programs are grouped together.\n"]},
{"authors": ["Ruiyi Zhang", "Chunyuan Li", "Changyou Chen", "Lawrence Carin"], "title": ["Learning Structural Weight Uncertainty for Sequential Decision-Making"], "date": ["2017-12-30T04:34:34Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.00085v2"], "summary": ["  Learning probability distributions on the weights of neural networks (NNs)\nhas recently proven beneficial in many applications. Bayesian methods, such as\nStein variational gradient descent (SVGD), offer an elegant framework to reason\nabout NN model uncertainty. However, by assuming independent Gaussian priors\nfor the individual NN weights (as often applied), SVGD does not impose prior\nknowledge that there is often structural information (dependence) among\nweights. We propose efficient posterior learning of structural weight\nuncertainty, within an SVGD framework, by employing matrix variate Gaussian\npriors on NN parameters. We further investigate the learned structural\nuncertainty in sequential decision-making problems, including contextual\nbandits and reinforcement learning. Experiments on several synthetic and real\ndatasets indicate the superiority of our model, compared with state-of-the-art\nmethods.\n"]},
{"authors": ["\u0141ukasz Kidzi\u0144ski", "Sharada Prasanna Mohanty", "Carmichael Ong", "Zhewei Huang", "Shuchang Zhou", "Anton Pechenko", "Adam Stelmaszczyk", "Piotr Jarosik", "Mikhail Pavlov", "Sergey Kolesnikov", "Sergey Plis", "Zhibo Chen", "Zhizheng Zhang", "Jiale Chen", "Jun Shi", "Zhuobin Zheng", "Chun Yuan", "Zhihui Lin", "Henryk Michalewski", "Piotr Mi\u0142o\u015b", "B\u0142a\u017cej Osi\u0144ski", "Andrew Melnik", "Malte Schilling", "Helge Ritter", "Sean Carroll", "Jennifer Hicks", "Sergey Levine", "Marcel Salath\u00e9", "Scott Delp"], "title": ["Learning to Run challenge solutions: Adapting reinforcement learning\n  methods for neuromusculoskeletal environments"], "date": ["2018-04-02T00:19:31Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.00361v1"], "summary": ["  In the NIPS 2017 Learning to Run challenge, participants were tasked with\nbuilding a controller for a musculoskeletal model to make it run as fast as\npossible through an obstacle course. Top participants were invited to describe\ntheir algorithms. In this work, we present eight solutions that used deep\nreinforcement learning approaches, based on algorithms such as Deep\nDeterministic Policy Gradient, Proximal Policy Optimization, and Trust Region\nPolicy Optimization. Many solutions use similar relaxations and heuristics,\nsuch as reward shaping, frame skipping, discretization of the action space,\nsymmetry, and policy blending. However, each of the eight teams implemented\ndifferent modifications of the known algorithms.\n"]},
{"authors": ["Jahanzaib Shabbir", "Tarique Anwer"], "title": ["Artificial Intelligence and its Role in Near Future"], "date": ["2018-04-01T23:12:30Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.01396v1"], "summary": ["  AI technology has a long history which is actively and constantly changing\nand growing. It focuses on intelligent agents, which contain devices that\nperceive the environment and based on which takes actions in order to maximize\ngoal success chances. In this paper, we will explain the modern AI basics and\nvarious representative applications of AI. In the context of the modern\ndigitalized world, AI is the property of machines, computer programs, and\nsystems to perform the intellectual and creative functions of a person,\nindependently find ways to solve problems, be able to draw conclusions and make\ndecisions. Most artificial intelligence systems have the ability to learn,\nwhich allows people to improve their performance over time. The recent research\non AI tools, including machine learning, deep learning and predictive analysis\nintended toward increasing the planning, learning, reasoning, thinking and\naction taking ability. Based on which, the proposed research intends towards\nexploring on how the human intelligence differs from the artificial\nintelligence. Moreover, we critically analyze what AI of today is capable of\ndoing, why it still cannot reach human intelligence and what are the open\nchallenges existing in front of AI to reach and outperform human level of\nintelligence. Furthermore, it will explore the future predictions for\nartificial intelligence and based on which potential solution will be\nrecommended to solve it within next decades.\n"]},
{"authors": ["James Lucas", "Richard Zemel", "Roger Grosse"], "title": ["Aggregated Momentum: Stability Through Passive Damping"], "date": ["2018-04-01T17:53:03Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.00325v1"], "summary": ["  Momentum is a simple and widely used trick which allows gradient-based\noptimizers to pick up speed in low curvature directions. Its performance\ndepends crucially on a damping coefficient $\\beta$. Large $\\beta$ values can\npotentially deliver much larger speedups, but are prone to oscillations and\ninstability; hence one typically resorts to small values such as 0.5 or 0.9. We\npropose Aggregated Momentum (AggMo), a variant of momentum which combines\nmultiple velocity vectors with different $\\beta$ parameters. AggMo is trivial\nto implement, but significantly dampens oscillations, enabling it to remain\nstable even for aggressive $\\beta$ values such as 0.999. We reinterpret\nNesterov's accelerated gradient descent as a special case of AggMo and provide\ntheoretical convergence bounds for online convex optimization. Empirically, we\nfind that AggMo is a suitable drop-in replacement for other momentum methods,\nand frequently delivers faster convergence.\n"]},
{"authors": ["Karl Schlechta"], "title": ["A Reliability Theory of Truth"], "date": ["2018-01-03T14:51:47Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.01788v3"], "summary": ["  Our approach is basically a coherence approach, but we avoid the well-known\npitfalls of coherence theories of truth. Consistency is replaced by\nreliability, which expresses support and attack, and, in principle, every\ntheory (or agent, message) counts. At the same time, we do not require a\npriviledged access to \"reality\". A centerpiece of our approach is that we\nattribute reliability also to agents, messages, etc., so an unreliable source\nof information will be less important in future. Our ideas can also be extended\nto value systems, and even actions, e.g., of animals.\n"]},
{"authors": ["Karamjit Singh", "Vishal Sunder"], "title": ["CIKM AnalytiCup 2017 Lazada Product Title Quality Challenge An Ensemble\n  of Deep and Shallow Learning to predict the Quality of Product Titles"], "date": ["2018-04-01T13:02:57Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.01000v1"], "summary": ["  We present an approach where two different models (Deep and Shallow) are\ntrained separately on the data and a weighted average of the outputs is taken\nas the final result. For the Deep approach, we use different combinations of\nmodels like Convolution Neural Network, pretrained word2vec embeddings and\nLSTMs to get representations which are then used to train a Deep Neural\nNetwork. For Clarity prediction, we also use an Attentive Pooling approach for\nthe pooling operation so as to be aware of the Title-Category pair. For the\nshallow approach, we use boosting technique LightGBM on features generated\nusing title and categories. We find that an ensemble of these approaches does a\nbetter job than using them alone suggesting that the results of the deep and\nshallow approach are highly complementary\n"]},
{"authors": ["Sara Bunian", "Alessandro Canossa", "Randy Colvin", "Magy Seif El-Nasr"], "title": ["Modeling Individual Differences in Game Behavior using HMM"], "date": ["2018-04-01T01:43:48Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.00245v1"], "summary": ["  Player modeling is an important concept that has gained much attention in\ngame research due to its utility in developing adaptive techniques to target\nbetter designs for engagement and retention. Previous work has explored\nmodeling individual differences using machine learning algorithms per- formed\non aggregated game actions. However, players' individual differences may be\nbetter manifested through sequential patterns of the in-game player's actions.\nWhile few works have explored sequential analysis of player data, none have\nexplored the use of Hidden Markov Models (HMM) to model individual differences,\nwhich is the topic of this paper. In par- ticular, we developed a modeling\napproach using data col- lected from players playing a Role-Playing Game (RPG).\nOur proposed approach is two fold: 1. We present a Hidden Markov Model (HMM) of\nplayer in-game behaviors to model individual differences, and 2. using the\noutput of the HMM, we generate behavioral features used to classify real world\nplayers' characteristics, including game expertise and the big five personality\ntraits. Our results show predictive power for some of personality traits, such\nas game expertise and conscientiousness, but the most influential factor was\ngame expertise.\n"]},
{"authors": ["Oscar Chang", "Hod Lipson"], "title": ["Neural Network Quine"], "date": ["2018-03-15T16:54:43Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.05859v3"], "summary": ["  Self-replication is a key aspect of biological life that has been largely\noverlooked in Artificial Intelligence systems. Here we describe how to build\nand train self-replicating neural networks. The network replicates itself by\nlearning to output its own weights. The network is designed using a loss\nfunction that can be optimized with either gradient-based or non-gradient-based\nmethods. We also describe a method we call regeneration to train the network\nwithout explicit optimization, by injecting the network with predictions of its\nown parameters. The best solution for a self-replicating network was found by\nalternating between regeneration and optimization steps. Finally, we describe a\ndesign for a self-replicating neural network that can solve an auxiliary task\nsuch as MNIST image classification. We observe that there is a trade-off\nbetween the network's ability to classify images and its ability to replicate,\nbut training is biased towards increasing its specialization at image\nclassification at the expense of replication. This is analogous to the\ntrade-off between reproduction and other tasks observed in nature. We suggest\nthat a self-replication mechanism for artificial intelligence is useful because\nit introduces the possibility of continual improvement through natural\nselection.\n"]},
{"authors": ["Abdelhamid Boudane", "Said Jabbour", "Badran Raddaoui", "Lakhdar Sais"], "title": ["Efficient Encodings of Conditional Cardinality Constraints"], "date": ["2018-03-31T20:29:07Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.00211v1"], "summary": ["  In the encoding of many real-world problems to propositional satisfiability,\nthe cardinality constraint is a recurrent constraint that needs to be managed\neffectively. Several efficient encodings have been proposed while missing that\nsuch a constraint can be involved in a more general propositional formulation.\nTo avoid combinatorial explosion, Tseitin principle usually used to translate\nsuch general propositional formula to Conjunctive Normal Form (CNF), introduces\nfresh propositional variables to represent sub-formulas and/or complex\ncontraints. Thanks to Plaisted and Greenbaum improvement, the polarity of the\nsub-formula $\\Phi$ is taken into account leading to conditional constraints of\nthe form $y\\rightarrow \\Phi$, or $\\Phi\\rightarrow y$, where $y$ is a fresh\npropositional variable. In the case where $\\Phi$ represents a cardinality\nconstraint, such translation leads to conditional cardinality constraints\nsubject of the present paper. We first show that when all the clauses encoding\nthe cardinality constraint are augmented with an additional new variable, most\nof the well-known encodings cease to maintain the generalized arc consistency\nproperty. Then, we consider some of these encodings and show how they can be\nextended to recover such important property. An experimental validation is\nconducted on a SAT-based pattern mining application, where such conditional\ncardinality constraints is a cornerstone, showing the relevance of our proposed\napproach.\n"]},
{"authors": ["Gopal Sharma", "Rishabh Goyal", "Difan Liu", "Evangelos Kalogerakis", "Subhransu Maji"], "title": ["CSGNet: Neural Shape Parser for Constructive Solid Geometry"], "date": ["2017-12-22T03:18:57Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1712.08290v2"], "summary": ["  We present a neural architecture that takes as input a 2D or 3D shape and\noutputs a program that generates the shape. The instructions in our program are\nbased on constructive solid geometry principles, i.e., a set of boolean\noperations on shape primitives defined recursively. Bottom-up techniques for\nthis shape parsing task rely on primitive detection and are inherently slow\nsince the search space over possible primitive combinations is large. In\ncontrast, our model uses a recurrent neural network that parses the input shape\nin a top-down manner, which is significantly faster and yields a compact and\neasy-to-interpret sequence of modeling instructions. Our model is also more\neffective as a shape detector compared to existing state-of-the-art detection\ntechniques. We finally demonstrate that our network can be trained on novel\ndatasets without ground-truth program annotations through policy gradient\ntechniques.\n"]},
{"authors": ["\u0141ukasz Kidzi\u0144ski", "Sharada P. Mohanty", "Carmichael Ong", "Jennifer L. Hicks", "Sean F. Carroll", "Sergey Levine", "Marcel Salath\u00e9", "Scott L. Delp"], "title": ["Learning to Run challenge: Synthesizing physiologically accurate motion\n  using deep reinforcement learning"], "date": ["2018-03-31T17:56:28Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.00198v1"], "summary": ["  Synthesizing physiologically-accurate human movement in a variety of\nconditions can help practitioners plan surgeries, design experiments, or\nprototype assistive devices in simulated environments, reducing time and costs\nand improving treatment outcomes. Because of the large and complex solution\nspaces of biomechanical models, current methods are constrained to specific\nmovements and models, requiring careful design of a controller and hindering\nmany possible applications. We sought to discover if modern optimization\nmethods efficiently explore these complex spaces. To do this, we posed the\nproblem as a competition in which participants were tasked with developing a\ncontroller to enable a physiologically-based human model to navigate a complex\nobstacle course as quickly as possible, without using any experimental data.\nThey were provided with a human musculoskeletal model and a physics-based\nsimulation environment. In this paper, we discuss the design of the\ncompetition, technical difficulties, results, and analysis of the top\ncontrollers. The challenge proved that deep reinforcement learning techniques,\ndespite their high computational cost, can be successfully employed as an\noptimization method for synthesizing physiologically feasible motion in\nhigh-dimensional biomechanical systems.\n"]},
{"authors": ["Kyle Richardson"], "title": ["A Language for Function Signature Representations"], "date": ["2018-03-31T13:01:29Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.00987v1"], "summary": ["  Recent work by (Richardson and Kuhn, 2017a,b; Richardson et al., 2018) looks\nat semantic parser induction and question answering in the domain of source\ncode libraries and APIs. In this brief note, we formalize the representations\nbeing learned in these studies and introduce a simple domain specific language\nand a systematic translation from this language to first-order logic. By\nrecasting the target representations in terms of classical logic, we aim to\nbroaden the applicability of existing code datasets for investigating more\ncomplex natural language understanding and reasoning problems in the software\ndomain.\n"]},
{"authors": ["Piotr Mirowski", "Matthew Koichi Grimes", "Mateusz Malinowski", "Karl Moritz Hermann", "Keith Anderson", "Denis Teplyashin", "Karen Simonyan", "Koray Kavukcuoglu", "Andrew Zisserman", "Raia Hadsell"], "title": ["Learning to Navigate in Cities Without a Map"], "date": ["2018-03-31T12:58:12Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.00168v1"], "summary": ["  Navigating through unstructured environments is a basic capability of\nintelligent creatures, and thus is of fundamental interest in the study and\ndevelopment of artificial intelligence. Long-range navigation is a complex\ncognitive task that relies on developing an internal representation of space,\ngrounded by recognisable landmarks and robust visual processing, that can\nsimultaneously support continuous self-localisation (\"I am here\") and a\nrepresentation of the goal (\"I am going there\"). Building upon recent research\nthat applies deep reinforcement learning to maze navigation problems, we\npresent an end-to-end deep reinforcement learning approach that can be applied\non a city scale. Recognising that successful navigation relies on integration\nof general policies with locale-specific knowledge, we propose a dual pathway\narchitecture that allows locale-specific features to be encapsulated, while\nstill enabling transfer to multiple cities. We present an interactive\nnavigation environment that uses Google StreetView for its photographic content\nand worldwide coverage, and demonstrate that our learning method allows agents\nto learn to navigate multiple cities and to traverse to target destinations\nthat may be kilometres away. A video summarizing our research and showing the\ntrained agent in diverse city environments as well as on the transfer task is\navailable at: goo.gl/ESUfho.\n"]},
{"authors": ["Daniel O\u00f1oro-Rubio", "Mathias Niepert", "Alberto Garc\u00eda-Dur\u00e1n", "Roberto Gonz\u00e1lez", "Roberto J. L\u00f3pez-Sastre"], "title": ["Representation Learning for Visual-Relational Knowledge Graphs"], "date": ["2017-09-07T15:31:54Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1709.02314v5"], "summary": ["  A visual-relational knowledge graph (KG) is a multi-relational graph whose\nentities are associated with images. We introduce ImageGraph, a KG with 1,330\nrelation types, 14,870 entities, and 829,931 images. Visual-relational KGs lead\nto novel probabilistic query types where images are treated as first-class\ncitizens. Both the prediction of relations between unseen images and\nmulti-relational image retrieval can be formulated as query types in a\nvisual-relational KG. We approach the problem of answering such queries with a\nnovel combination of deep convolutional networks and models for learning\nknowledge graph embeddings. The resulting models can answer queries such as\n\"How are these two unseen images related to each other?\" We also explore a\nzero-shot learning scenario where an image of an entirely new entity is linked\nwith multiple relations to entities of an existing KG. The multi-relational\ngrounding of unseen entity images into a knowledge graph serves as the\ndescription of such an entity. We conduct experiments to demonstrate that the\nproposed deep architectures in combination with KG embedding objectives can\nanswer the visual-relational queries efficiently and accurately.\n"]},
{"authors": ["Jiankai Sun", "Sobhan Moosavi", "Rajiv Ramnath", "Srinivasan Parthasarathy"], "title": ["QDEE: Question Difficulty and Expertise Estimation in Community Question\n  Answering Sites"], "date": ["2018-03-31T02:56:19Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.00109v1"], "summary": ["  In this paper, we present a framework for Question Difficulty and Expertise\nEstimation (QDEE) in Community Question Answering sites (CQAs) such as Yahoo!\nAnswers and Stack Overflow, which tackles a fundamental challenge in\ncrowdsourcing: how to appropriately route and assign questions to users with\nthe suitable expertise. This problem domain has been the subject of much\nresearch and includes both language-agnostic as well as language conscious\nsolutions. We bring to bear a key language-agnostic insight: that users gain\nexpertise and therefore tend to ask as well as answer more difficult questions\nover time. We use this insight within the popular competition (directed) graph\nmodel to estimate question difficulty and user expertise by identifying key\nhierarchical structure within said model. An important and novel contribution\nhere is the application of \"social agony\" to this problem domain. Difficulty\nlevels of newly posted questions (the cold-start problem) are estimated by\nusing our QDEE framework and additional textual features. We also propose a\nmodel to route newly posted questions to appropriate users based on the\ndifficulty level of the question and the expertise of the user. Extensive\nexperiments on real world CQAs such as Yahoo! Answers and Stack Overflow data\ndemonstrate the improved efficacy of our approach over contemporary\nstate-of-the-art models. The QDEE framework also allows us to characterize user\nexpertise in novel ways by identifying interesting patterns and roles played by\ndifferent users in such CQAs.\n"]},
{"authors": ["Fan Yang", "Jiazhong Nie", "William W. Cohen", "Ni Lao"], "title": ["Learning to Organize Knowledge with N-Gram Machines"], "date": ["2017-11-17T22:02:53Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.06744v2"], "summary": ["  Deep neural networks (DNNs) had great success on NLP tasks such as language\nmodeling, machine translation and certain question answering (QA) tasks.\nHowever, the success is limited at more knowledge intensive tasks such as QA\nfrom a big corpus. Existing end-to-end deep QA models (Miller et al., 2016;\nWeston et al., 2014) need to read the entire text after observing the question,\nand therefore their complexity in responding a question is linear in the text\nsize. This is prohibitive for practical tasks such as QA from Wikipedia, a\nnovel, or the Web. We propose to solve this scalability issue by using symbolic\nmeaning representations, which can be indexed and retrieved efficiently with\ncomplexity that is independent of the text size. More specifically, we use\nsequence-to-sequence models to encode knowledge symbolically and generate\nprograms to answer questions from the encoded knowledge. We apply our approach,\ncalled the N-Gram Machine (NGM), to the bAbI tasks (Weston et al., 2015) and a\nspecial version of them (\"life-long bAbI\") which has stories of up to 10\nmillion sentences. Our experiments show that NGM can successfully solve both of\nthese tasks accurately and efficiently. Unlike fully differentiable memory\nmodels, NGM's time complexity and answering quality are not affected by the\nstory length. The whole system of NGM is trained end-to-end with REINFORCE\n(Williams, 1992). To avoid high variance in gradient estimation, which is\ntypical in discrete latent variable models, we use beam search instead of\nsampling. To tackle the exponentially large search space, we use a stabilized\nauto-encoding objective and a structure tweak procedure to iteratively reduce\nand refine the search space.\n"]},
{"authors": ["Jyh-Jing Hwang", "Sergei Azernikov", "Alexei A. Efros", "Stella X. Yu"], "title": ["Learning Beyond Human Expertise with Generative Models for Dental\n  Restorations"], "date": ["2018-03-30T21:56:38Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.00064v1"], "summary": ["  Computer vision has advanced significantly that many discriminative\napproaches such as object recognition are now widely used in real applications.\nWe present another exciting development that utilizes generative models for the\nmass customization of medical products such as dental crowns. In the dental\nindustry, it takes a technician years of training to design synthetic crowns\nthat restore the function and integrity of missing teeth. Each crown must be\ncustomized to individual patients, and it requires human expertise in a\ntime-consuming and labor-intensive process, even with computer-assisted design\nsoftware. We develop a fully automatic approach that learns not only from human\ndesigns of dental crowns, but also from natural spatial profiles between\nopposing teeth. The latter is hard to account for by technicians but important\nfor proper biting and chewing functions. Built upon a Generative Adversar-ial\nNetwork architecture (GAN), our deep learning model predicts the customized\ncrown-filled depth scan from the crown-missing depth scan and opposing depth\nscan. We propose to incorporate additional space constraints and statistical\ncompatibility into learning. Our automatic designs exceed human technicians'\nstandards for good morphology and functionality, and our algorithm is being\ntested for production use.\n"]},
{"authors": ["Chris Paxton", "Yotam Barnoy", "Kapil Katyal", "Raman Arora", "Gregory D. Hager"], "title": ["Visual Robot Task Planning"], "date": ["2018-03-30T21:52:49Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.00062v1"], "summary": ["  Prospection, the act of predicting the consequences of many possible futures,\nis intrinsic to human planning and action, and may even be at the root of\nconsciousness. Surprisingly, this idea has been explored comparatively little\nin robotics. In this work, we propose a neural network architecture and\nassociated planning algorithm that (1) learns a representation of the world\nuseful for generating prospective futures after the application of high-level\nactions, (2) uses this generative model to simulate the result of sequences of\nhigh-level actions in a variety of environments, and (3) uses this same\nrepresentation to evaluate these actions and perform tree search to find a\nsequence of high-level actions in a new environment. Models are trained via\nimitation learning on a variety of domains, including navigation,\npick-and-place, and a surgical robotics task. Our approach allows us to\nvisualize intermediate motion goals and learn to plan complex activity from\nvisual information.\n"]},
{"authors": ["Hang Ma", "Wolfgang H\u00f6nig", "Liron Cohen", "Tansel Uras", "Hong Xu", "T. K. Satish Kumar", "Nora Ayanian", "Sven Koenig"], "title": ["Overview: A Hierarchical Framework for Plan Generation and Execution in\n  Multi-Robot Systems"], "date": ["2018-03-30T19:20:23Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.00038v1"], "summary": ["  The authors present an overview of a hierarchical framework for coordinating\ntask- and motion-level operations in multirobot systems. Their framework is\nbased on the idea of using simple temporal networks to simultaneously reason\nabout precedence/causal constraints required for task-level coordination and\nsimple temporal constraints required to take some kinematic constraints of\nrobots into account. In the plan-generation phase, the framework provides a\ncomputationally scalable method for generating plans that achieve high-level\ntasks for groups of robots and take some of their kinematic constraints into\naccount. In the plan-execution phase, the framework provides a method for\nabsorbing an imperfect plan execution to avoid time-consuming re-planning in\nmany cases. The authors use the multirobot path-planning problem as a case\nstudy to present the key ideas behind their framework for the long-term\nautonomy of multirobot systems.\n"]},
{"authors": ["Zhongzheng Ren", "Yong Jae Lee", "Michael S. Ryoo"], "title": ["Learning to Anonymize Faces for Privacy Preserving Action Detection"], "date": ["2018-03-30T17:55:04Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.11556v1"], "summary": ["  There is an increasing concern in computer vision devices invading the\nprivacy of their users by recording unwanted videos. On one hand, we want the\ncamera systems/robots to recognize important events and assist human daily life\nby understanding its videos, but on the other hand we also want to ensure that\nthey do not intrude people's privacy. In this paper, we propose a new\nprincipled approach for learning a video face anonymizer. We use an adversarial\ntraining setting in which two competing systems fight: (1) a video anonymizer\nthat modifies the original video to remove privacy-sensitive information (i.e.,\nhuman face) while still trying to maximize spatial action detection\nperformance, and (2) a discriminator that tries to extract privacy-sensitive\ninformation from such anonymized videos. The end result is a video anonymizer\nthat performs a pixel-level modification to anonymize each person's face, with\nminimal effect on action detection performance. We experimentally confirm the\nbenefit of our approach compared to conventional hand-crafted video/face\nanonymization methods including masking, blurring, and noise adding. See the\nproject page https://jason718.github.io/project/privacy/main.html for a demo\nvideo and more results.\n"]},
{"authors": ["Alexander Grabner", "Peter M. Roth", "Vincent Lepetit"], "title": ["3D Pose Estimation and 3D Model Retrieval for Objects in the Wild"], "date": ["2018-03-30T14:47:49Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.11493v1"], "summary": ["  We propose a scalable, efficient and accurate approach to retrieve 3D models\nfor objects in the wild. Our contribution is twofold. We first present a 3D\npose estimation approach for object categories which significantly outperforms\nthe state-of-the-art on Pascal3D+. Second, we use the estimated pose as a prior\nto retrieve 3D models which accurately represent the geometry of objects in RGB\nimages. For this purpose, we render depth images from 3D models under our\npredicted pose and match learned image descriptors of RGB images against those\nof rendered depth images using a CNN-based multi-view metric learning approach.\nIn this way, we are the first to report quantitative results for 3D model\nretrieval on Pascal3D+, where our method chooses the same models as human\nannotators for 50% of the validation images on average. In addition, we show\nthat our method, which was trained purely on Pascal3D+, retrieves rich and\naccurate 3D models from ShapeNet given RGB images of objects in the wild.\n"]},
{"authors": ["Haris Aziz"], "title": ["A Rule for Committee Selection with Soft Diversity Constraints"], "date": ["2018-03-30T12:36:36Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.11437v1"], "summary": ["  Committee selection with diversity or distributional constraints is a\nubiquitous problem. However, many of the formal approaches proposed so far have\ncertain drawbacks including (1) computationally intractability in general, and\n(2) inability to suggest a solution for certain instances where the hard\nconstraints cannot be met. We propose a practical and polynomial-time algorithm\nfor diverse committee selection that draws on the idea of using soft bounds and\nsatisfies natural axioms.\n"]},
{"authors": ["Nicholas Guttenberg", "Ryota Kanai"], "title": ["Learning to generate classifiers"], "date": ["2018-03-30T07:43:35Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.11373v1"], "summary": ["  We train a network to generate mappings between training sets and\nclassification policies (a 'classifier generator') by conditioning on the\nentire training set via an attentional mechanism. The network is directly\noptimized for test set performance on an training set of related tasks, which\nis then transferred to unseen 'test' tasks. We use this to optimize for\nperformance in the low-data and unsupervised learning regimes, and obtain\nsignificantly better performance in the 10-50 datapoint regime than support\nvector classifiers, random forests, XGBoost, and k-nearest neighbors on a range\nof small datasets.\n"]},
{"authors": ["Xingwei Cao", "Xuyang Zhao", "Qibin Zhao"], "title": ["Tensorizing Generative Adversarial Nets"], "date": ["2017-10-30T05:05:02Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.10772v2"], "summary": ["  Generative Adversarial Network (GAN) and its variants exhibit\nstate-of-the-art performance in the class of generative models. To capture\nhigher-dimensional distributions, the common learning procedure requires high\ncomputational complexity and a large number of parameters. The problem of\nemploying such massive framework arises when deploying it on a platform with\nlimited computational power such as mobile phones. In this paper, we present a\nnew generative adversarial framework by representing each layer as a tensor\nstructure connected by multilinear operations, aiming to reduce the number of\nmodel parameters by a large factor while preserving the generative performance\nand sample quality. To learn the model, we employ an efficient algorithm which\nalternatively optimizes both discriminator and generator. Experimental outcomes\ndemonstrate that our model can achieve high compression rate for model\nparameters up to $35$ times when compared to the original GAN for MNIST\ndataset.\n"]},
{"authors": ["Nicholas Carlini", "David Wagner"], "title": ["Audio Adversarial Examples: Targeted Attacks on Speech-to-Text"], "date": ["2018-01-05T23:40:04Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.01944v2"], "summary": ["  We construct targeted audio adversarial examples on automatic speech\nrecognition. Given any audio waveform, we can produce another that is over\n99.9% similar, but transcribes as any phrase we choose (recognizing up to 50\ncharacters per second of audio). We apply our white-box iterative\noptimization-based attack to Mozilla's implementation DeepSpeech end-to-end,\nand show it has a 100% success rate. The feasibility of this attack introduce a\nnew domain to study adversarial examples.\n"]},
{"authors": ["Andrew J. Davison"], "title": ["FutureMapping: The Computational Structure of Spatial AI Systems"], "date": ["2018-03-29T23:46:34Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.11288v1"], "summary": ["  We discuss and predict the evolution of Simultaneous Localisation and Mapping\n(SLAM) into a general geometric and semantic `Spatial AI' perception capability\nfor intelligent embodied devices. A big gap remains between the visual\nperception performance that devices such as augmented reality eyewear or\ncomsumer robots will require and what is possible within the constraints\nimposed by real products. Co-design of algorithms, processors and sensors will\nbe needed. We explore the computational structure of current and future Spatial\nAI algorithms and consider this within the landscape of ongoing hardware\ndevelopments.\n"]},
{"authors": ["Joris M. Mooij", "Sara Magliacane", "Tom Claassen"], "title": ["Joint Causal Inference from Multiple Contexts"], "date": ["2016-11-30T20:50:33Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1611.10351v3"], "summary": ["  The gold standard for discovering causal relations is by means of\nexperimentation. Over the last decades, alternative methods have been proposed\nthat can infer causal relations between variables from certain statistical\npatterns in purely observational data. We introduce Joint Causal Inference\n(JCI), a novel approach to causal discovery from multiple data sets that\nelegantly unifies both approaches. JCI is a causal modeling approach rather\nthan a specific algorithm, and it can be used in combination with any causal\ndiscovery algorithm that can take into account certain background knowledge.\nThe main idea is to reduce causal discovery from multiple datasets originating\nfrom different contexts (e.g., different experimental conditions) to causal\ndiscovery from a single pooled dataset by adding a set of auxiliary context\nvariables. JCI offers the following features: it deals with several different\ntypes of interventions in a unified fashion, it can learn intervention targets,\nit pools data across different datasets which improves the statistical power of\nindependence tests, and by exploiting differences in distribution between\ncontexts it improves on the accuracy and identifiability of the predicted\ncausal relations. We evaluate the approach on flow cytometry data.\n"]},
{"authors": ["Kush R. Varshney"], "title": ["How an Electrical Engineer Became an Artificial Intelligence Researcher,\n  a Multiphase Active Contours Analysis"], "date": ["2018-03-29T21:11:32Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.11261v1"], "summary": ["  This essay examines how what is considered to be artificial intelligence (AI)\nhas changed over time and come to intersect with the expertise of the author.\nInitially, AI developed on a separate trajectory, both topically and\ninstitutionally, from pattern recognition, neural information processing,\ndecision and control systems, and allied topics by focusing on symbolic systems\nwithin computer science departments rather than on continuous systems in\nelectrical engineering departments. The separate evolutions continued\nthroughout the author's lifetime, with some crossover in reinforcement learning\nand graphical models, but were shocked into converging by the virality of deep\nlearning, thus making an electrical engineer into an AI researcher. Now that\nthis convergence has happened, opportunity exists to pursue an agenda that\ncombines learning and reasoning bridged by interpretable machine learning\nmodels.\n"]},
{"authors": ["Kun Ho Kim", "Oisin Mac Aodha", "Pietro Perona"], "title": ["Context Embedding Networks"], "date": ["2017-09-22T18:46:40Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.01691v3"], "summary": ["  Low dimensional embeddings that capture the main variations of interest in\ncollections of data are important for many applications. One way to construct\nthese embeddings is to acquire estimates of similarity from the crowd. However,\nsimilarity is a multi-dimensional concept that varies from individual to\nindividual. Existing models for learning embeddings from the crowd typically\nmake simplifying assumptions such as all individuals estimate similarity using\nthe same criteria, the list of criteria is known in advance, or that the crowd\nworkers are not influenced by the data that they see. To overcome these\nlimitations we introduce Context Embedding Networks (CENs). In addition to\nlearning interpretable embeddings from images, CENs also model worker biases\nfor different attributes along with the visual context i.e. the visual\nattributes highlighted by a set of images. Experiments on two noisy crowd\nannotated datasets show that modeling both worker bias and visual context\nresults in more interpretable embeddings compared to existing approaches.\n"]},
{"authors": ["Xiaoyuan Liang", "Xunsheng Du", "Guiling Wang", "Zhu Han"], "title": ["Deep Reinforcement Learning for Traffic Light Control in Vehicular\n  Networks"], "date": ["2018-03-29T15:24:28Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.11115v1"], "summary": ["  Existing inefficient traffic light control causes numerous problems, such as\nlong delay and waste of energy. To improve efficiency, taking real-time traffic\ninformation as an input and dynamically adjusting the traffic light duration\naccordingly is a must. In terms of how to dynamically adjust traffic signals'\nduration, existing works either split the traffic signal into equal duration or\nextract limited traffic information from the real data. In this paper, we study\nhow to decide the traffic signals' duration based on the collected data from\ndifferent sensors and vehicular networks. We propose a deep reinforcement\nlearning model to control the traffic light. In the model, we quantify the\ncomplex traffic scenario as states by collecting data and dividing the whole\nintersection into small grids. The timing changes of a traffic light are the\nactions, which are modeled as a high-dimension Markov decision process. The\nreward is the cumulative waiting time difference between two cycles. To solve\nthe model, a convolutional neural network is employed to map the states to\nrewards. The proposed model is composed of several components to improve the\nperformance, such as dueling network, target network, double Q-learning\nnetwork, and prioritized experience replay. We evaluate our model via\nsimulation in the Simulation of Urban MObility (SUMO) in a vehicular network,\nand the simulation results show the efficiency of our model in controlling\ntraffic lights.\n"]},
{"authors": ["Gabrielle Ras", "Marcel van Gerven", "Pim Haselager"], "title": ["Explanation Methods in Deep Learning: Users, Values, Concerns and\n  Challenges"], "date": ["2018-03-20T16:44:47Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.07517v2"], "summary": ["  Issues regarding explainable AI involve four components: users, laws &\nregulations, explanations and algorithms. Together these components provide a\ncontext in which explanation methods can be evaluated regarding their adequacy.\nThe goal of this chapter is to bridge the gap between expert users and lay\nusers. Different kinds of users are identified and their concerns revealed,\nrelevant statements from the General Data Protection Regulation are analyzed in\nthe context of Deep Neural Networks (DNNs), a taxonomy for the classification\nof existing explanation methods is introduced, and finally, the various classes\nof explanation methods are analyzed to verify if user concerns are justified.\nOverall, it is clear that (visual) explanations can be given about various\naspects of the influence of the input on the output. However, it is noted that\nexplanation methods or interfaces for lay users are missing and we speculate\nwhich criteria these methods / interfaces should satisfy. Finally it is noted\nthat two important concerns are difficult to address with explanation methods:\nthe concern about bias in datasets that leads to biased DNNs, as well as the\nsuspicion about unfair outcomes.\n"]},
{"authors": ["Qiao Zheng", "Herv\u00e9 Delingette", "Nicolas Duchateau", "Nicholas Ayache"], "title": ["3D Consistent Biventricular Myocardial Segmentation Using Deep Learning\n  for Mesh Generation"], "date": ["2018-03-29T14:08:12Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.11080v1"], "summary": ["  We present a novel automated method to segment the myocardium of both left\nand right ventricles in MRI volumes. The segmentation is consistent in 3D\nacross the slices such that it can be directly used for mesh generation. Two\nspecific neural networks with multi-scale coarse-to-fine prediction structure\nare proposed to cope with the small training dataset and trained using an\noriginal loss function. The former segments a slice in the middle of the\nvolume. Then the latter iteratively propagates the slice segmentations towards\nthe base and the apex, in a spatially consistent way. We perform 5-fold\ncross-validation on the 15 cases from STACOM to validate the method. For\ntraining, we use real cases and their synthetic variants generated by combining\nmotion simulation and image synthesis. Accurate and consistent testing results\nare obtained.\n"]},
{"authors": ["Toon Van Craenendonck", "Sebastijan Duman\u010di\u0107", "Elia Van Wolputte", "Hendrik Blockeel"], "title": ["COBRAS: Fast, Iterative, Active Clustering with Pairwise Constraints"], "date": ["2018-03-29T13:52:59Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.11060v1"], "summary": ["  Constraint-based clustering algorithms exploit background knowledge to\nconstruct clusterings that are aligned with the interests of a particular user.\nThis background knowledge is often obtained by allowing the clustering system\nto pose pairwise queries to the user: should these two elements be in the same\ncluster or not? Active clustering methods aim to minimize the number of queries\nneeded to obtain a good clustering by querying the most informative pairs\nfirst. Ideally, a user should be able to answer a couple of these queries,\ninspect the resulting clustering, and repeat these two steps until a\nsatisfactory result is obtained. We present COBRAS, an approach to active\nclustering with pairwise constraints that is suited for such an interactive\nclustering process. A core concept in COBRAS is that of a super-instance: a\nlocal region in the data in which all instances are assumed to belong to the\nsame cluster. COBRAS constructs such super-instances in a top-down manner to\nproduce high-quality results early on in the clustering process, and keeps\nrefining these super-instances as more pairwise queries are given to get more\ndetailed clusterings later on. We experimentally demonstrate that COBRAS\nproduces good clusterings at fast run times, making it an excellent candidate\nfor the iterative clustering scenario outlined above.\n"]},
{"authors": ["Ruth Fong", "Andrea Vedaldi"], "title": ["Net2Vec: Quantifying and Explaining how Concepts are Encoded by Filters\n  in Deep Neural Networks"], "date": ["2018-01-10T17:01:36Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.03454v2"], "summary": ["  In an effort to understand the meaning of the intermediate representations\ncaptured by deep networks, recent papers have tried to associate specific\nsemantic concepts to individual neural network filter responses, where\ninteresting correlations are often found, largely by focusing on extremal\nfilter responses. In this paper, we show that this approach can favor\neasy-to-interpret cases that are not necessarily representative of the average\nbehavior of a representation.\n  A more realistic but harder-to-study hypothesis is that semantic\nrepresentations are distributed, and thus filters must be studied in\nconjunction. In order to investigate this idea while enabling systematic\nvisualization and quantification of multiple filter responses, we introduce the\nNet2Vec framework, in which semantic concepts are mapped to vectorial\nembeddings based on corresponding filter responses. By studying such\nembeddings, we are able to show that 1., in most cases, multiple filters are\nrequired to code for a concept, that 2., often filters are not concept specific\nand help encode multiple concepts, and that 3., compared to single filter\nactivations, filter embeddings are able to better characterize the meaning of a\nrepresentation and its relationship to other concepts.\n"]},
{"authors": ["Sima Sharifirad", "Azra Nazari", "Mehdi Ghatee"], "title": ["Modified SMOTE Using Mutual Information and Different Sorts of Entropies"], "date": ["2018-03-29T10:41:19Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.11002v1"], "summary": ["  SMOTE is one of the oversampling techniques for balancing the datasets and it\nis considered as a pre-processing step in learning algorithms. In this paper,\nfour new enhanced SMOTE are proposed that include an improved version of KNN in\nwhich the attribute weights are defined by mutual information firstly and then\nthey are replaced by maximum entropy, Renyi entropy and Tsallis entropy. These\nfour pre-processing methods are combined with 1NN and J48 classifiers and their\nperformance are compared with the previous methods on 11 imbalanced datasets\nfrom KEEL repository. The results show that these pre-processing methods\nimproves the accuracy compared with the previous stablished works. In addition,\nas a case study, the first pre-processing method is applied on transportation\ndata of Tehran-Bazargan Highway in Iran with IR equal to 36.\n"]},
{"authors": ["Richard Kenway"], "title": ["Protection against Cloning for Deep Learning"], "date": ["2018-03-29T10:02:09Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.10995v1"], "summary": ["  The susceptibility of deep learning to adversarial attack can be understood\nin the framework of the Renormalisation Group (RG) and the vulnerability of a\nspecific network may be diagnosed provided the weights in each layer are known.\nAn adversary with access to the inputs and outputs could train a second network\nto clone these weights and, having identified a weakness, use them to compute\nthe perturbation of the input data which exploits it. However, the RG framework\nalso provides a means to poison the outputs of the network imperceptibly,\nwithout affecting their legitimate use, so as to prevent such cloning of its\nweights and thereby foil the generation of adversarial data.\n"]},
{"authors": ["Ian P. Gent", "Ciaran McCreesh", "Ian Miguel", "Neil C. A. Moore", "Peter Nightingale", "Patrick Prosser", "Chris Unsworth"], "title": ["A Review of Literature on Parallel Constraint Solving"], "date": ["2018-03-29T09:34:09Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.10981v1"], "summary": ["  As multicore computing is now standard, it seems irresponsible for\nconstraints researchers to ignore the implications of it. Researchers need to\naddress a number of issues to exploit parallelism, such as: investigating which\nconstraint algorithms are amenable to parallelisation; whether to use shared\nmemory or distributed computation; whether to use static or dynamic\ndecomposition; and how to best exploit portfolios and cooperating search. We\nreview the literature, and see that we can sometimes do quite well, some of the\ntime, on some instances, but we are far from a general solution. Yet there\nseems to be little overall guidance that can be given on how best to exploit\nmulticore computers to speed up constraint solving. We hope at least that this\nsurvey will provide useful pointers to future researchers wishing to correct\nthis situation.\n  Under consideration in Theory and Practice of Logic Programming (TPLP).\n"]},
{"authors": ["Jixin Liu", "Yanjing Wang"], "title": ["Weakly Aggregative Modal Logic: Characterization and Interpolation"], "date": ["2018-03-29T08:13:20Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.10953v1"], "summary": ["  In this paper, we study the model theoretical aspects of Weakly Aggregative\nModal Logic (WAL), which is a collection of disguised polyadic modal logics\nwith $n$-ary modalities whose arguments are all the same. We give a\nvan-Benthem-Rosen characterization theorem of WAL based on an intuitive notion\nof bisimulation, and show that WAL has Craig Interpolation.\n"]},
{"authors": ["Xin Wang", "Wenhu Chen", "Jiawei Wu", "Yuan-Fang Wang", "William Yang Wang"], "title": ["Video Captioning via Hierarchical Reinforcement Learning"], "date": ["2017-11-29T22:23:59Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.11135v3"], "summary": ["  Video captioning is the task of automatically generating a textual\ndescription of the actions in a video. Although previous work (e.g.\nsequence-to-sequence model) has shown promising results in abstracting a coarse\ndescription of a short video, it is still very challenging to caption a video\ncontaining multiple fine-grained actions with a detailed description. This\npaper aims to address the challenge by proposing a novel hierarchical\nreinforcement learning framework for video captioning, where a high-level\nManager module learns to design sub-goals and a low-level Worker module\nrecognizes the primitive actions to fulfill the sub-goal. With this\ncompositional framework to reinforce video captioning at different levels, our\napproach significantly outperforms all the baseline methods on a newly\nintroduced large-scale dataset for fine-grained video captioning. Furthermore,\nour non-ensemble model has already achieved the state-of-the-art results on the\nwidely-used MSR-VTT dataset.\n"]},
{"authors": ["Aditya Grover", "Todor Markov", "Peter Attia", "Norman Jin", "Nicholas Perkins", "Bryan Cheong", "Michael Chen", "Zi Yang", "Stephen Harris", "William Chueh", "Stefano Ermon"], "title": ["Best arm identification in multi-armed bandits with delayed feedback"], "date": ["2018-03-29T06:46:38Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.10937v1"], "summary": ["  We propose a generalization of the best arm identification problem in\nstochastic multi-armed bandits (MAB) to the setting where every pull of an arm\nis associated with delayed feedback. The delay in feedback increases the\neffective sample complexity of standard algorithms, but can be offset if we\nhave access to partial feedback received before a pull is completed. We propose\na general framework to model the relationship between partial and delayed\nfeedback, and as a special case we introduce efficient algorithms for settings\nwhere the partial feedback are biased or unbiased estimators of the delayed\nfeedback. Additionally, we propose a novel extension of the algorithms to the\nparallel MAB setting where an agent can control a batch of arms. Our\nexperiments in real-world settings, involving policy search and hyperparameter\noptimization in computational sustainability domains for fast charging of\nbatteries and wildlife corridor construction, demonstrate that exploiting the\nstructure of partial feedback can lead to significant improvements over\nbaselines in both sequential and parallel MAB.\n"]},
{"authors": ["Yuanlu Xu", "Lei Qin", "Xiaobai Liu", "Jianwen Xie", "Song-Chun Zhu"], "title": ["A Causal And-Or Graph Model for Visibility Fluent Reasoning in Tracking\n  Interacting Objects"], "date": ["2017-09-16T00:21:44Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1709.05437v2"], "summary": ["  Tracking humans that are interacting with the other subjects or environment\nremains unsolved in visual tracking, because the visibility of the human of\ninterests in videos is unknown and might vary over time. In particular, it is\nstill difficult for state-of-the-art human trackers to recover complete human\ntrajectories in crowded scenes with frequent human interactions. In this work,\nwe consider the visibility status of a subject as a fluent variable, whose\nchange is mostly attributed to the subject's interaction with the surrounding,\ne.g., crossing behind another object, entering a building, or getting into a\nvehicle, etc. We introduce a Causal And-Or Graph (C-AOG) to represent the\ncausal-effect relations between an object's visibility fluent and its\nactivities, and develop a probabilistic graph model to jointly reason the\nvisibility fluent change (e.g., from visible to invisible) and track humans in\nvideos. We formulate this joint task as an iterative search of a feasible\ncausal graph structure that enables fast search algorithm, e.g., dynamic\nprogramming method. We apply the proposed method on challenging video sequences\nto evaluate its capabilities of estimating visibility fluent changes of\nsubjects and tracking subjects of interests over time. Results with comparisons\ndemonstrate that our method outperforms the alternative trackers and can\nrecover complete trajectories of humans in complicated scenarios with frequent\nhuman interactions.\n"]},
{"authors": ["Jack Harmer", "Linus Gissl\u00e9n", "Henrik Holst", "Joakim Bergdahl", "Tom Olsson", "Kristoffer Sj\u00f6\u00f6", "Magnus Nordin"], "title": ["Imitation Learning with Concurrent Actions in 3D Games"], "date": ["2018-03-14T16:59:17Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.05402v3"], "summary": ["  In this work we describe a novel deep reinforcement learning neural network\narchitecture that allows multiple actions to be selected at every time-step.\nMulti-action policies allows complex behaviors to be learnt that are otherwise\nhard to achieve when using single action selection techniques. This work\ndescribes an algorithm that uses both imitation learning (IL) and temporal\ndifference (TD) reinforcement learning (RL) to provide a 4x improvement in\ntraining time and 2.5x improvement in performance over single action selection\nTD RL. We demonstrate the capabilities of this network using a complex in-house\n3D game. Mimicking the behavior of the expert teacher significantly improves\nworld state exploration and allows the agents vision system to be trained more\nrapidly than TD RL alone. This initial training technique kick-starts TD\nlearning and the agent quickly learns to surpass the capabilities of the\nexpert.\n"]},
{"authors": ["Wen Shen", "Jacob W. Crandall", "Ke Yan", "Cristina V. Lopes"], "title": ["Information Design in Crowdfunding under Thresholding Policies"], "date": ["2017-09-12T20:29:08Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1709.04049v5"], "summary": ["  Crowdfunding has emerged as a prominent way for entrepreneurs to secure\nfunding without sophisticated intermediation. In crowdfunding, an entrepreneur\noften has to decide how to disclose the campaign status in order to collect as\nmany contributions as possible. Such decisions are difficult to make primarily\ndue to incomplete information. We propose information design as a tool to help\nthe entrepreneur to improve revenue by influencing backers' beliefs. We\nintroduce a heuristic algorithm to dynamically compute information-disclosure\npolicies for the entrepreneur, followed by an empirical evaluation to\ndemonstrate its competitiveness over the widely-adopted immediate-disclosure\npolicy. Our results demonstrate that the immediate-disclosure policy is not\noptimal when backers follow thresholding policies despite its ease of\nimplementation. With appropriate heuristics, an entrepreneur can benefit from\ndynamic information disclosure. Our work sheds light on information design in a\ndynamic setting where agents make decisions using thresholding policies.\n"]},
{"authors": ["Vivek Sharma", "Ali Diba", "Davy Neven", "Michael S. Brown", "Luc Van Gool", "Rainer Stiefelhagen"], "title": ["Classification Driven Dynamic Image Enhancement"], "date": ["2017-10-20T14:54:29Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.07558v3"], "summary": ["  Convolutional neural networks rely on image texture and structure to serve as\ndiscriminative features to classify the image content. Image enhancement\ntechniques can be used as preprocessing steps to help improve the overall image\nquality and in turn improve the overall effectiveness of a CNN. Existing image\nenhancement methods, however, are designed to improve the perceptual quality of\nan image for a human observer. In this paper, we are interested in learning\nCNNs that can emulate image enhancement and restoration, but with the overall\ngoal to improve image classification and not necessarily human perception. To\nthis end, we present a unified CNN architecture that uses a range of\nenhancement filters that can enhance image-specific details via end-to-end\ndynamic filter learning. We demonstrate the effectiveness of this strategy on\nfour challenging benchmark datasets for fine-grained, object, scene, and\ntexture classification: CUB-200-2011, PASCAL-VOC2007, MIT-Indoor, and DTD.\nExperiments using our proposed enhancement show promising results on all the\ndatasets. In addition, our approach is capable of improving the performance of\nall generic CNN architectures.\n"]},
{"authors": ["Javier Andreu Perez", "Fani Deligianni", "Daniele Ravi", "Guang-Zhong Yang"], "title": ["Artificial Intelligence and Robotics"], "date": ["2018-03-28T19:11:24Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.10813v1"], "summary": ["  The recent successes of AI have captured the wildest imagination of both the\nscientific communities and the general public. Robotics and AI amplify human\npotentials, increase productivity and are moving from simple reasoning towards\nhuman-like cognitive abilities. Current AI technologies are used in a set area\nof applications, ranging from healthcare, manufacturing, transport, energy, to\nfinancial services, banking, advertising, management consulting and government\nagencies. The global AI market is around 260 billion USD in 2016 and it is\nestimated to exceed 3 trillion by 2024. To understand the impact of AI, it is\nimportant to draw lessons from it's past successes and failures and this white\npaper provides a comprehensive explanation of the evolution of AI, its current\nstatus and future directions.\n"]},
{"authors": ["Hanie Sedghi", "Ashish Sabharwal"], "title": ["Knowledge Completion for Generics using Guided Tensor Factorization"], "date": ["2016-12-12T19:53:04Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1612.03871v3"], "summary": ["  Given a knowledge base or KB containing (noisy) facts about common nouns or\ngenerics, such as \"all trees produce oxygen\" or \"some animals live in forests\",\nwe consider the problem of inferring additional such facts at a precision\nsimilar to that of the starting KB. Such KBs capture general knowledge about\nthe world, and are crucial for various applications such as question answering.\nDifferent from commonly studied named entity KBs such as Freebase, generics KBs\ninvolve quantification, have more complex underlying regularities, tend to be\nmore incomplete, and violate the commonly used locally closed world assumption\n(LCWA). We show that existing KB completion methods struggle with this new\ntask, and present the first approach that is successful. Our results\ndemonstrate that external information, such as relation schemas and entity\ntaxonomies, if used appropriately, can be a surprisingly powerful tool in this\nsetting. First, our simple yet effective knowledge guided tensor factorization\napproach achieves state-of-the-art results on two generics KBs (80% precise)\nfor science, doubling their size at 74%-86% precision. Second, our novel\ntaxonomy guided, submodular, active learning method for collecting annotations\nabout rare entities (e.g., oriole, a bird) is 6x more effective at inferring\nfurther new facts about them than multiple active learning baselines.\n"]},
{"authors": ["Konrad Zolna", "Devansh Arpit", "Dendi Suhubdy", "Yoshua Bengio"], "title": ["Fraternal Dropout"], "date": ["2017-10-31T19:32:45Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.00066v4"], "summary": ["  Recurrent neural networks (RNNs) are important class of architectures among\nneural networks useful for language modeling and sequential prediction.\nHowever, optimizing RNNs is known to be harder compared to feed-forward neural\nnetworks. A number of techniques have been proposed in literature to address\nthis problem. In this paper we propose a simple technique called fraternal\ndropout that takes advantage of dropout to achieve this goal. Specifically, we\npropose to train two identical copies of an RNN (that share parameters) with\ndifferent dropout masks while minimizing the difference between their\n(pre-softmax) predictions. In this way our regularization encourages the\nrepresentations of RNNs to be invariant to dropout mask, thus being robust. We\nshow that our regularization term is upper bounded by the expectation-linear\ndropout objective which has been shown to address the gap due to the difference\nbetween the train and inference phases of dropout. We evaluate our model and\nachieve state-of-the-art results in sequence modeling tasks on two benchmark\ndatasets - Penn Treebank and Wikitext-2. We also show that our approach leads\nto performance improvement by a significant margin in image captioning\n(Microsoft COCO) and semi-supervised (CIFAR-10) tasks.\n"]},
{"authors": ["Luis A. Pineda"], "title": ["A Distributed Extension of the Turing Machine"], "date": ["2018-03-28T14:36:54Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.10648v1"], "summary": ["  The Turing Machine has two implicit properties that depend on its underlying\nnotion of computing: the format is fully determinate and computations are\ninformation preserving. Distributed representations lack these properties and\ncannot be fully captured by Turing's standard model. To address this limitation\na distributed extension of the Turing Machine is introduced in this paper. In\nthe extended machine, functions and abstractions are expressed extensionally\nand computations are entropic. The machine is applied to the definition of an\nassociative memory, with its corresponding memory register, recognition and\nretrieval operations. The memory is tested with an experiment for storing and\nrecognizing hand written digits with satisfactory results. The experiment can\nbe seen as a proof of concept that information can be stored and processed\neffectively in a highly distributed fashion using a symbolic but not fully\ndeterminate format. The new machine augments the symbolic mode of computing\nwith consequences on the way Church Thesis is understood. The paper is\nconcluded with a discussion of some implications of the extended machine for\nArtificial Intelligence and Cognition.\n"]},
{"authors": ["Jon Barker", "Shinji Watanabe", "Emmanuel Vincent", "Jan Trmal"], "title": ["The fifth 'CHiME' Speech Separation and Recognition Challenge: Dataset,\n  task and baselines"], "date": ["2018-03-28T13:51:09Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.10609v1"], "summary": ["  The CHiME challenge series aims to advance robust automatic speech\nrecognition (ASR) technology by promoting research at the interface of speech\nand language processing, signal processing , and machine learning. This paper\nintroduces the 5th CHiME Challenge, which considers the task of distant\nmulti-microphone conversational ASR in real home environments. Speech material\nwas elicited using a dinner party scenario with efforts taken to capture data\nthat is representative of natural conversational speech and recorded by 6\nKinect microphone arrays and 4 binaural microphone pairs. The challenge\nfeatures a single-array track and a multiple-array track and, for each track,\ndistinct rankings will be produced for systems focusing on robustness with\nrespect to distant-microphone capture vs. systems attempting to address all\naspects of the task including conversational language modeling. We discuss the\nrationale for the challenge and provide a detailed description of the data\ncollection procedure, the task, and the baseline systems for array\nsynchronization, speech enhancement, and conventional and end-to-end ASR.\n"]},
{"authors": ["Tobias Hinz", "Stefan Wermter"], "title": ["Image Generation and Translation with Disentangled Representations"], "date": ["2018-03-28T12:53:01Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.10567v1"], "summary": ["  Generative models have made significant progress in the tasks of modeling\ncomplex data distributions such as natural images. The introduction of\nGenerative Adversarial Networks (GANs) and auto-encoders lead to the\npossibility of training on big data sets in an unsupervised manner. However,\nfor many generative models it is not possible to specify what kind of image\nshould be generated and it is not possible to translate existing images into\nnew images of similar domains. Furthermore, models that can perform\nimage-to-image translation often need distinct models for each domain, making\nit hard to scale these systems to multiple domain image-to-image translation.\nWe introduce a model that can do both, controllable image generation and\nimage-to-image translation between multiple domains. We split our image\nrepresentation into two parts encoding unstructured and structured information\nrespectively. The latter is designed in a disentangled manner, so that\ndifferent parts encode different image characteristics. We train an encoder to\nencode images into these representations and use a small amount of labeled data\nto specify what kind of information should be encoded in the disentangled part.\nA generator is trained to generate images from these representations using the\ncharacteristics provided by the disentangled part of the representation.\nThrough this we can control what kind of images the generator generates,\ntranslate images between different domains, and even learn unknown\ndata-generating factors while only using one single model.\n"]},
{"authors": ["Uri Alon", "Meital Zilberstein", "Omer Levy", "Eran Yahav"], "title": ["code2vec: Learning Distributed Representations of Code"], "date": ["2018-03-26T09:05:30Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.09473v2"], "summary": ["  We present a neural model for representing snippets of code as continuous\ndistributed vectors. The main idea is to represent code as a collection of\npaths in its abstract syntax tree, and aggregate these paths, in a smart and\nscalable way, into a single fixed-length $\\textit{code vector}$, which can be\nused to predict semantic properties of the snippet.\n  We demonstrate the effectiveness of our approach by using it to predict a\nmethod's name from the vector representation of its body. We evaluate our\napproach by training a model on a dataset of $14$M methods. We show that code\nvectors trained on this dataset can predict method names from files that were\ncompletely unobserved during training. Furthermore, we show that our model\nlearns useful method name vectors that capture semantic similarities,\ncombinations, and analogies.\n  Comparing previous techniques over the same data set, our approach obtains a\nrelative improvement of over $75\\%$, being the first to successfully predict\nmethod names based on a large, cross-project, corpus.\n"]},
{"authors": ["Anantha Padmanabha", "R. Ramanujam", "Yanjing Wang"], "title": ["Bundled fragments of first-order modal logic: (un)decidability"], "date": ["2018-03-28T10:20:13Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.10508v1"], "summary": ["  Quantified modal logic provides a natural logical language for reasoning\nabout modal attitudes even while retaining the richness of quantification for\nreferring to predicates over domains. But then most fragments of the logic are\nundecidable, over many model classes. Over the years, only a few fragments\n(such as the monodic) have been shown to be decidable. In this paper, we study\nfragments that bundle quantifiers and modalities together, inspired by earlier\nwork on epistemic logics of know-how/why/what. As always with quantified modal\nlogics, it makes a significant difference whether the domain stays the same\nacross worlds, or not. In particular, we show that the bundle $\\forall \\Box$ is\nundecidable over constant domain interpretations, even with only monadic\npredicates, whereas $\\exists \\Box$ bundle is decidable. On the other hand, over\nincreasing domain interpretations, we get decidability with both $\\forall \\Box$\nand $\\exists \\Box$ bundles with unrestricted predicates. In these cases, we\nalso obtain tableau based procedures that run in \\PSPACE. We further show that\nthe $\\exists \\Box$ bundle cannot distinguish between constant domain and\nincreasing domain interpretations.\n"]},
{"authors": ["Konda Reddy Mopuri", "Utkarsh Ojha", "Utsav Garg", "R. Venkatesh Babu"], "title": ["NAG: Network for Adversary Generation"], "date": ["2017-12-09T14:27:49Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1712.03390v2"], "summary": ["  Adversarial perturbations can pose a serious threat for deploying machine\nlearning systems. Recent works have shown existence of image-agnostic\nperturbations that can fool classifiers over most natural images. Existing\nmethods present optimization approaches that solve for a fooling objective with\nan imperceptibility constraint to craft the perturbations. However, for a given\nclassifier, they generate one perturbation at a time, which is a single\ninstance from the manifold of adversarial perturbations. Also, in order to\nbuild robust models, it is essential to explore the manifold of adversarial\nperturbations. In this paper, we propose for the first time, a generative\napproach to model the distribution of adversarial perturbations. The\narchitecture of the proposed model is inspired from that of GANs and is trained\nusing fooling and diversity objectives. Our trained generator network attempts\nto capture the distribution of adversarial perturbations for a given classifier\nand readily generates a wide variety of such perturbations. Our experimental\nevaluation demonstrates that perturbations crafted by our model (i) achieve\nstate-of-the-art fooling rates, (ii) exhibit wide variety and (iii) deliver\nexcellent cross model generalizability. Our work can be deemed as an important\nstep in the process of inferring about the complex manifolds of adversarial\nperturbations.\n"]},
{"authors": ["Jaan Aru", "Raul Vicente"], "title": ["What deep learning can tell us about higher cognitive functions like\n  mindreading?"], "date": ["2018-03-28T08:58:49Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.10470v1"], "summary": ["  Can deep learning (DL) guide our understanding of computations happening in\nbiological brain? We will first briefly consider how DL has contributed to the\nresearch on visual object recognition. In the main part we will assess whether\nDL could also help us to clarify the computations underlying higher cognitive\nfunctions such as Theory of Mind. In addition, we will compare the objectives\nand learning signals of brains and machines, leading us to conclude that simply\nscaling up the current DL algorithms will not lead to human level mindreading\nskills. We then provide some insights about how to fairly compare human and DL\nperformance. In the end we find that DL can contribute to our understanding of\nbiological computations by providing an example of an end-to-end algorithm that\nsolves the same problems the biological agents face.\n"]},
{"authors": ["Eunhee Kang", "Jaejun Yoo", "Jong Chul Ye"], "title": ["Deep Convolutional Framelet Denosing for Low-Dose CT via Wavelet\n  Residual Network"], "date": ["2017-07-31T16:17:31Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1707.09938v3"], "summary": ["  Model based iterative reconstruction (MBIR) algorithms for low-dose X-ray CT\nare computationally expensive. To address this problem, we recently proposed a\ndeep convolutional neural network (CNN) for low-dose X-ray CT and won the\nsecond place in 2016 AAPM Low-Dose CT Grand Challenge. However, some of the\ntexture were not fully recovered. To address this problem, here we propose a\nnovel framelet-based denoising algorithm using wavelet residual network which\nsynergistically combines the expressive power of deep learning and the\nperformance guarantee from the framelet-based denoising algorithms. The new\nalgorithms were inspired by the recent interpretation of the deep convolutional\nneural network (CNN) as a cascaded convolution framelet signal representation.\nExtensive experimental results confirm that the proposed networks have\nsignificantly improved performance and preserves the detail texture of the\noriginal images.\n"]},
{"authors": ["Zhou Xing", "Fei Xiao"], "title": ["Predictions of short-term driving intention using recurrent neural\n  network on sequential data"], "date": ["2018-03-28T03:14:50Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.00532v1"], "summary": ["  Predictions of driver's intentions and their behaviors using the road is of\ngreat importance for planning and decision making processes of autonomous\ndriving vehicles. In particular, relatively short-term driving intentions are\nthe fundamental units that constitute more sophisticated driving goals,\nbehaviors, such as overtaking the slow vehicle in front, exit or merge onto a\nhigh way, etc. While it is not uncommon that most of the time human driver can\nrationalize, in advance, various on-road behaviors, intentions, as well as the\nassociated risks, aggressiveness, reciprocity characteristics, etc., such\nreasoning skills can be challenging and difficult for an autonomous driving\nsystem to learn. In this article, we demonstrate a disciplined methodology that\ncan be used to build and train a predictive drive system, therefore to learn\nthe on-road characteristics aforementioned.\n"]},
{"authors": ["Piji Li", "Lidong Bing", "Wai Lam"], "title": ["Actor-Critic based Training Framework for Abstractive Summarization"], "date": ["2018-03-28T02:47:51Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.11070v1"], "summary": ["  We present a training framework for neural abstractive summarization based on\nactor-critic approaches from reinforcement learning. In the traditional neural\nnetwork based methods, the objective is only to maximize the likelihood of the\npredicted summaries, no other assessment constraints are considered, which may\ngenerate low-quality summaries or even incorrect sentences. To alleviate this\nproblem, we employ an actor-critic framework to enhance the training procedure.\nFor the actor, we employ the typical attention based sequence-to-sequence\n(seq2seq) framework as the policy network for summary generation. For the\ncritic, we combine the maximum likelihood estimator with a well designed global\nsummary quality estimator which is a neural network based binary classifier\naiming to make the generated summaries indistinguishable from the human-written\nones. Policy gradient method is used to conduct the parameter learning. An\nalternating training strategy is proposed to conduct the joint training of the\nactor and critic models. Extensive experiments on some benchmark datasets in\ndifferent languages show that our framework achieves improvements over the\nstate-of-the-art methods.\n"]},
{"authors": ["Yasuo Tabei", "Yoshihiro Yamanishi", "Rasmus Pagh"], "title": ["Scalable Alignment Kernels via Space-Efficient Feature Maps"], "date": ["2018-02-18T14:16:28Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06382v5"], "summary": ["  String kernels are attractive data analysis tools for analyzing string data.\nAmong them, alignment kernels are known for their high prediction accuracies in\nstring classifications when tested in combination with SVMs in various\napplications. However, alignment kernels have a crucial drawback in that they\nscale poorly due to their quadratic computation complexity in the number of\ninput strings, which limits large-scale applications in practice. We present\nthe first approximation named ESP+SFM for alignment kernels by leveraging a\nmetric embedding named edit-sensitive parsing (ESP) and space-efficient feature\nmaps (SFM) for random Fourier features (RFF) for large-scale string analyses.\nInput strings are projected into vectors of RFF by leveraging ESP and SFM.\nThen, SVMs are trained on the projected vectors, which enables to significantly\nimprove the scalability of alignment kernels while preserving their prediction\naccuracies. We experimentally test ESP+ SFM on its ability to learn SVMs for\nlarge-scale string classifications with various massive string data, and we\ndemonstrate the superior performance of ESP+SFM with respect to prediction\naccuracy, scalability and computation efficiency.\n"]},
{"authors": ["Aavaas Gajurel", "Sushil J Louis", "Daniel J Mendez", "Siming Liu"], "title": ["Neuroevolution for RTS Micro"], "date": ["2018-03-27T19:48:21Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.10288v1"], "summary": ["  This paper uses neuroevolution of augmenting topologies to evolve control\ntactics for groups of units in real-time strategy games. In such games, players\nbuild economies to generate armies composed of multiple types of units with\ndifferent attack and movement characteristics to combat each other. This paper\nevolves neural networks to control movement and attack commands, also called\nmicro, for a group of ranged units skirmishing with a group of melee units. Our\nresults show that neuroevolution of augmenting topologies can effectively\ngenerate neural networks capable of good micro for our ranged units against a\ngroup of hand-coded melee units. The evolved neural networks lead to kiting\nbehavior for the ranged units which is a common tactic used by professional\nplayers in ranged versus melee skirmishes in popular real-time strategy games\nlike Starcraft. The evolved neural networks also generalized well to other\nstarting positions and numbers of units. We believe these results indicate the\npotential of neuroevolution for generating effective micro in real-time\nstrategy games.\n"]},
{"authors": ["Maria-Florina Balcan", "Travis Dick", "Tuomas Sandholm", "Ellen Vitercik"], "title": ["Learning to Branch"], "date": ["2018-03-27T15:47:24Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.10150v1"], "summary": ["  Tree search algorithms, such as branch-and-bound, are the most widely used\ntools for solving combinatorial and nonconvex problems. For example, they are\nthe foremost method for solving (mixed) integer programs and constraint\nsatisfaction problems. Tree search algorithms recursively partition the search\nspace to find an optimal solution. In order to keep the tree size small, it is\ncrucial to carefully decide, when expanding a tree node, which question\n(typically variable) to branch on at that node in order to partition the\nremaining space. Numerous partitioning techniques (e.g., variable selection)\nhave been proposed, but there is no theory describing which technique is\noptimal. We show how to use machine learning to determine an optimal weighting\nof any set of partitioning procedures for the instance distribution at hand\nusing samples from the distribution. We provide the first sample complexity\nguarantees for tree search algorithm configuration. These guarantees bound the\nnumber of samples sufficient to ensure that the empirical performance of an\nalgorithm over the samples nearly matches its expected performance on the\nunknown instance distribution. This thorough theoretical investigation\nnaturally gives rise to our learning algorithm. Via experiments, we show that\nlearning an optimal weighting of partitioning procedures can dramatically\nreduce tree size, and we prove that this reduction can even be exponential.\nThrough theory and experiments, we show that learning to branch is both\npractical and hugely beneficial.\n"]},
{"authors": ["Md Mahadi Hasan Nahid", "Md. Ashraful Islam", "Bishwajit Purkaystha", "Md Saiful Islam"], "title": ["Comprehending Real Numbers: Development of Bengali Real Number Speech\n  Corpus"], "date": ["2018-03-27T15:27:07Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.10136v1"], "summary": ["  Speech recognition has received a less attention in Bengali literature due to\nthe lack of a comprehensive dataset. In this paper, we describe the development\nprocess of the first comprehensive Bengali speech dataset on real numbers. It\ncomprehends all the possible words that may arise in uttering any Bengali real\nnumber. The corpus has ten speakers from the different regions of Bengali\nnative people. It comprises of more than two thousands of speech samples in a\ntotal duration of closed to four hours. We also provide a deep analysis of our\ncorpus, highlight some of the notable features of it, and finally evaluate the\nperformances of two of the notable Bengali speech recognizers on it.\n"]},
{"authors": ["Beatrice Perez", "Mirco Musolesi", "Gianluca Stringhini"], "title": ["You are your Metadata: Identification and Obfuscation of Social Media\n  Users using Metadata Information"], "date": ["2018-03-27T15:23:53Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.10133v1"], "summary": ["  Metadata are associated to most of the information we produce in our daily\ninteractions and communication in the digital world. Yet, surprisingly,\nmetadata are often still catergorized as non-sensitive. Indeed, in the past,\nresearchers and practitioners have mainly focused on the problem of the\nidentification of a user from the content of a message.\n  In this paper, we use Twitter as a case study to quantify the uniqueness of\nthe association between metadata and user identity and to understand the\neffectiveness of potential obfuscation strategies. More specifically, we\nanalyze atomic fields in the metadata and systematically combine them in an\neffort to classify new tweets as belonging to an account using different\nmachine learning algorithms of increasing complexity. We demonstrate that\nthrough the application of a supervised learning algorithm, we are able to\nidentify any user in a group of 10,000 with approximately 96.7% accuracy.\nMoreover, if we broaden the scope of our search and consider the 10 most likely\ncandidates we increase the accuracy of the model to 99.22%. We also found that\ndata obfuscation is hard and ineffective for this type of data: even after\nperturbing 60% of the training data, it is still possible to classify users\nwith an accuracy higher than 95%. These results have strong implications in\nterms of the design of metadata obfuscation strategies, for example for data\nset release, not only for Twitter, but, more generally, for most social media\nplatforms.\n"]},
{"authors": ["Bharath Bhushan Damodaran", "Benjamin Kellenberger", "R\u00e9mi Flamary", "Devis Tuia", "Nicolas Courty"], "title": ["DeepJDOT: Deep Joint distribution optimal transport for unsupervised\n  domain adaptation"], "date": ["2018-03-27T13:54:05Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.10081v1"], "summary": ["  In computer vision, one is often confronted with problems of domain shifts,\nwhich occur when one applies a classifier trained on a source dataset to target\ndata sharing similar characteristics (e.g. same classes), but also different\nlatent data structures (e.g. different acquisition conditions). In such a\nsituation, the model will perform poorly on the new data, since the classifier\nis specialized to recognize visual cues specific to the source domain. In this\nwork we explore a solution, named DeepJDOT, to tackle this problem: through a\nmeasure of discrepancy on joint deep representations/labels based on optimal\ntransport, we not only learn new data representations aligned between the\nsource and target domain, but also simultaneously preserve the discriminative\ninformation used by the classifier. We applied DeepJDOT to a series of visual\nrecognition tasks, where it compares favorably against state-of-the-art deep\ndomain adaptation methods.\n"]},
{"authors": ["Alberto Perez Veiga"], "title": ["Applications of Artificial Intelligence to Network Security"], "date": ["2018-03-27T09:54:30Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.09992v1"], "summary": ["  Attacks to networks are becoming more complex and sophisticated every day.\nBeyond the so-called script-kiddies and hacking newbies, there is a myriad of\nprofessional attackers seeking to make serious profits infiltrating in\ncorporate networks. Either hostile governments, big corporations or mafias are\nconstantly increasing their resources and skills in cybercrime in order to spy,\nsteal or cause damage more effectively. traditional approaches to Network\nSecurity seem to start hitting their limits and it is being recognized the need\nfor a smarter approach to threat detections. This paper provides an\nintroduction on the need for evolution of Cyber Security techniques and how\nArtificial Intelligence could be of application to help solving some of the\nproblems. It provides also, a high-level overview of some state of the art AI\nNetwork Security techniques, to finish analysing what is the foreseeable future\nof the application of AI to Network Security.\n"]},
{"authors": ["Stephan Bongers", "Joris M. Mooij"], "title": ["From Random Differential Equations to Structural Causal Models: the\n  stochastic case"], "date": ["2018-03-23T13:20:56Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.08784v2"], "summary": ["  Random Differential Equations provide a natural extension of Ordinary\nDifferential Equations to the stochastic setting. We show how, and under which\nconditions, every equilibrium state of a Random Differential Equation (RDE) can\nbe described by a Structural Causal Model (SCM), while pertaining the causal\nsemantics. This provides an SCM that captures the stochastic and causal\nbehavior of the RDE, which can model both cycles and confounders. This enables\nthe study of the equilibrium states of the RDE by applying the theory and\nstatistical tools available for SCMs, for example, marginalizations and Markov\nproperties, as we illustrate by means of an example. Our work thus provides a\ndirect connection between two fields that so far have been developing in\nisolation.\n"]},
{"authors": ["Roberto Maestre", "Juan Duque", "Alberto Rubio", "Juan Ar\u00e9valo"], "title": ["Reinforcement Learning for Fair Dynamic Pricing"], "date": ["2018-03-27T09:00:48Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.09967v1"], "summary": ["  Unfair pricing policies have been shown to be one of the most negative\nperceptions customers can have concerning pricing, and may result in long-term\nlosses for a company. Despite the fact that dynamic pricing models help\ncompanies maximize revenue, fairness and equality should be taken into account\nin order to avoid unfair price differences between groups of customers. This\npaper shows how to solve dynamic pricing by using Reinforcement Learning (RL)\ntechniques so that prices are maximized while keeping a balance between revenue\nand fairness. We demonstrate that RL provides two main features to support\nfairness in dynamic pricing: on the one hand, RL is able to learn from recent\nexperience, adapting the pricing policy to complex market environments; on the\nother hand, it provides a trade-off between short and long-term objectives,\nhence integrating fairness into the model's core. Considering these two\nfeatures, we propose the application of RL for revenue optimization, with the\nadditional integration of fairness as part of the learning procedure by using\nJain's index as a metric. Results in a simulated environment show a significant\nimprovement in fairness while at the same time maintaining optimisation of\nrevenue.\n"]},
{"authors": ["Andy Zeng", "Shuran Song", "Stefan Welker", "Johnny Lee", "Alberto Rodriguez", "Thomas Funkhouser"], "title": ["Learning Synergies between Pushing and Grasping with Self-supervised\n  Deep Reinforcement Learning"], "date": ["2018-03-27T08:31:28Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.09956v1"], "summary": ["  Skilled robotic manipulation benefits from complex synergies between\nnon-prehensile (e.g. pushing) and prehensile (e.g. grasping) actions: pushing\ncan help rearrange cluttered objects to make space for arms and fingers;\nlikewise, grasping can help displace objects to make pushing movements more\nprecise and collision-free. In this work, we demonstrate that it is possible to\ndiscover and learn these synergies from scratch through model-free deep\nreinforcement learning. Our method involves training two fully convolutional\nnetworks that map from visual observations to actions: one infers the utility\nof pushes for a dense pixel-wise sampling of end effector orientations and\nlocations, while the other does the same for grasping. Both networks are\ntrained jointly in a Q-learning framework and are entirely self-supervised by\ntrial and error, where rewards are provided from successful grasps. In this\nway, our policy learns pushing motions that enable future grasps, while\nlearning grasps that can leverage past pushes. During picking experiments in\nboth simulation and real-world scenarios, we find that our system quickly\nlearns complex behaviors amid challenging cases of clutter, and achieves better\ngrasping success rates and picking efficiencies than baseline alternatives\nafter only a few hours of training. We further demonstrate that our method is\ncapable of generalizing to novel objects. Qualitative results (videos), code,\npre-trained models, and simulation environments are available at\nhttp://vpg.cs.princeton.edu\n"]},
{"authors": ["Dasong Li", "Jianbo Wang"], "title": ["Image Semantic Transformation: Faster, Lighter and Stronger"], "date": ["2018-03-27T07:20:46Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.09932v1"], "summary": ["  We propose Image-Semantic-Transformation-Reconstruction-Circle(ISTRC) model,\na novel and powerful method using facenet's Euclidean latent space to\nunderstand the images. As the name suggests, ISTRC construct the circle, able\nto perfectly reconstruct images. One powerful Euclidean latent space embedded\nin ISTRC is FaceNet's last layer with the power of distinguishing and\nunderstanding images. Our model will reconstruct the images and manipulate\nEuclidean latent vectors to achieve semantic transformations and semantic\nimages arthimetic calculations. In this paper, we show that ISTRC performs 10\nhigh-level semantic transformations like \"Male and female\",\"add smile\",\"open\nmouth\", \"deduct beard or add mustache\", \"bigger/smaller nose\", \"make older and\nyounger\", \"bigger lips\", \"bigger eyes\", \"bigger/smaller mouths\" and \"more\nattractive\". It just takes 3 hours(GTX 1080) to train the models of 10 semantic\ntransformations.\n"]},
{"authors": ["Tanvi Verma", "Pradeep Varakantham", "Hoong Chuin Lau"], "title": ["Entropy Controlled Non-Stationarity for Improving Performance of\n  Independent Learners in Anonymous MARL Settings"], "date": ["2018-03-27T07:10:20Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.09928v1"], "summary": ["  With the advent of sequential matching (of supply and demand) systems (uber,\nLyft, Grab for taxis; ubereats, deliveroo, etc for food; amazon prime, lazada\netc. for groceries) across many online and offline services, individuals (taxi\ndrivers, delivery boys, delivery van drivers, etc.) earn more by being at the\n\"right\" place at the \"right\" time. We focus on learning techniques for\nproviding guidance (on right locations to be at right times) to individuals in\nthe presence of other \"learning\" individuals. Interactions between indivduals\nare anonymous, i.e, the outcome of an interaction (competing for demand) is\nindependent of the identity of the agents and therefore we refer to these as\nAnonymous MARL settings.\n  Existing research of relevance is on independent learning using Reinforcement\nLearning (RL) or on Multi-Agent Reinforcement Learning (MARL). The number of\nindividuals in aggregation systems is extremely large and individuals have\ntheir own selfish interest (of maximising revenue). Therefore, traditional MARL\napproaches are either not scalable or assumptions of common objective or action\ncoordination are not viable. In this paper, we focus on improving performance\nof independent reinforcement learners, specifically the popular Deep Q-Networks\n(DQN) and Advantage Actor Critic (A2C) approaches by exploiting anonymity.\nSpecifically, we control non-stationarity introduced by other agents using\nentropy of agent density distribution. We demonstrate a significant improvement\nin revenue for individuals and for all agents together with our learners on a\ngeneric experimental set up for aggregation systems and a real world taxi\ndataset.\n"]},
{"authors": ["Eunwoo Kim", "Chanho Ahn", "Songhwai Oh"], "title": ["NestedNet: Learning Nested Sparse Structures in Deep Neural Networks"], "date": ["2017-12-11T14:09:06Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1712.03781v2"], "summary": ["  Recently, there have been increasing demands to construct compact deep\narchitectures to remove unnecessary redundancy and to improve the inference\nspeed. While many recent works focus on reducing the redundancy by eliminating\nunneeded weight parameters, it is not possible to apply a single deep\narchitecture for multiple devices with different resources. When a new device\nor circumstantial condition requires a new deep architecture, it is necessary\nto construct and train a new network from scratch. In this work, we propose a\nnovel deep learning framework, called a nested sparse network, which exploits\nan n-in-1-type nested structure in a neural network. A nested sparse network\nconsists of multiple levels of networks with a different sparsity ratio\nassociated with each level, and higher level networks share parameters with\nlower level networks to enable stable nested learning. The proposed framework\nrealizes a resource-aware versatile architecture as the same network can meet\ndiverse resource requirements. Moreover, the proposed nested network can learn\ndifferent forms of knowledge in its internal networks at different levels,\nenabling multiple tasks using a single network, such as coarse-to-fine\nhierarchical classification. In order to train the proposed nested sparse\nnetwork, we propose efficient weight connection learning and channel and layer\nscheduling strategies. We evaluate our network in multiple tasks, including\nadaptive deep compression, knowledge distillation, and learning class\nhierarchy, and demonstrate that nested sparse networks perform competitively,\nbut more efficiently, compared to existing methods.\n"]},
{"authors": ["Ashley D. Edwards", "Laura Downs", "James C. Davidson"], "title": ["Forward-Backward Reinforcement Learning"], "date": ["2018-03-27T04:33:08Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.10227v1"], "summary": ["  Goals for reinforcement learning problems are typically defined through\nhand-specified rewards. To design such problems, developers of learning\nalgorithms must inherently be aware of what the task goals are, yet we often\nrequire agents to discover them on their own without any supervision beyond\nthese sparse rewards. While much of the power of reinforcement learning derives\nfrom the concept that agents can learn with little guidance, this requirement\ngreatly burdens the training process. If we relax this one restriction and\nendow the agent with knowledge of the reward function, and in particular of the\ngoal, we can leverage backwards induction to accelerate training. To achieve\nthis, we propose training a model to learn to take imagined reversal steps from\nknown goal states. Rather than training an agent exclusively to determine how\nto reach a goal while moving forwards in time, our approach travels backwards\nto jointly predict how we got there. We evaluate our work in Gridworld and\nTowers of Hanoi and empirically demonstrate that it yields better performance\nthan standard DDQN.\n"]},
{"authors": ["Jie Liu", "Hao Zheng"], "title": ["MLE-induced Likelihood for Markov Random Fields"], "date": ["2018-03-27T04:05:44Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.09887v1"], "summary": ["  Due to the intractable partition function, the exact likelihood function for\na Markov random field (MRF), in many situations, can only be approximated.\nMajor approximation approaches include pseudolikelihood and Laplace\napproximation. In this paper, we propose a novel way of approximating the\nlikelihood function through first approximating the marginal likelihood\nfunctions of individual parameters and then reconstructing the joint likelihood\nfunction from these marginal likelihood functions. For approximating the\nmarginal likelihood functions, we derive a particular likelihood function from\na modified scenario of coin tossing which is useful for capturing how one\nparameter interacts with the remaining parameters in the likelihood function.\nFor reconstructing the joint likelihood function, we use an appropriate copula\nto link up these marginal likelihood functions. Numerical investigation\nsuggests the superior performance of our approach. Especially as the size of\nthe MRF increases, both the numerical performance and the computational cost of\nour approach remain consistently satisfactory, whereas Laplace approximation\ndeteriorates and pseudolikelihood becomes computationally unbearable.\n"]},
{"authors": ["Christoph Salge", "Christian Guckelsberger", "Rodrigo Canaan", "Tobias Mahlmann"], "title": ["Accelerating Empowerment Computation with UCT Tree Search"], "date": ["2018-03-27T03:05:35Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.09866v1"], "summary": ["  Models of intrinsic motivation present an important means to produce sensible\nbehaviour in the absence of extrinsic rewards. Applications in video games are\nvaried, and range from intrinsically motivated general game-playing agents to\nnon-player characters such as companions and enemies. The information-theoretic\nquantity of Empowerment is a particularly promising candidate motivation to\nproduce believable, generic and robust behaviour. However, while it can be used\nin the absence of external reward functions that would need to be crafted and\nlearned, empowerment is computationally expensive. In this paper, we propose a\nmodified UCT tree search method to mitigate empowerment's computational\ncomplexity in discrete and deterministic scenarios. We demonstrate how to\nmodify a Monte-Carlo Search Tree with UCT to realise empowerment maximisation,\nand discuss three additional modifications that facilitate better sampling. We\nevaluate the approach both quantitatively, by analysing how close our approach\ngets to the baseline of exhaustive empowerment computation with varying amounts\nof computational resources, and qualitatively, by analysing the resulting\nbehaviour in a Minecraft-like scenario.\n"]},
{"authors": ["Licheng Yu", "Zhe Lin", "Xiaohui Shen", "Jimei Yang", "Xin Lu", "Mohit Bansal", "Tamara L. Berg"], "title": ["MAttNet: Modular Attention Network for Referring Expression\n  Comprehension"], "date": ["2018-01-24T20:54:26Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.08186v3"], "summary": ["  In this paper, we address referring expression comprehension: localizing an\nimage region described by a natural language expression. While most recent work\ntreats expressions as a single unit, we propose to decompose them into three\nmodular components related to subject appearance, location, and relationship to\nother objects. This allows us to flexibly adapt to expressions containing\ndifferent types of information in an end-to-end framework. In our model, which\nwe call the Modular Attention Network (MAttNet), two types of attention are\nutilized: language-based attention that learns the module weights as well as\nthe word/phrase attention that each module should focus on; and visual\nattention that allows the subject and relationship modules to focus on relevant\nimage components. Module weights combine scores from all three modules\ndynamically to output an overall score. Experiments show that MAttNet\noutperforms previous state-of-art methods by a large margin on both\nbounding-box-level and pixel-level comprehension tasks. Demo and code are\nprovided.\n"]},
{"authors": ["Christoph Salge", "Michael Cerny Green", "Rodrigo Canaan", "Julian Togelius"], "title": ["Generative Design in Minecraft (GDMC), Settlement Generation Competition"], "date": ["2018-03-27T02:35:02Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.09853v1"], "summary": ["  This paper introduces the settlement generation competition for Minecraft,\nthe first part of the Generative Design in Minecraft challenge. The settlement\ngeneration competition is about creating Artificial Intelligence (AI) agents\nthat can produce functional, aesthetically appealing and believable settlements\nadapted to a given Minecraft map - ideally at a level that can compete with\nhuman created designs. The aim of the competition is to advance procedural\ncontent generation for games, especially in overcoming the challenges of\nadaptive and holistic PCG. The paper introduces the technical details of the\nchallenge, but mostly focuses on what challenges this competition provides and\nwhy they are scientifically relevant.\n"]},
{"authors": ["Luigi Asprino", "Valerio Basile", "Paolo Ciancarini", "Valentina Presutti"], "title": ["Empirical Analysis of Foundational Distinctions in the Web of Data"], "date": ["2018-03-26T20:56:30Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.09840v1"], "summary": ["  A main difference between pre-Web artificial intelligence and the current one\nis that the Web and its Semantic extension (i.e. Web of Data) contain open\nglobal-scale knowledge and make it available to potentially intelligent\nmachines that may want to benefit from it. Nevertheless, most of the Web of\nData lacks ontological distinctions and has a sparse distribution of\naxiomatisations. For example, foundational distinctions such as whether an\nentity is inherently a class or an individual, or whether it is a physical\nobject or not, are hardly expressed in the data, although they have been\nlargely studied and formalised by foundational ontologies (e.g. DOLCE, SUMO).\nThere is a gap between these ontologies, that often formalise or are inspired\nby preexisting philosophical theories and are developed with a top-down\napproach, and the Web of Data that is mostly derived from existing databases or\nfrom crowd-based effort (e.g. DBpedia, Wikidata, Freebase). We investigate\nwhether the Web provides an empirical foundation for characterising entities of\nthe Web of Data according to foundational distinctions. We want to answer\nquestions such as \"is the DBpedia entity for dog a class or an instance?\" We\nreport on a set of experiments based on machine learning and crowdsourcing that\nshow promising results.\n"]},
{"authors": ["Zolt\u00e1n Kov\u00e1cs", "Tom\u00e1s Recio", "M. Pilar V\u00e9lez"], "title": ["Detecting truth, just on parts"], "date": ["2018-02-16T09:24:29Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.05875v2"], "summary": ["  We introduce and discuss, through a computational algebraic geometry\napproach, the automatic reasoning handling of propositions that are\nsimultaneously true and false over some relevant collections of instances. A\nrigorous, algorithmic criterion is presented for detecting such cases, and its\nperformance is exemplified through the implementation of this test on the\ndynamic geometry program GeoGebra.\n"]},
{"authors": ["Biplav Srivastava"], "title": ["On Chatbots Exhibiting Goal-Directed Autonomy in Dynamic Environments"], "date": ["2018-03-26T18:51:33Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.09789v1"], "summary": ["  Conversation interfaces (CIs), or chatbots, are a popular form of intelligent\nagents that engage humans in task-oriented or informal conversation. In this\nposition paper and demonstration, we argue that chatbots working in dynamic\nenvironments, like with sensor data, can not only serve as a promising platform\nto research issues at the intersection of learning, reasoning, representation\nand execution for goal-directed autonomy; but also handle non-trivial business\napplications. We explore the underlying issues in the context of Water Advisor,\na preliminary multi-modal conversation system that can access and explain water\nquality data.\n"]},
{"authors": ["Daniel Karapetyan", "Andrew J. Parkes", "Thomas St\u00fctzle"], "title": ["Algorithm Configuration: Learning policies for the quick termination of\n  poor performers"], "date": ["2018-03-26T18:38:35Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.09785v1"], "summary": ["  One way to speed up the algorithm configuration task is to use short runs\ninstead of long runs as much as possible, but without discarding the\nconfigurations that eventually do well on the long runs. We consider the\nproblem of selecting the top performing configurations of the Conditional\nMarkov Chain Search (CMCS), a general algorithm schema that includes, for\nexamples, VNS. We investigate how the structure of performance on short tests\nlinks with those on long tests, showing that significant differences arise\nbetween test domains. We propose a \"performance envelope\" method to exploit the\nlinks; that learns when runs should be terminated, but that automatically\nadapts to the domain.\n"]},
{"authors": ["Andrew Jaegle", "Oleh Rybkin", "Konstantinos G. Derpanis", "Kostas Daniilidis"], "title": ["Predicting the Future with Transformational States"], "date": ["2018-03-26T18:00:07Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.09760v1"], "summary": ["  An intelligent observer looks at the world and sees not only what is, but\nwhat is moving and what can be moved. In other words, the observer sees how the\npresent state of the world can transform in the future. We propose a model that\npredicts future images by learning to represent the present state and its\ntransformation given only a sequence of images. To do so, we introduce an\narchitecture with a latent state composed of two components designed to capture\n(i) the present image state and (ii) the transformation between present and\nfuture states, respectively. We couple this latent state with a recurrent\nneural network (RNN) core that predicts future frames by transforming past\nstates into future states by applying the accumulated state transformation with\na learned operator. We describe how this model can be integrated into an\nencoder-decoder convolutional neural network (CNN) architecture that uses\nweighted residual connections to integrate representations of the past with\nrepresentations of the future. Qualitatively, our approach generates image\nsequences that are stable and capture realistic motion over multiple predicted\nframes, without requiring adversarial training. Quantitatively, our method\nachieves prediction results comparable to state-of-the-art results on standard\nimage prediction benchmarks (Moving MNIST, KTH, and UCF101).\n"]},
{"authors": ["Olivier Deiss", "Siddharth Biswal", "Jing Jin", "Haoqi Sun", "M. Brandon Westover", "Jimeng Sun"], "title": ["HAMLET: Interpretable Human And Machine co-LEarning Technique"], "date": ["2018-03-26T16:29:03Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.09702v1"], "summary": ["  Efficient label acquisition processes are key to obtaining robust\nclassifiers. However, data labeling is often challenging and subject to high\nlevels of label noise. This can arise even when classification targets are well\ndefined, if instances to be labeled are more difficult than the prototypes used\nto define the class, leading to disagreements among the expert community.\n  Here, we enable efficient training of deep neural networks. From\nlow-confidence labels, we iteratively improve their quality by simultaneous\nlearning of machines and experts. We call it Human And Machine co-LEarning\nTechnique (HAMLET). Throughout the process, experts become more consistent,\nwhile the algorithm provides them with explainable feedback for confirmation.\nHAMLET uses a neural embedding function and a memory module filled with diverse\nreference embeddings from different classes. Its output includes classification\nlabels and highly relevant reference embeddings as explanation.\n  We took the study of brain monitoring at intensive care unit (ICU) as an\napplication of HAMLET on continuous electroencephalography (cEEG) data.\nAlthough cEEG monitoring yields large volumes of data, labeling costs and\ndifficulty make it hard to build a classifier. Additionally, while experts\nagree on the labels of clear-cut examples of cEEG patterns, labeling many\nreal-world cEEG data can be extremely challenging. Thus, a large minority of\nsequences might be mislabeled. HAMLET has shown significant performance gain\nagainst deep learning and other baselines, increasing accuracy from 7.03% to\n68.75% on challenging inputs. Besides improved performance, clinical experts\nconfirmed the interpretability of those reference embeddings in helping\nexplaining the classification results by HAMLET.\n"]},
{"authors": ["Cem Eteke", "Hayati Havlucu", "Nisa \u0130rem K\u0131rba\u00e7", "Mehmet Cengiz Onba\u015fl\u0131", "Aykut Co\u015fkun", "Terry Eskenazi", "O\u011fuzhan \u00d6zcan", "Bar\u0131\u015f Akg\u00fcn"], "title": ["Flow From Motion: A Deep Learning Approach"], "date": ["2018-03-26T16:12:48Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.09689v1"], "summary": ["  Wearable devices have the potential to enhance sports performance, yet they\nare not fulfilling this promise. Our previous studies with 6 professional\ntennis coaches and 20 players indicate that this could be due the lack of\npsychological or mental state feedback, which the coaches claim to provide.\nTowards this end, we propose to detect the flow state, mental state of optimal\nperformance, using wearables data to be later used in training. We performed a\nstudy with a professional tennis coach and two players. The coach provided\nlabels about the players' flow state while each player had a wearable device on\ntheir racket holding wrist. We trained multiple models using the wearables data\nand the coach labels. Our deep neural network models achieved around 98%\ntesting accuracy for a variety of conditions. This suggests that the flow state\nor what coaches recognize as flow, can be detected using wearables data in\ntennis which is a novel result. The implication for the HCI community is that\nhaving access to such information would allow for design of novel hardware and\ninteraction paradigms that would be helpful in professional athlete training.\n"]},
{"authors": ["Christoph Benzm\u00fcller", "Xavier Parent"], "title": ["I/O Logic in HOL --- First Steps"], "date": ["2018-03-26T15:53:31Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.09681v1"], "summary": ["  A semantical embedding of input/output logic in classical higher-order logic\nis presented. This embedding enables the mechanisation and automation of\nreasoning tasks in input/output logic with off-the-shelf higher-order theorem\nprovers and proof assistants. The key idea for the solution presented here\nresults from the analysis of an inaccurate previous embedding attempt, which we\nwill discuss as well.\n"]},
{"authors": ["Malte Ludewig", "Dietmar Jannach"], "title": ["Evaluation of Session-based Recommendation Algorithms"], "date": ["2018-03-26T13:46:07Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.09587v1"], "summary": ["  Recommender systems help users find relevant items of interest, for example\non e-commerce or media streaming sites. Most academic research is concerned\nwith approaches that personalize the recommendations according to long-term\nuser profiles. In many real-world applications, however, such long-term\nprofiles often do not exist and recommendations therefore have to be made\nsolely based on the observed behavior of a user during an ongoing session.\nGiven the high practical relevance of the problem, an increased interest in\nthis problem can be observed in recent years, leading to a number of proposals\nfor session-based recommendation algorithms that typically aim to predict the\nuser's immediate next actions. In this work, we present the results of an\nin-depth performance comparison of a number of such algorithms, using a variety\nof datasets and evaluation measures. Our comparison includes the most recent\napproaches based on recurrent neural networks like GRU4REC, factorized Markov\nmodel approaches such as FISM or Fossil, as well as more simple methods based,\ne.g., on nearest neighbor schemes. Our experiments reveal that algorithms of\nthis latter class, despite their sometimes almost trivial nature, often perform\nequally well or significantly better than today's more complex approaches based\non deep neural networks. Our results therefore suggest that there is\nsubstantial room for improvement regarding the development of more\nsophisticated session-based recommendation algorithms.\n"]},
{"authors": ["Nils Reimers", "Iryna Gurevych"], "title": ["Why Comparing Single Performance Scores Does Not Allow to Draw\n  Conclusions About Machine Learning Approaches"], "date": ["2018-03-26T13:35:14Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.09578v1"], "summary": ["  Developing state-of-the-art approaches for specific tasks is a major driving\nforce in our research community. Depending on the prestige of the task,\npublishing it can come along with a lot of visibility. The question arises how\nreliable are our evaluation methodologies to compare approaches?\n  One common methodology to identify the state-of-the-art is to partition data\ninto a train, a development and a test set. Researchers can train and tune\ntheir approach on some part of the dataset and then select the model that\nworked best on the development set for a final evaluation on unseen test data.\nTest scores from different approaches are compared, and performance differences\nare tested for statistical significance.\n  In this publication, we show that there is a high risk that a statistical\nsignificance in this type of evaluation is not due to a superior learning\napproach. Instead, there is a high risk that the difference is due to chance.\nFor example for the CoNLL 2003 NER dataset we observed in up to 26% of the\ncases type I errors (false positives) with a threshold of p < 0.05, i.e.,\nfalsely concluding a statistically significant difference between two identical\napproaches.\n  We prove that this evaluation setup is unsuitable to compare learning\napproaches. We formalize alternative evaluation setups based on score\ndistributions.\n"]},
{"authors": ["Zachary A. Pardos", "Zihao Fan", "Weijie Jiang"], "title": ["Connectionist Recommendation in the Wild"], "date": ["2018-03-26T12:08:28Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.09535v1"], "summary": ["  The aggregate behaviors of users can collectively encode deep semantic\ninformation about the objects with which they interact. In this paper, we\ndemonstrate novel ways in which the synthesis of these data can illuminate the\nterrain of users' environment and support them in their decision making and\nwayfinding. A novel application of Recurrent Neural Networks and skip-gram\nmodels, approaches popularized by their application to modeling language, are\nbrought to bear on student university enrollment sequences to create vector\nrepresentations of courses and map out traversals across them. We present\ndemonstrations of how scrutability from these neural networks can be gained and\nhow the combination of these techniques can be seen as an evolution of content\ntagging and a means for a recommender to balance user preferences inferred from\ndata with those explicitly specified. From validation of the models to the\ndevelopment of a UI, we discuss additional requisite functionality informed by\nthe results of a field study leading to the ultimate deployment of the system\nat a university.\n"]},
{"authors": ["Dan Nguyen", "Troy Long", "Xun Jia", "Weiguo Lu", "Xuejun Gu", "Zohaib Iqbal", "Steve Jiang"], "title": ["Dose Prediction with U-net: A Feasibility Study for Predicting Dose\n  Distributions from Contours using Deep Learning on Prostate IMRT Patients"], "date": ["2017-09-26T19:43:29Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1709.09233v2"], "summary": ["  With the advancement of treatment modalities in radiation therapy for cancer\npatients, outcomes have improved, but at the cost of increased treatment plan\ncomplexity and planning time. The accurate prediction of dose distributions\nwould alleviate this issue by guiding clinical plan optimization to save time\nand maintain high quality plans. We have modified a convolutional deep network\nmodel, U-net (originally designed for segmentation purposes), for predicting\ndose from patient image contours. We show that, as an example, we are able to\naccurately predict the dose of intensity-modulated radiation therapy (IMRT) for\nprostate cancer patients, where the average dice similarity coefficient is 0.91\nwhen comparing the predicted vs. true isodose volumes between 0% and 100% of\nthe prescription dose. The average value of the absolute differences in [max,\nmean] dose is found to be under 5% of the prescription dose, specifically for\neach structure is [1.80%, 1.03%](PTV), [1.94%, 4.22%](Bladder), [1.80%,\n0.48%](Body), [3.87%, 1.79%](L Femoral Head), [5.07%, 2.55%](R Femoral Head),\nand [1.26%, 1.62%](Rectum) of the prescription dose. We thus managed to map a\ndesired radiation dose distribution from a patient's PTV and OAR contours. As\nan additional advantage, relatively little data was used in the techniques and\nmodels described in this paper.\n"]},
{"authors": ["Makoto Naruse", "Takatomo Mihana", "Hirokazu Hori", "Hayato Saigo", "Kazuya Okamura", "Mikio Hasegawa", "Atsushi Uchida"], "title": ["Scalable photonic reinforcement learning by time-division multiplexing\n  of laser chaos"], "date": ["2018-03-26T05:56:54Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.09425v1"], "summary": ["  Reinforcement learning involves decision making in dynamic and uncertain\nenvironments and constitutes a crucial element of artificial intelligence. In\nour previous work, we experimentally demonstrated that the ultrafast chaotic\noscillatory dynamics of lasers can be used to solve the two-armed bandit\nproblem efficiently, which requires decision making concerning a class of\ndifficult trade-offs called the exploration-exploitation dilemma. However, only\ntwo selections were employed in that research; thus, the scalability of the\nlaser-chaos-based reinforcement learning should be clarified. In this study, we\ndemonstrated a scalable, pipelined principle of resolving the multi-armed\nbandit problem by introducing time-division multiplexing of chaotically\noscillated ultrafast time-series. The experimental demonstrations in which\nbandit problems with up to 64 arms were successfully solved are presented in\nthis report. Detailed analyses are also provided that include performance\ncomparisons among laser chaos signals generated in different physical\nconditions, which coincide with the diffusivity inherent in the time series.\nThis study paves the way for ultrafast reinforcement learning by taking\nadvantage of the ultrahigh bandwidths of light wave and practical enabling\ntechnologies.\n"]},
{"authors": ["Li He", "Liang Wang", "Kaipeng Liu", "Bo Wu", "Weinan Zhang"], "title": ["Optimizing Sponsored Search Ranking Strategy by Deep Reinforcement\n  Learning"], "date": ["2018-03-20T10:18:26Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.07347v3"], "summary": ["  Sponsored search is an indispensable business model and a major revenue\ncontributor of almost all the search engines. From the advertisers' side,\nparticipating in ranking the search results by paying for the sponsored search\nadvertisement to attract more awareness and purchase facilitates their\ncommercial goal. From the users' side, presenting personalized advertisement\nreflecting their propensity would make their online search experience more\nsatisfactory. Sponsored search platforms rank the advertisements by a ranking\nfunction to determine the list of advertisements to show and the charging price\nfor the advertisers. Hence, it is crucial to find a good ranking function which\ncan simultaneously satisfy the platform, the users and the advertisers.\nMoreover, advertisements showing positions under different queries from\ndifferent users may associate with advertisement candidates of different bid\nprice distributions and click probability distributions, which requires the\nranking functions to be optimized adaptively to the traffic characteristics. In\nthis work, we proposed a generic framework to optimize the ranking functions by\ndeep reinforcement learning methods. The framework is composed of two parts: an\noffline learning part which initializes the ranking functions by learning from\na simulated advertising environment, allowing adequate exploration of the\nranking function parameter space without hurting the performance of the\ncommercial platform. An online learning part which further optimizes the\nranking functions by adapting to the online data distribution. Experimental\nresults on a large-scale sponsored search platform confirm the effectiveness of\nthe proposed method.\n"]},
{"authors": ["Tianbing Xu", "Qiang Liu", "Liang Zhao", "Jian Peng"], "title": ["Learning to Explore with Meta-Policy Gradient"], "date": ["2018-03-13T21:04:17Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.05044v2"], "summary": ["  The performance of off-policy learning, including deep Q-learning and deep\ndeterministic policy gradient (DDPG), critically depends on the choice of the\nexploration policy. Existing exploration methods are mostly based on adding\nnoise to the on-going actor policy and can only explore \\emph{local} regions\nclose to what the actor policy dictates. In this work, we develop a simple\nmeta-policy gradient algorithm that allows us to adaptively learn the\nexploration policy in DDPG. Our algorithm allows us to train flexible\nexploration behaviors that are independent of the actor policy, yielding a\n\\emph{global exploration} that significantly speeds up the learning process.\nWith an extensive study, we show that our method significantly improves the\nsample-efficiency of DDPG on a variety of reinforcement learning tasks.\n"]},
{"authors": ["Tianbing Xu"], "title": ["Variational Inference for Policy Gradient"], "date": ["2018-02-21T22:18:20Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.07833v2"], "summary": ["  Inspired by the seminal work on Stein Variational Inference and Stein\nVariational Policy Gradient, we derived a method to generate samples from the\nposterior variational parameter distribution by \\textit{explicitly} minimizing\nthe KL divergence to match the target distribution in an amortize fashion.\nConsequently, we applied this varational inference technique into vanilla\npolicy gradient, TRPO and PPO with Bayesian Neural Network parameterizations\nfor reinforcement learning problems.\n"]},
{"authors": ["Kuang-Huei Lee", "Xiaodong He", "Lei Zhang", "Linjun Yang"], "title": ["CleanNet: Transfer Learning for Scalable Image Classifier Training with\n  Label Noise"], "date": ["2017-11-20T03:50:53Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.07131v2"], "summary": ["  In this paper, we study the problem of learning image classification models\nwith label noise. Existing approaches depending on human supervision are\ngenerally not scalable as manually identifying correct or incorrect labels is\ntime-consuming, whereas approaches not relying on human supervision are\nscalable but less effective. To reduce the amount of human supervision for\nlabel noise cleaning, we introduce CleanNet, a joint neural embedding network,\nwhich only requires a fraction of the classes being manually verified to\nprovide the knowledge of label noise that can be transferred to other classes.\nWe further integrate CleanNet and conventional convolutional neural network\nclassifier into one framework for image classification learning. We demonstrate\nthe effectiveness of the proposed algorithm on both of the label noise\ndetection task and the image classification on noisy data task on several\nlarge-scale datasets. Experimental results show that CleanNet can reduce label\nnoise detection error rate on held-out classes where no human supervision\navailable by 41.5% compared to current weakly supervised methods. It also\nachieves 47% of the performance gain of verifying all images with only 3.2%\nimages verified on an image classification task. Source code and dataset will\nbe available at kuanghuei.github.io/CleanNetProject.\n"]},
{"authors": ["Mehdi S. M. Sajjadi", "Raviteja Vemulapalli", "Matthew Brown"], "title": ["Frame-Recurrent Video Super-Resolution"], "date": ["2018-01-14T17:53:53Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.04590v4"], "summary": ["  Recent advances in video super-resolution have shown that convolutional\nneural networks combined with motion compensation are able to merge information\nfrom multiple low-resolution (LR) frames to generate high-quality images.\nCurrent state-of-the-art methods process a batch of LR frames to generate a\nsingle high-resolution (HR) frame and run this scheme in a sliding window\nfashion over the entire video, effectively treating the problem as a large\nnumber of separate multi-frame super-resolution tasks. This approach has two\nmain weaknesses: 1) Each input frame is processed and warped multiple times,\nincreasing the computational cost, and 2) each output frame is estimated\nindependently conditioned on the input frames, limiting the system's ability to\nproduce temporally consistent results.\n  In this work, we propose an end-to-end trainable frame-recurrent video\nsuper-resolution framework that uses the previously inferred HR estimate to\nsuper-resolve the subsequent frame. This naturally encourages temporally\nconsistent results and reduces the computational cost by warping only one image\nin each step. Furthermore, due to its recurrent nature, the proposed method has\nthe ability to assimilate a large number of previous frames without increased\ncomputational demands. Extensive evaluations and comparisons with previous\nmethods validate the strengths of our approach and demonstrate that the\nproposed framework is able to significantly outperform the current state of the\nart.\n"]},
{"authors": ["Vinith Misra", "Sumit Bhatia"], "title": ["Bernoulli Embeddings for Graphs"], "date": ["2018-03-25T07:19:47Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.09211v1"], "summary": ["  Just as semantic hashing can accelerate information retrieval, binary valued\nembeddings can significantly reduce latency in the retrieval of graphical data.\nWe introduce a simple but effective model for learning such binary vectors for\nnodes in a graph. By imagining the embeddings as independent coin flips of\nvarying bias, continuous optimization techniques can be applied to the\napproximate expected loss. Embeddings optimized in this fashion consistently\noutperform the quantization of both spectral graph embeddings and various\nlearned real-valued embeddings, on both ranking and pre-ranking tasks for a\nvariety of datasets.\n"]},
{"authors": ["Pin Wang", "Ching-Yao Chan"], "title": ["Autonomous Ramp Merge Maneuver Based on Reinforcement Learning with\n  Continuous Action Space"], "date": ["2018-03-25T05:10:10Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.09203v1"], "summary": ["  Ramp merging is a critical maneuver for road safety and traffic efficiency.\nMost of the current automated driving systems developed by multiple automobile\nmanufacturers and suppliers are typically limited to restricted access freeways\nonly. Extending the automated mode to ramp merging zones presents substantial\nchallenges. One is that the automated vehicle needs to incorporate a future\nobjective (e.g. a successful and smooth merge) and optimize a long-term reward\nthat is impacted by subsequent actions when executing the current action.\nFurthermore, the merging process involves interaction between the merging\nvehicle and its surrounding vehicles whose behavior may be cooperative or\nadversarial, leading to distinct merging countermeasures that are crucial to\nsuccessfully complete the merge. In place of the conventional rule-based\napproaches, we propose to apply reinforcement learning algorithm on the\nautomated vehicle agent to find an optimal driving policy by maximizing the\nlong-term reward in an interactive driving environment. Most importantly, in\ncontrast to most reinforcement learning applications in which the action space\nis resolved as discrete, our approach treats the action space as well as the\nstate space as continuous without incurring additional computational costs. Our\nunique contribution is the design of the Q-function approximation whose format\nis structured as a quadratic function, by which simple but effective neural\nnetworks are used to estimate its coefficients. The results obtained through\nthe implementation of our training platform demonstrate that the vehicle agent\nis able to learn a safe, smooth and timely merging policy, indicating the\neffectiveness and practicality of our approach.\n"]},
{"authors": ["Yuan Gong", "Christian Poellabauer"], "title": ["An Overview of Vulnerabilities of Voice Controlled Systems"], "date": ["2018-03-24T19:41:25Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.09156v1"], "summary": ["  Over the last few years, a rapidly increasing number of Internet-of-Things\n(IoT) systems that adopt voice as the primary user input have emerged. These\nsystems have been shown to be vulnerable to various types of voice spoofing\nattacks. However, how exactly these techniques differ or relate to each other\nhas not been extensively studied. In this paper, we provide a survey of recent\nattack and defense techniques for voice controlled systems and propose a\nclassification of these techniques. We also discuss the need for a universal\ndefense strategy that protects a system from various types of attacks.\n"]},
{"authors": ["Vinayak Mathur", "Arpit Singh"], "title": ["The Rapidly Changing Landscape of Conversational Agents"], "date": ["2018-03-22T15:53:59Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.08419v2"], "summary": ["  Conversational agents have become ubiquitous, ranging from goal-oriented\nsystems for helping with reservations to chit-chat models found in modern\nvirtual assistants. In this survey paper, we explore this fascinating field. We\nlook at some of the pioneering work that defined the field and gradually move\nto the current state-of-the-art models. We look at statistical, neural,\ngenerative adversarial network based and reinforcement learning based\napproaches and how they evolved. Along the way we discuss various challenges\nthat the field faces, lack of context in utterances, not having a good\nquantitative metric to compare models, lack of trust in agents because they do\nnot have a consistent persona etc. We structure this paper in a way that\nanswers these pertinent questions and discusses competing approaches to solve\nthem.\n"]},
{"authors": ["Alexander N. Gorban", "Bogdan Grechuk", "Ivan Y. Tyukin"], "title": ["Augmented Artificial Intelligence: a Conceptual Framework"], "date": ["2018-02-06T19:05:27Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.02172v3"], "summary": ["  All artificial Intelligence (AI) systems make errors. These errors are\nunexpected, and differ often from the typical human mistakes (\"non-human\"\nerrors). The AI errors should be corrected without damage of existing skills\nand, hopefully, avoiding direct human expertise. This paper presents an initial\nsummary report of project taking new and systematic approach to improving the\nintellectual effectiveness of the individual AI by communities of AIs. We\ncombine some ideas of learning in heterogeneous multiagent systems with new and\noriginal mathematical approaches for non-iterative corrections of errors of\nlegacy AI systems. The mathematical foundations of AI non-destructive\ncorrection are presented and a series of new stochastic separation theorems is\nproven. These theorems provide a new instrument for the development, analysis,\nand assessment of machine learning methods and algorithms in high dimension.\nThey demonstrate that in high dimensions and even for exponentially large\nsamples, linear classifiers in their classical Fisher's form are powerful\nenough to separate errors from correct responses with high probability and to\nprovide efficient solution to the non-destructive corrector problem. In\nparticular, we prove some hypotheses formulated in our paper `Stochastic\nSeparation Theorems' (Neural Networks, 94, 255--259, 2017), and answer one\ngeneral problem published by Donoho and Tanner in 2009.\n"]},
{"authors": ["Pedro F. Felzenszwalb"], "title": ["Similar Elements and Metric Labeling on Complete Graphs"], "date": ["2018-03-21T17:55:02Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.08037v2"], "summary": ["  We consider a problem that involves finding similar elements in a collection\nof sets. The problem is motivated by applications in machine learning and\npattern recognition. We formulate the similar elements problem as an\noptimization and give an efficient approximation algorithm that finds a\nsolution within a factor of 2 of the optimal. The similar elements problem is a\nspecial case of the metric labeling problem and we also give an efficient\n2-approximation algorithm for the metric labeling problem on complete graphs.\n"]},
{"authors": ["Chris Martens", "Eric Butler", "Joseph C. Osborn"], "title": ["A Resourceful Reframing of Behavior Trees"], "date": ["2018-03-24T12:28:04Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.09099v1"], "summary": ["  Designers of autonomous agents, whether in physical or virtual environments,\nneed to express nondeterminisim, failure, and parallelism in behaviors, as well\nas accounting for synchronous coordination between agents. Behavior Trees are a\nsemi-formalism deployed widely for this purpose in the games industry, but with\nchallenges to scalability, reasoning, and reuse of common sub-behaviors.\n  We present an alternative formulation of behavior trees through a language\ndesign perspective, giving a formal operational semantics, type system, and\ncorresponding implementation. We express specifications for atomic behaviors as\nlinear logic formulas describing how they transform the environment, and our\ntype system uses linear sequent calculus to derive a compositional type\nassignment to behavior tree expressions. These types expose the conditions\nrequired for behaviors to succeed and allow abstraction over parameters to\nbehaviors, enabling the development of behavior \"building blocks\" amenable to\ncompositional reasoning and reuse.\n"]},
{"authors": ["Yi Tay", "Luu Anh Tuan", "Siu Cheung Hui"], "title": ["Multi-range Reasoning for Machine Comprehension"], "date": ["2018-03-24T08:10:04Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.09074v1"], "summary": ["  We propose MRU (Multi-Range Reasoning Units), a new fast compositional\nencoder for machine comprehension (MC). Our proposed MRU encoders are\ncharacterized by multi-ranged gating, executing a series of parameterized\ncontract-and-expand layers for learning gating vectors that benefit from long\nand short-term dependencies. The aims of our approach are as follows: (1)\nlearning representations that are concurrently aware of long and short-term\ncontext, (2) modeling relationships between intra-document blocks and (3) fast\nand efficient sequence encoding. We show that our proposed encoder demonstrates\npromising results both as a standalone encoder and as well as a complementary\nbuilding block. We conduct extensive experiments on three challenging MC\ndatasets, namely RACE, SearchQA and NarrativeQA, achieving highly competitive\nperformance on all. On the RACE benchmark, our model outperforms DFN (Dynamic\nFusion Networks) by 1.5%-6% without using any recurrent or convolution layers.\nSimilarly, we achieve competitive performance relative to AMANDA on the\nSearchQA benchmark and BiDAF on the NarrativeQA benchmark without using any\nLSTM/GRU layers. Finally, incorporating MRU encoders with standard BiLSTM\narchitectures further improves performance, achieving state-of-the-art results.\n"]},
{"authors": ["A. V. Palagin", "N. G. Petrenko", "V. Yu. Velychko", "K. S. Malakhov"], "title": ["Development of formal models, algorithms, procedures, engineering and\n  functioning of the software system \"Instrumental complex for ontological\n  engineering purpose\""], "date": ["2018-03-24T07:14:00Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.10684v1"], "summary": ["  The given paper considered a generalized model representation of the software\nsystem \"Instrumental complex for ontological engineering purpose\". Represented\ncomplete software system development process. Developed relevant formal models\nof the software system \"Instrumental complex for ontological engineering\npurpose\", represented as mathematical expressions, UML diagrams, and also\ndescribed the three-tier architecture of the software system \"Instrumental\ncomplex for ontological engineering purpose\" in a client-server environment.\n"]},
{"authors": ["Daniel A. Abolafia", "Mohammad Norouzi", "Jonathan Shen", "Rui Zhao", "Quoc V. Le"], "title": ["Neural Program Synthesis with Priority Queue Training"], "date": ["2018-01-10T19:35:25Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.03526v2"], "summary": ["  We consider the task of program synthesis in the presence of a reward\nfunction over the output of programs, where the goal is to find programs with\nmaximal rewards. We employ an iterative optimization scheme, where we train an\nRNN on a dataset of K best programs from a priority queue of the generated\nprograms so far. Then, we synthesize new programs and add them to the priority\nqueue by sampling from the RNN. We benchmark our algorithm, called priority\nqueue training (or PQT), against genetic algorithm and reinforcement learning\nbaselines on a simple but expressive Turing complete programming language\ncalled BF. Our experimental results show that our simple PQT algorithm\nsignificantly outperforms the baselines. By adding a program length penalty to\nthe reward function, we are able to synthesize short, human readable programs.\n"]},
{"authors": ["Timnit Gebru", "Jamie Morgenstern", "Briana Vecchione", "Jennifer Wortman Vaughan", "Hanna Wallach", "Hal Daume\u00e9 III", "Kate Crawford"], "title": ["Datasheets for Datasets"], "date": ["2018-03-23T23:22:18Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.09010v1"], "summary": ["  Currently there is no standard way to identify how a dataset was created, and\nwhat characteristics, motivations, and potential skews it represents. To begin\nto address this issue, we propose the concept of a datasheet for datasets, a\nshort document to accompany public datasets, commercial APIs, and pretrained\nmodels. The goal of this proposal is to enable better communication between\ndataset creators and users, and help the AI community move toward greater\ntransparency and accountability. By analogy, in computer hardware, it has\nbecome industry standard to accompany everything from the simplest components\n(e.g., resistors), to the most complex microprocessor chips, with datasheets\ndetailing standard operating characteristics, test results, recommended usage,\nand other information. We outline some of the questions a datasheet for\ndatasets should answer. These questions focus on when, where, and how the\ntraining data was gathered, its recommended use cases, and, in the case of\nhuman-centric datasets, information regarding the subjects' demographics and\nconsent as applicable. We develop prototypes of datasheets for two well-known\ndatasets: Labeled Faces in The Wild~\\cite{lfw} and the Pang \\& Lee Polarity\nDataset~\\cite{polarity}.\n"]},
{"authors": ["Craig Sherstan", "Marlos C. Machado", "Patrick M. Pilarski"], "title": ["Accelerating Learning in Constructive Predictive Frameworks with the\n  Successor Representation"], "date": ["2018-03-23T22:40:22Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.09001v1"], "summary": ["  Here we propose using the successor representation (SR) to accelerate\nlearning in a constructive knowledge system based on general value functions\n(GVFs). In real-world settings like robotics for unstructured and dynamic\nenvironments, it is infeasible to model all meaningful aspects of a system and\nits environment by hand due to both complexity and size. Instead, robots must\nbe capable of learning and adapting to changes in their environment and task,\nincrementally constructing models from their own experience. GVFs, taken from\nthe field of reinforcement learning (RL), are a way of modeling the world as\npredictive questions. One approach to such models proposes a massive network of\ninterconnected and interdependent GVFs, which are incrementally added over\ntime. It is reasonable to expect that new, incrementally added predictions can\nbe learned more swiftly if the learning process leverages knowledge gained from\npast experience. The SR provides such a means of separating the dynamics of the\nworld from the prediction targets and thus capturing regularities that can be\nreused across multiple GVFs. As a primary contribution of this work, we show\nthat using SR-based predictions can improve sample efficiency and learning\nspeed in a continual learning setting where new predictions are incrementally\nadded and learned over time. We analyze our approach in a grid-world and then\ndemonstrate its potential on data from a physical robot arm.\n"]},
{"authors": ["Chuhang Zou", "Alex Colburn", "Qi Shan", "Derek Hoiem"], "title": ["LayoutNet: Reconstructing the 3D Room Layout from a Single RGB Image"], "date": ["2018-03-23T22:25:52Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.08999v1"], "summary": ["  We propose an algorithm to predict room layout from a single image that\ngeneralizes across panoramas and perspective images, cuboid layouts and more\ngeneral layouts (e.g. L-shape room). Our method operates directly on the\npanoramic image, rather than decomposing into perspective images as do recent\nworks. Our network architecture is similar to that of RoomNet, but we show\nimprovements due to aligning the image based on vanishing points, predicting\nmultiple layout elements (corners, boundaries, size and translation), and\nfitting a constrained Manhattan layout to the resulting predictions. Our method\ncompares well in speed and accuracy to other existing work on panoramas,\nachieves among the best accuracy for perspective images, and can handle both\ncuboid-shaped and more general Manhattan layouts.\n"]},
{"authors": ["Roberta Raileanu", "Emily Denton", "Arthur Szlam", "Rob Fergus"], "title": ["Modeling Others using Oneself in Multi-Agent Reinforcement Learning"], "date": ["2018-02-26T23:27:53Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.09640v3"], "summary": ["  We consider the multi-agent reinforcement learning setting with imperfect\ninformation in which each agent is trying to maximize its own utility. The\nreward function depends on the hidden state (or goal) of both agents, so the\nagents must infer the other players' hidden goals from their observed behavior\nin order to solve the tasks. We propose a new approach for learning in these\ndomains: Self Other-Modeling (SOM), in which an agent uses its own policy to\npredict the other agent's actions and update its belief of their hidden state\nin an online manner. We evaluate this approach on three different tasks and\nshow that the agents are able to learn better policies using their estimate of\nthe other players' hidden states, in both cooperative and adversarial settings.\n"]},
{"authors": ["Bokai Cao", "Lei Zheng", "Chenwei Zhang", "Philip S. Yu", "Andrea Piscitello", "John Zulueta", "Olu Ajilore", "Kelly Ryan", "Alex D. Leow"], "title": ["DeepMood: Modeling Mobile Phone Typing Dynamics for Mood Detection"], "date": ["2018-03-23T21:29:21Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.08986v1"], "summary": ["  The increasing use of electronic forms of communication presents new\nopportunities in the study of mental health, including the ability to\ninvestigate the manifestations of psychiatric diseases unobtrusively and in the\nsetting of patients' daily lives. A pilot study to explore the possible\nconnections between bipolar affective disorder and mobile phone usage was\nconducted. In this study, participants were provided a mobile phone to use as\ntheir primary phone. This phone was loaded with a custom keyboard that\ncollected metadata consisting of keypress entry time and accelerometer\nmovement. Individual character data with the exceptions of the backspace key\nand space bar were not collected due to privacy concerns. We propose an\nend-to-end deep architecture based on late fusion, named DeepMood, to model the\nmulti-view metadata for the prediction of mood scores. Experimental results\nshow that 90.31% prediction accuracy on the depression score can be achieved\nbased on session-level mobile phone typing dynamics which is typically less\nthan one minute. It demonstrates the feasibility of using mobile phone metadata\nto infer mood disturbance and severity.\n"]},
{"authors": ["Patrick Huber", "Jan Niehues", "Alex Waibel"], "title": ["Automated Evaluation of Out-of-Context Errors"], "date": ["2018-03-23T21:20:00Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.08983v1"], "summary": ["  We present a new approach to evaluate computational models for the task of\ntext understanding by the means of out-of-context error detection. Through the\nnovel design of our automated modification process, existing large-scale data\nsources can be adopted for a vast number of text understanding tasks. The data\nis thereby altered on a semantic level, allowing models to be tested against a\nchallenging set of modified text passages that require to comprise a broader\nnarrative discourse. Our newly introduced task targets actual real-world\nproblems of transcription and translation systems by inserting authentic\nout-of-context errors. The automated modification process is applied to the\n2016 TEDTalk corpus. Entirely automating the process allows the adoption of\ncomplete datasets at low cost, facilitating supervised learning procedures and\ndeeper networks to be trained and tested. To evaluate the quality of the\nmodification algorithm a language model and a supervised binary classification\nmodel are trained and tested on the altered dataset. A human baseline\nevaluation is examined to compare the results with human performance. The\noutcome of the evaluation task indicates the difficulty to detect semantic\nerrors for machine-learning algorithms and humans, showing that the errors\ncannot be identified when limited to a single sentence.\n"]},
{"authors": ["Tim Hwang"], "title": ["Computational Power and the Social Impact of Artificial Intelligence"], "date": ["2018-03-23T20:39:04Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.08971v1"], "summary": ["  Machine learning is a computational process. To that end, it is inextricably\ntied to computational power - the tangible material of chips and semiconductors\nthat the algorithms of machine intelligence operate on. Most obviously,\ncomputational power and computing architectures shape the speed of training and\ninference in machine learning, and therefore influence the rate of progress in\nthe technology. But, these relationships are more nuanced than that: hardware\nshapes the methods used by researchers and engineers in the design and\ndevelopment of machine learning models. Characteristics such as the power\nconsumption of chips also define where and how machine learning can be used in\nthe real world.\n  Despite this, many analyses of the social impact of the current wave of\nprogress in AI have not substantively brought the dimension of hardware into\ntheir accounts. While a common trope in both the popular press and scholarly\nliterature is to highlight the massive increase in computational power that has\nenabled the recent breakthroughs in machine learning, the analysis frequently\ngoes no further than this observation around magnitude. This paper aims to dig\nmore deeply into the relationship between computational power and the\ndevelopment of machine learning. Specifically, it examines how changes in\ncomputing architectures, machine learning methodologies, and supply chains\nmight influence the future of AI. In doing so, it seeks to trace a set of\nspecific relationships between this underlying hardware layer and the broader\nsocial impacts and risks around AI.\n"]},
{"authors": ["Laura Giordano", "Daniele Theseider Dupr\u00e9"], "title": ["Defeasible Reasoning in SROEL: from Rational Entailment to Rational\n  Closure"], "date": ["2018-03-23T17:06:02Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.08885v1"], "summary": ["  In this work we study a rational extension $SROEL^R T$ of the low complexity\ndescription logic SROEL, which underlies the OWL EL ontology language. The\nextension involves a typicality operator T, whose semantics is based on Lehmann\nand Magidor's ranked models and allows for the definition of defeasible\ninclusions. We consider both rational entailment and minimal entailment. We\nshow that deciding instance checking under minimal entailment is in general\n$\\Pi^P_2$-hard, while, under rational entailment, instance checking can be\ncomputed in polynomial time. We develop a Datalog calculus for instance\nchecking under rational entailment and exploit it, with stratified negation,\nfor computing the rational closure of simple KBs in polynomial time.\n"]},
{"authors": ["Edward Hughes", "Joel Z. Leibo", "Matthew G. Philips", "Karl Tuyls", "Edgar A. Du\u00e9\u00f1ez-Guzm\u00e1n", "Antonio Garc\u00eda Casta\u00f1eda", "Iain Dunning", "Tina Zhu", "Kevin R. McKee", "Raphael Koster", "Heather Roff", "Thore Graepel"], "title": ["Inequity aversion resolves intertemporal social dilemmas"], "date": ["2018-03-23T17:05:38Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.08884v1"], "summary": ["  Groups of humans are often able to find ways to cooperate with one another in\ncomplex, temporally extended social dilemmas. Models based on behavioral\neconomics are only able to explain this phenomenon for unrealistic stateless\nmatrix games. Recently, multi-agent reinforcement learning has been applied to\ngeneralize social dilemma problems to temporally and spatially extended Markov\ngames. However, this has not yet generated an agent that learns to cooperate in\nsocial dilemmas as humans do. A key insight is that many, but not all, human\nindividuals have inequity averse social preferences. This promotes a particular\nresolution of the matrix game social dilemma wherein inequity-averse\nindividuals are personally pro-social and punish defectors. Here we extend this\nidea to Markov games and show that it promotes cooperation in several types of\nsequential social dilemma, via a profitable interaction with policy\nlearnability. In particular, we find that inequity aversion improves temporal\ncredit assignment for the important class of intertemporal social dilemmas.\nThese results help explain how large-scale cooperation may emerge and persist.\n"]},
{"authors": ["Chris Fields", "James F. Glazebrook"], "title": ["A mosaic of Chu spaces and Channel Theory with applications to Object\n  Identification and Mereological Complexity"], "date": ["2018-03-23T16:41:36Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.08874v1"], "summary": ["  Chu Spaces and Channel Theory are well established areas of investigation in\nthe general context of category theory. We review a range of examples and\napplications of these methods in logic and computer science, including Formal\nConcept Analysis, distributed systems and ontology development. We then employ\nthese methods to describe human object perception, beginning with the\nconstruction of uncategorized object files and proceeding through\ncategorization, individual object identification and the tracking of object\nidentity through time. We investigate the relationship between abstraction and\nmereological categorization, particularly as these affect object identity\ntracking. This we accomplish in terms of information flow that is semantically\nstructured in terms of local logics, while at the same time this framework also\nprovides an inferential mechanism towards identification and perception. We\nshow how a mereotopology naturally emerges from the representation of\nclassifications by simplicial complexes, and briefly explore the emergence of\ngeometric relations and interactions between objects.\n"]},
{"authors": ["Nicola Pellican\u00f2", "Sylvie Le H\u00e9garat-Mascle", "Emanuel Aldea"], "title": ["2CoBel : An Efficient Belief Function Extension for Two-dimensional\n  Continuous Spaces"], "date": ["2018-03-23T16:05:07Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.08857v1"], "summary": ["  This paper introduces an innovative approach for handling 2D compound\nhypotheses within the Belief Function Theory framework. We propose a\npolygon-based generic rep- resentation which relies on polygon clipping\noperators. This approach allows us to account in the computational cost for the\nprecision of the representation independently of the cardinality of the\ndiscernment frame. For the BBA combination and decision making, we propose\nefficient algorithms which rely on hashes for fast lookup, and on a topological\nordering of the focal elements within a directed acyclic graph encoding their\ninterconnections. Additionally, an implementation of the functionalities\nproposed in this paper is provided as an open source library. Experimental\nresults on a pedestrian localization problem are reported. The experiments show\nthat the solution is accurate and that it fully benefits from the scalability\nof the 2D search space granularity provided by our representation.\n"]},
{"authors": ["Tom Hanika", "Jens Zumbr\u00e4gel"], "title": ["Towards Collaborative Conceptual Exploration"], "date": ["2017-12-23T23:25:08Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1712.08858v2"], "summary": ["  In domains with high knowledge distribution a natural objective is to create\nprinciple foundations for collaborative interactive learning environments. We\npresent a first mathematical characterization of a collaborative learning\ngroup, a consortium, based on closure systems of attribute sets and the\nwell-known attribute exploration algorithm from formal concept analysis. To\nthis end, we introduce (weak) local experts for subdomains of a given knowledge\ndomain. These entities are able to refute and potentially accept a given\n(implicational) query for some closure system that is a restriction of the\nwhole domain. On this we build up a consortial expert and show first insights\nabout the ability of such an expert to answer queries. Furthermore, we depict\ntechniques on how to cope with falsely accepted implications and on combining\ncounterexamples. Using notions from combinatorial design theory we further\nexpand those insights as far as providing first results on the decidability\nproblem if a given consortium is able to explore some target domain.\nApplications in conceptual knowledge acquisition as well as in collaborative\ninteractive ontology learning are at hand.\n"]},
{"authors": ["Javier \u00c1lvez", "Paqui Lucio", "German Rigau"], "title": ["Black-box Testing of First-Order Logic Ontologies Using WordNet"], "date": ["2017-05-29T14:41:20Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1705.10217v3"], "summary": ["  Artificial Intelligence aims to provide computer programs with commonsense\nknowledge to reason about our world. This paper offers a new practical approach\ntowards automated commonsense reasoning with first-order logic (FOL)\nontologies. We propose a new black-box testing methodology of FOL SUMO-based\nontologies by exploiting WordNet and its mapping into SUMO. Our proposal\nincludes a method for the (semi-)automatic creation of a very large benchmark\nof competency questions and a procedure for its automated evaluation by using\nautomated theorem provers (ATPs). Applying different quality criteria, our\ntesting proposal enables a successful evaluation of a) the competency of\nseveral translations of SUMO into FOL and b) the performance of various\nautomated ATPs. Finally, we also provide a fine-grained and complete analysis\nof the commonsense reasoning competency of current FOL SUMO-based ontologies.\n"]},
{"authors": ["Elisa Maiettini", "Giulia Pasquale", "Lorenzo Rosasco", "Lorenzo Natale"], "title": ["Speeding-up Object Detection Training for Robotics with FALKON"], "date": ["2018-03-23T11:13:29Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.08740v1"], "summary": ["  Latest deep learning methods for object detection provided remarkable\nperformance boost, but have limits when used in robotic applications. One of\nthe most relevant issues is the long training time, which is due to the large\nsize and unbalance of the associated training sets, characterized by few\npositive and tons of negative (i.e. background) examples. Proposed approaches,\neither based on end-to-end learning by back-propagation [22], or standard\nkernel methods trained with Hard Negatives Mining on top of deep features [8],\nproved to be effective, but prohibitively slow for on-line applications. In\nthis paper we propose a novel pipeline for object detection that overcomes this\nproblem and provides comparable performance, with a 60x training speedup. Our\npipeline combines (i) the Region Proposal Network and the deep feature\nextractor from [22] to efficiently select candidate RoIs and encode them into\npowerful representations, with (ii) the recently proposed FALKON [23]\nalgorithm, a novel kernel-based method that allows to quickly train on millions\nof points. We address the size and unbalance of training data by exploiting the\nstochastic subsampling intrinsic into the method, combined with a novel, fast,\nbootstrapping approach. We assess the effectiveness of the approach in a\nstandard computer vision setting (PASCAL VOC 2007 [5]) and demonstrate its\napplicability to a real robotic scenario as represented by the iCubWorld\nTransformations [18] dataset.\n"]},
{"authors": ["Rahaf Aljundi", "Francesca Babiloni", "Mohamed Elhoseiny", "Marcus Rohrbach", "Tinne Tuytelaars"], "title": ["Memory Aware Synapses: Learning what (not) to forget"], "date": ["2017-11-27T09:48:44Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.09601v2"], "summary": ["  Humans can learn in a continuous manner. Old rarely utilized knowledge can be\noverwritten by new incoming information while important, frequently used\nknowledge is prevented from being erased. In artificial learning systems,\nlifelong learning so far has focused mainly on accumulating knowledge over\ntasks and overcoming catastrophic forgetting. In this paper, we argue that,\ngiven the limited model capacity and the unlimited new information to be\nlearned, knowledge has to be preserved or erased selectively. Inspired by\nneuroplasticity, we propose a novel approach for lifelong learning, coined\nMemory Aware Synapses (MAS). It computes the importance of the parameters of a\nneural network in an unsupervised and online manner. Given a new sample which\nis fed to the network, MAS accumulates an importance measure for each parameter\nof the network, based on how sensitive the predicted output function is to a\nchange in this parameter. When learning a new task, changes to important\nparameters can then be penalized, effectively preventing important knowledge\nrelated to previous tasks from being overwritten. Further, we show an\ninteresting connection between a local version of our method and Hebb's\nrule,which is a model for the learning process in the brain. We test our method\non a sequence of object recognition tasks and on the challenging problem of\nlearning an embedding for predicting $<$subject, predicate, object$>$ triplets.\nWe show state-of-the-art performance and, for the first time, the ability to\nadapt the importance of the parameters based on unlabeled data towards what the\nnetwork needs (not) to forget, which may vary depending on test conditions.\n"]},
{"authors": ["Irene Teinemaa", "Niek Tax", "Massimiliano de Leoni", "Marlon Dumas", "Fabrizio Maria Maggi"], "title": ["Foundations of Prescriptive Process Monitoring"], "date": ["2018-03-23T09:27:38Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.08706v1"], "summary": ["  Predictive process monitoring is concerned with the analysis of events\nproduced during the execution of a process in order to predict the future state\nof ongoing cases thereof. Existing techniques in this field are able to\npredict, at each step of a case, the likelihood that the case will end up in an\nundesired outcome. These techniques, however, do not take into account what\nprocess workers may do with the generated predictions in order to decrease the\nlikelihood of undesired outcomes. This paper proposes a framework for\nprescriptive process monitoring, which extends predictive monitoring approaches\nwith concepts of alarms, interventions, compensations, and mitigation effects.\nThe framework incorporates a parameterized cost model to assess the\ncost-benefit tradeoffs of applying prescriptive process monitoring in a given\nsetting. The paper also outlines an approach to optimize the generation of\nalarms given a dataset and a set of cost model parameters. The proposed\napproach is empirically evaluated using a range of real-life event logs.\n"]},
{"authors": ["Chunbiao Zhu", "Xing Cai", "Kan Huang", "Thomas H Li", "Ge Li"], "title": ["PDNet: Prior-model Guided Depth-enhanced Network for Salient Object\n  Detection"], "date": ["2018-03-23T02:04:47Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.08636v1"], "summary": ["  Fully convolutional neural networks (FCNs) have shown outstanding performance\nin many computer vision tasks including salient object detection. However,\nthere still remains two issues needed to be addressed in deep learning based\nsaliency detection. One is the lack of tremendous amount of annotated data to\ntrain a network. The other is the lack of robustness for extracting salient\nobjects in images containing complex scenes. In this paper, we present a new\narchitecture$ - $PDNet, a robust prior-model guided depth-enhanced network for\nRGB-D salient object detection. In contrast to existing works, in which RGB-D\nvalues of image pixels are fed directly to a network, the proposed architecture\nis composed of a master network for processing RGB values, and a sub-network\nmaking full use of depth cues and incorporate depth-based features into the\nmaster network. To overcome the limited size of the labeled RGB-D dataset for\ntraining, we employ a large conventional RGB dataset to pre-train the master\nnetwork, which proves to contribute largely to the final accuracy. Extensive\nevaluations over five benchmark datasets demonstrate that our proposed method\nperforms favorably against the state-of-the-art approaches.\n"]},
{"authors": ["Jiawei Zhang", "Limeng Cui", "Fisher B. Gouza"], "title": ["SEGEN: Sample-Ensemble Genetic Evolutional Network Model"], "date": ["2018-03-23T01:43:37Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.08631v1"], "summary": ["  Deep learning, a rebranding of deep neural network research works, has\nachieved remarkable success in recent years. With multiple hidden layers, deep\nlearning models aim at computing hierarchical features or representations of\nthe observational data. Meanwhile, due to its severe disadvantages in data\nconsumption, computational resources, parameter tuning efforts and the lack of\nresult explainability, deep learning has also suffered from lots of criticism.\nIn this paper, we will introduce a new representation learning model, namely\n\"Sample-Ensemble Genetic Evolutional Network\" (SEGEN), which can serve as an\nalternative approach to deep learning models. Instead of building one single\ndeep model, based on a set of sampled sub-instances, SEGEN adopts a\ngenetic-evolutional learning strategy to build a group of unit models\ngenerations by generations. The unit models incorporated in SEGEN can be either\ntraditional machine learning models or the recent deep learning models with a\nmuch \"smaller\" and \"shallower\" architecture. The learning results of each\ninstance at the final generation will be effectively combined from each unit\nmodel via diffusive propagation and ensemble learning strategies. From the\ncomputational perspective, SEGEN requires far less data, fewer computational\nresources and parameter tuning works, but has sound theoretic interpretability\nof the learning process and results. Extensive experiments have been done on\nreal-world network structured datasets, and the experimental results obtained\nby SEGEN have demonstrate its advantages over the other state-of-the-art\nrepresentation learning models.\n"]},
{"authors": ["Kuo-Kai Hsieh", "Li-C. Wang"], "title": ["A Concept Learning Tool Based On Calculating Version Space Cardinality"], "date": ["2018-03-23T01:11:01Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.08625v1"], "summary": ["  In this paper, we proposed VeSC-CoL (Version Space Cardinality based Concept\nLearning) to deal with concept learning on extremely imbalanced datasets,\nespecially when cross-validation is not a viable option. VeSC-CoL uses version\nspace cardinality as a measure for model quality to replace cross-validation.\nInstead of naive enumeration of the version space, Ordered Binary Decision\nDiagram and Boolean Satisfiability are used to compute the version space.\nExperiments show that VeSC-CoL can accurately learn the target concept when\ncomputational resource is allowed.\n"]},
{"authors": ["Sam Greydanus", "Anurag Koul", "Jonathan Dodge", "Alan Fern"], "title": ["Visualizing and Understanding Atari Agents"], "date": ["2017-10-31T23:03:17Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.00138v4"], "summary": ["  Deep reinforcement learning (deep RL) agents have achieved remarkable success\nin a broad range of game-playing and continuous control tasks. While these\nagents are effective at maximizing rewards, it is often unclear what strategies\nthey use to do so. In this paper, we take a step toward explaining deep RL\nagents through a case study using Atari 2600 environments. In particular, we\nfocus on using saliency maps to understand how an agent learns and executes a\npolicy. We introduce a method for generating useful saliency maps and use it to\nshow 1) what strong agents attend to, 2) whether agents are making decisions\nfor the right or wrong reasons, and 3) how agents evolve during learning. We\nalso test our method on non-expert human subjects and find that it improves\ntheir ability to reason about these agents. Overall, our results show that\nsaliency information can provide significant insight into an RL agent's\ndecisions and learning behavior.\n"]},
{"authors": ["Jennifer Ortiz", "Magdalena Balazinska", "Johannes Gehrke", "S. Sathiya Keerthi"], "title": ["Learning State Representations for Query Optimization with Deep\n  Reinforcement Learning"], "date": ["2018-03-22T22:39:32Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.08604v1"], "summary": ["  Deep reinforcement learning is quickly changing the field of artificial\nintelligence. These models are able to capture a high level understanding of\ntheir environment, enabling them to learn difficult dynamic tasks in a variety\nof domains. In the database field, query optimization remains a difficult\nproblem. Our goal in this work is to explore the capabilities of deep\nreinforcement learning in the context of query optimization. At each state, we\nbuild queries incrementally and encode properties of subqueries through a\nlearned representation. The challenge here lies in the formation of the state\ntransition function, which defines how the current subquery state combines with\nthe next query operation (action) to yield the next state. As a first step in\nthis direction, we focus the state representation problem and the formation of\nthe state transition function. We describe our approach and show preliminary\nresults. We further discuss how we can use the state representation to improve\nquery optimization using reinforcement learning.\n"]},
{"authors": ["Mikhail Khodak", "Nikunj Saunshi", "Kiran Vodrahalli"], "title": ["A Large Self-Annotated Corpus for Sarcasm"], "date": ["2017-04-19T02:01:39Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1704.05579v4"], "summary": ["  We introduce the Self-Annotated Reddit Corpus (SARC), a large corpus for\nsarcasm research and for training and evaluating systems for sarcasm detection.\nThe corpus has 1.3 million sarcastic statements -- 10 times more than any\nprevious dataset -- and many times more instances of non-sarcastic statements,\nallowing for learning in both balanced and unbalanced label regimes. Each\nstatement is furthermore self-annotated -- sarcasm is labeled by the author,\nnot an independent annotator -- and provided with user, topic, and conversation\ncontext. We evaluate the corpus for accuracy, construct benchmarks for sarcasm\ndetection, and evaluate baseline methods.\n"]},
{"authors": ["Mathias Lechner", "Ramin M. Hasani", "Radu Grosu"], "title": ["Neuronal Circuit Policies"], "date": ["2018-03-22T19:23:32Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.08554v1"], "summary": ["  We propose an effective way to create interpretable control agents, by\nre-purposing the function of a biological neural circuit model, to govern\nsimulated and real world reinforcement learning (RL) test-beds. We model the\ntap-withdrawal (TW) neural circuit of the nematode, C. elegans, a circuit\nresponsible for the worm's reflexive response to external mechanical touch\nstimulations, and learn its synaptic and neuronal parameters as a policy for\ncontrolling basic RL tasks. We also autonomously park a real rover robot on a\npre-defined trajectory, by deploying such neuronal circuit policies learned in\na simulated environment. For reconfiguration of the purpose of the TW neural\ncircuit, we adopt a search-based RL algorithm. We show that our neuronal\npolicies perform as good as deep neural network policies with the advantage of\nrealizing interpretable dynamics at the cell level.\n"]},
{"authors": ["Kevin Chen", "Christopher B. Choy", "Manolis Savva", "Angel X. Chang", "Thomas Funkhouser", "Silvio Savarese"], "title": ["Text2Shape: Generating Shapes from Natural Language by Learning Joint\n  Embeddings"], "date": ["2018-03-22T17:57:47Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.08495v1"], "summary": ["  We present a method for generating colored 3D shapes from natural language.\nTo this end, we first learn joint embeddings of freeform text descriptions and\ncolored 3D shapes. Our model combines and extends learning by association and\nmetric learning approaches to learn implicit cross-modal connections, and\nproduces a joint representation that captures the many-to-many relations\nbetween language and physical properties of 3D shapes such as color and shape.\nTo evaluate our approach, we collect a large dataset of natural language\ndescriptions for physical 3D objects in the ShapeNet dataset. With this learned\njoint embedding we demonstrate text-to-shape retrieval that outperforms\nbaseline approaches. Using our embeddings with a novel conditional Wasserstein\nGAN framework, we generate colored 3D shapes from text. Our method is the first\nto connect natural language text with realistic 3D objects exhibiting rich\nvariations in color, texture, and shape detail. See video at\nhttps://youtu.be/zraPvRdl13Q\n"]},
{"authors": ["Felix Draxler", "Kambis Veschgini", "Manfred Salmhofer", "Fred A. Hamprecht"], "title": ["Essentially No Barriers in Neural Network Energy Landscape"], "date": ["2018-03-02T15:22:10Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.00885v3"], "summary": ["  Training neural networks involves finding minima of a high-dimensional\nnon-convex loss function. Knowledge of the structure of this energy landscape\nis sparse. Relaxing from linear interpolations, we construct continuous paths\nbetween minima of recent neural network architectures on CIFAR10 and CIFAR100.\nSurprisingly, the paths are essentially flat in both the training and test\nlandscapes. This implies that neural networks have enough capacity for\nstructural changes, or that these changes are small between minima. Also, each\nminimum has at least one vanishing Hessian eigenvalue in addition to those\nresulting from trivial invariance.\n"]},
{"authors": ["Yi Zhu", "Yang Long", "Yu Guan", "Shawn Newsam", "Ling Shao"], "title": ["Towards Universal Representation for Unseen Action Recognition"], "date": ["2018-03-22T17:02:45Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.08460v1"], "summary": ["  Unseen Action Recognition (UAR) aims to recognise novel action categories\nwithout training examples. While previous methods focus on inner-dataset\nseen/unseen splits, this paper proposes a pipeline using a large-scale training\nsource to achieve a Universal Representation (UR) that can generalise to a more\nrealistic Cross-Dataset UAR (CD-UAR) scenario. We first address UAR as a\nGeneralised Multiple-Instance Learning (GMIL) problem and discover\n'building-blocks' from the large-scale ActivityNet dataset using distribution\nkernels. Essential visual and semantic components are preserved in a shared\nspace to achieve the UR that can efficiently generalise to new datasets.\nPredicted UR exemplars can be improved by a simple semantic adaptation, and\nthen an unseen action can be directly recognised using UR during the test.\nWithout further training, extensive experiments manifest significant\nimprovements over the UCF101 and HMDB51 benchmarks.\n"]},
{"authors": ["Stephan Alaniz"], "title": ["Deep Reinforcement Learning with Model Learning and Monte Carlo Tree\n  Search in Minecraft"], "date": ["2018-03-22T16:53:34Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.08456v1"], "summary": ["  Deep reinforcement learning has been successfully applied to several\nvisual-input tasks using model-free methods. In this paper, we propose a\nmodel-based approach that combines learning a DNN-based transition model with\nMonte Carlo tree search to solve a block-placing task in Minecraft. Our learned\ntransition model predicts the next frame and the rewards one step ahead given\nthe last four frames of the agent's first-person-view image and the current\naction. Then a Monte Carlo tree search algorithm uses this model to plan the\nbest sequence of actions for the agent to perform. On the proposed task in\nMinecraft, our model-based approach reaches the performance comparable to the\nDeep Q-Network's, but learns faster and, thus, is more training sample\nefficient.\n"]},
{"authors": ["Furui Liu", "Laiwan Chan"], "title": ["Causal Inference on Discrete Data via Estimating Distance Correlations"], "date": ["2018-03-21T01:39:08Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.07712v2"], "summary": ["  In this paper, we deal with the problem of inferring causal directions when\nthe data is on discrete domain. By considering the distribution of the cause\n$P(X)$ and the conditional distribution mapping cause to effect $P(Y|X)$ as\nindependent random variables, we propose to infer the causal direction via\ncomparing the distance correlation between $P(X)$ and $P(Y|X)$ with the\ndistance correlation between $P(Y)$ and $P(X|Y)$. We infer \"$X$ causes $Y$\" if\nthe dependence coefficient between $P(X)$ and $P(Y|X)$ is smaller. Experiments\nare performed to show the performance of the proposed method.\n"]},
{"authors": ["KiJung Yoon", "Renjie Liao", "Yuwen Xiong", "Lisa Zhang", "Ethan Fetaya", "Raquel Urtasun", "Richard Zemel", "Xaq Pitkow"], "title": ["Inference in Probabilistic Graphical Models by Graph Neural Networks"], "date": ["2018-03-21T01:09:07Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.07710v2"], "summary": ["  A useful computation when acting in a complex environment is to infer the\nmarginal probabilities or most probable states of task-relevant variables.\nProbabilistic graphical models can efficiently represent the structure of such\ncomplex data, but performing these inferences is generally difficult.\nMessage-passing algorithms, such as belief propagation, are a natural way to\ndisseminate evidence amongst correlated variables while exploiting the graph\nstructure, but these algorithms can struggle when the conditional dependency\ngraphs contain loops. Here we use Graph Neural Networks (GNNs) to learn a\nmessage-passing algorithm that solves these inference tasks. We first show that\nthe architecture of GNNs is well-matched to inference tasks. We then\ndemonstrate the efficacy of this inference approach by training GNNs on an\nensemble of graphical models and showing that they substantially outperform\nbelief propagation on loopy graphs. Our message-passing algorithms generalize\nout of the training set to larger graphs and graphs with different structure.\n"]},
{"authors": ["Alexandre Garcia", "Slim Essid", "Chlo\u00e9 Clavel", "Florence d'Alch\u00e9-Buc"], "title": ["Structured Output Learning with Abstention: Application to Accurate\n  Opinion Prediction"], "date": ["2018-03-22T13:48:30Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.08355v1"], "summary": ["  Motivated by Supervised Opinion Analysis, we propose a novel framework\ndevoted to Structured Output Learning with Abstention (SOLA). The structure\nprediction model is able to abstain from predicting some labels in the\nstructured output at a cost chosen by the user in a flexible way. For that\npurpose, we decompose the problem into the learning of a pair of predictors,\none devoted to structured abstention and the other, to structured output\nprediction. To compare fully labeled training data with predictions potentially\ncontaining abstentions, we define a wide class of asymmetric abstention-aware\nlosses. Learning is achieved by surrogate regression in an appropriate feature\nspace while prediction with abstention is performed by solving a new pre-image\nproblem. Thus, SOLA extends recent ideas about Structured Output Prediction via\nsurrogate problems and calibration theory and enjoys statistical guarantees on\nthe resulting excess risk. Instantiated on a hierarchical abstention-aware\nloss, SOLA is shown to be relevant for fine-grained opinion mining and gives\nstate-of-the-art results on this task. Moreover, the abstention-aware\nrepresentations can be used to competitively predict user-review ratings based\non a sentence-level opinion predictor.\n"]},
{"authors": ["Barbara Bruno", "Fulvio Mastrogiovanni", "Federico Pecora", "Antonio Sgorbissa", "Alessandro Saffiotti"], "title": ["A framework for Culture-aware Robots based on Fuzzy Logic"], "date": ["2018-03-22T13:29:52Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.08343v1"], "summary": ["  Cultural adaptation, i.e., the matching of a robot's behaviours to the\ncultural norms and preferences of its user, is a well known key requirement for\nthe success of any assistive application. However, culture-dependent robot\nbehaviours are often implicitly set by designers, thus not allowing for an easy\nand automatic adaptation to different cultures. This paper presents a method\nfor the design of culture-aware robots, that can automatically adapt their\nbehaviour to conform to a given culture. We propose a mapping from cultural\nfactors to related parameters of robot behaviours which relies on linguistic\nvariables to encode heterogeneous cultural factors in a uniform formalism, and\non fuzzy rules to encode qualitative relations among multiple variables. We\nillustrate the approach in two practical case studies.\n"]},
{"authors": ["Torsten Koller", "Felix Berkenkamp", "Matteo Turchetta", "Andreas Krause"], "title": ["Learning-based Model Predictive Control for Safe Exploration and\n  Reinforcement Learning"], "date": ["2018-03-22T09:41:45Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.08287v1"], "summary": ["  Learning-based methods have been successful in solving complex control tasks\nwithout significant prior knowledge about the system. However, these methods\ntypically do not provide any safety guarantees, which prevents their use in\nsafety-critical, real-world applications. In this paper, we present a\nlearning-based model predictive control scheme that provides provable\nhigh-probability safety guarantees. To this end, we exploit regularity\nassumptions on the dynamics in terms of a Gaussian process prior to construct\nprovably accurate confidence intervals on predicted trajectories. Unlike\nprevious approaches, we do not assume that model uncertainties are independent.\nBased on these predictions, we guarantee that trajectories satisfy safety\nconstraints. Moreover, we use a terminal set constraint to recursively\nguarantee the existence of safe control actions at every iteration. In our\nexperiments, we show that the resulting algorithm can be used to safely and\nefficiently explore and learn about dynamic systems.\n"]},
{"authors": ["Sumeet Singh", "Jonathan Lacotte", "Anirudha Majumdar", "Marco Pavone"], "title": ["Risk-sensitive Inverse Reinforcement Learning via Semi- and\n  Non-Parametric Methods"], "date": ["2017-11-28T00:07:10Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.10055v2"], "summary": ["  The literature on Inverse Reinforcement Learning (IRL) typically assumes that\nhumans take actions in order to minimize the expected value of a cost function,\ni.e., that humans are risk neutral. Yet, in practice, humans are often far from\nbeing risk neutral. To fill this gap, the objective of this paper is to devise\na framework for risk-sensitive IRL in order to explicitly account for a human's\nrisk sensitivity. To this end, we propose a flexible class of models based on\ncoherent risk measures, which allow us to capture an entire spectrum of risk\npreferences from risk-neutral to worst-case. We propose efficient\nnon-parametric algorithms based on linear programming and semi-parametric\nalgorithms based on maximum likelihood for inferring a human's underlying risk\nmeasure and cost function for a rich class of static and dynamic\ndecision-making settings. The resulting approach is demonstrated on a simulated\ndriving game with ten human participants. Our method is able to infer and mimic\na wide range of qualitatively different driving styles from highly risk-averse\nto risk-neutral in a data-efficient manner. Moreover, comparisons of the\nRisk-Sensitive (RS) IRL approach with a risk-neutral model show that the RS-IRL\nframework more accurately captures observed participant behavior both\nqualitatively and quantitatively, especially in scenarios where catastrophic\noutcomes such as collisions can occur.\n"]},
{"authors": ["Stephen Merity", "Nitish Shirish Keskar", "Richard Socher"], "title": ["An Analysis of Neural Language Modeling at Multiple Scales"], "date": ["2018-03-22T06:25:47Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.08240v1"], "summary": ["  Many of the leading approaches in language modeling introduce novel, complex\nand specialized architectures. We take existing state-of-the-art word level\nlanguage models based on LSTMs and QRNNs and extend them to both larger\nvocabularies as well as character-level granularity. When properly tuned, LSTMs\nand QRNNs achieve state-of-the-art results on character-level (Penn Treebank,\nenwik8) and word-level (WikiText-103) datasets, respectively. Results are\nobtained in only 12 hours (WikiText-103) to 2 days (enwik8) using a single\nmodern GPU.\n"]},
{"authors": ["Tianchen Zhao"], "title": ["Information Theoretic Interpretation of Deep learning"], "date": ["2018-03-21T16:03:29Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.07980v2"], "summary": ["  We interpret part of the experimental results of Shwartz-Ziv and Tishby\n[2017]. Inspired by these results, we established a conjecture of the dynamics\nof the machinary of deep neural network. This conjecture can be used to explain\nthe counterpart result by Saxe et al. [2018].\n"]},
{"authors": ["Sathya N. Ravi", "Ronak Mehta", "Vikas Singh"], "title": ["Robust Blind Deconvolution via Mirror Descent"], "date": ["2018-03-21T20:55:26Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.08137v1"], "summary": ["  We revisit the Blind Deconvolution problem with a focus on understanding its\nrobustness and convergence properties. Provable robustness to noise and other\nperturbations is receiving recent interest in vision, from obtaining immunity\nto adversarial attacks to assessing and describing failure modes of algorithms\nin mission critical applications. Further, many blind deconvolution methods\nbased on deep architectures internally make use of or optimize the basic\nformulation, so a clearer understanding of how this sub-module behaves, when it\ncan be solved, and what noise injection it can tolerate is a first order\nrequirement. We derive new insights into the theoretical underpinnings of blind\ndeconvolution. The algorithm that emerges has nice convergence guarantees and\nis provably robust in a sense we formalize in the paper. Interestingly, these\ntechnical results play out very well in practice, where on standard datasets\nour algorithm yields results competitive with or superior to the state of the\nart. Keywords: blind deconvolution, robust continuous optimization\n"]},
{"authors": ["David J. Heeger", "Wayne E. Mackey"], "title": ["ORGaNICs: A Theory of Working Memory in Brains and Machines"], "date": ["2018-03-16T16:04:09Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.06288v2"], "summary": ["  Working memory is a cognitive process that is responsible for temporarily\nholding and manipulating information. Most of the empirical neuroscience\nresearch on working memory has focused on measuring sustained activity in\nprefrontal cortex (PFC) and/or parietal cortex during simple delayed-response\ntasks, and most of the models of working memory have been based on neural\nintegrators. But working memory means much more than just holding a piece of\ninformation online. We describe a new theory of working memory, based on a\nrecurrent neural circuit that we call ORGaNICs (Oscillatory Recurrent GAted\nNeural Integrator Circuits). ORGaNICs are a variety of Long Short Term Memory\nunits (LSTMs), imported from machine learning and artificial intelligence.\nORGaNICs can be used to explain the complex dynamics of delay-period activity\nin prefrontal cortex (PFC) during a working memory task. The theory is\nanalytically tractable so that we can characterize the dynamics, and the theory\nprovides a means for reading out information from the dynamically varying\nresponses at any point in time, in spite of the complex dynamics. ORGaNICs can\nbe implemented with a biophysical (electrical circuit) model of pyramidal\ncells, combined with shunting inhibition via a thalamocortical loop. Although\nintroduced as a computational theory of working memory, ORGaNICs are also\napplicable to models of sensory processing, motor preparation and motor\ncontrol. ORGaNICs offer computational advantages compared to other varieties of\nLSTMs that are commonly used in AI applications. Consequently, ORGaNICs are a\nframework for canonical computation in brains and machines.\n"]},
{"authors": ["Kuang-Huei Lee", "Xi Chen", "Gang Hua", "Houdong Hu", "Xiaodong He"], "title": ["Stacked Cross Attention for Image-Text Matching"], "date": ["2018-03-21T17:22:27Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.08024v1"], "summary": ["  In this paper, we study the problem of image-text matching. Inferring the\nlatent semantic alignment between objects or other salient stuffs (e.g. snow,\nsky, lawn) and the corresponding words in sentences allows to capture\nfine-grained interplay between vision and language, and makes image-text\nmatching more interpretable. Prior works either simply aggregate the similarity\nof all possible pairs of regions and words without attending differentially to\nmore and less important words or regions, or use a multi-step attentional\nprocess to capture limited number of semantic alignments which is less\ninterpretable. In this paper, we present Stacked Cross Attention to discover\nthe full latent alignments using both image regions and words in sentence as\ncontext and infer the image-text similarity. Our approach achieves the\nstate-of-the-art results on the MS-COCO and Flickr30K datasets. On Flickr30K,\nour approach outperforms the current best methods by 22.1% in text retrieval\nfrom image query, and 18.2% in image retrieval with text query (based on\nRecall@1). On MS-COCO, our approach improves sentence retrieval by 17.8% and\nimage retrieval by 16.6% (based on Recall@1 using the 5K test set).\n"]},
{"authors": ["Fanlin Meng", "Xiao-Jun Zeng", "Yan Zhang", "Chris J. Dent", "Dunwei Gong"], "title": ["An Integrated Optimization + Learning Approach to Optimal Dynamic\n  Pricing for the Retailer with Multi-type Customers in Smart Grids"], "date": ["2016-12-18T18:44:49Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1612.05971v3"], "summary": ["  In this paper, we consider a realistic and meaningful scenario in the context\nof smart grids where an electricity retailer serves three different types of\ncustomers, i.e., customers with an optimal home energy management system\nembedded in their smart meters (C-HEMS), customers with only smart meters\n(C-SM), and customers without smart meters (C-NONE). The main objective of this\npaper is to support the retailer to make optimal day-ahead dynamic pricing\ndecisions in such a mixed customer pool. To this end, we propose a two-level\ndecision-making framework where the retailer acting as upper-level agent\nfirstly announces its electricity prices of next 24 hours and customers acting\nas lower-level agents subsequently schedule their energy usages accordingly.\nFor the lower level problem, we model the price responsiveness of different\ncustomers according to their unique characteristics. For the upper level\nproblem, we optimize the dynamic prices for the retailer to maximize its profit\nsubject to realistic market constraints. The above two-level model is tackled\nby genetic algorithms (GA) based distributed optimization methods while its\nfeasibility and effectiveness are confirmed via simulation results.\n"]},
{"authors": ["Felix Lindner", "Martin Mose Bentzen"], "title": ["A Formalization of Kant's Second Formulation of the Categorical\n  Imperative"], "date": ["2018-01-09T22:23:21Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.03160v2"], "summary": ["  We present a formalization and computational implementation of the second\nformulation of Kant's categorical imperative. This ethical principle requires\nan agent to never treat someone merely as a means but always also as an end.\nHere we interpret this principle in terms of how persons are causally affected\nby actions. We introduce Kantian causal agency models in which moral patients,\nactions, goals, and causal influence are represented, and we show how to\nformalize several readings of Kant's categorical imperative that correspond to\nKant's concept of strict and wide duties towards oneself and others. Stricter\nversions handle cases where an action directly causally affects oneself or\nothers, whereas the wide version maximizes the number of persons being treated\nas an end. We discuss limitations of our formalization by pointing to one of\nKant's cases that the machinery cannot handle in a satisfying way.\n"]},
{"authors": ["Sandra Wachter", "Brent Mittelstadt", "Chris Russell"], "title": ["Counterfactual Explanations without Opening the Black Box: Automated\n  Decisions and the GDPR"], "date": ["2017-11-01T15:39:23Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.00399v3"], "summary": ["  There has been much discussion of the right to explanation in the EU General\nData Protection Regulation, and its existence, merits, and disadvantages.\nImplementing a right to explanation that opens the black box of algorithmic\ndecision-making faces major legal and technical barriers. Explaining the\nfunctionality of complex algorithmic decision-making systems and their\nrationale in specific cases is a technically challenging problem. Some\nexplanations may offer little meaningful information to data subjects, raising\nquestions around their value. Explanations of automated decisions need not\nhinge on the general public understanding how algorithmic systems function.\nEven though such interpretability is of great importance and should be pursued,\nexplanations can, in principle, be offered without opening the black box.\nLooking at explanations as a means to help a data subject act rather than\nmerely understand, one could gauge the scope and content of explanations\naccording to the specific goal or action they are intended to support. From the\nperspective of individuals affected by automated decision-making, we propose\nthree aims for explanations: (1) to inform and help the individual understand\nwhy a particular decision was reached, (2) to provide grounds to contest the\ndecision if the outcome is undesired, and (3) to understand what would need to\nchange in order to receive a desired result in the future, based on the current\ndecision-making model. We assess how each of these goals finds support in the\nGDPR. We suggest data controllers should offer a particular type of\nexplanation, unconditional counterfactual explanations, to support these three\naims. These counterfactual explanations describe the smallest change to the\nworld that can be made to obtain a desirable outcome, or to arrive at the\nclosest possible world, without needing to explain the internal logic of the\nsystem.\n"]},
{"authors": ["Alexandre Bazin", "Jessie Carbonnel", "Marianne Huchard", "Giacomo Kahn"], "title": ["On-demand Relational Concept Analysis"], "date": ["2018-03-21T10:50:26Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.07847v1"], "summary": ["  Formal Concept Analysis and its associated conceptual structures have been\nused to support exploratory search through conceptual navigation. Relational\nConcept Analysis (RCA) is an extension of Formal Concept Analysis to process\nrelational datasets. RCA and its multiple interconnected structures represent\ngood candidates to support exploratory search in relational datasets, as they\nare enabling navigation within a structure as well as between the connected\nstructures. However, building the entire structures does not present an\nefficient solution to explore a small localised area of the dataset, for\ninstance to retrieve the closest alternatives to a given query. In these cases,\ngenerating only a concept and its neighbour concepts at each navigation step\nappears as a less costly alternative. In this paper, we propose an algorithm to\ncompute a concept and its neighbourhood in extended concept lattices. The\nconcepts are generated directly from the relational context family, and possess\nboth formal and relational attributes. The algorithm takes into account two RCA\nscaling operators. We illustrate it on an example.\n"]},
{"authors": ["Tommaso Soru", "Stefano Ruberto", "Diego Moussallem", "Edgard Marx", "Diego Esteves", "Axel-Cyrille Ngonga Ngomo"], "title": ["Expeditious Generation of Knowledge Graph Embeddings"], "date": ["2018-03-21T10:06:28Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.07828v1"], "summary": ["  Knowledge Graph Embedding methods aim at representing entities and relations\nin a knowledge base as points or vectors in a continuous vector space. Several\napproaches using embeddings have shown promising results on tasks such as link\nprediction, entity recommendation, question answering, and triplet\nclassification. However, only a few methods can compute low-dimensional\nembeddings of very large knowledge bases. In this paper, we propose KG2Vec, a\nnovel approach to Knowledge Graph Embedding based on the skip-gram model.\nInstead of using a predefined scoring function, we learn it relying on Long\nShort-Term Memories. We evaluated the goodness of our embeddings on knowledge\ngraph completion and show that KG2Vec is comparable to the quality of the\nscalable state-of-the-art approaches and can process large graphs by parsing\nmore than a hundred million triples in less than 6 hours on common hardware.\n"]},
{"authors": ["Christopher J. Cueva", "Xue-Xin Wei"], "title": ["Emergence of grid-like representations by training recurrent neural\n  networks to perform spatial localization"], "date": ["2018-03-21T07:09:57Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.07770v1"], "summary": ["  Decades of research on the neural code underlying spatial navigation have\nrevealed a diverse set of neural response properties. The Entorhinal Cortex\n(EC) of the mammalian brain contains a rich set of spatial correlates,\nincluding grid cells which encode space using tessellating patterns. However,\nthe mechanisms and functional significance of these spatial representations\nremain largely mysterious. As a new way to understand these neural\nrepresentations, we trained recurrent neural networks (RNNs) to perform\nnavigation tasks in 2D arenas based on velocity inputs. Surprisingly, we find\nthat grid-like spatial response patterns emerge in trained networks, along with\nunits that exhibit other spatial correlates, including border cells and\nband-like cells. All these different functional types of neurons have been\nobserved experimentally. The order of the emergence of grid-like and border\ncells is also consistent with observations from developmental studies.\nTogether, our results suggest that grid cells, border cells and others as\nobserved in EC may be a natural solution for representing space efficiently\ngiven the predominant recurrent connections in the neural circuits.\n"]},
{"authors": ["Edmond Awad", "Sydney Levine", "Max Kleiman-Weiner", "Sohan Dsouza", "Joshua B. Tenenbaum", "Azim Shariff", "Jean-Fran\u00e7ois Bonnefon", "Iyad Rahwan"], "title": ["Blaming humans in autonomous vehicle accidents: Shared responsibility\n  across levels of automation"], "date": ["2018-03-19T21:20:56Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.07170v2"], "summary": ["  When a semi-autonomous car crashes and harms someone, how are blame and\ncausal responsibility distributed across the human and machine drivers? In this\narticle, we consider cases in which a pedestrian was hit and killed by a car\nbeing operated under shared control of a primary and a secondary driver. We\nfind that when only one driver makes an error, that driver receives the blame\nand is considered causally responsible for the harm, regardless of whether that\ndriver is a machine or a human. However, when both drivers make errors in cases\nof shared control between a human and a machine, the blame and responsibility\nattributed to the machine is reduced. This finding portends a public\nunder-reaction to the malfunctioning AI components of semi-autonomous cars and\ntherefore has a direct policy implication: a bottom-up regulatory scheme (which\noperates through tort law that is adjudicated through the jury system) could\nfail to properly regulate the safety of shared-control vehicles; instead, a\ntop-down scheme (enacted through federal laws) may be called for.\n"]},
{"authors": ["Haotian Guan", "Zhilei Liu", "Longbiao Wang", "Jianwu Dang", "Ruiguo Yu"], "title": ["Speech Emotion Recognition Considering Local Dynamic Features"], "date": ["2018-03-21T03:52:26Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.07738v1"], "summary": ["  Recently, increasing attention has been directed to the study of the speech\nemotion recognition, in which global acoustic features of an utterance are\nmostly used to eliminate the content differences. However, the expression of\nspeech emotion is a dynamic process, which is reflected through dynamic\ndurations, energies, and some other prosodic information when one speaks. In\nthis paper, a novel local dynamic pitch probability distribution feature, which\nis obtained by drawing the histogram, is proposed to improve the accuracy of\nspeech emotion recognition. Compared with most of the previous works using\nglobal features, the proposed method takes advantage of the local dynamic\ninformation conveyed by the emotional speech. Several experiments on Berlin\nDatabase of Emotional Speech are conducted to verify the effectiveness of the\nproposed method. The experimental results demonstrate that the local dynamic\ninformation obtained with the proposed method is more effective for speech\nemotion recognition than the traditional global features.\n"]},
{"authors": ["Xin Wang", "Wenhan Xiong", "Hongmin Wang", "William Yang Wang"], "title": ["Look Before You Leap: Bridging Model-Free and Model-Based Reinforcement\n  Learning for Planned-Ahead Vision-and-Language Navigation"], "date": ["2018-03-21T03:21:38Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.07729v1"], "summary": ["  Existing research studies on vision and language grounding for robot\nnavigation focus on improving model-free deep reinforcement learning (DRL)\nmodels in synthetic environments. However, model-free DRL models do not\nconsider the dynamics in the real-world environments, and they often fail to\ngeneralize to new scenes. In this paper, we take a radical approach to bridge\nthe gap between synthetic studies and real-world practices---We propose a\nnovel, planned-ahead hybrid reinforcement learning model that combines\nmodel-free and model-based reinforcement learning to solve a real-world\nvision-language navigation task. Our look-ahead module tightly integrates a\nlook-ahead policy model with an environment model that predicts the next state\nand the reward. Experimental results suggest that our proposed method\nsignificantly outperforms the baselines and achieves the best on the real-world\nRoom-to-Room dataset. Moreover, our scalable method is more generalizable when\ntransferring to unseen environments, and the relative success rate is increased\nby 15.5% on the unseen test set.\n"]},
{"authors": ["Jasdeep Singh", "Vincent Ying", "Alex Nutkiewicz"], "title": ["Attention on Attention: Architectures for Visual Question Answering\n  (VQA)"], "date": ["2018-03-21T03:05:58Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.07724v1"], "summary": ["  Visual Question Answering (VQA) is an increasingly popular topic in deep\nlearning research, requiring coordination of natural language processing and\ncomputer vision modules into a single architecture. We build upon the model\nwhich placed first in the VQA Challenge by developing thirteen new attention\nmechanisms and introducing a simplified classifier. We performed 300 GPU hours\nof extensive hyperparameter and architecture searches and were able to achieve\nan evaluation score of 64.78%, outperforming the existing state-of-the-art\nsingle model's validation score of 63.15%.\n"]},
{"authors": ["Alexander Kott"], "title": ["Challenges and Characteristics of Intelligent Autonomy for Internet of\n  Battle Things in Highly Adversarial Environments"], "date": ["2018-03-20T22:15:14Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.11256v1"], "summary": ["  Numerous, artificially intelligent, networked things will populate the\nbattlefield of the future, operating in close collaboration with human\nwarfighters, and fighting as teams in highly adversarial environments. This\npaper explores the characteristics, capabilities and intelligence required of\nsuch a network of intelligent things and humans - Internet of Battle Things\n(IOBT). It will experience unique challenges that are not yet well addressed by\nthe current generation of AI and machine learning.\n"]},
{"authors": ["Ronan Riochet", "Mario Ynocente Castro", "Mathieu Bernard", "Adam Lerer", "Rob Fergus", "V\u00e9ronique Izard", "Emmanuel Dupoux"], "title": ["IntPhys: A Framework and Benchmark for Visual Intuitive Physics\n  Reasoning"], "date": ["2018-03-20T19:29:46Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.07616v1"], "summary": ["  In order to reach human performance on complex visual tasks, artificial\nsystems need to incorporate a significant amount of understanding of the world\nin terms of macroscopic objects, movements, forces, etc. Inspired by work on\nintuitive physics in infants, we propose an evaluation framework which\ndiagnoses how much a given system understands about physics by testing whether\nit can tell apart well matched videos of possible versus impossible events. The\ntest requires systems to compute a physical plausibility score over an entire\nvideo. It is free of bias and can test a range of specific physical reasoning\nskills. We then describe the first release of a benchmark dataset aimed at\nlearning intuitive physics in an unsupervised way, using videos constructed\nwith a game engine. We describe two Deep Neural Network baseline systems\ntrained with a future frame prediction objective and tested on the possible\nversus impossible discrimination task. The analysis of their results compared\nto human data gives novel insights in the potentials and limitations of next\nframe prediction architectures.\n"]},
{"authors": ["Lilian Edwards", "Michael Veale"], "title": ["Enslaving the Algorithm: From a \"Right to an Explanation\" to a \"Right to\n  Better Decisions\"?"], "date": ["2018-03-20T17:27:03Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.07540v1"], "summary": ["  As concerns about unfairness and discrimination in \"black box\" machine\nlearning systems rise, a legal \"right to an explanation\" has emerged as a\ncompellingly attractive approach for challenge and redress. We outline recent\ndebates on the limited provisions in European data protection law, and\nintroduce and analyze newer explanation rights in French administrative law and\nthe draft modernized Council of Europe Convention 108. While individual rights\ncan be useful, in privacy law they have historically unreasonably burdened the\naverage data subject. \"Meaningful information\" about algorithmic logics is more\ntechnically possible than commonly thought, but this exacerbates a new\n\"transparency fallacy\"---an illusion of remedy rather than anything\nsubstantively helpful. While rights-based approaches deserve a firm place in\nthe toolbox, other forms of governance, such as impact assessments, \"soft law,\"\njudicial review, and model repositories deserve more attention, alongside\ncatalyzing agencies acting for users to control algorithmic system design.\n"]},
{"authors": ["Martin Gebser", "Roland Kaminski", "Benjamin Kaufmann", "Torsten Schaub"], "title": ["Multi-shot ASP solving with clingo"], "date": ["2017-05-27T11:52:40Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1705.09811v2"], "summary": ["  We introduce a new flexible paradigm of grounding and solving in Answer Set\nProgramming (ASP), which we refer to as multi-shot ASP solving, and present its\nimplementation in the ASP system clingo.\n  Multi-shot ASP solving features grounding and solving processes that deal\nwith continuously changing logic programs. In doing so, they remain operative\nand accommodate changes in a seamless way. For instance, such processes allow\nfor advanced forms of search, as in optimization or theory solving, or\ninteraction with an environment, as in robotics or query-answering. Common to\nthem is that the problem specification evolves during the reasoning process,\neither because data or constraints are added, deleted, or replaced. This\nevolutionary aspect adds another dimension to ASP since it brings about state\nchanging operations. We address this issue by providing an operational\nsemantics that characterizes grounding and solving processes in multi-shot ASP\nsolving. This characterization provides a semantic account of grounder and\nsolver states along with the operations manipulating them.\n  The operative nature of multi-shot solving avoids redundancies in relaunching\ngrounder and solver programs and benefits from the solver's learning\ncapacities. clingo accomplishes this by complementing ASP's declarative input\nlanguage with control capacities. On the declarative side, a new directive\nallows for structuring logic programs into named and parameterizable\nsubprograms. The grounding and integration of these subprograms into the\nsolving process is completely modular and fully controllable from the\nprocedural side. To this end, clingo offers a new application programming\ninterface that is conveniently accessible via scripting languages.\n"]},
{"authors": ["Jerome Feldman"], "title": ["Mysteries of Visual Experience"], "date": ["2016-04-28T20:41:25Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1604.08612v4"], "summary": ["  Science is a crowning glory of the human spirit and its applications remain\nour best hope for social progress. But there are limitations to current science\nand perhaps to any science. The general mind-body problem is known to be\nintractable and currently mysterious. This is one of many deep problems that\nare universally agreed to be beyond the current purview of Science, including\nquantum phenomena, etc. But all of these famous unsolved problems are either\nremote from everyday experience (entanglement, dark matter) or are hard to even\ndefine sharply (phenomenology, consciousness, etc.).\n  In this note, we will consider some obvious computational problems in vision\nthat arise every time that we open our eyes and yet are demonstrably\nincompatible with current theories of neural computation. The focus will be on\ntwo related phenomena, known as the neural binding problem and the illusion of\na detailed stable visual world.\n"]},
{"authors": ["Ethan Knight", "Osher Lerner"], "title": ["Natural Gradient Deep Q-learning"], "date": ["2018-03-20T15:22:52Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.07482v1"], "summary": ["  This paper presents findings for training a Q-learning reinforcement learning\nagent using natural gradient techniques. We compare the original deep Q-network\n(DQN) algorithm to its natural gradient counterpart (NGDQN), measuring NGDQN\nand DQN performance on classic controls environments without target networks.\nWe find that NGDQN performs favorably relative to DQN, converging to\nsignificantly better policies faster and more frequently. These results\nindicate that natural gradient could be used for value function optimization in\nreinforcement learning to accelerate and stabilize training.\n"]},
{"authors": ["Marcello Balduccini", "Edward Griffor", "Michael Huth", "Claire Vishik", "Martin Burns", "David Wollman"], "title": ["Ontology-Based Reasoning about the Trustworthiness of Cyber-Physical\n  Systems"], "date": ["2018-03-20T13:55:07Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.07438v1"], "summary": ["  It has been challenging for the technical and regulatory communities to\nformulate requirements for trustworthiness of the cyber-physical systems (CPS)\ndue to the complexity of the issues associated with their design, deployment,\nand operations. The US National Institute of Standards and Technology (NIST),\nthrough a public working group, has released a CPS Framework that adopts a\nbroad and integrated view of CPS and positions trustworthiness among other\naspects of CPS. This paper takes the model created by the CPS Framework and its\nfurther developments one step further, by applying ontological approaches and\nreasoning techniques in order to achieve greater understanding of CPS. The\nexample analyzed in the paper demonstrates the enrichment of the original CPS\nmodel obtained through ontology and reasoning and its ability to deliver\nadditional insights to the developers and operators of CPS.\n"]},
{"authors": ["Andrew Lensen", "Bing Xue", "Mengjie Zhang"], "title": ["Generating Redundant Features with Unsupervised Multi-Tree Genetic\n  Programming"], "date": ["2018-02-02T04:19:04Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.00554v2"], "summary": ["  Recently, feature selection has become an increasingly important area of\nresearch due to the surge in high-dimensional datasets in all areas of modern\nlife. A plethora of feature selection algorithms have been proposed, but it is\ndifficult to truly analyse the quality of a given algorithm. Ideally, an\nalgorithm would be evaluated by measuring how well it removes known bad\nfeatures. Acquiring datasets with such features is inherently difficult, and so\na common technique is to add synthetic bad features to an existing dataset.\nWhile adding noisy features is an easy task, it is very difficult to\nautomatically add complex, redundant features. This work proposes one of the\nfirst approaches to generating redundant features, using a novel genetic\nprogramming approach. Initial experiments show that our proposed method can\nautomatically create difficult, redundant features which have the potential to\nbe used for creating high-quality feature selection benchmark datasets.\n"]},
{"authors": ["Yuchi Tian", "Kexin Pei", "Suman Jana", "Baishakhi Ray"], "title": ["DeepTest: Automated Testing of Deep-Neural-Network-driven Autonomous\n  Cars"], "date": ["2017-08-28T23:26:14Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1708.08559v2"], "summary": ["  Recent advances in Deep Neural Networks (DNNs) have led to the development of\nDNN-driven autonomous cars that, using sensors like camera, LiDAR, etc., can\ndrive without any human intervention. Most major manufacturers including Tesla,\nGM, Ford, BMW, and Waymo/Google are working on building and testing different\ntypes of autonomous vehicles. The lawmakers of several US states including\nCalifornia, Texas, and New York have passed new legislation to fast-track the\nprocess of testing and deployment of autonomous vehicles on their roads.\n  However, despite their spectacular progress, DNNs, just like traditional\nsoftware, often demonstrate incorrect or unexpected corner case behaviors that\ncan lead to potentially fatal collisions. Several such real-world accidents\ninvolving autonomous cars have already happened including one which resulted in\na fatality. Most existing testing techniques for DNN-driven vehicles are\nheavily dependent on the manual collection of test data under different driving\nconditions which become prohibitively expensive as the number of test\nconditions increases.\n  In this paper, we design, implement and evaluate DeepTest, a systematic\ntesting tool for automatically detecting erroneous behaviors of DNN-driven\nvehicles that can potentially lead to fatal crashes. First, our tool is\ndesigned to automatically generated test cases leveraging real-world changes in\ndriving conditions like rain, fog, lighting conditions, etc. DeepTest\nsystematically explores different parts of the DNN logic by generating test\ninputs that maximize the numbers of activated neurons. DeepTest found thousands\nof erroneous behaviors under different realistic driving conditions (e.g.,\nblurring, rain, fog, etc.) many of which lead to potentially fatal crashes in\nthree top performing DNNs in the Udacity self-driving car challenge.\n"]},
{"authors": ["Aravind Rajeswaran", "Kendall Lowrey", "Emanuel Todorov", "Sham Kakade"], "title": ["Towards Generalization and Simplicity in Continuous Control"], "date": ["2017-03-08T01:33:51Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1703.02660v2"], "summary": ["  This work shows that policies with simple linear and RBF parameterizations\ncan be trained to solve a variety of continuous control tasks, including the\nOpenAI gym benchmarks. The performance of these trained policies are\ncompetitive with state of the art results, obtained with more elaborate\nparameterizations such as fully connected neural networks. Furthermore,\nexisting training and testing scenarios are shown to be very limited and prone\nto over-fitting, thus giving rise to only trajectory-centric policies. Training\nwith a diverse initial state distribution is shown to produce more global\npolicies with better generalization. This allows for interactive control\nscenarios where the system recovers from large on-line perturbations; as shown\nin the supplementary video.\n"]},
{"authors": ["Cathy Wu", "Aravind Rajeswaran", "Yan Duan", "Vikash Kumar", "Alexandre M Bayen", "Sham Kakade", "Igor Mordatch", "Pieter Abbeel"], "title": ["Variance Reduction for Policy Gradient with Action-Dependent Factorized\n  Baselines"], "date": ["2018-03-20T03:52:04Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.07246v1"], "summary": ["  Policy gradient methods have enjoyed great success in deep reinforcement\nlearning but suffer from high variance of gradient estimates. The high variance\nproblem is particularly exasperated in problems with long horizons or\nhigh-dimensional action spaces. To mitigate this issue, we derive a bias-free\naction-dependent baseline for variance reduction which fully exploits the\nstructural form of the stochastic policy itself and does not make any\nadditional assumptions about the MDP. We demonstrate and quantify the benefit\nof the action-dependent baseline through both theoretical analysis as well as\nnumerical results, including an analysis of the suboptimality of the optimal\nstate-dependent baseline. The result is a computationally efficient policy\ngradient algorithm, which scales to high-dimensional control problems, as\ndemonstrated by a synthetic 2000-dimensional target matching task. Our\nexperimental results indicate that action-dependent baselines allow for faster\nlearning on standard reinforcement learning benchmarks and high-dimensional\nhand manipulation and synthetic tasks. Finally, we show that the general idea\nof including additional information in baselines for improved variance\nreduction can be extended to partially observed and multi-agent tasks.\n"]},
{"authors": ["Justin Gottschlich", "Armando Solar-Lezama", "Nesime Tatbul", "Michael Carbin", "Martin Rinard", "Regina Barzilay", "Saman Amarasinghe", "Joshua B Tenenbaum", "Tim Mattson"], "title": ["The Three Pillars of Machine-Based Programming"], "date": ["2018-03-20T03:51:29Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.07244v1"], "summary": ["  In this position paper, we describe our vision of the future of machine-based\nprogramming through a categorical examination of three pillars of research.\nThose pillars are: (i) intention, (ii) invention, and(iii) adaptation.\nIntention emphasizes advancements in the human-to-computer and\ncomputer-to-machine-learning interfaces. Invention emphasizes the creation or\nrefinement of algorithms or core hardware and software building blocks through\nmachine learning (ML). Adaptation emphasizes advances in the use of ML-based\nconstructs to autonomously evolve software.\n"]},
{"authors": ["Ziv Epstein", "Blakeley H. Payne", "Judy Hanwen Shen", "Abhimanyu Dubey", "Bjarke Felbo", "Matthew Groh", "Nick Obradovich", "Manuel Cebrian", "Iyad Rahwan"], "title": ["Closing the AI Knowledge Gap"], "date": ["2018-03-20T03:16:10Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.07233v1"], "summary": ["  AI researchers employ not only the scientific method, but also methodology\nfrom mathematics and engineering. However, the use of the scientific method -\nspecifically hypothesis testing - in AI is typically conducted in service of\nengineering objectives. Growing interest in topics such as fairness and\nalgorithmic bias show that engineering-focused questions only comprise a subset\nof the important questions about AI systems. This results in the AI Knowledge\nGap: the number of unique AI systems grows faster than the number of studies\nthat characterize these systems' behavior. To close this gap, we argue that the\nstudy of AI could benefit from the greater inclusion of researchers who are\nwell positioned to formulate and test hypotheses about the behavior of AI\nsystems. We examine the barriers preventing social and behavioral scientists\nfrom conducting such studies. Our diagnosis suggests that accelerating the\nscientific study of AI systems requires new incentives for academia and\nindustry, mediated by new tools and institutions. To address these needs, we\npropose a two-sided marketplace called TuringBox. On one side, AI contributors\nupload existing and novel algorithms to be studied scientifically by others. On\nthe other side, AI examiners develop and post machine intelligence tasks\ndesigned to evaluate and characterize algorithmic behavior. We discuss this\nmarket's potential to democratize the scientific study of AI behavior, and thus\nnarrow the AI Knowledge Gap.\n"]},
{"authors": ["Timur Garipov", "Pavel Izmailov", "Dmitrii Podoprikhin", "Dmitry Vetrov", "Andrew Gordon Wilson"], "title": ["Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs"], "date": ["2018-02-27T17:13:28Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.10026v3"], "summary": ["  The loss functions of deep neural networks are complex and their geometric\nproperties are not well understood. We show that the optima of these complex\nloss functions are in fact connected by simple curves, such as a polygonal\nchain with only one bend, over which training and test accuracy are nearly\nconstant. We introduce a training procedure to discover these high-accuracy\npathways between modes. Inspired by this new geometric insight, we also propose\na new ensembling method entitled Fast Geometric Ensembling (FGE). Using FGE we\ncan train high-performing ensembles in the time required to train a single\nmodel. We achieve improved performance compared to the recent state-of-the-art\nSnapshot Ensembles, on CIFAR-10 and CIFAR-100, using state-of-the-art deep\nresidual networks. On ImageNet we improve the top-1 error-rate of a pre-trained\nResNet by 0.56% by running FGE for just 5 epochs.\n"]},
{"authors": ["Marta R. Costa-juss\u00e0", "Noe Casas", "Maite Melero"], "title": ["English-Catalan Neural Machine Translation in the Biomedical Domain\n  through the cascade approach"], "date": ["2018-03-19T19:48:48Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.07139v1"], "summary": ["  This paper describes the methodology followed to build a neural machine\ntranslation system in the biomedical domain for the English-Catalan language\npair. This task can be considered a low-resourced task from the point of view\nof the domain and the language pair. To face this task, this paper reports\nexperiments on a cascade pivot strategy through Spanish for the neural machine\ntranslation using the English-Spanish SCIELO and Spanish-Catalan El Peri\\'odico\ndatabase. To test the final performance of the system, we have created a new\ntest data set for English-Catalan in the biomedical domain which is freely\navailable on request.\n"]},
{"authors": ["Niels Justesen", "Sebastian Risi"], "title": ["Automated Curriculum Learning by Rewarding Temporally Rare Events"], "date": ["2018-03-19T19:35:44Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.07131v1"], "summary": ["  Reward shaping allows reinforcement learning (RL) agents to accelerate\nlearning by receiving additional reward signals. However, these signals can be\ndifficult to design manually, especially for complex RL tasks. We propose a\nsimple and general approach that determines the reward of pre-defined events by\ntheir rarity alone. Here events become less rewarding as they are experienced\nmore often, which encourages the agent to continually explore new types of\nevents as it learns. The adaptiveness of this reward function results in a form\nof automated curriculum learning that does not have to be specified by the\nexperimenter. We demonstrate that this Rarity of Events (RoE) approach enables\nthe agent to succeed in challenging VizDoom scenarios without access to the\nextrinsic reward from the environment. Furthermore, the results demonstrate\nthat RoE learns a more versatile policy that adapts well to critical changes in\nthe environment. Rewarding events based on their rarity could help in many\nunsolved RL environments that are characterized by sparse extrinsic rewards but\na plethora of known event types.\n"]},
{"authors": ["A. Rupam Mahmood", "Dmytro Korenkevych", "Brent J. Komer", "James Bergstra"], "title": ["Setting up a Reinforcement Learning Task with a Real-World Robot"], "date": ["2018-03-19T17:59:05Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.07067v1"], "summary": ["  Reinforcement learning is a promising approach to developing hard-to-engineer\nadaptive solutions for complex and diverse robotic tasks. However, learning\nwith real-world robots is often unreliable and difficult, which resulted in\ntheir low adoption in reinforcement learning research. This difficulty is\nworsened by the lack of guidelines for setting up learning tasks with robots.\nIn this work, we develop a learning task with a UR5 robotic arm to bring to\nlight some key elements of a task setup and study their contributions to the\nchallenges with robots. We find that learning performance can be highly\nsensitive to the setup, and thus oversights and omissions in setup details can\nmake effective learning, reproducibility, and fair comparison hard. Our study\nsuggests some mitigating steps to help future experimenters avoid difficulties\nand pitfalls. We show that highly reliable and repeatable experiments can be\nperformed in our setup, indicating the possibility of reinforcement learning\nresearch extensively based on real-world robots.\n"]},
{"authors": ["Paul D\u00fctting", "Zhe Feng", "Harikrishna Narasimhan", "David C. Parkes"], "title": ["Optimal Auctions through Deep Learning"], "date": ["2017-06-12T04:03:15Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1706.03459v2"], "summary": ["  Designing an auction that maximizes expected revenue is an intricate task.\nIndeed, as of today--despite major efforts and impressive progress over the\npast few years--only the single-item case is fully understood. In this work, we\ninitiate the exploration of the use of tools from deep learning on this topic.\nThe design objective is revenue optimal, dominant-strategy incentive compatible\nauctions. We show that multi-layer neural networks can learn almost-optimal\nauctions for settings for which there are analytical solutions, such as\nMyerson's auction for a single item, Manelli and Vincent's mechanism for a\nsingle bidder with additive preferences over two items, or Yao's auction for\ntwo additive bidders with binary support distributions and multiple items, even\nif no prior knowledge about the form of optimal auctions is encoded in the\nnetwork and the only feedback during training is revenue and regret. We further\nshow how characterization results, even rather implicit ones such as Rochet's\ncharacterization through induced utilities and their gradients, can be\nleveraged to obtain more precise fits to the optimal design. We conclude by\ndemonstrating the potential of deep learning for deriving optimal auctions with\nhigh revenue for poorly understood problems.\n"]},
{"authors": ["Mengnan Du", "Ninghao Liu", "Qingquan Song", "Xia Hu"], "title": ["Towards Explanation of DNN-based Prediction with Guided Feature\n  Inversion"], "date": ["2018-03-19T17:35:26Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.00506v1"], "summary": ["  While deep neural networks (DNN) have become an effective computational tool,\nthe prediction results are often criticized by the lack of interpretability,\nwhich is essential in many real-world applications such as health informatics.\nExisting attempts based on local interpretations aim to identify relevant\nfeatures contributing the most to the prediction of DNN by monitoring the\nneighborhood of a given input. They usually simply ignore the intermediate\nlayers of the DNN that might contain rich information for interpretation. To\nbridge the gap, in this paper, we propose to investigate a guided feature\ninversion framework for taking advantage of the deep architectures towards\neffective interpretation. The proposed framework not only determines the\ncontribution of each feature in the input but also provides insights into the\ndecision-making process of DNN models. By further interacting with the neuron\nof the target category at the output layer of the DNN, we enforce the\ninterpretation result to be class-discriminative. We apply the proposed\ninterpretation model to different CNN architectures to provide explanations for\nimage data and conduct extensive experiments on ImageNet and PASCAL VOC07\ndatasets. The interpretation results demonstrate the effectiveness of our\nproposed framework in providing class-discriminative interpretation for\nDNN-based prediction.\n"]},
{"authors": ["Horia Mania", "Aurelia Guy", "Benjamin Recht"], "title": ["Simple random search provides a competitive approach to reinforcement\n  learning"], "date": ["2018-03-19T17:35:14Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.07055v1"], "summary": ["  A common belief in model-free reinforcement learning is that methods based on\nrandom search in the parameter space of policies exhibit significantly worse\nsample complexity than those that explore the space of actions. We dispel such\nbeliefs by introducing a random search method for training static, linear\npolicies for continuous control problems, matching state-of-the-art sample\nefficiency on the benchmark MuJoCo locomotion tasks. Our method also finds a\nnearly optimal controller for a challenging instance of the Linear Quadratic\nRegulator, a classical problem in control theory, when the dynamics are not\nknown. Computationally, our random search algorithm is at least 15 times more\nefficient than the fastest competing model-free methods on these benchmarks. We\ntake advantage of this computational efficiency to evaluate the performance of\nour method over hundreds of random seeds and many different hyperparameter\nconfigurations for each benchmark task. Our simulations highlight a high\nvariability in performance in these benchmark tasks, suggesting that commonly\nused estimations of sample efficiency do not adequately evaluate the\nperformance of RL algorithms.\n"]},
{"authors": ["Ari S. Morcos", "David G. T. Barrett", "Neil C. Rabinowitz", "Matthew Botvinick"], "title": ["On the importance of single directions for generalization"], "date": ["2018-03-19T14:42:19Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.06959v1"], "summary": ["  Despite their ability to memorize large datasets, deep neural networks often\nachieve good generalization performance. However, the differences between the\nlearned solutions of networks which generalize and those which do not remain\nunclear. Additionally, the tuning properties of single directions (defined as\nthe activation of a single unit or some linear combination of units in response\nto some input) have been highlighted, but their importance has not been\nevaluated. Here, we connect these lines of inquiry to demonstrate that a\nnetwork's reliance on single directions is a good predictor of its\ngeneralization performance, across networks trained on datasets with different\nfractions of corrupted labels, across ensembles of networks trained on datasets\nwith unmodified labels, across different hyperparameters, and over the course\nof training. While dropout only regularizes this quantity up to a point, batch\nnormalization implicitly discourages single direction reliance, in part by\ndecreasing the class selectivity of individual units. Finally, we find that\nclass selectivity is a poor predictor of task importance, suggesting not only\nthat networks which generalize well minimize their dependence on individual\nunits by reducing their selectivity, but also that individually selective units\nmay not be necessary for strong network performance.\n"]},
{"authors": ["Majd Latah", "Levent Toker"], "title": ["Artificial Intelligence Enabled Software Defined Networking: A\n  Comprehensive Overview"], "date": ["2018-03-19T07:05:25Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.06818v1"], "summary": ["  In recent years, the increased demand for dynamic management of network\nresources in modern computer networks in general and in today's data centers in\nparticular has resulted in a new promising architecture, in which a more\nflexible controlling functionalities can be achieved with high level of\nabstraction. In software defined networking (SDN) architecture, a central\nmanagement of the forwarding elements (i.e. switches and routers) is\naccomplished by a central unit, which can be programmed directly to perform\nfundamental networking tasks or implementing any other additional services.\nCombining both central management and network programmability, opens the door\nto employ more advanced techniques such as artificial intelligence (AI) in\norder to deal with high-demand and rapidly-changing networks. In this study, we\nprovide a detailed overview of current efforts and recent advancements to\ninclude AI in SDN-based networks.\n"]},
{"authors": ["Aaron Hertzmann"], "title": ["Can Computers Create Art?"], "date": ["2018-01-13T21:04:13Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.04486v5"], "summary": ["  This essay discusses whether computers, using Artificial Intelligence (AI),\ncould create art. The first part concerns AI-based tools for assisting with art\nmaking. The history of technologies that automated aspects of art is covered,\nincluding photography and animation. In each case, we see initial fears and\ndenial of the technology, followed by a blossoming of new creative and\nprofessional opportunities for artists. The hype and reality of Artificial\nIntelligence (AI) tools for art making is discussed, together with predictions\nabout how AI tools will be used. The second part speculates about whether it\ncould ever happen that AI systems could conceive of artwork, and be credited\nwith authorship of an artwork. It is theorized that art is something created by\nsocial agents, and so computers cannot be credited with authorship of art in\nour current understanding. A few ways that this could change are also\nhypothesized.\n"]},
{"authors": ["Kyle E. C. Booth", "Minh Do", "J. Christopher Beck", "Eleanor Rieffel", "Davide Venturelli", "Jeremy Frank"], "title": ["Comparing and Integrating Constraint Programming and Temporal Planning\n  for Quantum Circuit Compilation"], "date": ["2018-03-19T01:29:02Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.06775v1"], "summary": ["  Recently, the makespan-minimization problem of compiling a general class of\nquantum algorithms into near-term quantum processors has been introduced to the\nAI community. The research demonstrated that temporal planning is a strong\napproach for a class of quantum circuit compilation (QCC) problems. In this\npaper, we explore the use of constraint programming (CP) as an alternative and\ncomplementary approach to temporal planning. We extend previous work by\nintroducing two new problem variations that incorporate important\ncharacteristics identified by the quantum computing community. We apply\ntemporal planning and CP to the baseline and extended QCC problems as both\nstand-alone and hybrid approaches. Our hybrid methods use solutions found by\ntemporal planning to warm start CP, leveraging the ability of the former to\nfind satisficing solutions to problems with a high degree of task optionality,\nan area that CP typically struggles with. The CP model, benefiting from\ninferred bounds on planning horizon length and task counts provided by the warm\nstart, is then used to find higher quality solutions. Our empirical evaluation\nindicates that while stand-alone CP is only competitive for the smallest\nproblems, CP in our hybridization with temporal planning out-performs\nstand-alone temporal planning in the majority of problem classes.\n"]},
{"authors": ["Tuomas Haarnoja", "Vitchyr Pong", "Aurick Zhou", "Murtaza Dalal", "Pieter Abbeel", "Sergey Levine"], "title": ["Composable Deep Reinforcement Learning for Robotic Manipulation"], "date": ["2018-03-19T01:17:16Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.06773v1"], "summary": ["  Model-free deep reinforcement learning has been shown to exhibit good\nperformance in domains ranging from video games to simulated robotic\nmanipulation and locomotion. However, model-free methods are known to perform\npoorly when the interaction time with the environment is limited, as is the\ncase for most real-world robotic tasks. In this paper, we study how maximum\nentropy policies trained using soft Q-learning can be applied to real-world\nrobotic manipulation. The application of this method to real-world manipulation\nis facilitated by two important features of soft Q-learning. First, soft\nQ-learning can learn multimodal exploration strategies by learning policies\nrepresented by expressive energy-based models. Second, we show that policies\nlearned with soft Q-learning can be composed to create new policies, and that\nthe optimality of the resulting policy can be bounded in terms of the\ndivergence between the composed policies. This compositionality provides an\nespecially valuable tool for real-world manipulation, where constructing new\npolicies by composing existing skills can provide a large gain in efficiency\nover training from scratch. Our experimental evaluation demonstrates that soft\nQ-learning is substantially more sample efficient than prior model-free deep\nreinforcement learning methods, and that compositionality can be performed for\nboth simulated and real-world tasks.\n"]},
{"authors": ["Eric Liang", "Richard Liaw", "Philipp Moritz", "Robert Nishihara", "Roy Fox", "Ken Goldberg", "Joseph E. Gonzalez", "Michael I. Jordan", "Ion Stoica"], "title": ["Ray RLlib: A Framework for Distributed Reinforcement Learning"], "date": ["2017-12-26T19:43:59Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1712.09381v3"], "summary": ["  Reinforcement learning (RL) training involves the deep nesting of highly\nirregular computation patterns, each of which typically exhibits opportunities\nfor distributed computation. Current RL libraries offer parallelism at the\nlevel of the entire program, coupling all algorithm components together and\nmaking existing implementations difficult to scale, combine, and reuse. We\nargue for distributing RL components in a composable way by adapting algorithms\nfor top-down hierarchical control, thereby encapsulating parallelism and\nresource requirements within short-running compute tasks.\n  We demonstrate this principle by building RLlib on top of a task-based\nframework and show that we can implement a wide range of state-of-the art\nalgorithms on top of a small set of general abstractions. These abstractions\nare key to composability and reuse in RLlib and do not come at the cost of\nperformance---in our experiments, RLlib matches or exceeds the performance of\nhighly optimized reference implementations. Ray RLlib is available as part of\nRay at https://github.com/ray-project/ray/.\n"]},
{"authors": ["Garrett B. Goh", "Charles Siegel", "Abhinav Vishnu", "Nathan O. Hodas", "Nathan Baker"], "title": ["How Much Chemistry Does a Deep Neural Network Need to Know to Make\n  Accurate Predictions?"], "date": ["2017-10-05T23:53:59Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.02238v2"], "summary": ["  The meteoric rise of deep learning models in computer vision research, having\nachieved human-level accuracy in image recognition tasks is firm evidence of\nthe impact of representation learning of deep neural networks. In the chemistry\ndomain, recent advances have also led to the development of similar CNN models,\nsuch as Chemception, that is trained to predict chemical properties using\nimages of molecular drawings. In this work, we investigate the effects of\nsystematically removing and adding localized domain-specific information to the\nimage channels of the training data. By augmenting images with only 3\nadditional basic information, and without introducing any architectural\nchanges, we demonstrate that an augmented Chemception (AugChemception)\noutperforms the original model in the prediction of toxicity, activity, and\nsolvation free energy. Then, by altering the information content in the images,\nand examining the resulting model's performance, we also identify two distinct\nlearning patterns in predicting toxicity/activity as compared to solvation free\nenergy. These patterns suggest that Chemception is learning about its tasks in\nthe manner that is consistent with established knowledge. Thus, our work\ndemonstrates that advanced chemical knowledge is not a pre-requisite for deep\nlearning models to accurately predict complex chemical properties.\n"]},
{"authors": ["Garrett B. Goh", "Nathan O. Hodas", "Charles Siegel", "Abhinav Vishnu"], "title": ["SMILES2Vec: An Interpretable General-Purpose Deep Neural Network for\n  Predicting Chemical Properties"], "date": ["2017-12-06T04:29:28Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1712.02034v2"], "summary": ["  Chemical databases store information in text representations, and the SMILES\nformat is a universal standard used in many cheminformatics software. Encoded\nin each SMILES string is structural information that can be used to predict\ncomplex chemical properties. In this work, we develop SMILES2vec, a deep RNN\nthat automatically learns features from SMILES to predict chemical properties,\nwithout the need for additional explicit feature engineering. Using Bayesian\noptimization methods to tune the network architecture, we show that an\noptimized SMILES2vec model can serve as a general-purpose neural network for\npredicting distinct chemical properties including toxicity, activity,\nsolubility and solvation energy, while also outperforming contemporary MLP\nneural networks that uses engineered features. Furthermore, we demonstrate\nproof-of-concept of interpretability by developing an explanation mask that\nlocalizes on the most important characters used in making a prediction. When\ntested on the solubility dataset, it identified specific parts of a chemical\nthat is consistent with established first-principles knowledge with an accuracy\nof 88%. Our work demonstrates that neural networks can learn technically\naccurate chemical concept and provide state-of-the-art accuracy, making\ninterpretable deep neural networks a useful tool of relevance to the chemical\nindustry.\n"]},
{"authors": ["Garrett B. Goh", "Charles Siegel", "Abhinav Vishnu", "Nathan O. Hodas"], "title": ["Using Rule-Based Labels for Weak Supervised Learning: A ChemNet for\n  Transferable Chemical Property Prediction"], "date": ["2017-12-07T17:25:48Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1712.02734v2"], "summary": ["  With access to large datasets, deep neural networks (DNN) have achieved\nhuman-level accuracy in image and speech recognition tasks. However, in\nchemistry, data is inherently small and fragmented. In this work, we develop an\napproach of using rule-based knowledge for training ChemNet, a transferable and\ngeneralizable deep neural network for chemical property prediction that learns\nin a weak-supervised manner from large unlabeled chemical databases. When\ncoupled with transfer learning approaches to predict other smaller datasets for\nchemical properties that it was not originally trained on, we show that\nChemNet's accuracy outperforms contemporary DNN models that were trained using\nconventional supervised learning. Furthermore, we demonstrate that the ChemNet\npre-training approach is equally effective on both CNN (Chemception) and RNN\n(SMILES2vec) models, indicating that this approach is network architecture\nagnostic and is effective across multiple data modalities. Our results indicate\na pre-trained ChemNet that incorporates chemistry domain knowledge, enables the\ndevelopment of generalizable neural networks for more accurate prediction of\nnovel chemical properties.\n"]},
{"authors": ["Haris Aziz", "Jerome Lang", "Jerome Monnot"], "title": ["Computing and Testing Pareto Optimal Committees"], "date": ["2018-03-18T11:35:36Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.06644v1"], "summary": ["  Selecting a set of alternatives based on the preferences of agents is an\nimportant problem in committee selection and beyond. Among the various criteria\nput forth for the desirability of a committee, Pareto optimality is a minimal\nand important requirement. As asking agents to specify their preferences over\nexponentially many subsets of alternatives is practically infeasible, we assume\nthat each agent specifies a weak order on single alternatives, from which a\npreference relation over subsets is derived using some preference extension. We\nconsider five prominent extensions (responsive, downward lexicographic, upward\nlexicographic, best, and worst). For each of them, we consider the\ncorresponding Pareto optimality notion, and we study the complexity of\ncomputing and verifying Pareto optimal outcomes. We also consider strategic\nissues: for four of the set extensions, we present a linear-time, Pareto\noptimal and strategyproof algorithm that even works for weak preferences.\n"]},
{"authors": ["Alon Talmor", "Jonathan Berant"], "title": ["The Web as a Knowledge-base for Answering Complex Questions"], "date": ["2018-03-18T11:28:12Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.06643v1"], "summary": ["  Answering complex questions is a time-consuming activity for humans that\nrequires reasoning and integration of information. Recent work on reading\ncomprehension made headway in answering simple questions, but tackling complex\nquestions is still an ongoing research challenge. Conversely, semantic parsers\nhave been successful at handling compositionality, but only when the\ninformation resides in a target knowledge-base. In this paper, we present a\nnovel framework for answering broad and complex questions, assuming answering\nsimple questions is possible using a search engine and a reading comprehension\nmodel. We propose to decompose complex questions into a sequence of simple\nquestions, and compute the final answer from the sequence of answers. To\nillustrate the viability of our approach, we create a new dataset of complex\nquestions, ComplexWebQuestions, and present a model that decomposes questions\nand interacts with the web to compute an answer. We empirically demonstrate\nthat question decomposition improves performance from 20.8 precision@1 to 27.5\nprecision@1 on this new dataset.\n"]},
{"authors": ["Christopher Kim", "Carson Chow"], "title": ["Learning recurrent dynamics in spiking networks"], "date": ["2018-03-18T07:51:19Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.06622v1"], "summary": ["  Spiking activity of neurons engaged in learning and performing a task show\ncomplex spatiotemporal dynamics. While the output of recurrent network models\ncan learn to perform various tasks, the possible range of recurrent dynamics\nthat emerge after learning remains unknown. Here we show that modifying the\nrecurrent connectivity with a recursive least squares algorithm provides\nsufficient flexibility for synaptic and spiking rate dynamics of spiking\nnetworks to produce a wide range of spatiotemporal activity. We apply the\ntraining method to learn arbitrary firing patterns, stabilize irregular spiking\nactivity of a balanced network, and reproduce the heterogeneous spiking rate\npatterns of cortical neurons engaged in motor planning and movement. We\nidentify sufficient conditions for successful learning, characterize two types\nof learning errors, and assess the network capacity. Our findings show that\nsynaptically-coupled recurrent spiking networks possess a vast computational\ncapability that can support the diverse activity patterns in the brain.\n"]},
{"authors": ["Wenhu Chen", "Guanlin Li", "Shuo Ren", "Shujie Liu", "Zhirui Zhang", "Mu Li", "Ming Zhou"], "title": ["Generative Bridging Network in Neural Sequence Prediction"], "date": ["2017-06-28T07:44:17Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1706.09152v5"], "summary": ["  In order to alleviate data sparsity and overfitting problems in maximum\nlikelihood estimation (MLE) for sequence prediction tasks, we propose the\nGenerative Bridging Network (GBN), in which a novel bridge module is introduced\nto assist the training of the sequence prediction model (the generator\nnetwork). Unlike MLE directly maximizing the conditional likelihood, the bridge\nextends the point-wise ground truth to a bridge distribution conditioned on it,\nand the generator is optimized to minimize their KL-divergence. Three different\nGBNs, namely uniform GBN, language-model GBN and coaching GBN, are proposed to\npenalize confidence, enhance language smoothness and relieve learning burden.\nExperiments conducted on two recognized sequence prediction tasks (machine\ntranslation and abstractive text summarization) show that our proposed GBNs can\nyield significant improvements over strong baselines. Furthermore, by analyzing\nsamples drawn from different bridges, expected influences on the generator are\nverified.\n"]},
{"authors": ["Zachary Sunberg", "Mykel Kochenderfer"], "title": ["Online algorithms for POMDPs with continuous state, action, and\n  observation spaces"], "date": ["2017-09-18T22:57:30Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1709.06196v4"], "summary": ["  Online solvers for partially observable Markov decision processes have been\napplied to problems with large discrete state spaces, but continuous state,\naction, and observation spaces remain a challenge. This paper begins by\ninvestigating double progressive widening (DPW) as a solution to this\nchallenge. However, we prove that this modification alone is not sufficient\nbecause the belief representations in the search tree collapse to a single\nparticle causing the algorithm to converge to a policy that is suboptimal\nregardless of the computation time. This paper proposes and evaluates two new\nalgorithms, POMCPOW and PFT-DPW, that overcome this deficiency by using\nweighted particle filtering. Simulation results show that these modifications\nallow the algorithms to be successful where previous approaches fail.\n"]},
{"authors": ["Chen Luo", "Anshumali Shrivastava"], "title": ["Scaling-up Split-Merge MCMC with Locality Sensitive Sampling (LSS)"], "date": ["2018-02-21T07:03:32Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.07444v2"], "summary": ["  Split-Merge MCMC (Monte Carlo Markov Chain) is one of the essential and\npopular variants of MCMC for problems when an MCMC state consists of an unknown\nnumber of components. It is well known that state-of-the-art methods for\nsplit-merge MCMC do not scale well. Strategies for rapid mixing requires smart\nand informative proposals to reduce the rejection rate. However, all known\nsmart proposals involve expensive operations to suggest informative\ntransitions. As a result, the cost of each iteration is prohibitive for massive\nscale datasets. It is further known that uninformative but computationally\nefficient proposals, such as random split-merge, leads to extremely slow\nconvergence. This tradeoff between mixing time and per update cost seems hard\nto get around. In this paper, we get around this tradeoff by utilizing simple\nsimilarity information, such as cosine similarity, between the entity vectors\nto design a proposal distribution. Such information is readily available in\nalmost all applications. We show that the recent use of locality sensitive\nhashing for efficient adaptive sampling can be leveraged to obtain a\ncomputationally efficient pseudo-marginal MCMC. The new split-merge MCMC has\ncheap proposal which is also informative and needs significantly fewer\niterations than random split-merge. Overall, we obtain a sweet tradeoff between\nconvergence and per update cost. As a direct consequence, our proposal, named\nLSHSM, is around 5x faster than the state-of-the-art sampling methods on both\nsynthetic datasets and two large real datasets KDDCUP and PubMed with several\nmillions of entities and thousands of clusters.\n"]},
{"authors": ["Spyridon Samothrakis"], "title": ["Viewpoint: Artificial Intelligence and Labour"], "date": ["2018-03-17T20:08:49Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.06563v1"], "summary": ["  The welfare of modern societies has been intrinsically linked to wage labour.\nWith some exceptions, the modern human has to sell her labour-power to be able\nreproduce biologically and socially. Thus, a lingering fear of technological\nunemployment features predominately as a theme among Artificial Intelligence\nresearchers. In this short paper we show that, if past trends are anything to\ngo by, this fear is irrational. On the contrary, we argue that the main problem\nhumanity will be facing is the normalisation of extremely long working hours.\n"]},
{"authors": ["Sumit Bhatia", "Purusharth Dwivedi", "Avneet Kaur"], "title": ["Tell Me Why Is It So? Explaining Knowledge Graph Relationships by\n  Finding Descriptive Support Passages"], "date": ["2018-03-17T19:26:26Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.06555v1"], "summary": ["  We address the problem of finding descriptive explanations of facts stored in\na knowledge graph. This is important in high-risk domains such as healthcare,\nintelligence, etc. where users need additional information for decision making\nand is especially crucial for applications that rely on automatically\nconstructed knowledge bases where machine learned systems extract facts from an\ninput corpus and working of the extractors is opaque to the end-user. We follow\nan approach inspired from information retrieval and propose a simple and\nefficient, yet effective solution that takes into account passage level as well\nas document level properties to produce a ranked list of passages describing a\ngiven input relation. We test our approach using Wikidata as the knowledge base\nand Wikipedia as the source corpus and report results of user studies conducted\nto study the effectiveness of our proposed model.\n"]},
{"authors": ["Pan Wei", "John E. Ball", "Derek T. Anderson"], "title": ["Fusion of an Ensemble of Augmented Image Detectors for Robust Object\n  Detection"], "date": ["2018-03-17T19:16:26Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.06554v1"], "summary": ["  A significant challenge in object detection is accurate identification of an\nobject's position in image space, whereas one algorithm with one set of\nparameters is usually not enough, and the fusion of multiple algorithms and/or\nparameters can lead to more robust results. Herein, a new computational\nintelligence fusion approach based on the dynamic analysis of agreement among\nobject detection outputs is proposed. Furthermore, we propose an online versus\njust in training image augmentation strategy. Experiments comparing the results\nboth with and without fusion are presented. We demonstrate that the augmented\nand fused combination results are the best, with respect to higher accuracy\nrates and reduction of outlier influences. The approach is demonstrated in the\ncontext of cone, pedestrian and box detection for Advanced Driver Assistance\nSystems (ADAS) applications.\n"]},
{"authors": ["Joseph Corneli", "Ursula Martin", "Dave Murray-Rust", "Gabriela Rino Nesin", "Alison Pease"], "title": ["Argumentation theory for mathematical argument"], "date": ["2018-03-17T13:20:37Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.06500v1"], "summary": ["  To adequately model mathematical arguments the analyst must be able to\nrepresent the mathematical objects under discussion and the relationships\nbetween them, as well as inferences drawn about these objects and relationships\nas the discourse unfolds. We introduce a framework with these properties, which\nhas been applied to both mathematical dialogues and expository texts. The\nframework can recover salient elements of discourse at, and within, the\nsentence level, as well as the way mathematical content connects to form larger\nargumentative structures. We show how the framework might be used to support\ncomputational reasoning, and argue that it provides a more natural way to\nexamine the process of proving theorems than do Lamport's structured proofs.\n"]},
{"authors": ["Ondrej Kuzelka", "Yuyi Wang", "Jesse Davis", "Steven Schockaert"], "title": ["PAC-Reasoning in Relational Domains"], "date": ["2018-03-15T14:20:06Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.05768v2"], "summary": ["  We consider the problem of predicting plausible missing facts in relational\ndata, given a set of imperfect logical rules. In particular, our aim is to\nprovide bounds on the (expected) number of incorrect inferences that are made\nin this way. Since for classical inference it is in general impossible to bound\nthis number in a non-trivial way, we consider two inference relations that\nweaken, but remain close in spirit to classical inference.\n"]},
{"authors": ["Yen-Chang Hsu", "Zhaoyang Lv", "Zsolt Kira"], "title": ["Learning to cluster in order to transfer across domains and tasks"], "date": ["2017-11-28T04:59:58Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.10125v3"], "summary": ["  This paper introduces a novel method to perform transfer learning across\ndomains and tasks, formulating it as a problem of learning to cluster. The key\ninsight is that, in addition to features, we can transfer similarity\ninformation and this is sufficient to learn a similarity function and\nclustering network to perform both domain adaptation and cross-task transfer\nlearning. We begin by reducing categorical information to pairwise constraints,\nwhich only considers whether two instances belong to the same class or not.\nThis similarity is category-agnostic and can be learned from data in the source\ndomain using a similarity network. We then present two novel approaches for\nperforming transfer learning using this similarity function. First, for\nunsupervised domain adaptation, we design a new loss function to regularize\nclassification with a constrained clustering loss, hence learning a clustering\nnetwork with the transferred similarity metric generating the training inputs.\nSecond, for cross-task learning (i.e., unsupervised clustering with unseen\ncategories), we propose a framework to reconstruct and estimate the number of\nsemantic clusters, again using the clustering network. Since the similarity\nnetwork is noisy, the key is to use a robust clustering algorithm, and we show\nthat our formulation is more robust than the alternative constrained and\nunconstrained clustering approaches. Using this method, we first show state of\nthe art results for the challenging cross-task problem, applied on Omniglot and\nImageNet. Our results show that we can reconstruct semantic clusters with high\naccuracy. We then evaluate the performance of cross-domain transfer using\nimages from the Office-31 and SVHN-MNIST tasks and present top accuracy on both\ndatasets. Our approach doesn't explicitly deal with domain discrepancy. If we\ncombine with a domain adaptation loss, it shows further improvement.\n"]},
{"authors": ["Yen-Chang Hsu", "Zheng Xu", "Zsolt Kira", "Jiawei Huang"], "title": ["Learning to Cluster for Proposal-Free Instance Segmentation"], "date": ["2018-03-17T04:35:21Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.06459v1"], "summary": ["  This work proposed a novel learning objective to train a deep neural network\nto perform end-to-end image pixel clustering. We applied the approach to\ninstance segmentation, which is at the intersection of image semantic\nsegmentation and object detection. We utilize the most fundamental property of\ninstance labeling -- the pairwise relationship between pixels -- as the\nsupervision to formulate the learning objective, then apply it to train a fully\nconvolutional network (FCN) for learning to perform pixel-wise clustering. The\nresulting clusters can be used as the instance labeling directly. To support\nlabeling of an unlimited number of instance, we further formulate ideas from\ngraph coloring theory into the proposed learning objective. The evaluation on\nthe Cityscapes dataset demonstrates strong performance and therefore proof of\nthe concept. Moreover, our approach won the second place in the lane detection\ncompetition of 2017 CVPR Autonomous Driving Challenge, and was the top\nperformer without using external data.\n"]},
{"authors": ["Leopoldo Bertossi", "Georg Gottlob", "Reinhard Pichler"], "title": ["Datalog: Bag Semantics via Set Semantics"], "date": ["2018-03-17T02:00:47Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.06445v1"], "summary": ["  Duplicates in data management are common and problematic. In this work, we\npresent a translation of Datalog under bag semantics into a well-behaved\nextension of Datalog (the so-called warded Datalog+-) under set semantics. From\na theoretical point of view, this allows us to reason on bag semantics by\nmaking use of the well-established theoretical foundations of set semantics.\nFrom a practical point of view, this allows us to handle the bag semantics of\nDatalog by powerful, existing query engines for the required extension of\nDatalog. Moreover, this translation has the potential for further extensions --\nabove all to capture the bag semantics of the semantic web query language\nSPARQL.\n"]},
{"authors": ["Othar Hansson", "Andrew Mayer", "Marco Valtorta"], "title": ["A New Result on the Complexity of Heuristic Estimates for the A*\n  Algorithm"], "date": ["2018-03-16T22:57:32Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.06422v1"], "summary": ["  Relaxed models are abstract problem descriptions generated by ignoring\nconstraints that are present in base-level problems. They play an important\nrole in planning and search algorithms, as it has been shown that the length of\nan optimal solution to a relaxed model yields a monotone heuristic for an A?\nsearch of a base-level problem. Optimal solutions to a relaxed model may be\ncomputed algorithmically or by search in a further relaxed model, leading to a\nsearch that explores a hierarchy of relaxed models. In this paper, we review\nthe traditional definition of problem relaxation and show that searching in the\nabstraction hierarchy created by problem relaxation will not reduce the\ncomputational effort required to find optimal solutions to the base- level\nproblem, unless the relaxed problem found in the hierarchy can be transformed\nby some optimization (e.g., subproblem factoring). Specifically, we prove that\nany A* search of the base-level using a heuristic h2 will largely dominate an\nA* search of the base-level using a heuristic h1, if h1 must be computed by an\nA* search of the relaxed model using h2.\n"]},
{"authors": ["Hossein Hosseini", "Radha Poovendran"], "title": ["Semantic Adversarial Examples"], "date": ["2018-03-16T18:02:14Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1804.00499v1"], "summary": ["  Deep neural networks are known to be vulnerable to adversarial examples,\ni.e., images that are maliciously perturbed to fool the model. Generating\nadversarial examples has been mostly limited to finding small perturbations\nthat maximize the model prediction error. Such images, however, contain\nartificial perturbations that make them somewhat distinguishable from natural\nimages. This property is used by several defense methods to counter adversarial\nexamples by applying denoising filters or training the model to be robust to\nsmall perturbations.\n  In this paper, we introduce a new class of adversarial examples, namely\n\"Semantic Adversarial Examples,\" as images that are arbitrarily perturbed to\nfool the model, but in such a way that the modified image semantically\nrepresents the same object as the original image. We formulate the problem of\ngenerating such images as a constrained optimization problem and develop an\nadversarial transformation based on the shape bias property of human cognitive\nsystem. In our method, we generate adversarial images by first converting the\nRGB image into the HSV (Hue, Saturation and Value) color space and then\nrandomly shifting the Hue and Saturation components, while keeping the Value\ncomponent the same. Our experimental results on CIFAR10 dataset show that the\naccuracy of VGG16 network on adversarial color-shifted images is 5.7%.\n"]},
{"authors": ["Celestine D\u00fcnner", "Thomas Parnell", "Dimitrios Sarigiannis", "Nikolas Ioannou", "Haralampos Pozidis"], "title": ["Snap Machine Learning"], "date": ["2018-03-16T17:37:12Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.06333v1"], "summary": ["  We describe an efficient, scalable machine learning library that enables very\nfast training of generalized linear models. We demonstrate that our library can\nremove the training time as a bottleneck for machine learning workloads,\nopening the door to a range of new applications. For instance, it allows more\nagile development, faster and more fine-grained exploration of the\nhyper-parameter space, enables scaling to massive datasets and makes frequent\nre-training of models possible in order to adapt to events as they occur. Our\nlibrary, named Snap Machine Learning (Snap ML), combines recent advances in\nmachine learning systems and algorithms in a nested manner to reflect the\nhierarchical architecture of modern distributed systems. This allows us to\neffectively leverage available network, memory and heterogeneous compute\nresources. On a terabyte-scale publicly available dataset for\nclick-through-rate prediction in computational advertising, we demonstrate the\ntraining of a logistic regression classifier in 1.53 minutes, a 46x improvement\nover the fastest reported performance.\n"]},
{"authors": ["Xun Liang"], "title": ["Simulating the future urban growth in Xiongan New Area: a upcoming big\n  city in China"], "date": ["2018-03-16T15:32:54Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.06916v1"], "summary": ["  China made the announement to create the Xiongan New Area in Hebei in April\n1,2017. Thus a new magacity about 110km south west of Beijing will emerge.\nXiongan New Area is of great practial significant and historical significant\nfor transferring Beijing's non-capital function. Simulating the urban dynamics\nin Xiongan New Area can help planners to decide where to build the new urban\nand further manage the future urban growth. However, only a little research\nfocus on the future urban development in Xiongan New Area. In addition,\nprevious models are unable to simulate the urban dynamics in Xiongan New Area.\nBecause there are no original high density urbna for these models to learn the\ntransition rules.In this study, we proposed a C-FLUS model to solve such\nproblems. This framework was implemented by coupling a modified Cellular\nautomata(CA). An elaborately designed random planted seeds machanism based on\nlocal maximums is addressed in the CA model to better simulate the occurrence\nof the new urban. Through an analysis of the current driving forces, the C-FLUS\ncan detect the potential start zone and simulate the urban development under\ndifferent scenarios in Xiongan New Area. Our study shows that the new urban is\nmost likely to occur in northwest of Xiongxian, and it will rapidly extend to\nRongcheng and Anxin until almost cover the northern part of Xiongan New Area.\nMoreover, the method can help planners to evaluate the impact of urban\nexpansion in Xiongan New Area.\n"]},
{"authors": ["Michael Veale", "Reuben Binns", "Max Van Kleek"], "title": ["Some HCI Priorities for GDPR-Compliant Machine Learning"], "date": ["2018-03-16T11:40:33Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.06174v1"], "summary": ["  In this short paper, we consider the roles of HCI in enabling the better\ngovernance of consequential machine learning systems using the rights and\nobligations laid out in the recent 2016 EU General Data Protection Regulation\n(GDPR)---a law which involves heavy interaction with people and systems.\nFocussing on those areas that relate to algorithmic systems in society, we\npropose roles for HCI in legal contexts in relation to fairness, bias and\ndiscrimination; data protection by design; data protection impact assessments;\ntransparency and explanations; the mitigation and understanding of automation\nbias; and the communication of envisaged consequences of processing.\n"]},
{"authors": ["Roman Kalkreuth"], "title": ["Towards Advanced Phenotypic Mutations in Cartesian Genetic Programming"], "date": ["2018-03-16T09:43:47Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.06127v1"], "summary": ["  Cartesian Genetic Programming is often used with a point mutation as the sole\ngenetic operator. In this paper, we propose two phenotypic mutation techniques\nand take a step towards advanced phenotypic mutations in Cartesian Genetic\nProgramming. The functionality of the proposed mutations is inspired by\nbiological evolution which mutates DNA sequences by inserting and deleting\nnucleotides. Experiments with symbolic regression and boolean functions\nproblems show a better search performance when the proposed mutations are in\nuse. The results of our experiments indicate that the use of phenotypic\nmutations could be beneficial for the use of Cartesian Genetic Programming.\n"]},
{"authors": ["Richard Kenway"], "title": ["Vulnerability of Deep Learning"], "date": ["2018-03-16T08:52:04Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.06111v1"], "summary": ["  The Renormalisation Group (RG) provides a framework in which it is possible\nto assess whether a deep-learning network is sensitive to small changes in the\ninput data and hence prone to error, or susceptible to adversarial attack.\nDistinct classification outputs are associated with different RG fixed points\nand sensitivity to small changes in the input data is due to the presence of\nrelevant operators at a fixed point. A numerical scheme, based on Monte Carlo\nRG ideas, is proposed for identifying the existence of relevant operators and\nthe corresponding directions of greatest sensitivity in the input data. Thus, a\ntrained deep-learning network may be tested for its robustness and, if it is\nvulnerable to attack, dangerous perturbations of the input data identified.\n"]},
{"authors": ["Guangyu Robert Yang", "Igor Ganichev", "Xiao-Jing Wang", "Jonathon Shlens", "David Sussillo"], "title": ["A dataset and architecture for visual reasoning with a working memory"], "date": ["2018-03-16T06:53:45Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.06092v1"], "summary": ["  A vexing problem in artificial intelligence is reasoning about events that\noccur in complex, changing visual stimuli such as in video analysis or game\nplay. Inspired by a rich tradition of visual reasoning and memory in cognitive\npsychology and neuroscience, we developed an artificial, configurable visual\nquestion and answer dataset (COG) to parallel experiments in humans and\nanimals. COG is much simpler than the general problem of video analysis, yet it\naddresses many of the problems relating to visual and logical reasoning and\nmemory -- problems that remain challenging for modern deep learning\narchitectures. We additionally propose a deep learning architecture that\nperforms competitively on other diagnostic VQA datasets (i.e. CLEVR) as well as\neasy settings of the COG dataset. However, several settings of COG result in\ndatasets that are progressively more challenging to learn. After training, the\nnetwork can zero-shot generalize to many new tasks. Preliminary analyses of the\nnetwork architectures trained on COG demonstrate that the network accomplishes\nthe task in a manner interpretable to humans.\n"]},
{"authors": ["Srayanta Mukherjee", "Devashish Shankar", "Atin Ghosh", "Nilam Tathawadekar", "Pramod Kompalli", "Sunita Sarawagi", "Krishnendu Chaudhury"], "title": ["ARMDN: Associative and Recurrent Mixture Density Networks for eRetail\n  Demand Forecasting"], "date": ["2018-03-10T12:45:11Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.03800v2"], "summary": ["  Accurate demand forecasts can help on-line retail organizations better plan\ntheir supply-chain processes. The challenge, however, is the large number of\nassociative factors that result in large, non-stationary shifts in demand,\nwhich traditional time series and regression approaches fail to model. In this\npaper, we propose a Neural Network architecture called AR-MDN, that\nsimultaneously models associative factors, time-series trends and the variance\nin the demand. We first identify several causal features and use a combination\nof feature embeddings, MLP and LSTM to represent them. We then model the output\ndensity as a learned mixture of Gaussian distributions. The AR-MDN can be\ntrained end-to-end without the need for additional supervision. We experiment\non a dataset of an year's worth of data over tens-of-thousands of products from\nFlipkart. The proposed architecture yields a significant improvement in\nforecasting accuracy when compared with existing alternatives.\n"]},
{"authors": ["Muhammad Shoaib Jaliawala", "Rizwan Ahmed Khan"], "title": ["Can Autism be Catered with Artificial Intelligence-Assisted Intervention\n  Technology? A Literature Review"], "date": ["2018-03-14T09:56:39Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.05181v2"], "summary": ["  This article presents an extensive literature review of technology based\nintervention methodologies for individuals facing Autism Spectrum Disorder\n(ASD). Reviewed methodologies include: contemporary Computer Aided Systems\n(CAS), Computer Vision Assisted Technologies (CVAT) and Virtual Reality (VR) or\nArtificial Intelligence-Assisted interventions. The research over the past\ndecade has provided enough demonstrations that individuals of ASD have a strong\ninterest in technology based interventions and can connect with them for longer\ndurations without facing any trouble(s). Theses technology based interventions\nare useful for individuals facing autism in clinical settings as well as at\nhome and classrooms.\n  Despite showing great promise, research in developing an advanced technology\nbased intervention that is clinically quantitative for ASD is minimal.\nMoreover, the clinicians are generally not convinced about the potential of the\ntechnology based interventions due to non-empirical nature of published\nresults. A major reason behind this non-acceptability is a vast majority of\nstudies on distinct intervention methodologies do not follow any specific\nstandard or research design. Consequently, the data produced by these studies\nis minimally appealing to the clinical community.\n  This research domain has a vast social impact as per official statistics\ngiven by the Autism Society of America, autism is the fastest growing\ndevelopmental disability in the United States (US). The estimated annual cost\nin the US for diagnosis and treatment for ASD is 236-262 Billion US Dollars.\nThe cost of up-bringing an ASD individual is estimated to be 1.4 million USD\nwhile statistics show 1% of the worlds' total population is suffering from ASD.\n"]},
{"authors": ["Chao-Chun Liang", "Yu-Shiang Wong", "Yi-Chung Lin", "Keh-Yih Su"], "title": ["A Meaning-based Statistical English Math Word Problem Solver"], "date": ["2018-03-16T03:07:06Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.06064v1"], "summary": ["  We introduce MeSys, a meaning-based approach to solving English math word\nproblems (MWPs) via understanding and reasoning in this paper. It first\nanalyzes the text, transforms both body and question parts into their\ncorresponding logic forms, and then performs inference on them. The associated\ncontext of each quantity is represented with proposed role-tags (e.g., nsubj,\nverb, etc.), which provides the flexibility for annotating an extracted math\nquantity with its associated context information (i.e., the physical meaning of\nthis quantity). Statistical models are proposed to select the operator and\noperands. A noisy dataset is designed to assess if a solver solves MWPs mainly\nvia understanding or pattern matching. Experimental results show that our\napproach outperforms existing systems on both benchmark datasets and the noisy\ndataset, which demonstrates that the proposed approach more understands the\nmeaning of each quantity in the text.\n"]},
{"authors": ["T\u00falio A. M. Toffolo", "Thibaut Vidal", "Tony Wauters"], "title": ["Heuristics for vehicle routing problems: Sequence or set optimization?"], "date": ["2018-03-16T03:00:18Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.06062v1"], "summary": ["  We investigate a structural decomposition for the capacitated vehicle routing\nproblem (CVRP) based on vehicle-to-customer \"assignment\" and visits\n\"sequencing\" decision variables. We show that an heuristic search focused on\nassignment decisions with a systematic optimal choice of sequences (using\nConcorde TSP solver) during each move evaluation is promising but requires a\nprohibitive computational effort. We therefore introduce an intermediate search\nspace, based on the dynamic programming procedure of Balas & Simonetti, which\nfinds a good compromise between intensification and computational efficiency. A\nvariety of speed-up techniques are proposed for a fast exploration:\nneighborhood reductions, dynamic move filters, memory structures, and\nconcatenation techniques. Finally, a tunneling strategy is designed to reshape\nthe search space as the algorithm progresses.\n  The combination of these techniques within a classical local search, as well\nas in the unified hybrid genetic search (UHGS) leads to significant\nimprovements of solution accuracy. New best solutions are found for\nsurprisingly small instances with as few as 256 customers. These solutions had\nnot been attained up to now with classic neighborhoods. Overall, this research\npermits to better evaluate the respective impact of sequence and assignment\noptimization, proposes new ways of combining the optimization of these two\ndecision sets, and opens promising research perspectives for the CVRP and its\nvariants.\n"]},
{"authors": ["Tom Zahavy", "Alex Dikopoltsev", "Oren Cohen", "Shie Mannor", "Mordechai Segev"], "title": ["Deep Learning Reconstruction of Ultra-Short Pulses"], "date": ["2018-03-15T22:37:31Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.06024v1"], "summary": ["  Ultra-short laser pulses with femtosecond to attosecond pulse duration are\nthe shortest systematic events humans can create. Characterization (amplitude\nand phase) of these pulses is a key ingredient in ultrafast science, e.g.,\nexploring chemical reactions and electronic phase transitions. Here, we propose\nand demonstrate, numerically and experimentally, the first deep neural network\ntechnique to reconstruct ultra-short optical pulses. We anticipate that this\napproach will extend the range of ultrashort laser pulses that can be\ncharacterized, e.g., enabling to diagnose very weak attosecond pulses.\n"]},
{"authors": ["Didier Barradas-Bautista", "Mat\u00edas Alvarado"], "title": ["Unraveling Go gaming nature by Ising Hamiltonian and common fate graphs:\n  tactics and statistics"], "date": ["2018-03-15T20:08:01Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.05983v1"], "summary": ["  Go gaming is a struggle between adversaries, black and white simple stones,\nand aim to control the most Go board territory for success. Rules are simple\nbut Go game fighting is highly intricate. Stones placement and interaction on\nboard is random-appearance, likewise interaction phenomena among basic elements\nin physics thermodynamics, chemistry, biology, or social issues. We model the\nGo game dynamic employing an Ising model energy function, whose interaction\ncoefficients reflect the application of rules and tactics to build long-term\nstrategies. At any step of the game, the energy function of the model assesses\nthe control and strength of a player over the board. A close fit between\npredictions of the model with actual game's scores is obtained. AlphaGo\ncomputer is the current top Go player, but its behavior does not wholly reveal\nthe Go gaming nature. The Ising function allows for precisely model the\nstochastic evolutions of Go gaming patterns, so, to advance the understanding\non Go own-dynamic -beyond the player`s abilities. The analysis of the frequency\nand combination of tactics shows the formation of patterns in the groups of\nstones during a game, regarding the turn of each player, or if human or\ncomputer adversaries are confronted.\n"]},
{"authors": ["Weihao Yuan", "Johannes A. Stork", "Danica Kragic", "Michael Y. Wang", "Kaiyu Hang"], "title": ["Rearrangement with Nonprehensile Manipulation Using Deep Reinforcement\n  Learning"], "date": ["2018-03-15T14:00:24Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.05752v1"], "summary": ["  Rearranging objects on a tabletop surface by means of nonprehensile\nmanipulation is a task which requires skillful interaction with the physical\nworld. Usually, this is achieved by precisely modeling physical properties of\nthe objects, robot, and the environment for explicit planning. In contrast, as\nexplicitly modeling the physical environment is not always feasible and\ninvolves various uncertainties, we learn a nonprehensile rearrangement strategy\nwith deep reinforcement learning based on only visual feedback. For this, we\nmodel the task with rewards and train a deep Q-network. Our potential\nfield-based heuristic exploration strategy reduces the amount of collisions\nwhich lead to suboptimal outcomes and we actively balance the training set to\navoid bias towards poor examples. Our training process leads to quicker\nlearning and better performance on the task as compared to uniform exploration\nand standard experience replay. We demonstrate empirical evidence from\nsimulation that our method leads to a success rate of 85%, show that our system\ncan cope with sudden changes of the environment, and compare our performance\nwith human level performance.\n"]},
{"authors": ["Kai Yi", "Zhiqiang Jian", "Shitao Chen", "Yu Chen", "Nanning Zheng"], "title": ["Knowledge-based Recurrent Attentive Neural Network for Traffic Sign\n  Detection"], "date": ["2018-03-13T12:45:55Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.05263v2"], "summary": ["  Accurate Traffic Sign Detection (TSD) can help drivers make better decision\naccording to the traffic regulations. TSD, regarded as a typical small object\ndetection problem in some way, is fundamental in the field of self-driving and\nadvanced driver assistance systems. However, small object detection is still an\nopen question. In this paper, we proposed a human brain inspired network to\nhandle this problem. Attention mechanism is an essential function of our brain,\nwe used a novel recurrent attentive neural network to improve the detection\naccuracy in a fine-grained manner. Further, as we human can combine domain\nspecific knowledge and intuitive knowledge to solve tricky tasks, we proposed\nan assumption that the location of the traffic signs obeys the reverse gaussian\ndistribution, which means the location is around the central bias of every\npicture. Experimental result shows that our methods achieved better performance\nthan several popular methods used in object detection.\n"]},
{"authors": ["Rianne van den Berg", "Leonard Hasenclever", "Jakub M. Tomczak", "Max Welling"], "title": ["Sylvester Normalizing Flows for Variational Inference"], "date": ["2018-03-15T09:15:14Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.05649v1"], "summary": ["  Variational inference relies on flexible approximate posterior distributions.\nNormalizing flows provide a general recipe to construct flexible variational\nposteriors. We introduce Sylvester normalizing flows, which can be seen as a\ngeneralization of planar flows. Sylvester normalizing flows remove the\nwell-known single-unit bottleneck from planar flows, making a single\ntransformation much more flexible. We compare the performance of Sylvester\nnormalizing flows against planar flows and inverse autoregressive flows and\ndemonstrate that they compare favorably on several datasets.\n"]},
{"authors": ["Sidi Lu", "Yaoming Zhu", "Weinan Zhang", "Jun Wang", "Yong Yu"], "title": ["Neural Text Generation: Past, Present and Beyond"], "date": ["2018-03-15T07:54:30Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.07133v1"], "summary": ["  This paper presents a systematic survey on recent development of neural text\ngeneration models. Specifically, we start from recurrent neural network\nlanguage models with the traditional maximum likelihood estimation training\nscheme and point out its shortcoming for text generation. We thus introduce the\nrecently proposed methods for text generation based on reinforcement learning,\nre-parametrization tricks and generative adversarial nets (GAN) techniques. We\ncompare different properties of these models and the corresponding techniques\nto handle their common problems such as gradient vanishing and generation\ndiversity. Finally, we conduct a benchmarking experiment with different types\nof neural text generation models on two well-known datasets and discuss the\nempirical results along with the aforementioned model properties.\n"]},
{"authors": ["Shai Shalev-Shwartz", "Shaked Shammah", "Amnon Shashua"], "title": ["On a Formal Model of Safe and Scalable Self-driving Cars"], "date": ["2017-08-21T18:22:19Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1708.06374v5"], "summary": ["  In recent years, car makers and tech companies have been racing towards self\ndriving cars. It seems that the main parameter in this race is who will have\nthe first car on the road. The goal of this paper is to add to the equation two\nadditional crucial parameters. The first is standardization of safety assurance\n--- what are the minimal requirements that every self-driving car must satisfy,\nand how can we verify these requirements. The second parameter is scalability\n--- engineering solutions that lead to unleashed costs will not scale to\nmillions of cars, which will push interest in this field into a niche academic\ncorner, and drive the entire field into a \"winter of autonomous driving\". In\nthe first part of the paper we propose a white-box, interpretable, mathematical\nmodel for safety assurance, which we call Responsibility-Sensitive Safety\n(RSS). In the second part we describe a design of a system that adheres to our\nsafety assurance requirements and is scalable to millions of cars.\n"]},
{"authors": ["Danfei Xu", "Suraj Nair", "Yuke Zhu", "Julian Gao", "Animesh Garg", "Li Fei-Fei", "Silvio Savarese"], "title": ["Neural Task Programming: Learning to Generalize Across Hierarchical\n  Tasks"], "date": ["2017-10-04T21:31:49Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.01813v2"], "summary": ["  In this work, we propose a novel robot learning framework called Neural Task\nProgramming (NTP), which bridges the idea of few-shot learning from\ndemonstration and neural program induction. NTP takes as input a task\nspecification (e.g., video demonstration of a task) and recursively decomposes\nit into finer sub-task specifications. These specifications are fed to a\nhierarchical neural program, where bottom-level programs are callable\nsubroutines that interact with the environment. We validate our method in three\nrobot manipulation tasks. NTP achieves strong generalization across sequential\ntasks that exhibit hierarchal and compositional structures. The experimental\nresults show that NTP learns to generalize well to- wards unseen tasks with\nincreasing lengths, variable topologies, and changing objectives.\n"]},
{"authors": ["Luchen Liu", "Jianhao Shen", "Ming Zhang", "Zichang Wang", "Jian Tang"], "title": ["Learning the Joint Representation of Heterogeneous Temporal Events for\n  Clinical Endpoint Prediction"], "date": ["2018-03-13T14:32:38Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.04837v2"], "summary": ["  The availability of a large amount of electronic health records (EHR)\nprovides huge opportunities to improve health care service by mining these\ndata. One important application is clinical endpoint prediction, which aims to\npredict whether a disease, a symptom or an abnormal lab test will happen in the\nfuture according to patients' history records. This paper develops deep\nlearning techniques for clinical endpoint prediction, which are effective in\nmany practical applications. However, the problem is very challenging since\npatients' history records contain multiple heterogeneous temporal events such\nas lab tests, diagnosis, and drug administrations. The visiting patterns of\ndifferent types of events vary significantly, and there exist complex nonlinear\nrelationships between different events. In this paper, we propose a novel model\nfor learning the joint representation of heterogeneous temporal events. The\nmodel adds a new gate to control the visiting rates of different events which\neffectively models the irregular patterns of different events and their\nnonlinear correlations. Experiment results with real-world clinical data on the\ntasks of predicting death and abnormal lab tests prove the effectiveness of our\nproposed approach over competitive baselines.\n"]},
{"authors": ["Trapit Bansal", "Jakub Pachocki", "Szymon Sidor", "Ilya Sutskever", "Igor Mordatch"], "title": ["Emergent Complexity via Multi-Agent Competition"], "date": ["2017-10-10T17:59:41Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.03748v3"], "summary": ["  Reinforcement learning algorithms can train agents that solve problems in\ncomplex, interesting environments. Normally, the complexity of the trained\nagent is closely related to the complexity of the environment. This suggests\nthat a highly capable agent requires a complex environment for training. In\nthis paper, we point out that a competitive multi-agent environment trained\nwith self-play can produce behaviors that are far more complex than the\nenvironment itself. We also point out that such environments come with a\nnatural curriculum, because for any skill level, an environment full of agents\nof this level will have the right level of difficulty. This work introduces\nseveral competitive multi-agent environments where agents compete in a 3D world\nwith simulated physics. The trained agents learn a wide variety of complex and\ninteresting skills, even though the environment themselves are relatively\nsimple. The skills include behaviors such as running, blocking, ducking,\ntackling, fooling opponents, kicking, and defending using both arms and legs. A\nhighlight of the learned behaviors can be found here: https://goo.gl/eR7fbX\n"]},
{"authors": ["Jiaming Song", "Shengjia Zhao", "Stefano Ermon"], "title": ["A-NICE-MC: Adversarial Training for MCMC"], "date": ["2017-06-23T04:19:04Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1706.07561v3"], "summary": ["  Existing Markov Chain Monte Carlo (MCMC) methods are either based on\ngeneral-purpose and domain-agnostic schemes which can lead to slow convergence,\nor hand-crafting of problem-specific proposals by an expert. We propose\nA-NICE-MC, a novel method to train flexible parametric Markov chain kernels to\nproduce samples with desired properties. First, we propose an efficient\nlikelihood-free adversarial training method to train a Markov chain and mimic a\ngiven data distribution. Then, we leverage flexible volume preserving flows to\nobtain parametric kernels for MCMC. Using a bootstrap approach, we show how to\ntrain efficient Markov chains to sample from a prescribed posterior\ndistribution by iteratively improving the quality of both the model and the\nsamples. A-NICE-MC provides the first framework to automatically design\nefficient domain-specific MCMC proposals. Empirical results demonstrate that\nA-NICE-MC combines the strong guarantees of MCMC with the expressiveness of\ndeep neural networks, and is able to significantly outperform competing methods\nsuch as Hamiltonian Monte Carlo.\n"]},
{"authors": ["Carl-Johan Hoel", "Krister Wolff", "Leo Laine"], "title": ["Automated Speed and Lane Change Decision Making using Deep Reinforcement\n  Learning"], "date": ["2018-03-14T18:25:44Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.10056v1"], "summary": ["  This paper introduces a method, based on deep reinforcement learning, for\nautomatically generating a general purpose decision making function. A Deep\nQ-Network agent was trained in a simulated environment to handle speed and lane\nchange decisions for a truck-trailer combination. In a highway driving case, it\nis shown that the method produced an agent that matched or surpassed the\nperformance of a commonly used reference model. To demonstrate the generality\nof the method, the exact same algorithm was also tested by training it for an\novertaking case on a road with oncoming traffic. Furthermore, a novel way of\napplying a convolutional neural network to high level input that represents\ninterchangeable objects is also introduced.\n"]},
{"authors": ["Peter Clark", "Isaac Cowhey", "Oren Etzioni", "Tushar Khot", "Ashish Sabharwal", "Carissa Schoenick", "Oyvind Tafjord"], "title": ["Think you have Solved Question Answering? Try ARC, the AI2 Reasoning\n  Challenge"], "date": ["2018-03-14T18:04:21Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.05457v1"], "summary": ["  We present a new question set, text corpus, and baselines assembled to\nencourage AI research in advanced question answering. Together, these\nconstitute the AI2 Reasoning Challenge (ARC), which requires far more powerful\nknowledge and reasoning than previous challenges such as SQuAD or SNLI. The ARC\nquestion set is partitioned into a Challenge Set and an Easy Set, where the\nChallenge Set contains only questions answered incorrectly by both a\nretrieval-based algorithm and a word co-occurence algorithm. The dataset\ncontains only natural, grade-school science questions (authored for human\ntests), and is the largest public-domain set of this kind (7,787 questions). We\ntest several baselines on the Challenge Set, including leading neural models\nfrom the SQuAD and SNLI tasks, and find that none are able to significantly\noutperform a random baseline, reflecting the difficult nature of this task. We\nare also releasing the ARC Corpus, a corpus of 14M science sentences relevant\nto the task, and implementations of the three neural baseline models tested.\nCan your model perform better? We pose ARC as a challenge to the community.\n"]},
{"authors": ["Pavel Izmailov", "Dmitrii Podoprikhin", "Timur Garipov", "Dmitry Vetrov", "Andrew Gordon Wilson"], "title": ["Averaging Weights Leads to Wider Optima and Better Generalization"], "date": ["2018-03-14T17:09:27Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.05407v1"], "summary": ["  Deep neural networks are typically trained by optimizing a loss function with\nan SGD variant, in conjunction with a decaying learning rate, until\nconvergence. We show that simple averaging of multiple points along the\ntrajectory of SGD, with a cyclical or constant learning rate, leads to better\ngeneralization than conventional training. We also show that this Stochastic\nWeight Averaging (SWA) procedure finds much broader optima than SGD, and\napproximates the recent Fast Geometric Ensembling (FGE) approach with a single\nmodel. Using SWA we achieve notable improvement in test accuracy over\nconventional SGD training on a range of state-of-the-art residual networks,\nPyramidNets, DenseNets, and Shake-Shake networks on CIFAR-10, CIFAR-100, and\nImageNet. In short, SWA is extremely easy to implement, improves\ngeneralization, and has almost no computational overhead.\n"]},
{"authors": ["F. Albarr\u00e1n-Arriagada", "J. C. Retamal", "E. Solano", "L. Lamata"], "title": ["Measurement-based adaptation protocol with quantum reinforcement\n  learning"], "date": ["2018-03-14T15:06:11Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.05340v1"], "summary": ["  Machine learning employs dynamical algorithms that mimic the human capacity\nto learn, where the reinforcement learning ones are among the most similar to\nhumans in this respect. On the other hand, adaptability is an essential aspect\nto perform any task efficiently in a changing environment, and it is\nfundamental for many purposes, such as natural selection. Here, we propose an\nalgorithm based on successive measurements to adapt one quantum state to a\nreference unknown state, in the sense of achieving maximum overlap. The\nprotocol naturally provides many identical copies of the reference state, such\nthat in each measurement iteration more information about it is obtained. In\nour protocol, we consider a system composed of three parts, the \"environment\"\nsystem, which provides the reference state copies; the register, which is an\nauxiliary subsystem that interacts with the environment to acquire information\nfrom it; and the agent, which corresponds to the quantum state that is adapted\nby digital feedback with input corresponding to the outcome of the measurements\non the register. With this proposal we can achieve an average fidelity between\nthe environment and the agent of more than $90\\% $ with less than $30$\niterations of the protocol. In addition, we extend the formalism to $ d\n$-dimensional states, reaching an average fidelity of around $80\\% $ in less\nthan $400$ iterations for $d=$ 11, for a variety of genuinely quantum as well\nas semiclassical states. This work paves the way for the development of quantum\nreinforcement learning protocols using quantum data, and the future deployment\nof semi-autonomous quantum systems.\n"]},
{"authors": ["William Woof", "Ke Chen"], "title": ["Learning to Play General Video-Games via an Object Embedding Network"], "date": ["2018-03-14T13:26:44Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.05262v1"], "summary": ["  Deep reinforcement learning (DRL) has proven to be an effective tool for\ncreating general video-game AI. However most current DRL video-game agents\nlearn end-to-end from the video-output of the game, which is superfluous for\nmany applications and creates a number of additional problems. More\nimportantly, directly working on pixel-based raw video data is substantially\ndistinct from what a human player does.In this paper, we present a novel method\nwhich enables DRL agents to learn directly from object information. This is\nobtained via use of an object embedding network (OEN) that compresses a set of\nobject feature vectors of different lengths into a single fixed-length unified\nfeature vector representing the current game-state and fulfills the DRL\nsimultaneously. We evaluate our OEN-based DRL agent by comparing to several\nstate-of-the-art approaches on a selection of games from the GVG-AI\nCompetition. Experimental results suggest that our object-based DRL agent\nyields performance comparable to that of those approaches used in our\ncomparative study.\n"]},
{"authors": ["Ilija Bogunovic", "Junyao Zhao", "Volkan Cevher"], "title": ["Robust Maximization of Non-Submodular Objectives"], "date": ["2018-02-20T12:02:01Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.07073v2"], "summary": ["  We study the problem of maximizing a monotone set function subject to a\ncardinality constraint $k$ in the setting where some number of elements $\\tau$\nis deleted from the returned set. The focus of this work is on the worst-case\nadversarial setting. While there exist constant-factor guarantees when the\nfunction is submodular, there are no guarantees for non-submodular objectives.\nIn this work, we present a new algorithm Oblivious-Greedy and prove the first\nconstant-factor approximation guarantees for a wider class of non-submodular\nobjectives. The obtained theoretical bounds are the first constant-factor\nbounds that also hold in the linear regime, i.e. when the number of deletions\n$\\tau$ is linear in $k$. Our bounds depend on established parameters such as\nthe submodularity ratio and some novel ones such as the inverse curvature. We\nbound these parameters for two important objectives including support selection\nand variance reduction. Finally, we numerically demonstrate the robust\nperformance of Oblivious-Greedy for these two objectives on various datasets.\n"]},
{"authors": ["Matthew Stephenson", "Jochen Renz", "Xiaoyu Ge", "Peng Zhang"], "title": ["The 2017 AIBIRDS Competition"], "date": ["2018-03-14T07:53:31Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.05156v1"], "summary": ["  This paper presents an overview of the sixth AIBIRDS competition, held at the\n26th International Joint Conference on Artificial Intelligence. This\ncompetition tasked participants with developing an intelligent agent which can\nplay the physics-based puzzle game Angry Birds. This game uses a sophisticated\nphysics engine that requires agents to reason and predict the outcome of\nactions with only limited environmental information. Agents entered into this\ncompetition were required to solve a wide assortment of previously unseen\nlevels within a set time limit. The physical reasoning and planning required to\nsolve these levels are very similar to those of many real-world problems. This\nyear's competition featured some of the best agents developed so far and even\nincluded several new AI techniques such as deep reinforcement learning. Within\nthis paper we describe the framework, rules, submitted agents and results for\nthis competition. We also provide some background information on related work\nand other video game AI competitions, as well as discussing some potential\nideas for future AIBIRDS competitions and agent improvements.\n"]},
{"authors": ["Boliang Lin"], "title": ["A Study of Car-to-Train Assignment Problem for Rail Express Cargos on\n  Scheduled and Unscheduled Train Service Network"], "date": ["2018-03-14T07:32:14Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.05760v1"], "summary": ["  Freight train services in a railway network system are generally divided into\ntwo categories: one is the unscheduled train, whose operating frequency\nfluctuates with origin-destination (OD) demands; the other is the scheduled\ntrain, which is running based on regular timetable just like the passenger\ntrains. The timetable will be released to the public if determined and it would\nnot be influenced by OD demands. Typically, the total capacity of scheduled\ntrains can usually satisfy the predicted demands of express cargos in average.\nHowever, the demands are changing in practice. Therefore, how to distribute the\nshipments between different stations to unscheduled and scheduled train\nservices has become an important research field in railway transportation. This\npaper focuses on the coordinated optimization of the rail express cargos\ndistribution in two service networks. On the premise of fully utilizing the\ncapacity of scheduled service network first, we established a Car-to-Train\n(CTT) assignment model to assign rail express cargos to scheduled and\nunscheduled trains scientifically. The objective function is to maximize the\nnet income of transporting the rail express cargos. The constraints include the\ncapacity restriction on the service arcs, flow balance constraints, logical\nrelationship constraint between two groups of decision variables and the due\ndate constraint. The last constraint is to ensure that the total transportation\ntime of a shipment would not be longer than its predefined due date. Finally,\nwe discuss the linearization techniques to simplify the model proposed in this\npaper, which make it possible for obtaining global optimal solution by using\nthe commercial software.\n"]},
{"authors": ["Olga Krestinskaya", "Alex Pappachen James"], "title": ["Feature extraction without learning in an analog Spatial Pooler\n  memristive-CMOS circuit design of Hierarchical Temporal Memory"], "date": ["2018-03-14T04:18:47Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.05131v1"], "summary": ["  Hierarchical Temporal Memory (HTM) is a neuromorphic algorithm that emulates\nsparsity, hierarchy and modularity resembling the working principles of\nneocortex. Feature encoding is an important step to create sparse binary\npatterns. This sparsity is introduced by the binary weights and random weight\nassignment in the initialization stage of the HTM. We propose the alternative\ndeterministic method for the HTM initialization stage, which connects the HTM\nweights to the input data and preserves natural sparsity of the input\ninformation. Further, we introduce the hardware implementation of the\ndeterministic approach and compare it to the traditional HTM and existing\nhardware implementation. We test the proposed approach on the face recognition\nproblem and show that it outperforms the conventional HTM approach.\n"]},
{"authors": ["Bryan Wilder"], "title": ["Algorithmic Social Intervention"], "date": ["2018-03-14T02:00:54Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.05098v1"], "summary": ["  Social and behavioral interventions are a critical tool for governments and\ncommunities to tackle deep-rooted societal challenges such as homelessness,\ndisease, and poverty. However, real-world interventions are almost always\nplagued by limited resources and limited data, which creates a computational\nchallenge: how can we use algorithmic techniques to enhance the targeting and\ndelivery of social and behavioral interventions? The goal of my thesis is to\nprovide a unified study of such questions, collectively considered under the\nname \"algorithmic social intervention\". This proposal introduces algorithmic\nsocial intervention as a distinct area with characteristic technical\nchallenges, presents my published research in the context of these challenges,\nand outlines open problems for future work. A common technical theme is\ndecision making under uncertainty: how can we find actions which will impact a\nsocial system in desirable ways under limitations of knowledge and resources?\nThe primary application area for my work thus far is public health, e.g. HIV or\ntuberculosis prevention. For instance, I have developed a series of algorithms\nwhich optimize social network interventions for HIV prevention. Two of these\nalgorithms have been pilot-tested in collaboration with LA-area service\nproviders for homeless youth, with preliminary results showing substantial\nimprovement over status-quo approaches. My work also spans other topics in\ninfectious disease prevention and underlying algorithmic questions in robust\nand risk-aware submodular optimization.\n"]},
{"authors": ["Sergio Hernandez Cerezo", "Guillem Duran Ballester"], "title": ["Fractal AI: A fragile theory of intelligence"], "date": ["2018-03-13T21:17:26Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.05049v1"], "summary": ["  Fractal AI is a theory for general artificial intelligence. It allows to\nderive new mathematical tools that constitute the foundations for a new kind of\nstochastic calculus, by modelling information using cellular automaton-like\nstructures instead of smooth functions.\n  In the repository included we are presenting a new Agent, derived from the\nfirst principles of the theory, which is capable of solving Atari games several\norders of magnitude more efficiently than other similar techniques, like Monte\nCarlo Tree Search.\n  The code provided shows how it is now possible to beat some of the current\nstate of the art benchmarks on Atari games, without previous learning and using\nless than 1000 samples to calculate each one of the actions when standard MCTS\nuses 3 Million samples. Among other things, Fractal AI makes it possible to\ngenerate a huge database of top performing examples with very little amount of\ncomputation required, transforming Reinforcement Learning into a supervised\nproblem.\n  The algorithm presented is capable of solving the exploration vs exploitation\ndilemma on both the discrete and continuous cases, while maintaining control\nover any aspect of the behavior of the Agent. From a general approach, new\ntechniques presented here have direct applications to other areas such as:\nNon-equilibrium thermodynamics, chemistry, quantum physics, economics,\ninformation theory, and non-linear control theory.\n"]},
{"authors": ["Subhash Kak"], "title": ["On the Algebra in Boole's Laws of Thought"], "date": ["2018-03-13T18:13:08Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.04994v1"], "summary": ["  This article explores the ideas that went into George Boole's development of\nan algebra for logical inference in his book The Laws of Thought. We explore in\nparticular his wife Mary Boole's claim that he was deeply influenced by Indian\nlogic and argue that his work was more than a framework for processing\npropositions. By exploring parallels between his work and Indian logic, we are\nable to explain several peculiarities of this work.\n"]},
{"authors": ["A. Shirzadi Babakan", "A. Alimohammadi", "M. Taleai"], "title": ["An agent-based evaluation of impacts of transport developments on the\n  modal shift in Tehran, Iran"], "date": ["2018-03-13T16:53:50Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.04934v1"], "summary": ["  Changes in travel modes used by people, particularly reduction of the private\ncar use, is an important determinant of effectiveness of transportation plans.\nBecause of dependencies between the choices of residential location and travel\nmode, integrated modelling of these choices has been proposed by some\nresearchers. In this paper, an agent-based microsimulation model has been\ndeveloped to evaluate impacts of different transport development plans on\nchoices of residential location and commuting mode of tenant households in\nTehran, the capital of Iran. In the proposed model, households are considered\nas agents who select their desired residential location using a constrained\nNSGA-II algorithm and in a competition with other households. In addition, they\nchoose their commuting mode by applying a multi-criteria decision making\nmethod. Afterwards, effects of development of a new highway, subway and bus\nrapid transit (BRT) line on their residential location and commuting mode\nchoices are evaluated. Results show that despite the residential self-selection\neffects, these plans result in considerable changes in the commuting mode of\ndifferent socioeconomic categories of households. Development of the new subway\nline shows promising results by reducing the private car use among the all\nsocio-economic categories of households. But the new highway development\nunsatisfactorily results in increase in the private car use. In addition,\ndevelopment of the new BRT line does not show significant effects on the\ncommuting mode change, particularly on decrease in the private car use.\n"]},
{"authors": ["R\u00e9mi Pautrat", "Konstantinos Chatzilygeroudis", "Jean-Baptiste Mouret"], "title": ["Bayesian Optimization with Automatic Prior Selection for Data-Efficient\n  Direct Policy Search"], "date": ["2017-09-20T15:04:50Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1709.06919v2"], "summary": ["  One of the most interesting features of Bayesian optimization for direct\npolicy search is that it can leverage priors (e.g., from simulation or from\nprevious tasks) to accelerate learning on a robot. In this paper, we are\ninterested in situations for which several priors exist but we do not know in\nadvance which one fits best the current situation. We tackle this problem by\nintroducing a novel acquisition function, called Most Likely Expected\nImprovement (MLEI), that combines the likelihood of the priors and the expected\nimprovement. We evaluate this new acquisition function on a transfer learning\ntask for a 5-DOF planar arm and on a possibly damaged, 6-legged robot that has\nto learn to walk on flat ground and on stairs, with priors corresponding to\ndifferent stairs and different kinds of damages. Our results show that MLEI\neffectively identifies and exploits the priors, even when there is no obvious\nmatch between the current situations and the priors.\n"]},
{"authors": ["A. S. Babakan", "M. Taleai"], "title": ["Impacts of transport development on residence choice of renter\n  households: An agent-based evaluation"], "date": ["2018-03-13T16:45:33Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.04932v1"], "summary": ["  Because of improving accessibility, transport developments play an important\nrole in residence choice of renter households. In this paper, an agent-based\nmodel is developed to investigate impacts of different transport developments\non residence choice of renter households in Tehran, the capital of Iran. In the\nproposed model, renter households are considered as agents who make a\nmulti-objective decision and compete with each other to rent a preferred\nresidential zone. Then, three transport development scenarios including\nconstruction a new highway, subway and bus rapid transit (BRT) line are\nsimulated and resulting changes in residence choice of agents are evaluated.\nResults show that transport development scenarios significantly affect\nresidence choice behavior of different socio-economic categories of renter\nhouseholds and lead to considerable changes in the residential demand,\ncomposition of residents, mean income level and mean car ownership in their\nvicinities.\n"]},
{"authors": ["Konstantinos Chatzilygeroudis", "Jean-Baptiste Mouret"], "title": ["Using Parameterized Black-Box Priors to Scale Up Model-Based Policy\n  Search for Robotics"], "date": ["2017-09-20T15:03:47Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1709.06917v2"], "summary": ["  The most data-efficient algorithms for reinforcement learning in robotics are\nmodel-based policy search algorithms, which alternate between learning a\ndynamical model of the robot and optimizing a policy to maximize the expected\nreturn given the model and its uncertainties. Among the few proposed\napproaches, the recently introduced Black-DROPS algorithm exploits a black-box\noptimization algorithm to achieve both high data-efficiency and good\ncomputation times when several cores are used; nevertheless, like all\nmodel-based policy search approaches, Black-DROPS does not scale to high\ndimensional state/action spaces. In this paper, we introduce a new model\nlearning procedure in Black-DROPS that leverages parameterized black-box priors\nto (1) scale up to high-dimensional systems, and (2) be robust to large\ninaccuracies of the prior information. We demonstrate the effectiveness of our\napproach with the \"pendubot\" swing-up task in simulation and with a physical\nhexapod robot (48D state space, 18D action space) that has to walk forward as\nfast as possible. The results show that our new algorithm is more\ndata-efficient than previous model-based policy search algorithms (with and\nwithout priors) and that it can allow a physical 6-legged robot to learn new\ngaits in only 16 to 30 seconds of interaction time.\n"]},
{"authors": ["A. Shirzadi Babakan", "A. Alimohammadi"], "title": ["An Agent-Based Simulation of Residential Location Choice of Tenants in\n  Tehran, Iran"], "date": ["2018-03-13T16:36:10Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.04927v1"], "summary": ["  Residential location choice modeling is one of the substantial components of\nland use and transportation models. While numerous aggregated mathematical and\nstatistical approaches have been developed to model the residence choice\nbehavior of households, disaggregated approaches such as the agent-based\nmodeling have shown interesting capabilities. In this article, a novel\nagent-based approach is developed to simulate the residential location choice\nof tenants in Tehran, the capital of Iran. Tenants are considered as agents who\nselect their desired residential alternatives according to their\ncharacteristics and preferences for various criteria such as the rent,\naccessibility to different services and facilities, environmental pollution,\nand distance from their workplace and former residence. The choice set of\nagents is limited to their desired residential alternatives by applying a\nconstrained NSGA-II algorithm. Then, agents compete with each other to select\ntheir final residence among their alternatives. Results of the proposed\napproach are validated by comparing simulated and actual residences of a sample\nof tenants. Results show that the proposed approach is able to accurately\nsimulate the residence of 59.3% of tenants at the traffic analysis zone level.\n"]},
{"authors": ["Stuart Armstrong"], "title": ["Good and safe uses of AI Oracles"], "date": ["2017-11-15T12:47:17Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.05541v4"], "summary": ["  An Oracle is a design for potentially high power artificial intelligences\n(AIs), where the AI is made safe by restricting it to only answer questions.\nUnfortunately most designs cause the Oracle to be motivated to manipulate\nhumans with the contents of their answers, and Oracles of potentially high\nintelligence might be very successful at this. Solving that problem, without\ncompromising the accuracy of the answer, is tricky. This paper reduces the\nissue to a cryptographic-style problem of Alice ensuring that her Oracle\nanswers her questions while not providing key information to an eavesdropping\nEve. Two Oracle designs solve this problem, one counterfactual (the Oracle\nanswers as if it expected its answer to never be read) and one on-policy, but\nlimited by the quantity of information it can transmit.\n"]},
{"authors": ["Philipp Geiger", "Lucian Carata", "Bernhard Schoelkopf"], "title": ["Causal inference for cloud computing"], "date": ["2016-03-04T19:28:13Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1603.01581v4"], "summary": ["  Cloud computing involves complex technical and economical systems and\ninteractions. This brings about various challenges, two of which are: (1)\ndebugging and control of computing systems with the help of sandbox\nexperiments, and (2) prediction of the cost of \"spot\" resources for decision\nmaking of cloud clients. In this paper, we formalize debugging by\ncounterfactual probabilities and control by post-(soft-)interventional\nprobabilities. We prove that counterfactuals can approximately be calculated\nfrom a \"stochastic\" graphical causal model (while they are originally defined\nonly for \"deterministic\" functional causal models), and based on this sketch an\napproach to address problem (1). To address problem (2), we formalize bidding\nby post-(soft-)interventional probabilities and present a simple mathematical\nresult on approximate integration of \"incomplete\" conditional probability\ndistributions. We show how this can be used by cloud clients to trade off\nprivacy against predictability of the outcome of their bidding actions in a toy\nscenario. We report experiments on simulated and real data.\n"]},
{"authors": ["Stuart Armstrong", "S\u00f6ren Mindermann"], "title": ["Impossibility of deducing preferences and rationality from human policy"], "date": ["2017-12-15T19:05:01Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1712.05812v3"], "summary": ["  Inverse reinforcement learning (IRL) attempts to infer human rewards or\npreferences from observed behavior. Since human planning systematically\ndeviates from rationality, several approaches have been tried to account for\nspecific human shortcomings. However, there has been little analysis of the\ngeneral problem of inferring the reward of a human of unknown rationality. The\nobserved behavior can, in principle, be decomposed into two components: a\nreward function and a planning algorithm, both of which have to be inferred\nfrom behavior. This paper presents a No Free Lunch theorem, showing that,\nwithout making `normative' assumptions beyond the data, nothing about the human\nreward function can be deduced from human behavior. Unlike most No Free Lunch\ntheorems, this cannot be alleviated by regularising with simplicity\nassumptions. We show that the simplest hypotheses which explain the data are\ngenerally degenerate.\n"]},
{"authors": ["Philipp Geiger", "Katja Hofmann", "Bernhard Sch\u00f6lkopf"], "title": ["Experimental and causal view on information integration in autonomous\n  agents"], "date": ["2016-06-14T08:38:18Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1606.04250v3"], "summary": ["  The amount of digitally available but heterogeneous information about the\nworld is remarkable, and new technologies such as self-driving cars, smart\nhomes, or the internet of things may further increase it. In this paper we\npresent preliminary ideas about certain aspects of the problem of how such\nheterogeneous information can be harnessed by autonomous agents. After\ndiscussing potentials and limitations of some existing approaches, we\ninvestigate how \\emph{experiments} can help to obtain a better understanding of\nthe problem. Specifically, we present a simple agent that integrates video data\nfrom a different agent, and implement and evaluate a version of it on the novel\nexperimentation platform \\emph{Malmo}. The focus of a second investigation is\non how information about the hardware of different agents, the agents' sensory\ndata, and \\emph{causal} information can be utilized for knowledge transfer\nbetween agents and subsequently more data-efficient decision making. Finally,\nwe discuss potential future steps w.r.t.\\ theory and experimentation, and\nformulate open questions.\n"]},
{"authors": ["Tom Zahavy", "Avinatan Hasidim", "Haim Kaplan", "Yishay Mansour"], "title": ["Hierarchical Reinforcement Learning: Approximating Optimal Discounted\n  TSP Using Local Policies"], "date": ["2018-03-13T08:13:11Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.04674v1"], "summary": ["  In this work, we provide theoretical guarantees for reward decomposition in\ndeterministic MDPs. Reward decomposition is a special case of Hierarchical\nReinforcement Learning, that allows one to learn many policies in parallel and\ncombine them into a composite solution. Our approach builds on mapping this\nproblem into a Reward Discounted Traveling Salesman Problem, and then deriving\napproximate solutions for it. In particular, we focus on approximate solutions\nthat are local, i.e., solutions that only observe information about the current\nstate. Local policies are easy to implement and do not require substantial\ncomputational resources as they do not perform planning. While local\ndeterministic policies, like Nearest Neighbor, are being used in practice for\nhierarchical reinforcement learning, we propose three stochastic policies that\nguarantee better performance than any deterministic policy.\n"]},
{"authors": ["Alexander Semenov", "Oleg Zaikin", "Ilya Otpuschennikov", "Stepan Kochemazov", "Alexey Ignatiev"], "title": ["On Cryptographic Attacks Using Backdoors for SAT"], "date": ["2018-03-13T06:29:50Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.04646v1"], "summary": ["  Propositional satisfiability (SAT) is at the nucleus of state-of-the-art\napproaches to a variety of computationally hard problems, one of which is\ncryptanalysis. Moreover, a number of practical applications of SAT can only be\ntackled efficiently by identifying and exploiting a subset of formula's\nvariables called backdoor set (or simply backdoors). This paper proposes a new\nclass of backdoor sets for SAT used in the context of cryptographic attacks,\nnamely guess-and-determine attacks. The idea is to identify the best set of\nbackdoor variables subject to a statistically estimated hardness of the\nguess-and-determine attack using a SAT solver. Experimental results on weakened\nvariants of the renowned encryption algorithms exhibit advantage of the\nproposed approach compared to the state of the art in terms of the estimated\nhardness of the resulting guess-and-determine attacks.\n"]},
{"authors": ["Tom De Smedt", "Guy De Pauw", "Pieter Van Ostaeyen"], "title": ["Automatic Detection of Online Jihadist Hate Speech"], "date": ["2018-03-13T02:09:06Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.04596v1"], "summary": ["  We have developed a system that automatically detects online jihadist hate\nspeech with over 80% accuracy, by using techniques from Natural Language\nProcessing and Machine Learning. The system is trained on a corpus of 45,000\nsubversive Twitter messages collected from October 2014 to December 2016. We\npresent a qualitative and quantitative analysis of the jihadist rhetoric in the\ncorpus, examine the network of Twitter users, outline the technical procedure\nused to train the system, and discuss examples of use.\n"]},
{"authors": ["Sebastian Guendel", "Sasa Grbic", "Bogdan Georgescu", "Kevin Zhou", "Ludwig Ritschl", "Andreas Meier", "Dorin Comaniciu"], "title": ["Learning to recognize Abnormalities in Chest X-Rays with Location-Aware\n  Dense Networks"], "date": ["2018-03-12T22:57:18Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.04565v1"], "summary": ["  Chest X-ray is the most common medical imaging exam used to assess multiple\npathologies. Automated algorithms and tools have the potential to support the\nreading workflow, improve efficiency, and reduce reading errors. With the\navailability of large scale data sets, several methods have been proposed to\nclassify pathologies on chest X-ray images. However, most methods report\nperformance based on random image based splitting, ignoring the high\nprobability of the same patient appearing in both training and test set. In\naddition, most methods fail to explicitly incorporate the spatial information\nof abnormalities or utilize the high resolution images. We propose a novel\napproach based on location aware Dense Networks (DNetLoc), whereby we\nincorporate both high-resolution image data and spatial information for\nabnormality classification. We evaluate our method on the largest data set\nreported in the community, containing a total of 86,876 patients and 297,541\nchest X-ray images. We achieve (i) the best average AUC score for published\ntraining and test splits on the single benchmarking data set (ChestX-Ray14),\nand (ii) improved AUC scores when the pathology location information is\nexplicitly used. To foster future research we demonstrate the limitations of\nthe current benchmarking setup and provide new reference patient-wise splits\nfor the used data sets. This could support consistent and meaningful\nbenchmarking of future methods on the largest publicly available data sets.\n"]},
{"authors": ["Pan Wei", "John E. Ball", "Derek T. Anderson", "Archit Harsh", "Christopher Archibald"], "title": ["Measuring Conflict in a Multi-Source Environment as a Normal Measure"], "date": ["2018-03-12T22:27:11Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.04556v1"], "summary": ["  In a multi-source environment, each source has its own credibility. If there\nis no external knowledge about credibility then we can use the information\nprovided by the sources to assess their credibility. In this paper, we propose\na way to measure conflict in a multi-source environment as a normal measure. We\nexamine our algorithm using three simulated examples of increasing conflict and\none experimental example. The results demonstrate that the proposed measure can\nrepresent conflict in a meaningful way similar to what a human might expect and\nfrom it we can identify conflict within our sources.\n"]},
{"authors": ["Pan Wei", "John E. Ball", "Derek T. Anderson"], "title": ["Multi-Sensor Conflict Measurement and Information Fusion"], "date": ["2018-03-12T22:10:14Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.04551v1"], "summary": ["  In sensing applications where multiple sensors observe the same scene, fusing\nsensor outputs can provide improved results. However, if some of the sensors\nare providing lower quality outputs, the fused results can be degraded. In this\nwork, a multi-sensor conflict measure is proposed which estimates multi-sensor\nconflict by representing each sensor output as interval-valued information and\nexamines the sensor output overlaps on all possible n-tuple sensor\ncombinations. The conflict is based on the sizes of the intervals and how many\nsensors output values lie in these intervals. In this work, conflict is defined\nin terms of how little the output from multiple sensors overlap. That is, high\ndegrees of overlap mean low sensor conflict, while low degrees of overlap mean\nhigh conflict. This work is a preliminary step towards a robust conflict and\nsensor fusion framework. In addition, a sensor fusion algorithm is proposed\nbased on a weighted sum of sensor outputs, where the weights for each sensor\ndiminish as the conflict measure increases. The proposed methods can be\nutilized to (1) assess a measure of multi-sensor conflict, and (2) improve\nsensor output fusion by lessening weighting for sensors with high conflict.\nUsing this measure, a simulated example is given to explain the mechanics of\ncalculating the conflict measure, and stereo camera 3D outputs are analyzed and\nfused. In the stereo camera case, the sensor output is corrupted by additive\nimpulse noise, DC offset, and Gaussian noise. Impulse noise is common in\nsensors due to intermittent interference, a DC offset a sensor bias or\nregistration error, and Gaussian noise represents a sensor output with low SNR.\nThe results show that sensor output fusion based on the conflict measure shows\nimproved accuracy over a simple averaging fusion strategy.\n"]},
{"authors": ["Neil C. Rabinowitz", "Frank Perbet", "H. Francis Song", "Chiyuan Zhang", "S. M. Ali Eslami", "Matthew Botvinick"], "title": ["Machine Theory of Mind"], "date": ["2018-02-21T19:00:10Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.07740v2"], "summary": ["  Theory of mind (ToM; Premack & Woodruff, 1978) broadly refers to humans'\nability to represent the mental states of others, including their desires,\nbeliefs, and intentions. We propose to train a machine to build such models\ntoo. We design a Theory of Mind neural network -- a ToMnet -- which uses\nmeta-learning to build models of the agents it encounters, from observations of\ntheir behaviour alone. Through this process, it acquires a strong prior model\nfor agents' behaviour, as well as the ability to bootstrap to richer\npredictions about agents' characteristics and mental states using only a small\nnumber of behavioural observations. We apply the ToMnet to agents behaving in\nsimple gridworld environments, showing that it learns to model random,\nalgorithmic, and deep reinforcement learning agents from varied populations,\nand that it passes classic ToM tasks such as the \"Sally-Anne\" test (Wimmer &\nPerner, 1983; Baron-Cohen et al., 1985) of recognising that others can hold\nfalse beliefs about the world. We argue that this system -- which autonomously\nlearns how to model other agents in its world -- is an important step forward\nfor developing multi-agent AI systems, for building intermediating technology\nfor machine-human interaction, and for advancing the progress on interpretable\nAI.\n"]},
{"authors": ["Leon Bottou", "Martin Arjovsky", "David Lopez-Paz", "Maxime Oquab"], "title": ["Geometrical Insights for Implicit Generative Modeling"], "date": ["2017-12-21T08:11:44Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1712.07822v2"], "summary": ["  Learning algorithms for implicit generative models can optimize a variety of\ncriteria that measure how the data distribution differs from the implicit model\ndistribution, including the Wasserstein distance, the Energy distance, and the\nMaximum Mean Discrepancy criterion. A careful look at the geometries induced by\nthese distances on the space of probability measures reveals interesting\ndifferences. In particular, we can establish surprising approximate global\nconvergence guarantees for the $1$-Wasserstein distance,even when the\nparametric generator has a nonconvex parametrization.\n"]},
{"authors": ["Faisal Alshargi", "Saeedeh Shekarpour", "Tommaso Soru", "Amit Sheth", "Uwe Quasthoff"], "title": ["Concept2vec: Metrics for Evaluating Quality of Embeddings for\n  Ontological Concepts"], "date": ["2018-03-12T19:46:10Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.04488v1"], "summary": ["  Although there is an emerging trend towards generating embeddings for\nprimarily unstructured data, and recently for structured data, there is not yet\nany systematic suite for measuring the quality of embeddings. This deficiency\nis further sensed with respect to embeddings generated for structured data\nbecause there are no concrete evaluation metrics measuring the quality of\nencoded structure as well as semantic patterns in the embedding space. In this\npaper, we introduce a framework containing three distinct tasks concerned with\nthe individual aspects of ontological concepts: (i) the categorization aspect,\n(ii) the hierarchical aspect, and (iii) the relational aspect. Then, in the\nscope of each task, a number of intrinsic metrics are proposed for evaluating\nthe quality of the embeddings. Furthermore, w.r.t. this framework multiple\nexperimental studies were run to compare the quality of the available embedding\nmodels. Employing this framework in future research can reduce misjudgment and\nprovide greater insight about quality comparisons of embeddings for ontological\nconcepts.\n"]},
{"authors": ["Fateha Khanam Bappee", "Amilcar Soares Junior", "Stan Matwin"], "title": ["Predicting Crime Using Spatial Features"], "date": ["2018-03-12T19:23:27Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.04474v1"], "summary": ["  Our study aims to build a machine learning model for crime prediction using\ngeospatial features for different categories of crime. The reverse geocoding\ntechnique is applied to retrieve open street map (OSM) spatial data. This study\nalso proposes finding hotpoints extracted from crime hotspots area found by\nHierarchical Density-Based Spatial Clustering of Applications with Noise\n(HDBSCAN). A spatial distance feature is then computed based on the position of\ndifferent hotpoints for various types of crime and this value is used as a\nfeature for classifiers. We test the engineered features in crime data from\nRoyal Canadian Mounted Police of Halifax, NS. We observed a significant\nperformance improvement in crime prediction using the new generated spatial\nfeatures.\n"]},
{"authors": ["Rayyan Ahmad Khan", "Rana Ali Amjad", "Martin Kleinsteuber"], "title": ["Clustering with Simultaneous Local and Global View of Data: A message\n  passing based approach"], "date": ["2018-03-12T18:56:38Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.04459v1"], "summary": ["  A good clustering algorithm should not only be able to discover clusters of\narbitrary shapes (global view) but also provide additional information, which\ncan be used to gain more meaningful insights into the internal structure of the\nclusters (local view). In this work we use the mathematical framework of factor\ngraphs and message passing algorithms to optimize a pairwise similarity based\ncost function, in the same spirit as was done in Affinity Propagation. Using\nthis framework we develop two variants of a new clustering algorithm, EAP and\nSHAPE. EAP/SHAPE can not only discover clusters of arbitrary shapes but also\nprovide a rich local view in the form of meaningful local representatives\n(exemplars) and connections between these local exemplars. We discuss how this\nlocal information can be used to gain various insights about the clusters\nincluding varying relative cluster densities and indication of local strength\nin different regions of a cluster . We also discuss how this can help an\nanalyst in discovering and resolving potential inconsistencies in the results.\nThe efficacy of EAP/SHAPE is shown by applying it to various synthetic and real\nworld benchmark datasets.\n"]},
{"authors": ["Meng Wang"], "title": ["Predicting Rich Drug-Drug Interactions via Biomedical Knowledge Graphs\n  and Text Jointly Embedding"], "date": ["2017-12-24T04:43:46Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1712.08875v4"], "summary": ["  Minimizing adverse reactions caused by drug-drug interactions has always been\na momentous research topic in clinical pharmacology. Detecting all possible\ninteractions through clinical studies before a drug is released to the market\nis a demanding task. The power of big data is opening up new approaches to\ndiscover various drug-drug interactions. However, these discoveries contain a\nhuge amount of noise and provide knowledge bases far from complete and\ntrustworthy ones to be utilized. Most existing studies focus on predicting\nbinary drug-drug interactions between drug pairs but ignore other interactions.\nIn this paper, we propose a novel framework, called PRD, to predict drug-drug\ninteractions. The framework uses the graph embedding that can overcome data\nincompleteness and sparsity issues to achieve multiple DDI label prediction.\nFirst, a large-scale drug knowledge graph is generated from different sources.\nThen, the knowledge graph is embedded with comprehensive biomedical text into a\ncommon low dimensional space. Finally, the learned embeddings are used to\nefficiently compute rich DDI information through a link prediction process. To\nvalidate the effectiveness of the proposed framework, extensive experiments\nwere conducted on real-world datasets. The results demonstrate that our model\noutperforms several state-of-the-art baseline methods in terms of capability\nand accuracy.\n"]},
{"authors": ["Kieran Greer"], "title": ["New Ideas for Brain Modelling 4"], "date": ["2017-08-16T08:32:03Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1708.04806v4"], "summary": ["  This paper continues the research that considers a new cognitive model based\nstrongly on the human brain. In particular, it considers the neural binding\nstructure of an earlier paper. It also describes some new methods in the areas\nof image processing and behaviour simulation. The work is all based on earlier\nresearch by the author and the new additions are intended to fit in with the\noverall design. For image processing, a grid-like structure is used with 'full\nlinking'. Each cell in the classifier grid stores a list of all other cells it\ngets associated with and this is used as the learned image that new input is\ncompared to. For the behaviour metric, a new prediction equation is suggested,\nas part of a simulation, that uses feedback and history to dynamically\ndetermine its course of action. While the new methods are from widely different\ntopics, both can be compared with the binary-analog type of interface that is\nthe main focus of the paper. It is suggested that the simplest of linking\nbetween a tree and ensemble can explain neural binding and variable signal\nstrengths.\n"]},
{"authors": ["Fulton Wang", "Cynthia Rudin"], "title": ["Extreme Dimension Reduction for Handling Covariate Shift"], "date": ["2017-11-29T16:20:06Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.10938v2"], "summary": ["  In the covariate shift learning scenario, the training and test covariate\ndistributions differ, so that a predictor's average loss over the training and\ntest distributions also differ. In this work, we explore the potential of\nextreme dimension reduction, i.e. to very low dimensions, in improving the\nperformance of importance weighting methods for handling covariate shift, which\nfail in high dimensions due to potentially high train/test covariate divergence\nand the inability to accurately estimate the requisite density ratios. We first\nformulate and solve a problem optimizing over linear subspaces a combination of\ntheir predictive utility and train/test divergence within. Applying it to\nsimulated and real data, we show extreme dimension reduction helps sometimes\nbut not always, due to a bias introduced by dimension reduction.\n"]},
{"authors": ["Pieter Gijsbers", "Joaquin Vanschoren", "Randal S. Olson"], "title": ["Layered TPOT: Speeding up Tree-based Pipeline Optimization"], "date": ["2018-01-18T13:36:51Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.06007v2"], "summary": ["  With the demand for machine learning increasing, so does the demand for tools\nwhich make it easier to use. Automated machine learning (AutoML) tools have\nbeen developed to address this need, such as the Tree-Based Pipeline\nOptimization Tool (TPOT) which uses genetic programming to build optimal\npipelines. We introduce Layered TPOT, a modification to TPOT which aims to\ncreate pipelines equally good as the original, but in significantly less time.\nThis approach evaluates candidate pipelines on increasingly large subsets of\nthe data according to their fitness, using a modified evolutionary algorithm to\nallow for separate competition between pipelines trained on different sample\nsizes. Empirical evaluation shows that, on sufficiently large datasets, Layered\nTPOT indeed finds better models faster.\n"]},
{"authors": ["Alberto Garcia-Duran", "Mathias Niepert"], "title": ["KBLRN : End-to-End Learning of Knowledge Base Representations with\n  Latent, Relational, and Numerical Features"], "date": ["2017-09-14T09:13:46Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1709.04676v2"], "summary": ["  We present KBLRN, a framework for end-to-end learning of knowledge base\nrepresentations from latent, relational, and numerical features. KBLRN\nintegrates feature types with a novel combination of neural representation\nlearning and probabilistic product of experts models. To the best of our\nknowledge, KBLRN is the first approach that learns representations of knowledge\nbases by integrating latent, relational, and numerical features. We show that\ninstances of KBLRN outperform existing methods on a range of knowledge base\ncompletion tasks. We contribute a novel data sets enriching commonly used\nknowledge base completion benchmarks with numerical features. We have made the\ndata sets available for further research. We also investigate the impact\nnumerical features have on the KB completion performance of KBLRN.\n"]},
{"authors": ["Nathalie Peyrard", "Marie-Jos\u00e9e Cros", "Simon de Givry", "Alain Franc", "St\u00e9phane Robin", "R\u00e9gis Sabbadin", "Thomas Schiex", "Matthieu Vignes"], "title": ["Exact and approximate inference in graphical models: variable\n  elimination and beyond"], "date": ["2015-06-29T08:45:11Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1506.08544v2"], "summary": ["  Probabilistic graphical models offer a powerful framework to account for the\ndependence structure between variables, which is represented as a graph.\nHowever, the dependence between variables may render inference tasks\nintractable. In this paper we review techniques exploiting the graph structure\nfor exact inference, borrowed from optimisation and computer science. They are\nbuilt on the principle of variable elimination whose complexity is dictated in\nan intricate way by the order in which variables are eliminated. The so-called\ntreewidth of the graph characterises this algorithmic complexity: low-treewidth\ngraphs can be processed efficiently. The first message that we illustrate is\ntherefore the idea that for inference in graphical model, the number of\nvariables is not the limiting factor, and it is worth checking for the\ntreewidth before turning to approximate methods. We show how algorithms\nproviding an upper bound of the treewidth can be exploited to derive a 'good'\nelimination order enabling to perform exact inference. The second message is\nthat when the treewidth is too large, algorithms for approximate inference\nlinked to the principle of variable elimination, such as loopy belief\npropagation and variational approaches, can lead to accurate results while\nbeing much less time consuming than Monte-Carlo approaches. We illustrate the\ntechniques reviewed in this article on benchmarks of inference problems in\ngenetic linkage analysis and computer vision, as well as on hidden variables\nrestoration in coupled Hidden Markov Models.\n"]},
{"authors": ["Gabriel Sepulveda", "Juan Carlos Niebles", "Alvaro Soto"], "title": ["A Deep Learning Based Behavioral Approach to Indoor Autonomous\n  Navigation"], "date": ["2018-03-12T05:27:07Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.04119v1"], "summary": ["  We present a semantically rich graph representation for indoor robotic\nnavigation. Our graph representation encodes: semantic locations such as\noffices or corridors as nodes, and navigational behaviors such as enter office\nor cross a corridor as edges. In particular, our navigational behaviors operate\ndirectly from visual inputs to produce motor controls and are implemented with\ndeep learning architectures. This enables the robot to avoid explicit\ncomputation of its precise location or the geometry of the environment, and\nenables navigation at a higher level of semantic abstraction. We evaluate the\neffectiveness of our representation by simulating navigation tasks in a large\nnumber of virtual environments. Our results show that using a simple sets of\nperceptual and navigational behaviors, the proposed approach can successfully\nguide the way of the robot as it completes navigational missions such as going\nto a specific office. Furthermore, our implementation shows to be effective to\ncontrol the selection and switching of behaviors.\n"]},
{"authors": ["Esther Derman", "Daniel J. Mankowitz", "Timothy A. Mann", "Shie Mannor"], "title": ["Soft-Robust Actor-Critic Policy-Gradient"], "date": ["2018-03-11T09:43:20Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.04848v1"], "summary": ["  Robust Reinforcement Learning aims to derive an optimal behavior that\naccounts for model uncertainty in dynamical systems. However, previous studies\nhave shown that by considering the worst case scenario, robust policies can be\noverly conservative. Our \\textit{soft-robust} framework is an attempt to\novercome this issue. In this paper, we present a novel Soft-Robust Actor-Critic\nalgorithm (SR-AC). It learns an optimal policy with respect to a distribution\nover an uncertainty set and stays robust to model uncertainty but avoids the\nconservativeness of robust strategies. We show convergence of the SR-AC and\ntest the efficiency of our approach on different domains by comparing it\nagainst regular learning methods and their robust formulations.\n"]},
{"authors": ["Renato Hermoza", "Ivan Sipiran"], "title": ["3D Reconstruction of Incomplete Archaeological Objects Using a\n  Generative Adversarial Network"], "date": ["2017-11-17T00:58:53Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.06363v2"], "summary": ["  We introduce a data-driven approach to aid the repairing and conservation of\narchaeological objects: ORGAN, an object reconstruction generative adversarial\nnetwork (GAN). By using an encoder-decoder 3D deep neural network on a GAN\narchitecture, and combining two loss objectives: a completion loss and an\nImproved Wasserstein GAN loss, we can train a network to effectively predict\nthe missing geometry of damaged objects. As archaeological objects can greatly\ndiffer between them, the network is conditioned on a variable, which can be a\nculture, a region or any metadata of the object. In our results, we show that\nour method can recover most of the information from damaged objects, even in\ncases where more than half of the voxels are missing, without producing many\nerrors.\n"]},
{"authors": ["Matthias Plappert", "Marcin Andrychowicz", "Alex Ray", "Bob McGrew", "Bowen Baker", "Glenn Powell", "Jonas Schneider", "Josh Tobin", "Maciek Chociej", "Peter Welinder", "Vikash Kumar", "Wojciech Zaremba"], "title": ["Multi-Goal Reinforcement Learning: Challenging Robotics Environments and\n  Request for Research"], "date": ["2018-02-26T17:20:14Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.09464v2"], "summary": ["  The purpose of this technical report is two-fold. First of all, it introduces\na suite of challenging continuous control tasks (integrated with OpenAI Gym)\nbased on currently existing robotics hardware. The tasks include pushing,\nsliding and pick & place with a Fetch robotic arm as well as in-hand object\nmanipulation with a Shadow Dexterous Hand. All tasks have sparse binary rewards\nand follow a Multi-Goal Reinforcement Learning (RL) framework in which an agent\nis told what to do using an additional input.\n  The second part of the paper presents a set of concrete research ideas for\nimproving RL algorithms, most of which are related to Multi-Goal RL and\nHindsight Experience Replay.\n"]},
{"authors": ["Lane A. Hemaspaandra", "David E. Narv\u00e1ez"], "title": ["The Opacity of Backbones and Backdoors Under a Weak Assumption"], "date": ["2017-06-14T16:46:01Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1706.04582v5"], "summary": ["  Backdoors and backbones of Boolean formulas are hidden structural properties.\nA natural goal, already in part realized, is that solver algorithms seek to\nobtain substantially better performance by exploiting these structures.\n  However, the present paper is not intended to improve the performance of SAT\nsolvers, but rather is a cautionary paper. In particular, the theme of this\npaper is that there is a potential chasm between the existence of such\nstructures in the Boolean formula and being able to effectively exploit them.\nThis does not mean that these structures are not useful to solvers. It does\nmean that one must be very careful not to assume that it is computationally\neasy to go from the existence of a structure to being able to get one's hands\non it and/or being able to exploit the structure.\n  For example, in this paper we show that, under the assumption that P $\\neq$\nNP, there are easily recognizable sets of Boolean formulas for which it is hard\nto determine whether they have a large backbone. We also show that, also under\nthe assumption P $\\neq$ NP, there are easily recognizable families of Boolean\nformulas with strong backdoors that are easy to find, yet for which it is hard\nto determine whether they are satisfiable.\n"]},
{"authors": ["Roland Fernandez", "Asli Celikyilmaz", "Rishabh Singh", "Paul Smolensky"], "title": ["Learning and analyzing vector encoding of symbolic representations"], "date": ["2018-03-10T16:44:58Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.03834v1"], "summary": ["  We present a formal language with expressions denoting general symbol\nstructures and queries which access information in those structures. A\nsequence-to-sequence network processing this language learns to encode symbol\nstructures and query them. The learned representation (approximately) shares a\nsimple linearity property with theoretical techniques for performing this task.\n"]},
{"authors": ["Albert Gatt", "Marc Tanti", "Adrian Muscat", "Patrizia Paggio", "Reuben A. Farrugia", "Claudia Borg", "Kenneth P. Camilleri", "Mike Rosner", "Lonneke van der Plas"], "title": ["Face2Text: Collecting an Annotated Image Description Corpus for the\n  Generation of Rich Face Descriptions"], "date": ["2018-03-10T15:52:08Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.03827v1"], "summary": ["  The past few years have witnessed renewed interest in NLP tasks at the\ninterface between vision and language. One intensively-studied problem is that\nof automatically generating text from images. In this paper, we extend this\nproblem to the more specific domain of face description. Unlike scene\ndescriptions, face descriptions are more fine-grained and rely on attributes\nextracted from the image, rather than objects and relations. Given that no data\nexists for this task, we present an ongoing crowdsourcing study to collect a\ncorpus of descriptions of face images taken `in the wild'. To gain a better\nunderstanding of the variation we find in face description and the possible\nissues that this may raise, we also conducted an annotation study on a subset\nof the corpus. Primarily, we found descriptions to refer to a mixture of\nattributes, not only physical, but also emotional and inferential, which is\nbound to create further challenges for current image-to-text methods.\n"]},
{"authors": ["Johannes F\u00fcrnkranz", "Tom\u00e1\u0161 Kliegr", "Heiko Paulheim"], "title": ["On Cognitive Preferences and the Interpretability of Rule-based Models"], "date": ["2018-03-04T08:26:43Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.01316v2"], "summary": ["  It is conventional wisdom in machine learning and data mining that logical\nmodels such as rule sets are more interpretable than other models, and that\namong such rule-based models, simpler models are more interpretable than more\ncomplex ones. In this position paper, we question this latter assumption, and\nrecapitulate evidence for and against this postulate. We also report the\nresults of an evaluation in a crowd-sourcing study, which does not reveal a\nstrong preference for simple rules, whereas we can observe a weak preference\nfor longer rules in some domains. We then continue to review criteria for\ninterpretability from the psychological literature, evaluate some of them, and\nbriefly discuss their potential use in machine learning.\n"]},
{"authors": ["Lin Feng", "Shuliang Xu", "Feilong Wang", "Shenglan Liu"], "title": ["Rough extreme learning machine: a new classification method based on\n  uncertainty measure"], "date": ["2017-10-30T09:37:20Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.10824v2"], "summary": ["  Extreme learning machine (ELM) is a new single hidden layer feedback neural\nnetwork. The weights of the input layer and the biases of neurons in hidden\nlayer are randomly generated, the weights of the output layer can be\nanalytically determined. ELM has been achieved good results for a large number\nof classification tasks. In this paper, a new extreme learning machine called\nrough extreme learning machine (RELM) was proposed. RELM uses rough set to\ndivide data into upper approximation set and lower approximation set, and the\ntwo approximation sets are utilized to train upper approximation neurons and\nlower approximation neurons. In addition, an attribute reduction is executed in\nthis algorithm to remove redundant attributes. The experimental results showed,\ncomparing with the comparison algorithms, RELM can get a better accuracy and\nrepeatability in most cases, RELM can not only maintain the advantages of fast\nspeed, but also effectively cope with the classification task for\nhigh-dimensional data.\n"]},
{"authors": ["Jason Liang", "Elliot Meyerson", "Risto Miikkulainen"], "title": ["Evolutionary Architecture Search For Deep Multitask Networks"], "date": ["2018-03-10T03:02:09Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.03745v1"], "summary": ["  Multitask learning, i.e. learning several tasks at once with the same neural\nnetwork, can improve performance in each of the tasks. Designing deep neural\nnetwork architectures for multitask learning is a challenge: There are many\nways to tie the tasks together, and the design choices matter. The size and\ncomplexity of this problem exceeds human design ability, making it a compelling\ndomain for evolutionary optimization. Using the existing state of the art soft\nordering architecture as the starting point, methods for evolving the modules\nof this architecture and for evolving the overall topology or routing between\nmodules are evaluated in this paper. A synergetic approach of evolving custom\nroutings with evolved, shared modules for each task is found to be very\npowerful, significantly improving the state of the art in the Omniglot\nmultitask, multialphabet character recognition domain. This result demonstrates\nhow evolution can be instrumental in advancing deep neural network and complex\nsystem design in general.\n"]},
{"authors": ["Kiran K. Thekumparampil", "Chong Wang", "Sewoong Oh", "Li-Jia Li"], "title": ["Attention-based Graph Neural Network for Semi-supervised Learning"], "date": ["2018-03-10T02:01:35Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.03735v1"], "summary": ["  Recently popularized graph neural networks achieve the state-of-the-art\naccuracy on a number of standard benchmark datasets for graph-based\nsemi-supervised learning, improving significantly over existing approaches.\nThese architectures alternate between a propagation layer that aggregates the\nhidden states of the local neighborhood and a fully-connected layer. Perhaps\nsurprisingly, we show that a linear model, that removes all the intermediate\nfully-connected layers, is still able to achieve a performance comparable to\nthe state-of-the-art models. This significantly reduces the number of\nparameters, which is critical for semi-supervised learning where number of\nlabeled examples are small. This in turn allows a room for designing more\ninnovative propagation layers. Based on this insight, we propose a novel graph\nneural network that removes all the intermediate fully-connected layers, and\nreplaces the propagation layers with attention mechanisms that respect the\nstructure of the graph. The attention mechanism allows us to learn a dynamic\nand adaptive local summary of the neighborhood to achieve more accurate\npredictions. In a number of experiments on benchmark citation networks\ndatasets, we demonstrate that our approach outperforms competing methods. By\nexamining the attention weights among neighbors, we show that our model\nprovides some interesting insights on how neighbors influence each other.\n"]},
{"authors": ["Mahmoud Hamandi", "Mike D'Arcy", "Pooyan Fazli"], "title": ["DeepMoTIon: Learning to Navigate Like Humans"], "date": ["2018-03-09T23:36:38Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.03719v1"], "summary": ["  We present a novel human-aware navigation approach, where the robot learns to\nmimic humans to navigate safely in crowds. The presented model referred to as\nDeepMoTIon, is trained with pedestrian surveillance data to predict human\nvelocity. The robot processes LiDAR scans via the trained network to navigate\nto the target location. We conduct extensive experiments to assess the\ndifferent components of our network and prove the necessity of each to imitate\nhumans. Our experiments show that DeepMoTIon outperforms state-of-the-art in\nterms of human imitation and reaches the target on 100% of the test cases\nwithout breaching humans' safe distance.\n"]},
{"authors": ["Arnab Ghosh", "Viveka Kulharia", "Vinay Namboodiri", "Philip H. S. Torr", "Puneet K. Dokania"], "title": ["Multi-Agent Diverse Generative Adversarial Networks"], "date": ["2017-04-10T15:26:23Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1704.02906v2"], "summary": ["  We propose an intuitive generalization to the Generative Adversarial Networks\n(GANs) and its conditional variants to address the well known mode collapse\nproblem. Firstly, we propose a multi-agent GAN architecture incorporating\nmultiple generators and one discriminator. Secondly, to enforce different\ngenerators to capture diverse high probability modes, we modify discriminator's\nobjective function where along with finding the real and fake samples, the\ndiscriminator has to identify the generator that generated the fake sample.\nIntuitively, to succeed in this task, the discriminator must learn to push\ndifferent generators towards different identifiable modes. Our framework\n(MAD-GAN) is generalizable in the sense that it can be easily combined with\nother existing variants of GANs to produce diverse samples. We perform\nextensive experiments on synthetic and real datasets and compare MAD-GAN with\ndifferent variants of GAN. We show high quality diverse sample generations for\nthe challenging tasks such as image-to-image translation (known to learn delta\ndistribution) and face generation. In addition, we show that MAD-GAN is able to\ndisentangle different modalities even when trained using highly challenging\nmulti-view dataset (mixture of forests, icebergs, bedrooms etc). In the end, we\nalso show its efficacy for the unsupervised feature representation task. In the\nappendix we introduce a similarity based competing objective which encourages\nthe different generators to generate varied samples judged by a user defined\nsimilarity metric. We show extensive evaluations on a 1-D setting of mixture of\ngaussians for non parametric density estimation. The theoretical proofs back\nthe efficacy of the framework and explains why various generators are pushed\ntowards distinct clusters of modes.\n"]},
{"authors": ["Jonathan Frankle", "Michael Carbin"], "title": ["The Lottery Ticket Hypothesis: Training Pruned Neural Networks"], "date": ["2018-03-09T18:51:28Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.03635v1"], "summary": ["  Recent work on neural network pruning indicates that, at training time,\nneural networks need to be significantly larger in size than is necessary to\nrepresent the eventual functions that they learn. This paper articulates a new\nhypothesis to explain this phenomenon. This conjecture, which we term the\n\"lottery ticket hypothesis,\" proposes that successful training depends on lucky\nrandom initialization of a smaller subcomponent of the network. Larger networks\nhave more of these \"lottery tickets,\" meaning they are more likely to luck out\nwith a subcomponent initialized in a configuration amenable to successful\noptimization.\n  This paper conducts a series of experiments with XOR and MNIST that support\nthe lottery ticket hypothesis. In particular, we identify these\nfortuitously-initialized subcomponents by pruning low-magnitude weights from\ntrained networks. We then demonstrate that these subcomponents can be\nsuccessfully retrained in isolation so long as the subnetworks are given the\nsame initializations as they had at the beginning of the training process.\nInitialized as such, these small networks reliably converge successfully, often\nfaster than the original network at the same level of accuracy. However, when\nthese subcomponents are randomly reinitialized or rearranged, they perform\nworse than the original network. In other words, large networks that train\nsuccessfully contain small subnetworks with initializations conducive to\noptimization.\n  The lottery ticket hypothesis and its connection to pruning are a step toward\ndeveloping architectures, initializations, and training strategies that make it\npossible to solve the same problems with much smaller networks.\n"]},
{"authors": ["Hussain Kazmi", "Johan Suykens", "Johan Driesen"], "title": ["Valuing knowledge, information and agency in Multi-agent Reinforcement\n  Learning: a case study in smart buildings"], "date": ["2018-03-09T12:48:03Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.03491v1"], "summary": ["  Increasing energy efficiency in buildings can reduce costs and emissions\nsubstantially. Historically, this has been treated as a local, or single-agent,\noptimization problem. However, many buildings utilize the same types of thermal\nequipment e.g. electric heaters and hot water vessels. During operation,\noccupants in these buildings interact with the equipment differently thereby\ndriving them to diverse regions in the state-space. Reinforcement learning\nagents can learn from these interactions, recorded as sensor data, to optimize\nthe overall energy efficiency. However, if these agents operate individually at\na household level, they can not exploit the replicated structure in the\nproblem. In this paper, we demonstrate that this problem can indeed benefit\nfrom multi-agent collaboration by making use of targeted exploration of the\nstate-space allowing for better generalization. We also investigate trade-offs\nbetween integrating human knowledge and additional sensors. Results show that\nsavings of over 40% are possible with collaborative multi-agent systems making\nuse of either expert knowledge or additional sensors with no loss of occupant\ncomfort. We find that such multi-agent systems comfortably outperform\ncomparable single agent systems.\n"]},
{"authors": ["Maarten Bieshaar", "Stefan Zernetsch", "Andreas Hubert", "Bernhard Sick", "Konrad Doll"], "title": ["Cooperative Starting Movement Detection of Cyclists Using Convolutional\n  Neural Networks and a Boosted Stacking Ensemble"], "date": ["2018-03-09T12:27:14Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.03487v1"], "summary": ["  In future, vehicles and other traffic participants will be interconnected and\nequipped with various types of sensors, allowing for cooperation on different\nlevels, such as situation prediction or intention detection. In this article we\npresent a cooperative approach for starting movement detection of cyclists\nusing a boosted stacking ensemble approach realizing feature- and decision\nlevel cooperation. We introduce a novel method based on a 3D Convolutional\nNeural Network (CNN) to detect starting motions on image sequences by learning\nspatio-temporal features. The CNN is complemented by a smart device based\nstarting movement detection originating from smart devices carried by the\ncyclist. Both model outputs are combined in a stacking ensemble approach using\nan extreme gradient boosting classifier resulting in a fast and yet robust\ncooperative starting movement detector. We evaluate our cooperative approach on\nreal-world data originating from experiments with 49 test subjects consisting\nof 84 starting motions.\n"]},
{"authors": ["Akira Taniguchi", "Yoshinobu Hagiwara", "Tadahiro Taniguchi", "Tetsunari Inamura"], "title": ["Online Spatial Concept and Lexical Acquisition with Simultaneous\n  Localization and Mapping"], "date": ["2017-04-15T17:18:11Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1704.04664v2"], "summary": ["  In this paper, we propose an online learning algorithm based on a\nRao-Blackwellized particle filter for spatial concept acquisition and mapping.\nWe have proposed a nonparametric Bayesian spatial concept acquisition model\n(SpCoA). We propose a novel method (SpCoSLAM) integrating SpCoA and FastSLAM in\nthe theoretical framework of the Bayesian generative model. The proposed method\ncan simultaneously learn place categories and lexicons while incrementally\ngenerating an environmental map. Furthermore, the proposed method has scene\nimage features and a language model added to SpCoA. In the experiments, we\ntested online learning of spatial concepts and environmental maps in a novel\nenvironment of which the robot did not have a map. Then, we evaluated the\nresults of online learning of spatial concepts and lexical acquisition. The\nexperimental results demonstrated that the robot was able to more accurately\nlearn the relationships between words and the place in the environmental map\nincrementally by using the proposed method.\n"]},
{"authors": ["Akira Taniguchi", "Yoshinobu Hagiwara", "Tadahiro Taniguchi", "Tetsunari Inamura"], "title": ["SpCoSLAM 2.0: An Improved and Scalable Online Learning of Spatial\n  Concepts and Language Models with Mapping"], "date": ["2018-03-09T12:06:04Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.03481v1"], "summary": ["  In this paper, we propose a novel online learning algorithm, SpCoSLAM 2.0 for\nspatial concepts and lexical acquisition with higher accuracy and scalability.\nIn previous work, we proposed SpCoSLAM as an online learning algorithm based on\nthe Rao--Blackwellized particle filter. However, this conventional algorithm\nhad problems such as the decrease of the estimation accuracy due to the\ninfluence of the early stages of learning as well as the increase of the\ncomputational complexity with the increase of the training data. Therefore, we\nfirst develop an improved algorithm by introducing new techniques such as\nrejuvenation. Next, we develop a scalable algorithm to reduce the calculation\ntime while maintaining a higher accuracy than the conventional algorithm. In\nthe experiment, we evaluate and compare the estimation accuracy and calculation\ntime of the proposed algorithm, conventional online algorithm, and batch\nlearning. The experimental results demonstrate that the proposed algorithm not\nonly exceeds the accuracy of the conventional algorithm but also capable of\nachieving an accuracy comparable to that of batch learning. In addition, the\nproposed algorithm showed that the calculation time does not depend on the\namount of training data and becomes constant for each step with the scalable\nalgorithm.\n"]},
{"authors": ["Maarten Bieshaar", "G\u00fcnther Reitberger", "Viktor Kre\u00df", "Stefan Zernetsch", "Konrad Doll", "Erich Fuchs", "Bernhard Sick"], "title": ["Highly Automated Learning for Improved Active Safety of Vulnerable Road\n  Users"], "date": ["2018-03-09T11:57:36Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.03479v1"], "summary": ["  Highly automated driving requires precise models of traffic participants.\nMany state of the art models are currently based on machine learning\ntechniques. Among others, the required amount of labeled data is one major\nchallenge. An autonomous learning process addressing this problem is proposed.\nThe initial models are iteratively refined in three steps: (1) detection and\ncontext identification, (2) novelty detection and active learning and (3)\nonline model adaption.\n"]},
{"authors": ["Alexander Boer", "Giovanni Sileno"], "title": ["Institutional Metaphors for Designing Large-Scale Distributed AI versus\n  AI Techniques for Running Institutions"], "date": ["2018-03-09T07:59:21Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.03407v1"], "summary": ["  Artificial Intelligence (AI) started out with an ambition to reproduce the\nhuman mind, but, as the sheer scale of that ambition became apparent, quickly\nretreated into either studying specialized intelligent behaviours, or proposing\noverarching architectural concepts for interfacing specialized intelligent\nbehaviour components, conceived of as agents in a kind of organization. This\nagent-based modeling paradigm, in turn, proves to have interesting applications\nin understanding, simulating, and predicting the behaviour of social and legal\nstructures on an aggregate level. This chapter examines a number of relevant\ncross-cutting concerns, conceptualizations, modeling problems and design\nchallenges in large-scale distributed Artificial Intelligence, as well as in\ninstitutional systems, and identifies potential grounds for novel advances.\n"]},
{"authors": ["Daniel S. Weld", "Gagan Bansal"], "title": ["Intelligible Artificial Intelligence"], "date": ["2018-03-09T06:38:55Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.04263v1"], "summary": ["  Since Artificial Intelligence (AI) software uses techniques like deep\nlookahead search and stochastic optimization of huge neural networks to fit\nmammoth datasets, it often results in complex behavior that is difficult for\npeople to understand. Yet organizations are deploying AI algorithms in many\nmission-critical settings. In order to trust their behavior, we must make it\nintelligible --- either by using inherently interpretable models or by\ndeveloping methods for explaining otherwise overwhelmingly complex decisions by\nlocal approximation, vocabulary alignment, and interactive dialog.\n"]},
{"authors": ["Adam Klivans", "Pravesh K. Kothari", "Raghu Meka"], "title": ["Efficient Algorithms for Outlier-Robust Regression"], "date": ["2018-03-08T18:30:31Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.03241v2"], "summary": ["  We give the first polynomial-time algorithm for performing linear or\npolynomial regression resilient to adversarial corruptions in both examples and\nlabels.\n  Given a sufficiently large (polynomial-size) training set drawn i.i.d. from\ndistribution D and subsequently corrupted on some fraction of points, our\nalgorithm outputs a linear function whose squared error is close to the squared\nerror of the best-fitting linear function with respect to D, assuming that the\nmarginal distribution of D over the input space is \\emph{certifiably\nhypercontractive}. This natural property is satisfied by many well-studied\ndistributions such as Gaussian, strongly log-concave distributions and, uniform\ndistribution on the hypercube among others. We also give a simple statistical\nlower bound showing that some distributional assumption is necessary to succeed\nin this setting.\n  These results are the first of their kind and were not known to be even\ninformation-theoretically possible prior to our work.\n  Our approach is based on the sum-of-squares (SoS) method and is inspired by\nthe recent applications of the method for parameter recovery problems in\nunsupervised learning. Our algorithm can be seen as a natural convex relaxation\nof the following conceptually simple non-convex optimization problem: find a\nlinear function and a large subset of the input corrupted sample such that the\nleast squares loss of the function over the subset is minimized over all\npossible large subsets.\n"]},
{"authors": ["Huan Gui", "Qi Zhu", "Liyuan Liu", "Aston Zhang", "Jiawei Han"], "title": ["Expert Finding in Heterogeneous Bibliographic Networks with\n  Locally-trained Embeddings"], "date": ["2018-03-09T03:28:36Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.03370v1"], "summary": ["  Expert finding is an important task in both industry and academia. It is\nchallenging to rank candidates with appropriate expertise for various queries.\nIn addition, different types of objects interact with one another, which\nnaturally forms heterogeneous information networks. We study the task of expert\nfinding in heterogeneous bibliographical networks based on two aspects: textual\ncontent analysis and authority ranking. Regarding the textual content analysis,\nwe propose a new method for query expansion via locally-trained embedding\nlearning with concept hierarchy as guidance, which is particularly tailored for\nspecific queries with narrow semantic meanings. Compared with global embedding\nlearning, locally-trained embedding learning projects the terms into a latent\nsemantic space constrained on relevant topics, therefore it preserves more\nprecise and subtle information for specific queries. Considering the candidate\nranking, the heterogeneous information network structure, while being largely\nignored in the previous studies of expert finding, provides additional\ninformation. Specifically, different types of interactions among objects play\ndifferent roles. We propose a ranking algorithm to estimate the authority of\nobjects in the network, treating each strongly-typed edge type individually. To\ndemonstrate the effectiveness of the proposed framework, we apply the proposed\nmethod to a large-scale bibliographical dataset with over two million entries\nand one million researcher candidates. The experiment results show that the\nproposed framework outperforms existing methods for both general and specific\nqueries.\n"]},
{"authors": ["Regis Riveret", "Pietro Baroni", "Yang Gao", "Guido Governatori", "Antonino Rotolo", "Giovanni Sartor"], "title": ["A Labelling Framework for Probabilistic Argumentation"], "date": ["2017-08-01T00:12:58Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1708.00109v2"], "summary": ["  The combination of argumentation and probability paves the way to new\naccounts of qualitative and quantitative uncertainty, thereby offering new\ntheoretical and applicative opportunities. Due to a variety of interests,\nprobabilistic argumentation is approached in the literature with different\nframeworks, pertaining to structured and abstract argumentation, and with\nrespect to diverse types of uncertainty, in particular the uncertainty on the\ncredibility of the premises, the uncertainty about which arguments to consider,\nand the uncertainty on the acceptance status of arguments or statements.\nTowards a general framework for probabilistic argumentation, we investigate a\nlabelling-oriented framework encompassing a basic setting for rule-based\nargumentation and its (semi-) abstract account, along with diverse types of\nuncertainty. Our framework provides a systematic treatment of various kinds of\nuncertainty and of their relationships and allows us to back or question\nassertions from the literature.\n"]},
{"authors": ["Nesime Tatbul", "Tae Jun Lee", "Stan Zdonik", "Justin Gottschlich"], "title": ["A New Model for Evaluating Range-Based Anomaly Detection Algorithms"], "date": ["2018-03-08T21:49:38Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.03639v1"], "summary": ["  Classical anomaly detection (AD) is principally concerned with point-based\nanomalies, anomalies that occur at a single point in time. While point-based\nanomalies are useful, many real-world anomalies are range-based, meaning they\noccur over a period of time. Therefore, applying classical point-based accuracy\nmeasures to range-based AD systems can be misleading. In this paper, we present\na new mathematical model that more accurately gauges the classification\ncorrectness of AD systems for range-based anomalies. Unlike prior work, our\nmathematical definitions are a superset of the classical AD definitions,\nenabling our system to also subsume point-based anomalies. Moreover, our system\nis broadly generalizable and provides a number of specialization functions that\ncan control the application's bias along a multi-dimensional axis.\n"]},
{"authors": ["I\u00f1igo Casanueva", "Pawe\u0142 Budzianowski", "Pei-Hao Su", "Stefan Ultes", "Lina Rojas-Barahona", "Bo-Hsiang Tseng", "Milica Ga\u0161i\u0107"], "title": ["Feudal Reinforcement Learning for Dialogue Management in Large Domains"], "date": ["2018-03-08T18:05:18Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.03232v1"], "summary": ["  Reinforcement learning (RL) is a promising approach to solve dialogue policy\noptimisation. Traditional RL algorithms, however, fail to scale to large\ndomains due to the curse of dimensionality. We propose a novel Dialogue\nManagement architecture, based on Feudal RL, which decomposes the decision into\ntwo steps; a first step where a master policy selects a subset of primitive\nactions, and a second step where a primitive action is chosen from the selected\nsubset. The structural information included in the domain ontology is used to\nabstract the dialogue state space, taking the decisions at each step using\ndifferent parts of the abstracted state. This, combined with an information\nsharing mechanism between slots, increases the scalability to large domains. We\nshow that an implementation of this approach, based on Deep-Q Networks,\nsignificantly outperforms previous state of the art in several dialogue domains\nand environments, without the need of any additional reward signal.\n"]},
{"authors": ["Gregory Farquhar", "Tim Rockt\u00e4schel", "Maximilian Igl", "Shimon Whiteson"], "title": ["TreeQN and ATreeC: Differentiable Tree-Structured Models for Deep\n  Reinforcement Learning"], "date": ["2017-10-31T11:54:35Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.11417v2"], "summary": ["  Combining deep model-free reinforcement learning with on-line planning is a\npromising approach to building on the successes of deep RL. On-line planning\nwith look-ahead trees has proven successful in environments where transition\nmodels are known a priori. However, in complex environments where transition\nmodels need to be learned from data, the deficiencies of learned models have\nlimited their utility for planning. To address these challenges, we propose\nTreeQN, a differentiable, recursive, tree-structured model that serves as a\ndrop-in replacement for any value function network in deep RL with discrete\nactions. TreeQN dynamically constructs a tree by recursively applying a\ntransition model in a learned abstract state space and then aggregating\npredicted rewards and state-values using a tree backup to estimate Q-values. We\nalso propose ATreeC, an actor-critic variant that augments TreeQN with a\nsoftmax layer to form a stochastic policy network. Both approaches are trained\nend-to-end, such that the learned model is optimised for its actual use in the\ntree. We show that TreeQN and ATreeC outperform n-step DQN and A2C on a\nbox-pushing task, as well as n-step DQN and value prediction networks (Oh et\nal. 2017) on multiple Atari games. Furthermore, we present ablation studies\nthat demonstrate the effect of different auxiliary losses on learning\ntransition models.\n"]},
{"authors": ["Jade Shi", "Rhiju Das", "Vijay S. Pande"], "title": ["SentRNA: Improving computational RNA design by incorporating a prior of\n  human design strategies"], "date": ["2018-03-08T15:12:16Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.03146v1"], "summary": ["  Designing RNA sequences that fold into specific structures and perform\ndesired biological functions is an emerging field in bioengineering with broad\napplications from intracellular chemical catalysis to cancer therapy via\nselective gene silencing. Effective RNA design requires first solving the\ninverse folding problem: given a target structure, propose a sequence that\nfolds into that structure. Although significant progress has been made in\ndeveloping computational algorithms for this purpose, current approaches are\nineffective at designing sequences for complex targets, limiting their utility\nin real-world applications. However, an alternative that has shown\nsignificantly higher performance are human players of the online RNA design\ngame EteRNA. Through many rounds of gameplay, these players have developed a\ncollective library of \"human\" rules and strategies for RNA design that have\nproven to be more effective than current computational approaches, especially\nfor complex targets. Here, we present an RNA design agent, SentRNA, which\nconsists of a fully-connected neural network trained using the $eternasolves$\ndataset, a set of $1.8 x 10^4$ player-submitted sequences across 724 unique\ntargets. The agent first predicts an initial sequence for a target using the\ntrained network, and then refines that solution if necessary using a short\nadaptive walk utilizing a canon of standard design moves. Through this\napproach, we observe SentRNA can learn and apply human-like design strategies\nto solve several complex targets previously unsolvable by any computational\napproach. We thus demonstrate that incorporating a prior of human design\nstrategies into a computational agent can significantly boost its performance,\nand suggests a new paradigm for machine-based RNA design.\n"]},
{"authors": ["Faisal N. Abu-Khzam", "Rana H. Mouawi"], "title": ["Concise Fuzzy Representation of Big Graphs: a Dimensionality Reduction\n  Approach"], "date": ["2018-03-08T14:44:56Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.03114v1"], "summary": ["  The enormous amount of data to be represented using large graphs exceeds in\nsome cases the resources of a conventional computer. Edges in particular can\ntake up a considerable amount of memory as compared to the number of nodes.\nHowever, rigorous edge storage might not always be essential to be able to draw\nthe needed conclusions. A similar problem takes records with many variables and\nattempts to extract the most discernible features. It is said that the\n\"dimension\" of this data is reduced. Following an approach with the same\nobjective in mind, we can map a graph representation to a k-dimensional space\nand answer queries of neighboring nodes by measuring Euclidean distances. The\naccuracy of our answers would decrease but would be compensated for by fuzzy\nlogic which gives an idea about the likelihood of error. This method allows for\nreasonable representation in memory while maintaining a fair amount of useful\ninformation. Promising preliminary results are obtained and reported by testing\nthe proposed approach on a number of Facebook graphs.\n"]},
{"authors": ["Drew A. Hudson", "Christopher D. Manning"], "title": ["Compositional Attention Networks for Machine Reasoning"], "date": ["2018-03-08T12:37:14Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.03067v1"], "summary": ["  We present the MAC network, a novel fully differentiable neural network\narchitecture, designed to facilitate explicit and expressive reasoning. Drawing\ninspiration from first principles of computer organization, MAC moves away from\nmonolithic black-box neural architectures towards a design that encourages both\ntransparency and versatility. The model approaches problems by decomposing them\ninto a series of attention-based reasoning steps, each performed by a novel\nrecurrent Memory, Attention, and Composition (MAC) cell that maintains a\nseparation between control and memory. By stringing the cells together and\nimposing structural constraints that regulate their interaction, MAC\neffectively learns to perform iterative reasoning processes that are directly\ninferred from the data in an end-to-end approach. We demonstrate the model's\nstrength, robustness and interpretability on the challenging CLEVR dataset for\nvisual reasoning, achieving a new state-of-the-art 98.9% accuracy, halving the\nerror rate of the previous best model. More importantly, we show that the model\nis computationally-efficient and data-efficient, in particular requiring 5x\nless data than existing models to achieve strong results.\n"]},
{"authors": ["Chengwei Zhang", "Xiaohong Li", "Jianye Hao", "Siqi Chen", "Karl Tuyls", "Wanli Xue"], "title": ["SA-IGA: A Multiagent Reinforcement Learning Method Towards Socially\n  Optimal Outcomes"], "date": ["2018-03-08T10:02:42Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.03021v1"], "summary": ["  In multiagent environments, the capability of learning is important for an\nagent to behave appropriately in face of unknown opponents and dynamic\nenvironment. From the system designer's perspective, it is desirable if the\nagents can learn to coordinate towards socially optimal outcomes, while also\navoiding being exploited by selfish opponents. To this end, we propose a novel\ngradient ascent based algorithm (SA-IGA) which augments the basic\ngradient-ascent algorithm by incorporating social awareness into the policy\nupdate process. We theoretically analyze the learning dynamics of SA-IGA using\ndynamical system theory and SA-IGA is shown to have linear dynamics for a wide\nrange of games including symmetric games. The learning dynamics of two\nrepresentative games (the prisoner's dilemma game and the coordination game)\nare analyzed in details. Based on the idea of SA-IGA, we further propose a\npractical multiagent learning algorithm, called SA-PGA, based on Q-learning\nupdate rule. Simulation results show that SA-PGA agent can achieve higher\nsocial welfare than previous social-optimality oriented Conditional Joint\nAction Learner (CJAL) and also is robust against individually rational\nopponents by reaching Nash equilibrium solutions.\n"]},
{"authors": ["Zlatan Ajanovic", "Michael Stolz", "Martin Horn"], "title": ["A novel model-based heuristic for energy optimal motion planning for\n  automated driving"], "date": ["2017-12-11T11:24:23Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1712.03719v2"], "summary": ["  Predictive motion planning is the key to achieve energy-efficient driving,\nwhich is one of the main benefits of automated driving. Researchers have been\nstudying the planning of velocity trajectories, a simpler form of motion\nplanning, for over a decade now and many different methods are available.\nDynamic programming has shown to be the most common choice due to its numerical\nbackground and ability to include nonlinear constraints and models. Although\nplanning of an optimal trajectory is done in a systematic way, dynamic\nprogramming does not use any knowledge about the considered problem to guide\nthe exploration and therefore explores all possible trajectories.\n  A* is a search algorithm which enables using knowledge about the problem to\nguide the exploration to the most promising solutions first. Knowledge has to\nbe represented in a form of a heuristic function, which gives an optimistic\nestimate of cost for transitioning to the final state, which is not a\nstraightforward task. This paper presents a novel heuristics incorporating air\ndrag and auxiliary power as well as operational costs of the vehicle, besides\nkinetic and potential energy and rolling resistance known in the literature.\nFurthermore, optimal cruising velocity, which depends on vehicle aerodynamic\nproperties and auxiliary power, is derived. Results are compared for different\nvariants of heuristic functions and dynamic programming as well.\n"]},
{"authors": ["Burak Demirel", "Arunselvan Ramaswamy", "Daniel E. Quevedo", "Holger Karl"], "title": ["DeepCAS: A Deep Reinforcement Learning Algorithm for Control-Aware\n  Scheduling"], "date": ["2018-03-08T08:20:43Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.02998v1"], "summary": ["  We consider networked control systems consisting of multiple independent\nclosed-loop control subsystems, operating over a shared communication network.\nSuch systems are ubiquitous in cyber-physical systems, Internet of Things, and\nlarge-scale industrial systems. In many large-scale settings, the size of the\ncommunication network is smaller than the size of the system. In consequence,\nscheduling issues arise. The main contribution of this paper is to develop a\ndeep reinforcement learning-based \\emph{control-aware} scheduling\n(\\textsc{DeepCAS}) algorithm to tackle these issues. We use the following\n(optimal) design strategy: First, we synthesize an optimal controller for each\nsubsystem; next, we design learning algorithm that adapts to the chosen\nsubsystem (plant) and controller. As a consequence of this adaptation, our\nalgorithm finds a schedule that minimizes the \\emph{control loss}. We present\nempirical results to show that \\textsc{DeepCAS} finds schedules with better\nperformance than periodic ones. Finally, we illustrate that our algorithm can\nbe used for \\emph{scheduling and resource allocation in more general networked\ncontrol settings than the above-mentioned one}.\n"]},
{"authors": ["Jiatao Gu", "Yong Wang", "Kyunghyun Cho", "Victor O. K. Li"], "title": ["Search Engine Guided Non-Parametric Neural Machine Translation"], "date": ["2017-05-20T06:53:09Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1705.07267v2"], "summary": ["  In this paper, we extend an attention-based neural machine translation (NMT)\nmodel by allowing it to access an entire training set of parallel sentence\npairs even after training. The proposed approach consists of two stages. In the\nfirst stage--retrieval stage--, an off-the-shelf, black-box search engine is\nused to retrieve a small subset of sentence pairs from a training set given a\nsource sentence. These pairs are further filtered based on a fuzzy matching\nscore based on edit distance. In the second stage--translation stage--, a novel\ntranslation model, called translation memory enhanced NMT (TM-NMT), seamlessly\nuses both the source sentence and a set of retrieved sentence pairs to perform\nthe translation. Empirical evaluation on three language pairs (En-Fr, En-De,\nand En-Es) shows that the proposed approach significantly outperforms the\nbaseline approach and the improvement is more significant when more relevant\nsentence pairs were retrieved.\n"]},
{"authors": ["M Ferguson", "K. H. Law"], "title": ["Learning Robust and Adaptive Real-World Continuous Control Using\n  Simulation and Transfer Learning"], "date": ["2018-02-13T09:23:14Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04520v2"], "summary": ["  We use model-free reinforcement learning, extensive simulation, and transfer\nlearning to develop a continuous control algorithm that has good zero-shot\nperformance in a real physical environment. We train a simulated agent to act\noptimally across a set of similar environments, each with dynamics drawn from a\nprior distribution. We propose that the agent is able to adjust its actions\nalmost immediately, based on small set of observations. This robust and\nadaptive behavior is enabled by using a policy gradient algorithm with an Long\nShort Term Memory (LSTM) function approximation. Finally, we train an agent to\nnavigate a two-dimensional environment with uncertain dynamics and noisy\nobservations. We demonstrate that this agent has good zero-shot performance in\na real physical environment. Our preliminary results indicate that the agent is\nable to infer the environmental dynamics after only a few timesteps, and adjust\nits actions accordingly.\n"]},
{"authors": ["Thanh Thi Nguyen"], "title": ["A Multi-Objective Deep Reinforcement Learning Framework"], "date": ["2018-03-08T04:50:21Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.02965v1"], "summary": ["  This paper presents a new multi-objective deep reinforcement learning (MODRL)\nframework based on deep Q-networks. We propose linear and non-linear methods to\ndevelop the MODRL framework that includes both single-policy and multi-policy\nstrategies. The experimental results on a deep sea treasure environment\nindicate that the proposed approach is able to converge to the optimal Pareto\nsolutions. The proposed framework is generic, which allows implementation of\ndifferent deep reinforcement learning algorithms in various complex\nenvironments. Details of the framework implementation can be referred to\nhttp://www.deakin.edu.au/~thanhthi/drl.htm.\n"]},
{"authors": ["Chengliang Yang", "Anand Rangarajan", "Sanjay Ranka"], "title": ["Visual Explanations From Deep 3D Convolutional Neural Networks for\n  Alzheimer's Disease Classification"], "date": ["2018-03-07T07:07:39Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.02544v2"], "summary": ["  We develop three efficient approaches for generating visual explanations from\n3D convolutional neural networks (3D-CNNs) for Alzheimer's disease\nclassification. One approach conducts sensitivity analysis on hierarchical 3D\nimage segmentation, and the other two visualize network activations on a\nspatial map. Visual checks and a quantitative localization benchmark indicate\nthat all approaches identify important brain parts for Alzheimer's disease\ndiagnosis. Comparative analysis show that the sensitivity analysis based\napproach has difficulty handling loosely distributed cerebral cortex, and\napproaches based on visualization of activations are constrained by the\nresolution of the convolutional layer. The complementarity of these methods\nimproves the understanding of 3D-CNNs in Alzheimer's disease classification\nfrom different perspectives.\n"]},
{"authors": ["Xinyun Chen", "Chang Liu", "Dawn Song"], "title": ["Towards Synthesizing Complex Programs from Input-Output Examples"], "date": ["2017-06-05T11:44:35Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1706.01284v4"], "summary": ["  In recent years, deep learning techniques have been developed to improve the\nperformance of program synthesis from input-output examples. Albeit its\nsignificant progress, the programs that can be synthesized by state-of-the-art\napproaches are still simple in terms of their complexity. In this work, we move\na significant step forward along this direction by proposing a new class of\nchallenging tasks in the domain of program synthesis from input-output\nexamples: learning a context-free parser from pairs of input programs and their\nparse trees. We show that this class of tasks are much more challenging than\npreviously studied tasks, and the test accuracy of existing approaches is\nalmost 0%.\n  We tackle the challenges by developing three novel techniques inspired by\nthree novel observations, which reveal the key ingredients of using deep\nlearning to synthesize a complex program. First, the use of a\nnon-differentiable machine is the key to effectively restrict the search space.\nThus our proposed approach learns a neural program operating a domain-specific\nnon-differentiable machine. Second, recursion is the key to achieve\ngeneralizability. Thus, we bake-in the notion of recursion in the design of our\nnon-differentiable machine. Third, reinforcement learning is the key to learn\nhow to operate the non-differentiable machine, but it is also hard to train the\nmodel effectively with existing reinforcement learning algorithms from a cold\nboot. We develop a novel two-phase reinforcement learning-based search\nalgorithm to overcome this issue. In our evaluation, we show that using our\nnovel approach, neural parsing programs can be learned to achieve 100% test\naccuracy on test inputs that are 500x longer than the training samples.\n"]},
{"authors": ["Atrisha Sarkar"], "title": ["A Brandom-ian view of Reinforcement Learning towards strong-AI"], "date": ["2018-03-07T23:26:49Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.02912v1"], "summary": ["  The analytic philosophy of Robert Brandom, based on the ideas of pragmatism,\npaints a picture of sapience, through inferentialism. In this paper, we present\na theory, that utilizes essential elements of Brandom's philosophy, towards the\nobjective of achieving strong-AI. We do this by connecting the constitutive\nelements of reinforcement learning and the Game Of Giving and Asking For\nReasons. Further, following Brandom's prescriptive thoughts, we restructure the\npopular reinforcement learning algorithm A3C, and show that RL algorithms can\nbe tuned towards the objective of strong-AI.\n"]},
{"authors": ["Fatma Faruq", "Bruno Lacerda", "Nick Hawes", "David Parker"], "title": ["Simultaneous Task Allocation and Planning Under Uncertainty"], "date": ["2018-03-07T22:47:52Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.02906v1"], "summary": ["  We propose novel techniques for task allocation and planning in multi-robot\nsystems operating in uncertain environments. Task allocation is performed\nsimultaneously with planning, which provides more detailed information about\nindividual robot behaviour, but also exploits the independence between tasks to\ndo so efficiently. We use Markov decision processes to model robot behaviour\nand linear temporal logic to specify tasks and safety constraints. Building\nupon techniques and tools from formal verification, we show how to generate a\nsequence of multi-robot policies, iteratively refining them to reallocate tasks\nif individual robots fail, and providing probabilistic guarantees on the\nperformance (and safe operation) of the team of robots under the resulting\npolicy. We implement our approach and evaluate it on a benchmark multi-robot\nexample.\n"]},
{"authors": ["Lajanugen Logeswaran", "Honglak Lee"], "title": ["An efficient framework for learning sentence representations"], "date": ["2018-03-07T22:02:10Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.02893v1"], "summary": ["  In this work we propose a simple and efficient framework for learning\nsentence representations from unlabelled data. Drawing inspiration from the\ndistributional hypothesis and recent work on learning sentence representations,\nwe reformulate the problem of predicting the context in which a sentence\nappears as a classification problem. Given a sentence and its context, a\nclassifier distinguishes context sentences from other contrastive sentences\nbased on their vector representations. This allows us to efficiently learn\ndifferent types of encoding functions, and we show that the model learns\nhigh-quality sentence representations. We demonstrate that our sentence\nrepresentations outperform state-of-the-art unsupervised and supervised\nrepresentation learning methods on several downstream NLP tasks that involve\nunderstanding sentence semantics while achieving an order of magnitude speedup\nin training time.\n"]},
{"authors": ["Xiaoxia Wu", "Rachel Ward", "L\u00e9on Bottou"], "title": ["WNGrad: Learn the Learning Rate in Gradient Descent"], "date": ["2018-03-07T20:30:35Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.02865v1"], "summary": ["  Adjusting the learning rate schedule in stochastic gradient methods is an\nimportant unresolved problem which requires tuning in practice. If certain\nparameters of the loss function such as smoothness or strong convexity\nconstants are known, theoretical learning rate schedules can be applied.\nHowever, in practice, such parameters are not known, and the loss function of\ninterest is not convex in any case. The recently proposed batch normalization\nreparametrization is widely adopted in most neural network architectures today\nbecause, among other advantages, it is robust to the choice of Lipschitz\nconstant of the gradient in loss function, allowing one to set a large learning\nrate without worry. Inspired by batch normalization, we propose a general\nnonlinear update rule for the learning rate in batch and stochastic gradient\ndescent so that the learning rate can be initialized at a high value, and is\nsubsequently decreased according to gradient observations along the way. The\nproposed method is shown to achieve robustness to the relationship between the\nlearning rate and the Lipschitz constant, and near-optimal convergence rates in\nboth the batch and stochastic settings ($O(1/T)$ for smooth loss in the batch\nsetting, and $O(1/\\sqrt{T})$ for convex loss in the stochastic setting). We\nalso show through numerical evidence that such robustness of the proposed\nmethod extends to highly nonconvex and possibly non-smooth loss function in\ndeep learning problems.Our analysis establishes some first theoretical\nunderstanding into the observed robustness for batch normalization and weight\nnormalization.\n"]},
{"authors": ["Daniel Russo", "Benjamin Van Roy"], "title": ["Satisficing in Time-Sensitive Bandit Learning"], "date": ["2018-03-07T19:41:44Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.02855v1"], "summary": ["  Much of the recent literature on bandit learning focuses on algorithms that\naim to converge on an optimal action. One shortcoming is that this orientation\ndoes not account for time sensitivity, which can play a crucial role when\nlearning an optimal action requires much more information than near-optimal\nones. Indeed, popular approaches such as upper-confidence-bound methods and\nThompson sampling can fare poorly in such situations. We consider instead\nlearning a satisficing action, which is near-optimal while requiring less\ninformation, and propose satisficing Thompson sampling, an algorithm that\nserves this purpose. We establish a general bound on expected discounted regret\nand study the application of satisficing Thompson sampling to linear and\ninfinite-armed bandits, demonstrating arbitrarily large benefits over Thompson\nsampling. We also discuss the relation between the notion of satisficing and\nthe theory of rate distortion, which offers guidance on the selection of\nsatisficing actions.\n"]},
{"authors": ["Daniel Estrada"], "title": ["Value Alignment, Fair Play, and the Rights of Service Robots"], "date": ["2018-03-07T19:33:08Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.02852v1"], "summary": ["  Ethics and safety research in artificial intelligence is increasingly framed\nin terms of \"alignment\" with human values and interests. I argue that Turing's\ncall for \"fair play for machines\" is an early and often overlooked contribution\nto the alignment literature. Turing's appeal to fair play suggests a need to\ncorrect human behavior to accommodate our machines, a surprising inversion of\nhow value alignment is treated today. Reflections on \"fair play\" motivate a\nnovel interpretation of Turing's notorious \"imitation game\" as a condition not\nof intelligence but instead of value alignment: a machine demonstrates a\nminimal degree of alignment (with the norms of conversation, for instance) when\nit can go undetected when interrogated by a human. I carefully distinguish this\ninterpretation from the Moral Turing Test, which is not motivated by a\nprinciple of fair play, but instead depends on imitation of human moral\nbehavior. Finally, I consider how the framework of fair play can be used to\nsituate the debate over robot rights within the alignment literature. I argue\nthat extending rights to service robots operating in public spaces is \"fair\" in\nprecisely the sense that it encourages an alignment of interests between humans\nand machines.\n"]},
{"authors": ["Sean A. Cantrell"], "title": ["The emergent algebraic structure of RNNs and embeddings in NLP"], "date": ["2018-03-07T19:06:08Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.02839v1"], "summary": ["  We examine the algebraic and geometric properties of a uni-directional GRU\nand word embeddings trained end-to-end on a text classification task. A\nhyperparameter search over word embedding dimension, GRU hidden dimension, and\na linear combination of the GRU outputs is performed. We conclude that words\nnaturally embed themselves in a Lie group and that RNNs form a nonlinear\nrepresentation of the group. Appealing to these results, we propose a novel\nclass of recurrent-like neural networks and a word embedding scheme.\n"]},
{"authors": ["Ilias Diakonikolas", "Gautam Kamath", "Daniel M. Kane", "Jerry Li", "Jacob Steinhardt", "Alistair Stewart"], "title": ["Sever: A Robust Meta-Algorithm for Stochastic Optimization"], "date": ["2018-03-07T18:47:48Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.02815v1"], "summary": ["  In high dimensions, most machine learning methods are brittle to even a small\nfraction of structured outliers. To address this, we introduce a new\nmeta-algorithm that can take in a base learner such as least squares or\nstochastic gradient descent, and harden the learner to be resistant to\noutliers. Our method, Sever, possesses strong theoretical guarantees yet is\nalso highly scalable -- beyond running the base learner itself, it only\nrequires computing the top singular vector of a certain $n \\times d$ matrix. We\napply Sever on a drug design dataset and a spam classification dataset, and\nfind that in both cases it has substantially greater robustness than several\nbaselines. On the spam dataset, with $1\\%$ corruptions, we achieved $7.4\\%$\ntest error, compared to $13.4\\%-20.5\\%$ for the baselines, and $3\\%$ error on\nthe uncorrupted dataset. Similarly, on the drug design dataset, with $10\\%$\ncorruptions, we achieved $1.42$ mean-squared error test error, compared to\n$1.51$-$2.33$ for the baselines, and $1.23$ error on the uncorrupted dataset.\n"]},
{"authors": ["Adam Stooke", "Pieter Abbeel"], "title": ["Accelerated Methods for Deep Reinforcement Learning"], "date": ["2018-03-07T18:39:12Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.02811v1"], "summary": ["  Deep reinforcement learning (RL) has achieved many recent successes, yet\nexperiment turn-around time remains a key bottleneck in research and in\npractice. We investigate how to optimize existing deep RL algorithms for modern\ncomputers, specifically for a combination of CPUs and GPUs. We confirm that\nboth policy gradient and Q-value learning algorithms can be adapted to learn\nusing many parallel simulator instances. We further find it possible to train\nusing batch sizes considerably larger than are standard, without negatively\naffecting sample complexity or final performance. We leverage these facts to\nbuild a unified framework for parallelization that dramatically hastens\nexperiments in both classes of algorithm. All neural network computations use\nGPUs, accelerating both data collection and training. Our results include using\nan entire NVIDIA DGX-1 to learn successful strategies in Atari games in\nsingle-digit minutes, using both synchronous and asynchronous algorithms.\n"]},
{"authors": ["Dilek K\u00fc\u00e7\u00fck", "Do\u011fan K\u00fc\u00e7\u00fck"], "title": ["OntoWind: An Improved and Extended Wind Energy Ontology"], "date": ["2018-03-07T18:34:44Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.02808v1"], "summary": ["  Ontologies are critical sources of semantic information for many application\ndomains. Hence, there are ontologies proposed and utilized for domains such as\nmedicine, chemical engineering, and electrical energy. In this paper, we\npresent an improved and extended version of a wind energy ontology previously\nproposed. First, the ontology is restructured to increase its understandability\nand coverage. Secondly, it is enriched with new concepts, crisp/fuzzy\nattributes, and instances to increase its usability in semantic applications\nregarding wind energy. The ultimate ontology is utilized within a Web-based\nsemantic portal application for wind energy, in order to showcase its\ncontribution in a genuine application. Hence, the current study is a\nsignificant to wind and thereby renewable energy informatics, with the\npresented publicly-available wind energy ontology and the implemented\nproof-of-concept system.\n"]},
{"authors": ["Paul Yaworsky"], "title": ["Realizing Intelligence"], "date": ["2018-03-07T17:40:06Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.02765v1"], "summary": ["  Order exists in the world. The intelligence process enables us to realize\nthat order, to some extent. We provide a high level description of intelligence\nusing simple definitions, basic building blocks, a conceptual framework and\ngeneral hierarchy. This perspective includes multiple levels of abstraction\noccurring in space and in time. The resulting model offers simple, useful ways\nto help realize the essence of intelligence.\n"]},
{"authors": ["Shangtong Zhang", "Osmar R. Zaiane"], "title": ["Comparing Deep Reinforcement Learning and Evolutionary Methods in\n  Continuous Control"], "date": ["2017-11-30T03:40:06Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1712.00006v2"], "summary": ["  Reinforcement Learning and the Evolutionary Strategy are two major approaches\nin addressing complicated control problems. Both are strong contenders and have\ntheir own devotee communities. Both groups have been very active in developing\nnew advances in their own domain and devising, in recent years, leading-edge\ntechniques to address complex continuous control tasks. Here, in the context of\nDeep Reinforcement Learning, we formulate a parallelized version of the\nProximal Policy Optimization method and a Deep Deterministic Policy Gradient\nmethod. Moreover, we conduct a thorough comparison between the state-of-the-art\ntechniques in both camps fro continuous control; evolutionary methods and Deep\nReinforcement Learning methods. The results show there is no consistent winner.\n"]},
{"authors": ["Shangtong Zhang", "Richard S. Sutton"], "title": ["A Deeper Look at Experience Replay"], "date": ["2017-12-04T06:03:26Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1712.01275v2"], "summary": ["  Recently experience replay is widely used in various deep reinforcement\nlearning (RL) algorithms, however in this paper we showcase that it is not as\ngood as people think. To be more specific, experience replay will significantly\nhurt the learning process if the size of replay buffer is not well tuned.\nAlthough experience replay is a necessary component in modern deep RL\nalgorithms to stabilize the network, we should be aware that the idea of\nexperience replay itself is not as good as people think. The size of the replay\nbuffer is an important hyper-parameter, which can significantly influence the\nperformance and has unfortunately been underestimated in the community for a\nlong time. In this paper we did a systematic empirical study of experience\nreplay under various function representations. We showcase that a large replay\nbuffer can significantly hurt the performance. Moreover, we propose a simple\nO(1) method to remedy the negative influence of a large replay buffer. We\nshowcase its utility in both simple grid world and challenging domains like\nAtari games. Moreover, we visualize how a large replay buffer hurts the\nlearning process.\n"]},
{"authors": ["Yikang Shen", "Shawn Tan", "Chin-Wei Huang", "Aaron Courville"], "title": ["Generating Contradictory, Neutral, and Entailing Sentences"], "date": ["2018-03-07T15:18:03Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.02710v1"], "summary": ["  Learning distributed sentence representations remains an interesting problem\nin the field of Natural Language Processing (NLP). We want to learn a model\nthat approximates the conditional latent space over the representations of a\nlogical antecedent of the given statement. In our paper, we propose an approach\nto generating sentences, conditioned on an input sentence and a logical\ninference label. We do this by modeling the different possibilities for the\noutput sentence as a distribution over the latent representation, which we\ntrain using an adversarial objective. We evaluate the model using two\nstate-of-the-art models for the Recognizing Textual Entailment (RTE) task, and\nmeasure the BLEU scores against the actual sentences as a probe for the\ndiversity of sentences produced by our model. The experiment results show that,\ngiven our framework, we have clear ways to improve the quality and diversity of\ngenerated sentences.\n"]},
{"authors": ["Wenfeng Feng", "Hankz Hankui Zhuo", "Subbarao Kambhampati"], "title": ["Extracting Action Sequences from Texts Based on Deep Reinforcement\n  Learning"], "date": ["2018-03-07T13:13:16Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.02632v1"], "summary": ["  Extracting action sequences from texts in natural language is challenging,\nwhich requires commonsense inferences based on world knowledge. Although there\nhas been work on extracting action scripts, instructions, navigation actions,\netc., they require either the set of candidate actions is provided in advance,\nor action descriptions are restricted in a specific form, e.g., description\ntemplates. In this paper, we aim to extract action sequences from texts in free\nnatural language, i.e., without any restricted templates, provided the\ncandidate set of actions is unknown. We propose to extract action sequences\nfrom texts based on the deep reinforcement learning framework. Specifically, we\nview \"selecting\" or \"eliminating\" words from texts as \"actions\", and texts\nassociated with actions as \"states\". We then build Q-networks to learn the\npolicy of extracting actions and extract plans from the labelled texts. We\nexhibit the effectiveness of our approach in several datasets with comparison\nto state-of-the-art approaches, including online experiments interacting with\nhumans.\n"]},
{"authors": ["Francesco Locatello", "Rajiv Khanna", "Joydeep Ghosh", "Gunnar R\u00e4tsch"], "title": ["Boosting Variational Inference: an Optimization Perspective"], "date": ["2017-08-05T08:42:11Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1708.01733v2"], "summary": ["  Variational inference is a popular technique to approximate a possibly\nintractable Bayesian posterior with a more tractable one. Recently, boosting\nvariational inference has been proposed as a new paradigm to approximate the\nposterior by a mixture of densities by greedily adding components to the\nmixture. However, as is the case with many other variational inference\nalgorithms, its theoretical properties have not been studied. In the present\nwork, we study the convergence properties of this approach from a modern\noptimization viewpoint by establishing connections to the classic Frank-Wolfe\nalgorithm. Our analyses yields novel theoretical insights regarding the\nsufficient conditions for convergence, explicit rates, and algorithmic\nsimplifications. Since a lot of focus in previous works for variational\ninference has been on tractability, our work is especially important as a much\nneeded attempt to bridge the gap between probabilistic models and their\ncorresponding theoretical properties.\n"]},
{"authors": ["Tobias Hinz", "Stefan Wermter"], "title": ["Inferencing Based on Unsupervised Learning of Disentangled\n  Representations"], "date": ["2018-03-07T12:58:53Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.02627v1"], "summary": ["  Combining Generative Adversarial Networks (GANs) with encoders that learn to\nencode data points has shown promising results in learning data representations\nin an unsupervised way. We propose a framework that combines an encoder and a\ngenerator to learn disentangled representations which encode meaningful\ninformation about the data distribution without the need for any labels. While\ncurrent approaches focus mostly on the generative aspects of GANs, our\nframework can be used to perform inference on both real and generated data\npoints. Experiments on several data sets show that the encoder learns\ninterpretable, disentangled representations which encode descriptive properties\nand can be used to sample images that exhibit specific characteristics.\n"]},
{"authors": ["Wenyu Du", "Shuai Yu", "Min Yang", "Qiang Qu", "Jia Zhu"], "title": ["GPSP: Graph Partition and Space Projection based Approach for\n  Heterogeneous Network Embedding"], "date": ["2018-03-07T10:54:25Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.02590v1"], "summary": ["  In this paper, we propose GPSP, a novel Graph Partition and Space Projection\nbased approach, to learn the representation of a heterogeneous network that\nconsists of multiple types of nodes and links. Concretely, we first partition\nthe heterogeneous network into homogeneous and bipartite subnetworks. Then, the\nprojective relations hidden in bipartite subnetworks are extracted by learning\nthe projective embedding vectors. Finally, we concatenate the projective\nvectors from bipartite subnetworks with the ones learned from homogeneous\nsubnetworks to form the final representation of the heterogeneous network.\nExtensive experiments are conducted on a real-life dataset. The results\ndemonstrate that GPSP outperforms the state-of-the-art baselines in two key\nnetwork mining tasks: node classification and clustering.\n"]},
{"authors": ["Vishwajeet Kumar", "Kireeti Boorla", "Yogesh Meena", "Ganesh Ramakrishnan", "Yuan-Fang Li"], "title": ["Automating Reading Comprehension by Generating Question and Answer Pairs"], "date": ["2018-03-07T07:55:11Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.03664v1"], "summary": ["  Neural network-based methods represent the state-of-the-art in question\ngeneration from text. Existing work focuses on generating only questions from\ntext without concerning itself with answer generation. Moreover, our analysis\nshows that handling rare words and generating the most appropriate question\ngiven a candidate answer are still challenges facing existing approaches. We\npresent a novel two-stage process to generate question-answer pairs from the\ntext. For the first stage, we present alternatives for encoding the span of the\npivotal answer in the sentence using Pointer Networks. In our second stage, we\nemploy sequence to sequence models for question generation, enhanced with rich\nlinguistic features. Finally, global attention and answer encoding are used for\ngenerating the question most relevant to the answer. We motivate and\nlinguistically analyze the role of each component in our framework and consider\ncompositions of these. This analysis is supported by extensive experimental\nevaluations. Using standard evaluation metrics as well as human evaluations,\nour experimental results validate the significant improvement in the quality of\nquestions generated by our framework over the state-of-the-art. The technique\npresented here represents another step towards more automated reading\ncomprehension assessment. We also present a live system \\footnote{Demo of the\nsystem is available at\n\\url{https://www.cse.iitb.ac.in/~vishwajeet/autoqg.html}.} to demonstrate the\neffectiveness of our approach.\n"]},
{"authors": ["Arif Gursoy", "Ibrahim Senturk", "Tahsin Oner"], "title": ["A New Algorithmic Decision for Categorical Syllogisms via Caroll's\n  Diagrams"], "date": ["2018-02-08T11:29:59Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04127v3"], "summary": ["  In this paper, we deal with a calculus system SLCD (Syllogistic Logic with\nCarroll Diagrams), which gives a formal approach to logical reasoning with\ndiagrams, for representations of the fundamental Aristotelian categorical\npropositions and show that they are closed under the syllogistic criterion of\ninference which is the deletion of middle term. Therefore, it is implemented to\nlet the formalism comprise synchronically bilateral and trilateral\ndiagrammatical appearance and a naive algorithmic nature. And also, there is no\nneed specific knowledge or exclusive ability to understand as well as to use\nit. Consequently, we give an effective algorithm used to determine whether a\nsyllogistic reasoning valid or not by using SLCD.\n"]},
{"authors": ["Tse-Yu Lin", "Yen-Lung Tsai"], "title": ["An Application of HodgeRank to Online Peer Assessment"], "date": ["2018-03-07T02:53:54Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.02509v1"], "summary": ["  Bias and heterogeneity in peer assessment can lead to the issue of unfair\nscoring in the educational field. To deal with this problem, we propose a\nreference ranking method for an online peer assessment system using HodgeRank.\nSuch a scheme provides instructors with an objective scoring reference based on\nmathematics.\n"]},
{"authors": ["Sergio Miguel-Tom\u00e9"], "title": ["Decision-making processes in the Cognitive Theory of True Conditions"], "date": ["2018-03-06T23:46:55Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.02476v1"], "summary": ["  The Cognitive Theory of True Conditions (CTTC) is a proposal to design the\nimplementation of cognitive abilities and to describe the model-theoretic\nsemantics of symbolic cognitive architectures. The CTTC is formulated\nmathematically using the multi-optional many-sorted past present future(MMPPF)\nstructures. This article discussed how decision-making processes are described\nin the CTTC.\n"]},
{"authors": ["Caiming Xiong", "Victor Zhong", "Richard Socher"], "title": ["Dynamic Coattention Networks For Question Answering"], "date": ["2016-11-05T04:53:40Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1611.01604v4"], "summary": ["  Several deep learning models have been proposed for question answering.\nHowever, due to their single-pass nature, they have no way to recover from\nlocal maxima corresponding to incorrect answers. To address this problem, we\nintroduce the Dynamic Coattention Network (DCN) for question answering. The DCN\nfirst fuses co-dependent representations of the question and the document in\norder to focus on relevant parts of both. Then a dynamic pointing decoder\niterates over potential answer spans. This iterative procedure enables the\nmodel to recover from initial local maxima corresponding to incorrect answers.\nOn the Stanford question answering dataset, a single DCN model improves the\nprevious state of the art from 71.0% F1 to 75.9%, while a DCN ensemble obtains\n80.4% F1.\n"]},
{"authors": ["Suchin Gururangan", "Swabha Swayamdipta", "Omer Levy", "Roy Schwartz", "Samuel R. Bowman", "Noah A. Smith"], "title": ["Annotation Artifacts in Natural Language Inference Data"], "date": ["2018-03-06T18:23:08Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.02324v1"], "summary": ["  Large-scale datasets for natural language inference are created by presenting\ncrowd workers with a sentence (premise), and asking them to generate three new\nsentences (hypotheses) that it entails, contradicts, or is logically neutral\nwith respect to. We show that, in a significant portion of such data, this\nprotocol leaves clues that make it possible to identify the label by looking\nonly at the hypothesis, without observing the premise. Specifically, we show\nthat a simple text categorization model can correctly classify the hypothesis\nalone in about 67% of SNLI (Bowman et. al, 2015) and 53% of MultiNLI (Williams\net. al, 2017). Our analysis reveals that specific linguistic phenomena such as\nnegation and vagueness are highly correlated with certain inference classes.\nOur findings suggest that the success of natural language inference models to\ndate has been overestimated, and that the task remains a hard open problem.\n"]},
{"authors": ["Juan Camilo Gamboa Higuera", "David Meger", "Gregory Dudek"], "title": ["Synthesizing Neural Network Controllers with Probabilistic Model based\n  Reinforcement Learning"], "date": ["2018-03-06T16:42:46Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.02291v1"], "summary": ["  We present an algorithm for rapidly learning controllers for robotics\nsystems. The algorithm follows the model-based reinforcement learning paradigm,\nand improves upon existing algorithms; namely Probabilistic learning in Control\n(PILCO) and a sample-based version of PILCO with neural network dynamics\n(Deep-PILCO). We propose training a neural network dynamics model using\nvariational dropout with truncated Log-Normal noise. This allows us to obtain a\ndynamics model with calibrated uncertainty, which can be used to simulate\ncontroller executions via rollouts. We also describe set of techniques,\ninspired by viewing PILCO as a recurrent neural network model, that are crucial\nto improve the convergence of the method. We test our method on a variety of\nbenchmark tasks, demonstrating data-efficiency that is competitive with PILCO,\nwhile being able to optimize complex neural network controllers. Finally, we\nassess the performance of the algorithm for learning motor controllers for a\nsix legged autonomous underwater vehicle. This demonstrates the potential of\nthe algorithm for scaling up the dimensionality and dataset sizes, in more\ncomplex control tasks.\n"]},
{"authors": ["Helen Hastie", "Francisco J. Chiyah Garcia", "David A. Robb", "Pedro Patron", "Atanas Laskov"], "title": ["MIRIAM: A Multimodal Chat-Based Interface for Autonomous Systems"], "date": ["2018-03-06T11:33:04Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.02124v1"], "summary": ["  We present MIRIAM (Multimodal Intelligent inteRactIon for Autonomous\nsysteMs), a multimodal interface to support situation awareness of autonomous\nvehicles through chat-based interaction. The user is able to chat about the\nvehicle's plan, objectives, previous activities and mission progress. The\nsystem is mixed initiative in that it pro-actively sends messages about key\nevents, such as fault warnings. We will demonstrate MIRIAM using SeeByte's\nSeeTrack command and control interface and Neptune autonomy simulator.\n"]},
{"authors": ["Helen Hastie", "Katrin Lohan", "Mike Chantler", "David A. Robb", "Subramanian Ramamoorthy", "Ron Petrick", "Sethu Vijayakumar", "David Lane"], "title": ["The ORCA Hub: Explainable Offshore Robotics through Intelligent\n  Interfaces"], "date": ["2018-03-06T10:43:38Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.02100v1"], "summary": ["  We present the UK Robotics and Artificial Intelligence Hub for Offshore\nRobotics for Certification of Assets (ORCA Hub), a 3.5 year EPSRC funded,\nmulti-site project. The ORCA Hub vision is to use teams of robots and\nautonomous intelligent systems (AIS) to work on offshore energy platforms to\nenable cheaper, safer and more efficient working practices. The ORCA Hub will\nresearch, integrate, validate and deploy remote AIS solutions that can operate\nwith existing and future offshore energy assets and sensors, interacting safely\nin autonomous or semi-autonomous modes in complex and cluttered environments,\nco-operating with remote operators. The goal is that through the use of such\nrobotic systems offshore, the need for personnel will decrease. To enable this\nto happen, the remote operator will need a high level of situation awareness\nand key to this is the transparency of what the autonomous systems are doing\nand why. This increased transparency will facilitate a trusting relationship,\nwhich is particularly key in high-stakes, hazardous situations.\n"]},
{"authors": ["Maarten Bieshaar"], "title": ["Where is my Device? - Detecting the Smart Device's Wearing Location in\n  the Context of Active Safety for Vulnerable Road Users"], "date": ["2018-03-06T10:34:47Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.02097v1"], "summary": ["  This article describes an approach to detect the wearing location of smart\ndevices worn by pedestrians and cyclists. The detection, which is based solely\non the sensors of the smart devices, is important context-information which can\nbe used to parametrize subsequent algorithms, e.g. for dead reckoning or\nintention detection to improve the safety of vulnerable road users. The wearing\nlocation recognition can in terms of Organic Computing (OC) be seen as a step\ntowards self-awareness and self-adaptation. For the wearing location detection\na two-stage process is presented. It is subdivided into moving detection\nfollowed by the wearing location classification. Finally, the approach is\nevaluated on a real world dataset consisting of pedestrians and cyclists.\n"]},
{"authors": ["G\u00fcnther Reitberger", "Stefan Zernetsch", "Maarten Bieshaar", "Bernhard Sick", "Konrad Doll", "Erich Fuchs"], "title": ["Cooperative Tracking of Cyclists Based on Smart Devices and\n  Infrastructure"], "date": ["2018-03-06T10:33:35Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.02096v1"], "summary": ["  In future traffic scenarios, vehicles and other traffic participants will be\ninterconnected and equipped with various types of sensors, allowing for\ncooperation based on data or information exchange. This article presents an\napproach to cooperative tracking of cyclists using smart devices and\ninfrastructure-based sensors. A smart device is carried by the cyclists and an\nintersection is equipped with a wide angle stereo camera system. Two tracking\nmodels are presented and compared. The first model is based on the stereo\ncamera system detections only, whereas the second model cooperatively combines\nthe camera based detections with velocity and yaw rate data provided by the\nsmart device. Our aim is to overcome limitations of tracking approaches based\non single data sources. We show in numerical evaluations on scenes where\ncyclists are starting or turning right that the cooperation leads to an\nimprovement in both the ability to keep track of a cyclist and the accuracy of\nthe track particularly when it comes to occlusions in the visual system. We,\ntherefore, contribute to the safety of vulnerable road users in future traffic.\n"]},
{"authors": ["Francisco J. Chiyah Garcia", "David A. Robb", "Xingkun Liu", "Atanas Laskov", "Pedro Patron", "Helen Hastie"], "title": ["Explain Yourself: A Natural Language Interface for Scrutable Autonomous\n  Robots"], "date": ["2018-03-06T10:13:29Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.02088v1"], "summary": ["  Autonomous systems in remote locations have a high degree of autonomy and\nthere is a need to explain what they are doing and why in order to increase\ntransparency and maintain trust. Here, we describe a natural language chat\ninterface that enables vehicle behaviour to be queried by the user. We obtain\nan interpretable model of autonomy through having an expert 'speak out-loud'\nand provide explanations during a mission. This approach is agnostic to the\ntype of autonomy model and as expert and operator are from the same user-group,\nwe predict that these explanations will align well with the operator's mental\nmodel, increase transparency and assist with operator training.\n"]},
{"authors": ["Alexandre P\u00e9r\u00e9", "S\u00e9bastien Forestier", "Olivier Sigaud", "Pierre-Yves Oudeyer"], "title": ["Unsupervised Learning of Goal Spaces for Intrinsically Motivated Goal\n  Exploration"], "date": ["2018-03-02T09:45:53Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.00781v2"], "summary": ["  Intrinsically motivated goal exploration algorithms enable machines to\ndiscover repertoires of policies that produce a diversity of effects in complex\nenvironments. These exploration algorithms have been shown to allow real world\nrobots to acquire skills such as tool use in high-dimensional continuous state\nand action spaces. However, they have so far assumed that self-generated goals\nare sampled in a specifically engineered feature space, limiting their\nautonomy. In this work, we propose to use deep representation learning\nalgorithms to learn an adequate goal space. This is a developmental 2-stage\napproach: first, in a perceptual learning stage, deep learning algorithms use\npassive raw sensor observations of world changes to learn a corresponding\nlatent space; then goal exploration happens in a second stage by sampling goals\nin this latent space. We present experiments where a simulated robot arm\ninteracts with an object, and we show that exploration algorithms using such\nlearned representations can match the performance obtained using engineered\nrepresentations.\n"]},
{"authors": ["Jizhe Wang", "Pipei Huang", "Huan Zhao", "Zhibo Zhang", "Binqiang Zhao", "Dik Lun Lee"], "title": ["Billion-scale Commodity Embedding for E-commerce Recommendation in\n  Alibaba"], "date": ["2018-03-06T05:20:14Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.02349v1"], "summary": ["  Recommender systems (RSs) have been the most important technology for\nincreasing the business in Taobao, the largest online consumer-to-consumer\n(C2C) platform in China. The billion-scale data in Taobao creates three major\nchallenges to Taobao's RS: scalability, sparsity and cold start. In this paper,\nwe present our technical solutions to address these three challenges. The\nmethods are based on the graph embedding framework. We first construct an item\ngraph from users' behavior history. Each item is then represented as a vector\nusing graph embedding. The item embeddings are employed to compute pairwise\nsimilarities between all items, which are then used in the recommendation\nprocess. To alleviate the sparsity and cold start problems, side information is\nincorporated into the embedding framework. We propose two aggregation methods\nto integrate the embeddings of items and the corresponding side information.\nExperimental results from offline experiments show that methods incorporating\nside information are superior to those that do not. Further, we describe the\nplatform upon which the embedding methods are deployed and the workflow to\nprocess the billion-scale data in Taobao. Using online A/B test, we show that\nthe online Click-Through-Rate (CTRs) are improved comparing to the previous\nrecommendation methods widely used in Taobao, further demonstrating the\neffectiveness and feasibility of our proposed methods in Taobao's live\nproduction environment.\n"]},
{"authors": ["Ofir Nachum", "Mohammad Norouzi", "George Tucker", "Dale Schuurmans"], "title": ["Smoothed Action Value Functions for Learning Gaussian Policies"], "date": ["2018-03-06T04:58:20Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.02348v1"], "summary": ["  State-action value functions (i.e., Q-values) are ubiquitous in reinforcement\nlearning (RL), giving rise to popular algorithms such as SARSA and Q-learning.\nWe propose a new notion of action value defined by a Gaussian smoothed version\nof the expected Q-value. We show that such smoothed Q-values still satisfy a\nBellman equation, making them learnable from experience sampled from an\nenvironment. Moreover, the gradients of expected reward with respect to the\nmean and covariance of a parameterized Gaussian policy can be recovered from\nthe gradient and Hessian of the smoothed Q-value function. Based on these\nrelationships, we develop new algorithms for training a Gaussian policy\ndirectly from a learned smoothed Q-value approximator. The approach is\nadditionally amenable to proximal optimization by augmenting the objective with\na penalty on KL-divergence from a previous policy. We find that the ability to\nlearn both a mean and covariance during training leads to significantly\nimproved results on standard continuous control benchmarks.\n"]},
{"authors": ["Siyuan Qi", "Song-Chun Zhu"], "title": ["Intent-aware Multi-agent Reinforcement Learning"], "date": ["2018-03-06T04:53:50Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.02018v1"], "summary": ["  This paper proposes an intent-aware multi-agent planning framework as well as\na learning algorithm. Under this framework, an agent plans in the goal space to\nmaximize the expected utility. The planning process takes the belief of other\nagents' intents into consideration. Instead of formulating the learning problem\nas a partially observable Markov decision process (POMDP), we propose a simple\nbut effective linear function approximation of the utility function. It is\nbased on the observation that for humans, other people's intents will pose an\ninfluence on our utility for a goal. The proposed framework has several major\nadvantages: i) it is computationally feasible and guaranteed to converge. ii)\nIt can easily integrate existing intent prediction and low-level planning\nalgorithms. iii) It does not suffer from sparse feedbacks in the action space.\nWe experiment our algorithm in a real-world problem that is non-episodic, and\nthe number of agents and goals can vary over time. Our algorithm is trained in\na scene in which aerial robots and humans interact, and tested in a novel scene\nwith a different environment. Experimental results show that our algorithm\nachieves the best performance and human-like behaviors emerge during the\ndynamic process.\n"]},
{"authors": ["Yuhui Xu", "Yongzhuang Wang", "Aojun Zhou", "Weiyao Lin", "Hongkai Xiong"], "title": ["Deep Neural Network Compression with Single and Multiple Level\n  Quantization"], "date": ["2018-03-06T01:47:52Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.03289v1"], "summary": ["  Network quantization is an effective solution to compress deep neural\nnetworks for practical usage. Existing network quantization methods cannot\nsufficiently exploit the depth information to generate low-bit compressed\nnetwork. In this paper, we propose two novel network quantization approaches,\nsingle-level network quantization (SLQ) for high-bit quantization and\nmulti-level network quantization (MLQ) for extremely low-bit quantization\n(ternary).We are the first to consider the network quantization from both width\nand depth level. In the width level, parameters are divided into two parts: one\nfor quantization and the other for re-training to eliminate the quantization\nloss. SLQ leverages the distribution of the parameters to improve the width\nlevel. In the depth level, we introduce incremental layer compensation to\nquantize layers iteratively which decreases the quantization loss in each\niteration. The proposed approaches are validated with extensive experiments\nbased on the state-of-the-art neural networks including AlexNet, VGG-16,\nGoogleNet and ResNet-18. Both SLQ and MLQ achieve impressive results.\n"]},
{"authors": ["Kavita Ganesan"], "title": ["ROUGE 2.0: Updated and Improved Measures for Evaluation of Summarization\n  Tasks"], "date": ["2018-03-05T21:35:04Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.01937v1"], "summary": ["  Evaluation of summarization tasks is extremely crucial to determining the\nquality of machine generated summaries. Over the last decade, ROUGE has become\nthe standard automatic evaluation measure for evaluating summarization tasks.\nWhile ROUGE has been shown to be effective in capturing n-gram overlap between\nsystem and human composed summaries, there are several limitations with the\nexisting ROUGE measures in terms of capturing synonymous concepts and coverage\nof topics. Thus, often times ROUGE scores do not reflect the true quality of\nsummaries and prevents multi-faceted evaluation of summaries (i.e. by topics,\nby overall content coverage and etc). In this paper, we introduce ROUGE 2.0,\nwhich has several updated measures of ROUGE: ROUGE-N+Synonyms, ROUGE-Topic,\nROUGE-Topic+Synonyms, ROUGE-TopicUniq and ROUGE-TopicUniq+Synonyms; all of\nwhich are improvements over the core ROUGE measures.\n"]},
{"authors": ["Maithra Raghu", "Alex Irpan", "Jacob Andreas", "Robert Kleinberg", "Quoc V. Le", "Jon Kleinberg"], "title": ["Can Deep Reinforcement Learning Solve Erdos-Selfridge-Spencer Games?"], "date": ["2017-11-07T06:16:56Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.02301v3"], "summary": ["  Deep reinforcement learning has achieved many recent successes, but our\nunderstanding of its strengths and limitations is hampered by the lack of rich\nenvironments in which we can fully characterize optimal behavior, and\ncorrespondingly diagnose individual actions against such a characterization.\nHere we consider a family of combinatorial games, arising from work of Erdos,\nSelfridge, and Spencer, and we propose their use as environments for evaluating\nand comparing different approaches to reinforcement learning. These games have\na number of appealing features: they are challenging for current learning\napproaches, but they form (i) a low-dimensional, simply parametrized\nenvironment where (ii) there is a linear closed form solution for optimal\nbehavior from any state, and (iii) the difficulty of the game can be tuned by\nchanging environment parameters in an interpretable way. We use these\nErdos-Selfridge-Spencer games not only to compare different algorithms, but\ntest for generalization, make comparisons to supervised learning, analyse\nmultiagent play, and even develop a self play algorithm.\n"]},
{"authors": ["Yongkai Wu", "Lu Zhang", "Xintao Wu"], "title": ["On Discrimination Discovery and Removal in Ranked Data using Causal\n  Graph"], "date": ["2018-03-05T19:53:40Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.01901v1"], "summary": ["  Predictive models learned from historical data are widely used to help\ncompanies and organizations make decisions. However, they may digitally\nunfairly treat unwanted groups, raising concerns about fairness and\ndiscrimination. In this paper, we study the fairness-aware ranking problem\nwhich aims to discover discrimination in ranked datasets and reconstruct the\nfair ranking. Existing methods in fairness-aware ranking are mainly based on\nstatistical parity that cannot measure the true discriminatory effect since\ndiscrimination is causal. On the other hand, existing methods in causal-based\nanti-discrimination learning focus on classification problems and cannot be\ndirectly applied to handle the ranked data. To address these limitations, we\npropose to map the rank position to a continuous score variable that represents\nthe qualification of the candidates. Then, we build a causal graph that\nconsists of both the discrete profile attributes and the continuous score. The\npath-specific effect technique is extended to the mixed-variable causal graph\nto identify both direct and indirect discrimination. The relationship between\nthe path-specific effects for the ranked data and those for the binary decision\nis theoretically analyzed. Finally, algorithms for discovering and removing\ndiscrimination from a ranked dataset are developed. Experiments using the real\ndataset show the effectiveness of our approaches.\n"]},
{"authors": ["Jiongqian Liang", "Peter Jacobs", "Jiankai Sun", "Srinivasan Parthasarathy"], "title": ["Semi-supervised Embedding in Attributed Networks with Outliers"], "date": ["2017-03-23T15:15:53Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1703.08100v3"], "summary": ["  In this paper, we propose a novel framework, called Semi-supervised Embedding\nin Attributed Networks with Outliers (SEANO), to learn a low-dimensional vector\nrepresentation that systematically captures the topological proximity,\nattribute affinity and label similarity of vertices in a partially labeled\nattributed network (PLAN). Our method is designed to work in both transductive\nand inductive settings while explicitly alleviating noise effects from\noutliers. Experimental results on various datasets drawn from the web, text and\nimage domains demonstrate the advantages of SEANO over state-of-the-art methods\nin semi-supervised classification under transductive as well as inductive\nsettings. We also show that a subset of parameters in SEANO is interpretable as\noutlier score and can significantly outperform baseline methods when applied\nfor detecting network outliers. Finally, we present the use of SEANO in a\nchallenging real-world setting -- flood mapping of satellite images and show\nthat it is able to outperform modern remote sensing algorithms for this task.\n"]},
{"authors": ["Haifeng Qian", "Mark N. Wegman"], "title": ["L2-Nonexpansive Neural Networks"], "date": ["2018-02-22T04:01:18Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.07896v2"], "summary": ["  This paper proposes a class of well-conditioned neural networks in which a\nunit amount of change in the inputs causes at most a unit amount of change in\nthe outputs or any of the internal layers. We develop the known methodology of\ncontrolling Lipschitz constants to realize its full potential in maximizing\nrobustness: our linear and convolution layers subsume those in the previous\nParseval networks as a special case and allow greater degrees of freedom;\naggregation, pooling, splitting and other operators are adapted in new ways,\nand a new loss function is proposed, all for the purpose of improving\nrobustness. With MNIST and CIFAR-10 classifiers, we demonstrate a number of\nadvantages. Without needing any adversarial training, the proposed classifiers\nexceed the state of the art in robustness against white-box L2-bounded\nadversarial attacks. Their outputs are quantitatively more meaningful than\nordinary networks and indicate levels of confidence. They are also free of\nexploding gradients, among other desirable properties.\n"]},
{"authors": ["Shiyu Liang", "Ruoyu Sun", "Yixuan Li", "R. Srikant"], "title": ["Understanding the Loss Surface of Neural Networks for Binary\n  Classification"], "date": ["2018-02-19T02:13:38Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.00909v2"], "summary": ["  It is widely conjectured that the reason that training algorithms for neural\nnetworks are successful because all local minima lead to similar performance,\nfor example, see (LeCun et al., 2015, Choromanska et al., 2015, Dauphin et al.,\n2014). Performance is typically measured in terms of two metrics: training\nperformance and generalization performance. Here we focus on the training\nperformance of single-layered neural networks for binary classification, and\nprovide conditions under which the training error is zero at all local minima\nof a smooth hinge loss function. Our conditions are roughly in the following\nform: the neurons have to be strictly convex and the surrogate loss function\nshould be a smooth version of hinge loss. We also provide counterexamples to\nshow that when the loss function is replaced with quadratic loss or logistic\nloss, the result may not hold.\n"]},
{"authors": ["Panpan Zheng", "Shuhan Yuan", "Xintao Wu", "Jun Li", "Aidong Lu"], "title": ["One-Class Adversarial Nets for Fraud Detection"], "date": ["2018-03-05T17:40:24Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.01798v1"], "summary": ["  Many online applications, such as online social networks or knowledge bases,\nare often attacked by malicious users who commit different types of actions\nsuch as vandalism on Wikipedia or fraudulent reviews on eBay. Currently, most\nof the fraud detection approaches require a training dataset that contains\nrecords of both benign and malicious users. However, in practice, there are\noften no or very few records of malicious users. In this paper, we develop\none-class adversarial nets (OCAN) for fraud detection using training data with\nonly benign users. OCAN first uses LSTM-Autoencoder to learn the\nrepresentations of benign users from their sequences of online activities. It\nthen detects malicious users by training a discriminator with a complementary\nGAN model that is different from the regular GAN model. Experimental results\nshow that our OCAN outperforms the state-of-the-art one-class classification\nmodels and achieves comparable performance with the latest multi-source LSTM\nmodel that requires both benign and malicious users in the training phase.\n"]},
{"authors": ["Christoph Benzm\u00fcller", "Ali Farjami", "Xavier Parent"], "title": ["Faithful Semantical Embedding of a Dyadic Deontic Logic in HOL"], "date": ["2018-02-23T09:24:26Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08454v2"], "summary": ["  A shallow semantical embedding of a dyadic deontic logic by Carmo and Jones\nin classical higher-order logic is presented. This embedding is proven sound\nand complete, that is, faithful.\n  The work presented here provides the theoretical foundation for the\nimplementation and automation of dyadic deontic logic within off-the-shelf\nhigher-order theorem provers and proof assistants.\n"]},
{"authors": ["Kieran Greer"], "title": ["Memory Search and Sense from Shallow Hierarchies"], "date": ["2018-03-05T14:46:19Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.01690v1"], "summary": ["  This paper describes an automatic process for combining patterns and\nfeatures, to guide a search process and reason about it. It is based on the\nfunctionality that a human brain might have, which is a highly distributed\nnetwork of simple neuronal components that can apply some level of matching and\ncross-referencing over retrieved patterns. The process uses memory in a more\ndynamic way and it can realise results using a shallow hierarchy, which is a\nrecognised brain-like construct. The paper gives one example of the process,\nusing computer chess as a case study.\n"]},
{"authors": ["Dan Barnes", "Will Maddern", "Geoffrey Pascoe", "Ingmar Posner"], "title": ["Driven to Distraction: Self-Supervised Distractor Learning for Robust\n  Monocular Visual Odometry in Urban Environments"], "date": ["2017-11-17T16:54:40Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.06623v2"], "summary": ["  We present a self-supervised approach to ignoring \"distractors\" in camera\nimages for the purposes of robustly estimating vehicle motion in cluttered\nurban environments. We leverage offline multi-session mapping approaches to\nautomatically generate a per-pixel ephemerality mask and depth map for each\ninput image, which we use to train a deep convolutional network. At run-time we\nuse the predicted ephemerality and depth as an input to a monocular visual\nodometry (VO) pipeline, using either sparse features or dense photometric\nmatching. Our approach yields metric-scale VO using only a single camera and\ncan recover the correct egomotion even when 90% of the image is obscured by\ndynamic, independently moving objects. We evaluate our robust VO methods on\nmore than 400km of driving from the Oxford RobotCar Dataset and demonstrate\nreduced odometry drift and significantly improved egomotion estimation in the\npresence of large moving vehicles in urban traffic.\n"]},
{"authors": ["Swen E. Gaudl"], "title": ["A Genetic Programming Framework for 2D Platform AI"], "date": ["2018-03-05T13:11:22Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.01648v1"], "summary": ["  There currently exists a wide range of techniques to model and evolve\nartificial players for games. Existing techniques range from black box neural\nnetworks to entirely hand-designed solutions. In this paper, we demonstrate the\nfeasibility of a genetic programming framework using human controller input to\nderive meaningful artificial players which can, later on, be optimised by hand.\nThe current state of the art in game character design relies heavily on human\ndesigners to manually create and edit scripts and rules for game characters. To\naddress this manual editing bottleneck, current computational intelligence\ntechniques approach the issue with fully autonomous character generators,\nreplacing most of the design process using black box solutions such as neural\nnetworks or the like. Our GP approach to this problem creates character\ncontrollers which can be further authored and developed by a designer it also\noffers designers to included their play style without the need to use a\nprogramming language. This keeps the designer in the loop while reducing\nrepetitive manual labour. Our system also provides insights into how players\nexpress themselves in games and into deriving appropriate models for\nrepresenting those insights. We present our framework, supporting findings and\nopen challenges.\n"]},
{"authors": ["Risi Kondor"], "title": ["N-body Networks: a Covariant Hierarchical Neural Network Architecture\n  for Learning Atomic Potentials"], "date": ["2018-03-05T10:17:01Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.01588v1"], "summary": ["  We describe N-body networks, a neural network architecture for learning the\nbehavior and properties of complex many body physical systems. Our specific\napplication is to learn atomic potential energy surfaces for use in molecular\ndynamics simulations. Our architecture is novel in that (a) it is based on a\nhierarchical decomposition of the many body system into subsytems, (b) the\nactivations of the network correspond to the internal state of each subsystem,\n(c) the \"neurons\" in the network are constructed explicitly so as to guarantee\nthat each of the activations is covariant to rotations, (d) the neurons operate\nentirely in Fourier space, and the nonlinearities are realized by tensor\nproducts followed by Clebsch-Gordan decompositions. As part of the description\nof our network, we give a characterization of what way the weights of the\nnetwork may interact with the activations so as to ensure that the covariance\nproperty is maintained.\n"]},
{"authors": ["Marc Aiguier", "Jamal Atif", "Isabelle Bloch", "Ram\u00f3n Pino-P\u00e9rez"], "title": ["Explanatory relations in arbitrary logics based on satisfaction systems,\n  cutting and retraction"], "date": ["2018-03-05T09:32:04Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.01571v1"], "summary": ["  The aim of this paper is to introduce a new framework for defining abductive\nreasoning operators based on a notion of retraction in arbitrary logics defined\nas satisfaction systems. We show how this framework leads to the design of\nexplanatory relations satisfying properties of abductive reasoning, and discuss\nits application to several logics. This extends previous work on propositional\nlogics where retraction was defined as a morphological erosion. Here weaker\nproperties are required for retraction, leading to a larger set of suitable\noperators for abduction for different logics.\n"]},
{"authors": ["Ahmed Hefny", "Zita Marinho", "Wen Sun", "Siddhartha Srinivasa", "Geoffrey Gordon"], "title": ["Recurrent Predictive State Policy Networks"], "date": ["2018-03-05T03:59:48Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.01489v1"], "summary": ["  We introduce Recurrent Predictive State Policy (RPSP) networks, a recurrent\narchitecture that brings insights from predictive state representations to\nreinforcement learning in partially observable environments. Predictive state\npolicy networks consist of a recursive filter, which keeps track of a belief\nabout the state of the environment, and a reactive policy that directly maps\nbeliefs to actions, to maximize the cumulative reward. The recursive filter\nleverages predictive state representations (PSRs) (Rosencrantz and Gordon,\n2004; Sun et al., 2016) by modeling predictive state-- a prediction of the\ndistribution of future observations conditioned on history and future actions.\nThis representation gives rise to a rich class of statistically consistent\nalgorithms (Hefny et al., 2018) to initialize the recursive filter. Predictive\nstate serves as an equivalent representation of a belief state. Therefore, the\npolicy component of the RPSP-network can be purely reactive, simplifying\ntraining while still allowing optimal behaviour. Moreover, we use the PSR\ninterpretation during training as well, by incorporating prediction error in\nthe loss function. The entire network (recursive filter and reactive policy) is\nstill differentiable and can be trained using gradient based methods. We\noptimize our policy using a combination of policy gradient based on rewards\n(Williams, 1992) and gradient descent based on prediction error. We show the\nefficacy of RPSP-networks under partial observability on a set of robotic\ncontrol tasks from OpenAI Gym. We empirically show that RPSP-networks perform\nwell compared with memory-preserving networks such as GRUs, as well as finite\nmemory models, being the overall best performing method.\n"]},
{"authors": ["Ludovic Font", "Philippe R. Richard", "Michel Gagnon"], "title": ["Improving QED-Tutrix by Automating the Generation of Proofs"], "date": ["2018-03-05T02:46:13Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.01468v1"], "summary": ["  The idea of assisting teachers with technological tools is not new.\nMathematics in general, and geometry in particular, provide interesting\nchallenges when developing educative softwares, both in the education and\ncomputer science aspects. QED-Tutrix is an intelligent tutor for geometry\noffering an interface to help high school students in the resolution of\ndemonstration problems. It focuses on specific goals: 1) to allow the student\nto freely explore the problem and its figure, 2) to accept proofs elements in\nany order, 3) to handle a variety of proofs, which can be customized by the\nteacher, and 4) to be able to help the student at any step of the resolution of\nthe problem, if the need arises. The software is also independent from the\nintervention of the teacher. QED-Tutrix offers an interesting approach to\ngeometry education, but is currently crippled by the lengthiness of the process\nof implementing new problems, a task that must still be done manually.\nTherefore, one of the main focuses of the QED-Tutrix' research team is to ease\nthe implementation of new problems, by automating the tedious step of finding\nall possible proofs for a given problem. This automation must follow\nfundamental constraints in order to create problems compatible with QED-Tutrix:\n1) readability of the proofs, 2) accessibility at a high school level, and 3)\npossibility for the teacher to modify the parameters defining the\n\"acceptability\" of a proof. We present in this paper the result of our\npreliminary exploration of possible avenues for this task. Automated theorem\nproving in geometry is a widely studied subject, and various provers exist.\nHowever, our constraints are quite specific and some adaptation would be\nrequired to use an existing prover. We have therefore implemented a prototype\nof automated prover to suit our needs. The future goal is to compare\nperformances and usability in our specific use-case between the existing\nprovers and our implementation.\n"]},
{"authors": ["Xun Zheng", "Bryon Aragam", "Pradeep Ravikumar", "Eric P. Xing"], "title": ["DAGs with NO TEARS: Smooth Optimization for Structure Learning"], "date": ["2018-03-04T21:09:13Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.01422v1"], "summary": ["  Estimating the structure of directed acyclic graphs (DAGs, also known as\nBayesian networks) is a challenging problem since the search space of DAGs is\ncombinatorial and scales superexponentially with the number of nodes. Existing\napproaches rely on various local heuristics for enforcing the acyclicity\nconstraint and are not well-suited to general purpose optimization packages for\ntheir solution. In this paper, we introduce a fundamentally different strategy:\nWe formulate the structure learning problem as a smooth, constrained\noptimization problem over real matrices that avoids this combinatorial\nconstraint entirely. This is achieved by a novel characterization of acyclicity\nthat is not only smooth but also exact. The resulting nonconvex, constrained\nprogram involves smooth functions whose gradients are easy to compute and only\ninvolve elementary matrix operations. By using existing black-box optimization\nroutines, our method uses global search to find an optimal DAG and can be\nimplemented in about 50 lines of Python and outperforms existing methods\nwithout imposing any structural constraints.\n"]},
{"authors": ["Shadi Abpeykar", "Mehdi Ghatee"], "title": ["A real-time rule-based system for bridge management based on CART\n  decision tree and SMO algorithms"], "date": ["2018-03-04T20:10:01Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.01412v1"], "summary": ["  To real-time management of the bridges under dynamic conditions, this paper\ndevelops a rule-based decision support framework to extract the necessary rules\nfrom simulation results made by Aimsun. In this rule-based system, the\nsupervised and the unsupervised learning algorithms are applied to generalize\nthe rules where the initial set of rules are provided by the aid of fuzzy rule\ngeneration algorithms on the results of Aimsun traffic micro-simulation\nsoftware. As a pilot case study, Nasr Bridge in Tehran is simulated in Aimsun7\nand WEKA data mining software is used to execute the learning algorithms. Based\non this experiment, the accuracy of the supervised algorithms to generalize the\nrules is greater than 80%. In addition, CART decision tree and sequential\nminimal optimization (SMO) provides 100% accuracy for normal data and so these\nalgorithms are so reliable for crisis management on bridge. This means that, it\nis possible to use such machine learning methods to manage bridges in the\nreal-time conditions.\n"]},
{"authors": ["Swen E. Gaudl", "Mark J. Nelson", "Simon Colton", "Rob Saunders", "Edward J. Powley", "Peter Ivey", "Blanca Perez Ferrer", "Michael Cook"], "title": ["Exploring Novel Game Spaces with Fluidic Games"], "date": ["2018-03-04T18:58:07Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.01403v1"], "summary": ["  With the growing integration of smartphones into our daily lives, and their\nincreased ease of use, mobile games have become highly popular across all\ndemographics. People listen to music, play games or read the news while in\ntransit or bridging gap times. While mobile gaming is gaining popularity,\nmobile expression of creativity is still in its early stages. We present here a\nnew type of mobile app -- fluidic games -- and illustrate our iterative\napproach to their design. This new type of app seamlessly integrates\nexploration of the design space into the actual user experience of playing the\ngame, and aims to enrich the user experience. To better illustrate the game\ndomain and our approach, we discuss one specific fluidic game, which is\navailable as a commercial product. We also briefly discuss open challenges such\nas player support and how generative techniques can aid the exploration of the\ngame space further.\n"]},
{"authors": ["Samer B. Nashed", "David M. Ilstrup", "Joydeep Biswas"], "title": ["Localization under Topological Uncertainty for Lane Identification of\n  Autonomous Vehicles"], "date": ["2018-03-04T16:49:37Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.01378v1"], "summary": ["  Autonomous vehicles (AVs) require accurate metric and topological location\nestimates for safe, effective navigation and decision-making. Although many\nhigh-definition (HD) roadmaps exist, they are not always accurate since public\nroads are dynamic, shaped unpredictably by both human activity and nature.\nThus, AVs must be able to handle situations in which the topology specified by\nthe map does not agree with reality. We present the Variable Structure Multiple\nHidden Markov Model (VSM-HMM) as a framework for localizing in the presence of\ntopological uncertainty, and demonstrate its effectiveness on an AV where lane\nmembership is modeled as a topological localization process. VSM-HMMs use a\ndynamic set of HMMs to simultaneously reason about location within a set of\nmost likely current topologies and therefore may also be applied to topological\nstructure estimation as well as AV lane estimation. In addition, we present an\nextension to the Earth Mover's Distance which allows uncertainty to be taken\ninto account when computing the distance between belief distributions on\nsimplices of arbitrary relative sizes.\n"]},
{"authors": ["Arief Koesdwiady", "Fakhri Karray"], "title": ["Improving Multi-Step Traffic Flow Prediction"], "date": ["2018-03-04T14:59:55Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.01365v1"], "summary": ["  In its simplest form, the traffic flow prediction problem is restricted to\npredicting a single time-step into the future. Multi-step traffic flow\nprediction extends this set-up to the case where predicting multiple time-steps\ninto the future based on some finite history is of interest. This problem is\nsignificantly more difficult than its single-step variant and is known to\nsuffer from degradation in predictions as the time step increases. In this\npaper, two approaches to improve multi-step traffic flow prediction performance\nin recursive and multi-output settings are introduced. In particular, a model\nthat allows recursive prediction approaches to take into account the temporal\ncontext in term of time-step index when making predictions is introduced. In\naddition, a conditional generative adversarial network-based data augmentation\nmethod is proposed to improve prediction performance in the multi-output\nsetting. The experiments on a real-world traffic flow dataset show that the two\nmethods improve on multi-step traffic flow prediction in recursive and\nmulti-output settings, respectively.\n"]},
{"authors": ["Arief Koesdwiady", "Fakhri Karray"], "title": ["SAFE: Spectral Evolution Analysis Feature Extraction for Non-Stationary\n  Time Series Prediction"], "date": ["2018-03-04T14:55:33Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.01364v1"], "summary": ["  This paper presents a practical approach for detecting non-stationarity in\ntime series prediction. This method is called SAFE and works by monitoring the\nevolution of the spectral contents of time series through a distance function.\nThis method is designed to work in combination with state-of-the-art machine\nlearning methods in real time by informing the online predictors to perform\nnecessary adaptation when a non-stationarity presents. We also propose an\nalgorithm to proportionally include some past data in the adaption process to\novercome the Catastrophic Forgetting problem. To validate our hypothesis and\ntest the effectiveness of our approach, we present comprehensive experiments in\ndifferent elements of the approach involving artificial and real-world\ndatasets. The experiments show that the proposed method is able to\nsignificantly save computational resources in term of processor or GPU cycles\nwhile maintaining high prediction performances.\n"]},
{"authors": ["Kuan Fang", "Yu Xiang", "Xiaocheng Li", "Silvio Savarese"], "title": ["Recurrent Autoregressive Networks for Online Multi-Object Tracking"], "date": ["2017-11-07T21:51:22Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.02741v2"], "summary": ["  The main challenge of online multi-object tracking is to reliably associate\nobject trajectories with detections in each video frame based on their tracking\nhistory. In this work, we propose the Recurrent Autoregressive Network (RAN), a\ntemporal generative modeling framework to characterize the appearance and\nmotion dynamics of multiple objects over time. The RAN couples an external\nmemory and an internal memory. The external memory explicitly stores previous\ninputs of each trajectory in a time window, while the internal memory learns to\nsummarize long-term tracking history and associate detections by processing the\nexternal memory. We conduct experiments on the MOT 2015 and 2016 datasets to\ndemonstrate the robustness of our tracking method in highly crowded and\noccluded scenes. Our method achieves top-ranked results on the two benchmarks.\n"]},
{"authors": ["Kuan Fang", "Yunfei Bai", "Stefan Hinterstoisser", "Silvio Savarese", "Mrinal Kalakrishnan"], "title": ["Multi-Task Domain Adaptation for Deep Learning of Instance Grasping from\n  Simulation"], "date": ["2017-10-17T17:54:50Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.06422v2"], "summary": ["  Learning-based approaches to robotic manipulation are limited by the\nscalability of data collection and accessibility of labels. In this paper, we\npresent a multi-task domain adaptation framework for instance grasping in\ncluttered scenes by utilizing simulated robot experiments. Our neural network\ntakes monocular RGB images and the instance segmentation mask of a specified\ntarget object as inputs, and predicts the probability of successfully grasping\nthe specified object for each candidate motor command. The proposed transfer\nlearning framework trains a model for instance grasping in simulation and uses\na domain-adversarial loss to transfer the trained model to real robots using\nindiscriminate grasping data, which is available both in simulation and the\nreal world. We evaluate our model in real-world robot experiments, comparing it\nwith alternative model architectures as well as an indiscriminate grasping\nbaseline.\n"]},
{"authors": ["Hankz Hankui Zhuo", "Yantian Zha", "Subbarao Kambhampati"], "title": ["Discovering Underlying Plans Based on Shallow Models"], "date": ["2018-03-04T03:18:22Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.02208v1"], "summary": ["  Plan recognition aims to discover target plans (i.e., sequences of actions)\nbehind observed actions, with history plan libraries or domain models in hand.\nPrevious approaches either discover plans by maximally \"matching\" observed\nactions to plan libraries, assuming target plans are from plan libraries, or\ninfer plans by executing domain models to best explain the observed actions,\nassuming that complete domain models are available. In real world applications,\nhowever, target plans are often not from plan libraries, and complete domain\nmodels are often not available, since building complete sets of plans and\ncomplete domain models are often difficult or expensive. In this paper we view\nplan libraries as corpora and learn vector representations of actions using the\ncorpora, we then discover target plans based on the vector representations.\nSpecifically, we propose two approaches, DUP and RNNPlanner, to discover target\nplans based on vector representations of actions. DUP explores the EM-style\nframework to capture local contexts of actions and discover target plans by\noptimizing the probability of target plans, while RNNPlanner aims to leverage\nlong-short term contexts of actions based on RNNs (recurrent neural networks)\nframework to help recognize target plans. In the experiments, we empirically\nshow that our approaches are capable of discovering underlying plans that are\nnot from plan libraries, without requiring domain models provided. We\ndemonstrate the effectiveness of our approaches by comparing its performance to\ntraditional plan recognition approaches in three planning domains. We also\ncompare DUP and RNNPlanner to see their advantages and disadvantages.\n"]},
{"authors": ["Shaojie Bai", "J. Zico Kolter", "Vladlen Koltun"], "title": ["An Empirical Evaluation of Generic Convolutional and Recurrent Networks\n  for Sequence Modeling"], "date": ["2018-03-04T00:20:29Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.01271v1"], "summary": ["  For most deep learning practitioners, sequence modeling is synonymous with\nrecurrent networks. Yet recent results indicate that convolutional\narchitectures can outperform recurrent networks on tasks such as audio\nsynthesis and machine translation. Given a new sequence modeling task or\ndataset, which architecture should one use? We conduct a systematic evaluation\nof generic convolutional and recurrent architectures for sequence modeling. The\nmodels are evaluated across a broad range of standard tasks that are commonly\nused to benchmark recurrent networks. Our results indicate that a simple\nconvolutional architecture outperforms canonical recurrent networks such as\nLSTMs across a diverse range of tasks and datasets, while demonstrating longer\neffective memory. We conclude that the common association between sequence\nmodeling and recurrent networks should be reconsidered, and convolutional\nnetworks should be regarded as a natural starting point for sequence modeling\ntasks.\n"]},
{"authors": ["Nima Safaei", "Corey Kiassat"], "title": ["A Swift Heuristic Method for Work Order Scheduling under the\n  Skilled-Workforce Constraint"], "date": ["2018-03-03T22:19:42Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.01252v1"], "summary": ["  The considered problem is how to optimally allocate a set of jobs to\ntechnicians of different skills such that the number of technicians of each\nskill does not exceed the number of persons with that skill designation. The\nkey motivation is the quick sensitivity analysis in terms of the workforce size\nwhich is quite necessary in many industries in the presence of unexpected work\norders. A time-indexed mathematical model is proposed to minimize the total\nweighted completion time of the jobs. The proposed model is decomposed into a\nnumber of single-skill sub-problems so that each one is a combination of a\nseries of nested binary Knapsack problems. A heuristic procedure is proposed to\nsolve the problem. Our experimental results, based on a real-world case study,\nreveal that the proposed method quickly produces a schedule statistically close\nto the optimal one while the classical optimal procedure is very\ntime-consuming.\n"]},
{"authors": ["Vahan Huroyan", "Gilad Lerman"], "title": ["Distributed Robust Subspace Recovery"], "date": ["2017-05-25T22:22:51Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1705.09382v2"], "summary": ["  We study Robust Subspace Recovery (RSR) in distributed settings. We consider\na huge dataset in an ad hoc network without a central processor, where each\nnode has access only to one chunk of the dataset. We assume that part of the\nwhole dataset lies around a low-dimensional subspace and the other part is\ncomposed of outliers that lie away from that subspace. The goal is to recover\nthe underlying subspace for the whole dataset, without transferring the data\nitself between the nodes. We apply the Consensus-Based Gradient method for the\nGeometric Median Subspace algorithm for RSR. We propose an iterative solution\nfor the local dual minimization problem and establish its $r$-linear\nconvergence. We also explain how to distributedly implement the Reaper and Fast\nMedian Subspace algorithms for RSR. We demonstrate the competitive performance\nof our algorithms for both synthetic and real data.\n"]},
{"authors": ["Isaac J. Sledge", "Jose C. Principe"], "title": ["An Analysis of the Value of Information when Exploring Stochastic,\n  Discrete Multi-Armed Bandits"], "date": ["2017-10-08T18:48:48Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.02869v2"], "summary": ["  In this paper, we propose an information-theoretic exploration strategy for\nstochastic, discrete multi-armed bandits that achieves optimal regret. Our\nstrategy is based on the value of information criterion. This criterion\nmeasures the trade-off between policy information and obtainable rewards. High\namounts of policy information are associated with exploration-dominant searches\nof the space and yield high rewards. Low amounts of policy information favor\nthe exploitation of existing knowledge. Information, in this criterion, is\nquantified by a parameter that can be varied during search. We demonstrate that\na simulated-annealing-like update of this parameter, with a sufficiently fast\ncooling schedule, leads to an optimal regret that is logarithmic with respect\nto the number of episodes.\n"]},
{"authors": ["Simon S. Du", "Jason D. Lee"], "title": ["On the Power of Over-parametrization in Neural Networks with Quadratic\n  Activation"], "date": ["2018-03-03T17:37:57Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.01206v1"], "summary": ["  We provide new theoretical insights on why over-parametrization is effective\nin learning neural networks. For a $k$ hidden node shallow network with\nquadratic activation and $n$ training data points, we show as long as $ k \\ge\n\\sqrt{2n}$, over-parametrization enables local search algorithms to find a\n\\emph{globally} optimal solution for general smooth and convex loss functions.\nFurther, despite that the number of parameters may exceed the sample size,\nusing theory of Rademacher complexity, we show with weight decay, the solution\nalso generalizes well if the data is sampled from a regular distribution such\nas Gaussian. To prove when $k\\ge \\sqrt{2n}$, the loss function has benign\nlandscape properties, we adopt an idea from smoothed analysis, which may have\nother applications in studying loss surfaces of neural networks.\n"]},
{"authors": ["Ahmed Fadhil"], "title": ["Beyond Patient Monitoring: Conversational Agents Role in Telemedicine &\n  Healthcare Support For Home-Living Elderly Individuals"], "date": ["2018-03-03T13:45:08Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.06000v1"], "summary": ["  There is a need for systems to dynamically interact with ageing populations\nto gather information, monitor health condition and provide support, especially\nafter hospital discharge or at-home settings. Several smart devices have been\ndelivered by digital health, bundled with telemedicine systems, smartphone and\nother digital services. While such solutions offer personalised data and\nsuggestions, the real disruptive step comes from the interaction of new digital\necosystem, represented by chatbots. Chatbots will play a leading role by\nembodying the function of a virtual assistant and bridging the gap between\npatients and clinicians. Powered by AI and machine learning algorithms,\nchatbots are forecasted to save healthcare costs when used in place of a human\nor assist them as a preliminary step of helping to assess a condition and\nproviding self-care recommendations. This paper describes integrating chatbots\ninto telemedicine systems intended for elderly patient after their hospital\ndischarge. The paper discusses possible ways to utilise chatbots to assist\nhealthcare providers and support patients with their condition.\n"]},
{"authors": ["Ahmed Fadhil"], "title": ["Towards Automatic & Personalised Mobile Health Interventions: An\n  Interactive Machine Learning Perspective"], "date": ["2018-03-03T10:30:56Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.01842v1"], "summary": ["  Machine learning (ML) is the fastest growing field in computer science and\nhealthcare, providing future benefits in improved medical diagnoses, disease\nanalyses and prevention. In this paper, we introduce an application of\ninteractive machine learning (iML) in a telemedicine system, to enable\nautomatic and personalised interventions for lifestyle promotion. We first\npresent the high level architecture of the system and the components forming\nthe overall architecture. We then illustrate the interactive machine learning\nprocess design. Prediction models are expected to be trained through the\nparticipants' profiles, activity performance, and feedback from the caregiver.\nFinally, we show some preliminary results during the system implementation and\ndiscuss future directions. We envisage the proposed system to be digitally\nimplemented, and behaviourally designed to promote healthy lifestyle and\nactivities, and hence prevent users from the risk of chronic diseases.\n"]},
{"authors": ["Ahmed Fadhil"], "title": ["A Conversational Interface to Improve Medication Adherence: Towards AI\n  Support in Patient's Treatment"], "date": ["2018-03-03T10:07:21Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.09844v1"], "summary": ["  Medication adherence is of utmost importance for many chronic conditions,\nregardless of the disease type. Engaging patients in self-tracking their\nmedication is a big challenge. One way to potentially reduce this burden is to\nuse reminders to promote wellness throughout all stages of life and improve\nmedication adherence. Chatbots have proven effectiveness in triggering users to\nengage in certain activity, such as medication adherence. In this paper, we\ndiscuss \"Roborto\", a chatbot to create an engaging interactive and intelligent\nenvironment for patients and assist in positive lifestyle modification. We\nintroduce a way for healthcare providers to track patients adherence and\nintervene whenever necessary. We describe the health, technical and behavioural\napproaches to the problem of medication non-adherence and propose a diagnostic\nand decision support tool. The proposed study will be implemented and validated\nthrough a pilot experiment with users to measure the efficacy of the proposed\napproach.\n"]},
{"authors": ["Bradly C. Stadie", "Ge Yang", "Rein Houthooft", "Xi Chen", "Yan Duan", "Yuhuai Wu", "Pieter Abbeel", "Ilya Sutskever"], "title": ["Some Considerations on Learning to Explore via Meta-Reinforcement\n  Learning"], "date": ["2018-03-03T07:13:43Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.01118v1"], "summary": ["  We consider the problem of exploration in meta reinforcement learning. Two\nnew meta reinforcement learning algorithms are suggested: E-MAML and\nE-$\\text{RL}^2$. Results are presented on a novel environment we call `Krazy\nWorld' and a set of maze environments. We show E-MAML and E-$\\text{RL}^2$\ndeliver better performance on tasks where exploration is important.\n"]},
{"authors": ["Hongwei Ge", "Mingde Zhao", "Liang Sun", "Zhen Wang", "Guozhen Tan", "Qiang Zhang", "C. L. Philip Chen"], "title": ["An Interactive Many Objective Evolutionary Algorithm with Cascade\n  Clustering and Reference Point Incremental Learning"], "date": ["2018-03-03T02:53:09Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.01097v1"], "summary": ["  Researches have shown difficulties in obtaining proximity while maintaining\ndiversity for solving many-objective optimization problems (MaOPs). The\ncomplexities of the true Pareto Front (PF) also pose serious challenges for the\npervasive algorithms for their insufficient ability to adapt to the\ncharacteristics of the true PF with no priori. This paper proposes a cascade\nClustering and reference point incremental Learning based Interactive Algorithm\n(CLIA) for many-objective optimization. In the cascade clustering process,\nusing reference lines provided by the learning process, individuals are\nclustered and intraclassly sorted in a bi-level cascade style for better\nproximity and diversity. In the reference point incremental learning process,\nusing the feedbacks from the clustering process, the proper generation of\nreference points is gradually obtained by incremental learning and the\nreference lines are accordingly repositioned. The advantages of the proposed\ninteractive algorithm CLIA lie not only in the proximity obtainment and\ndiversity maintenance but also in the versatility for the diverse PFs which\nuses only the interactions between the two processes without incurring extra\nevaluations. The experimental studies on the CEC'2018 MaOP benchmark functions\nhave shown that the proposed algorithm CLIA has satisfactory covering of the\ntrue PFs, and is competitive, stable and efficient compared with the\nstate-of-the-art algorithms.\n"]},
{"authors": ["Zhiming Zhou", "Weinan Zhang", "Jun Wang"], "title": ["Inception Score, Label Smoothing, Gradient Vanishing and -log(D(x))\n  Alternative"], "date": ["2017-08-05T08:15:07Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1708.01729v2"], "summary": ["  In this article, we mathematically study several GAN related topics,\nincluding Inception score, label smoothing, gradient vanishing and the\n-log(D(x)) alternative.\n  --- An advanced version is included in arXiv:1703.02000 \"Activation\nMaximization Generative Adversarial Nets\". Please refer Section 6 in 1703.02000\nfor detailed analysis on Inception Score, and refer its appendix for the\ndiscussions on Label Smoothing, Gradient Vanishing and -log(D(x)) Alternative.\n---\n"]},
{"authors": ["Timo Nolle", "Stefan Luettgen", "Alexander Seeliger", "Max M\u00fchlh\u00e4user"], "title": ["Analyzing Business Process Anomalies Using Autoencoders"], "date": ["2018-03-03T02:26:28Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.01092v1"], "summary": ["  Businesses are naturally interested in detecting anomalies in their internal\nprocesses, because these can be indicators for fraud and inefficiencies. Within\nthe domain of business intelligence, classic anomaly detection is not very\nfrequently researched. In this paper, we propose a method, using autoencoders,\nfor detecting and analyzing anomalies occurring in the execution of a business\nprocess. Our method does not rely on any prior knowledge about the process and\ncan be trained on a noisy dataset already containing the anomalies. We\ndemonstrate its effectiveness by evaluating it on 700 different datasets and\ntesting its performance against three state-of-the-art anomaly detection\nmethods. This paper is an extension of our previous work from 2016 [30].\nCompared to the original publication we have further refined the approach in\nterms of performance and conducted an elaborate evaluation on more\nsophisticated datasets including real-life event logs from the Business Process\nIntelligence Challenges of 2012 and 2017. In our experiments our approach\nreached an F1 score of 0.87, whereas the best unaltered state-of-the-art\napproach reached an F1 score of 0.72. Furthermore, our approach can be used to\nanalyze the detected anomalies in terms of which event within one execution of\nthe process causes the anomaly.\n"]},
{"authors": ["Wenhao Yu", "C. Karen Liu", "Greg Turk"], "title": ["Multi-task Learning with Gradient Guided Policy Specialization"], "date": ["2017-09-23T00:54:18Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1709.07979v3"], "summary": ["  We present a method for efficient learning of control policies for multiple\nrelated robotic motor skills. Our approach consists of two stages, joint\ntraining and specialization training. During the joint training stage, a neural\nnetwork policy is trained with minimal information to disambiguate the motor\nskills. This forces the policy to learn a common representation of the\ndifferent tasks. Then, during the specialization training stage we selectively\nsplit the weights of the policy based on a per-weight metric that measures the\ndisagreement among the multiple tasks. By splitting part of the control policy,\nit can be further trained to specialize to each task. To update the control\npolicy during learning, we use Trust Region Policy Optimization with\nGeneralized Advantage Function (TRPOGAE). We propose a modification to the\ngradient update stage of TRPO to better accommodate multi-task learning\nscenarios. We evaluate our approach on three continuous motor skill learning\nproblems in simulation: 1) a locomotion task where three single legged robots\nwith considerable difference in shape and size are trained to hop forward, 2) a\nmanipulation task where three robot manipulators with different sizes and joint\ntypes are trained to reach different locations in 3D space, and 3) locomotion\nof a two-legged robot, whose range of motion of one leg is constrained in\ndifferent ways. We compare our training method to three baselines. The first\nbaseline uses only joint training for the policy, the second trains independent\npolicies for each task, and the last randomly selects weights to split. We show\nthat our approach learns more efficiently than each of the baseline methods.\n"]},
{"authors": ["Raunak P. Bhattacharyya", "Derek J. Phillips", "Blake Wulfe", "Jeremy Morton", "Alex Kuefler", "Mykel J. Kochenderfer"], "title": ["Multi-Agent Imitation Learning for Driving Simulation"], "date": ["2018-03-02T21:18:16Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.01044v1"], "summary": ["  Simulation is an appealing option for validating the safety of autonomous\nvehicles. Generative Adversarial Imitation Learning (GAIL) has recently been\nshown to learn representative human driver models. These human driver models\nwere learned through training in single-agent environments, but they have\ndifficulty in generalizing to multi-agent driving scenarios. We argue these\ndifficulties arise because observations at training and test time are sampled\nfrom different distributions. This difference makes such models unsuitable for\nthe simulation of driving scenes, where multiple agents must interact\nrealistically over long time horizons. We extend GAIL to address these\nshortcomings through a parameter-sharing approach grounded in curriculum\nlearning. Compared with single-agent GAIL policies, policies generated by our\nPS-GAIL method prove superior at interacting stably in a multi-agent setting\nand capturing the emergent behavior of human drivers.\n"]},
{"authors": ["Daniel Levy", "Matthew D. Hoffman", "Jascha Sohl-Dickstein"], "title": ["Generalizing Hamiltonian Monte Carlo with Neural Networks"], "date": ["2017-11-25T18:08:02Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.09268v3"], "summary": ["  We present a general-purpose method to train Markov chain Monte Carlo\nkernels, parameterized by deep neural networks, that converge and mix quickly\nto their target distribution. Our method generalizes Hamiltonian Monte Carlo\nand is trained to maximize expected squared jumped distance, a proxy for mixing\nspeed. We demonstrate large empirical gains on a collection of simple but\nchallenging distributions, for instance achieving a 106x improvement in\neffective sample size in one case, and mixing when standard HMC makes no\nmeasurable progress in a second. Finally, we show quantitative and qualitative\ngains on a real-world task: latent-variable generative modeling. We release an\nopen source TensorFlow implementation of the algorithm.\n"]},
{"authors": ["Teng Li", "Zhiyuan Xu", "Jian Tang", "Yanzhi Wang"], "title": ["Model-Free Control for Distributed Stream Data Processing using Deep\n  Reinforcement Learning"], "date": ["2018-03-02T19:30:55Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.01016v1"], "summary": ["  In this paper, we focus on general-purpose Distributed Stream Data Processing\nSystems (DSDPSs), which deal with processing of unbounded streams of continuous\ndata at scale distributedly in real or near-real time. A fundamental problem in\na DSDPS is the scheduling problem with the objective of minimizing average\nend-to-end tuple processing time. A widely-used solution is to distribute\nworkload evenly over machines in the cluster in a round-robin manner, which is\nobviously not efficient due to lack of consideration for communication delay.\nModel-based approaches do not work well either due to the high complexity of\nthe system environment. We aim to develop a novel model-free approach that can\nlearn to well control a DSDPS from its experience rather than accurate and\nmathematically solvable system models, just as a human learns a skill (such as\ncooking, driving, swimming, etc). Specifically, we, for the first time, propose\nto leverage emerging Deep Reinforcement Learning (DRL) for enabling model-free\ncontrol in DSDPSs; and present design, implementation and evaluation of a novel\nand highly effective DRL-based control framework, which minimizes average\nend-to-end tuple processing time by jointly learning the system environment via\ncollecting very limited runtime statistics data and making decisions under the\nguidance of powerful Deep Neural Networks. To validate and evaluate the\nproposed framework, we implemented it based on a widely-used DSDPS, Apache\nStorm, and tested it with three representative applications. Extensive\nexperimental results show 1) Compared to Storm's default scheduler and the\nstate-of-the-art model-based method, the proposed framework reduces average\ntuple processing by 33.5% and 14.0% respectively on average. 2) The proposed\nframework can quickly reach a good scheduling solution during online learning,\nwhich justifies its practicability for online control in DSDPSs.\n"]},
{"authors": ["Emily Denton", "Rob Fergus"], "title": ["Stochastic Video Generation with a Learned Prior"], "date": ["2018-02-21T17:36:27Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.07687v2"], "summary": ["  Generating video frames that accurately predict future world states is\nchallenging. Existing approaches either fail to capture the full distribution\nof outcomes, or yield blurry generations, or both. In this paper we introduce\nan unsupervised video generation model that learns a prior model of uncertainty\nin a given environment. Video frames are generated by drawing samples from this\nprior and combining them with a deterministic estimate of the future frame. The\napproach is simple and easily trained end-to-end on a variety of datasets.\nSample generations are both varied and sharp, even many frames into the future,\nand compare favorably to those from existing approaches.\n"]},
{"authors": ["Miten Mistry", "Dimitrios Letsios", "Ruth Misener", "Gerhard Krennrich", "Robert M. Lee"], "title": ["Optimization with Gradient-Boosted Trees and Risk Control"], "date": ["2018-03-02T17:10:21Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.00952v1"], "summary": ["  Decision trees effectively represent the sparse, high dimensional and noisy\nnature of chemical data from experiments. Having learned a function from this\ndata, we may want to thereafter optimize the function, e.g., picking the best\nchemical process catalyst. In this way, we may repurpose legacy predictive\nmodels. This work studies a large-scale, industrially-relevant mixed-integer\nquadratic optimization problem involving: (i) gradient-boosted pre-trained\nregression trees modeling catalyst behavior, (ii) penalty functions mitigating\nrisk, and (iii) penalties enforcing composition constraints. We develop\nheuristic methods and an exact, branch-and-bound algorithm leveraging\nstructural properties of gradient-boosted trees and penalty functions. We\nnumerically test our methods on an industrial instance.\n"]},
{"authors": ["Christian Buck", "Jannis Bulian", "Massimiliano Ciaramita", "Wojciech Gajewski", "Andrea Gesmundo", "Neil Houlsby", "Wei Wang"], "title": ["Ask the Right Questions: Active Question Reformulation with\n  Reinforcement Learning"], "date": ["2017-05-22T16:19:21Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1705.07830v3"], "summary": ["  We frame Question Answering (QA) as a Reinforcement Learning task, an\napproach that we call Active Question Answering. We propose an agent that sits\nbetween the user and a black box QA system and learns to reformulate questions\nto elicit the best possible answers. The agent probes the system with,\npotentially many, natural language reformulations of an initial question and\naggregates the returned evidence to yield the best answer. The reformulation\nsystem is trained end-to-end to maximize answer quality using policy gradient.\nWe evaluate on SearchQA, a dataset of complex questions extracted from\nJeopardy!. The agent outperforms a state-of-the-art base model, playing the\nrole of the environment, and other benchmarks. We also analyze the language\nthat the agent has learned while interacting with the question answering\nsystem. We find that successful question reformulations look quite different\nfrom natural language paraphrases. The agent is able to discover non-trivial\nreformulation strategies that resemble classic information retrieval techniques\nsuch as term re-weighting (tf-idf) and stemming.\n"]},
{"authors": ["Benito van der Zander", "Maciej Li\u015bkiewicz", "Johannes Textor"], "title": ["Separators and Adjustment Sets in Causal Graphs: Complete Criteria and\n  an Algorithmic Framework"], "date": ["2018-02-28T22:28:08Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.00116v2"], "summary": ["  Principled reasoning about the identifiability of causal effects from\nnon-experimental data is an important application of graphical causal models.\nWe present an algorithmic framework for efficiently testing, constructing, and\nenumerating $m$-separators in ancestral graphs (AGs), a class of graphical\ncausal models that can represent uncertainty about the presence of latent\nconfounders. Furthermore, we prove a reduction from causal effect\nidentification by covariate adjustment to $m$-separation in a subgraph for\ndirected acyclic graphs (DAGs) and maximal ancestral graphs (MAGs). Jointly,\nthese results yield constructive criteria that characterize all adjustment sets\nas well as all minimal and minimum adjustment sets for identification of a\ndesired causal effect with multivariate exposures and outcomes in the presence\nof latent confounding. Our results extend several existing solutions for\nspecial cases of these problems. Our efficient algorithms allowed us to\nempirically quantify the identifiability gap between covariate adjustment and\nthe do-calculus in random DAGs, covering a wide range of scenarios.\nImplementations of our algorithms are provided in the R package dagitty.\n"]},
{"authors": ["Alexander Peysakhovich", "Adam Lerer"], "title": ["Consequentialist conditional cooperation in social dilemmas with\n  imperfect information"], "date": ["2017-10-19T00:54:53Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.06975v2"], "summary": ["  Social dilemmas, where mutual cooperation can lead to high payoffs but\nparticipants face incentives to cheat, are ubiquitous in multi-agent\ninteraction. We wish to construct agents that cooperate with pure cooperators,\navoid exploitation by pure defectors, and incentivize cooperation from the\nrest. However, often the actions taken by a partner are (partially) unobserved\nor the consequences of individual actions are hard to predict. We show that in\na large class of games good strategies can be constructed by conditioning one's\nbehavior solely on outcomes (ie. one's past rewards). We call this\nconsequentialist conditional cooperation. We show how to construct such\nstrategies using deep reinforcement learning techniques and demonstrate, both\nanalytically and experimentally, that they are effective in social dilemmas\nbeyond simple matrix games. We also show the limitations of relying purely on\nconsequences and discuss the need for understanding both the consequences of\nand the intentions behind an action.\n"]},
{"authors": ["Hiroaki Tsushima", "Eita Nakamura", "Katsutoshi Itoyama", "Kazuyoshi Yoshii"], "title": ["Generative Statistical Models with Self-Emergent Grammar of Chord\n  Sequences"], "date": ["2017-08-07T18:00:42Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1708.02255v3"], "summary": ["  Generative statistical models of chord sequences play crucial roles in music\nprocessing. To capture syntactic similarities among certain chords (e.g. in C\nmajor key, between G and G7 and between F and Dm), we study hidden Markov\nmodels and probabilistic context-free grammar models with latent variables\ndescribing syntactic categories of chord symbols and their unsupervised\nlearning techniques for inducing the latent grammar from data. Surprisingly, we\nfind that these models often outperform conventional Markov models in\npredictive power, and the self-emergent categories often correspond to\ntraditional harmonic functions. This implies the need for chord categories in\nharmony models from the informatics perspective.\n"]},
{"authors": ["Adam Lerer", "Alexander Peysakhovich"], "title": ["Maintaining cooperation in complex social dilemmas using deep\n  reinforcement learning"], "date": ["2017-07-04T17:02:05Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1707.01068v4"], "summary": ["  Social dilemmas are situations where individuals face a temptation to\nincrease their payoffs at a cost to total welfare. Building artificially\nintelligent agents that achieve good outcomes in these situations is important\nbecause many real world interactions include a tension between selfish\ninterests and the welfare of others. We show how to modify modern reinforcement\nlearning methods to construct agents that act in ways that are simple to\nunderstand, nice (begin by cooperating), provokable (try to avoid being\nexploited), and forgiving (try to return to mutual cooperation). We show both\ntheoretically and experimentally that such agents can maintain cooperation in\nMarkov social dilemmas. Our construction does not require training methods\nbeyond a modification of self-play, thus if an environment is such that good\nstrategies can be constructed in the zero-sum case (eg. Atari) then we can\nconstruct agents that solve social dilemmas in this environment.\n"]},
{"authors": ["Anjishnu Kumar", "Arpit Gupta", "Julian Chan", "Sam Tucker", "Bjorn Hoffmeister", "Markus Dreyer", "Stanislav Peshterliev", "Ankur Gandhe", "Denis Filiminov", "Ariya Rastrow", "Christian Monson", "Agnika Kumar"], "title": ["Just ASK: Building an Architecture for Extensible Self-Service Spoken\n  Language Understanding"], "date": ["2017-11-01T22:10:11Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.00549v4"], "summary": ["  This paper presents the design of the machine learning architecture that\nunderlies the Alexa Skills Kit (ASK) a large scale Spoken Language\nUnderstanding (SLU) Software Development Kit (SDK) that enables developers to\nextend the capabilities of Amazon's virtual assistant, Alexa. At Amazon, the\ninfrastructure powers over 25,000 skills deployed through the ASK, as well as\nAWS's Amazon Lex SLU Service. The ASK emphasizes flexibility, predictability\nand a rapid iteration cycle for third party developers. It imposes inductive\nbiases that allow it to learn robust SLU models from extremely small and sparse\ndatasets and, in doing so, removes significant barriers to entry for software\ndevelopers and dialogue systems researchers.\n"]},
{"authors": ["Dennis Diefenbach", "Andreas Both", "Kamal Singh", "Pierre Maret"], "title": ["Towards a Question Answering System over the Semantic Web"], "date": ["2018-03-02T12:59:50Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.00832v1"], "summary": ["  Thanks to the development of the Semantic Web, a lot of new structured data\nhas become available on the Web in the form of knowledge bases (KBs). Making\nthis valuable data accessible and usable for end-users is one of the main goals\nof Question Answering (QA) over KBs. Most current QA systems query one KB, in\none language (namely English). The existing approaches are not designed to be\neasily adaptable to new KBs and languages. We first introduce a new approach\nfor translating natural language questions to SPARQL queries. It is able to\nquery several KBs simultaneously, in different languages, and can easily be\nported to other KBs and languages. In our evaluation, the impact of our\napproach is proven using 5 different well-known and large KBs: Wikidata,\nDBpedia, MusicBrainz, DBLP and Freebase as well as 5 different languages namely\nEnglish, German, French, Italian and Spanish. Second, we show how we integrated\nour approach, to make it easily accessible by the research community and by\nend-users. To summarize, we provided a conceptional solution for multilingual,\nKB-agnostic Question Answering over the Semantic Web. The provided first\napproximation validates this concept.\n"]},
{"authors": ["Bhushan Kotnis", "Vivi Nastase"], "title": ["Learning Knowledge Graph Embeddings with Type Regularizer"], "date": ["2017-06-28T13:24:55Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1706.09278v2"], "summary": ["  Learning relations based on evidence from knowledge bases relies on\nprocessing the available relation instances. Many relations, however, have\nclear domain and range, which we hypothesize could help learn a better, more\ngeneralizing, model. We include such information in the RESCAL model in the\nform of a regularization factor added to the loss function that takes into\naccount the types (categories) of the entities that appear as arguments to\nrelations in the knowledge base. We note increased performance compared to the\nbaseline model in terms of mean reciprocal rank and hits@N, N = 1, 3, 10.\nFurthermore, we discover scenarios that significantly impact the effectiveness\nof the type regularizer.\n"]},
{"authors": ["Bhushan Kotnis", "Vivi Nastase"], "title": ["Analysis of the Impact of Negative Sampling on Link Prediction in\n  Knowledge Graphs"], "date": ["2017-08-22T20:53:29Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1708.06816v2"], "summary": ["  Knowledge graphs are large, useful, but incomplete knowledge repositories.\nThey encode knowledge through entities and relations which define each other\nthrough the connective structure of the graph. This has inspired methods for\nthe joint embedding of entities and relations in continuous low-dimensional\nvector spaces, that can be used to induce new edges in the graph, i.e., link\nprediction in knowledge graphs. Learning these representations relies on\ncontrasting positive instances with negative ones. Knowledge graphs include\nonly positive relation instances, leaving the door open for a variety of\nmethods for selecting negative examples. In this paper we present an empirical\nstudy on the impact of negative sampling on the learned embeddings, assessed\nthrough the task of link prediction. We use state-of-the-art knowledge graph\nembeddings -- \\rescal , TransE, DistMult and ComplEX -- and evaluate on\nbenchmark datasets -- FB15k and WN18. We compare well known methods for\nnegative sampling and additionally propose embedding based sampling methods. We\nnote a marked difference in the impact of these sampling methods on the two\ndatasets, with the \"traditional\" corrupting positives method leading to best\nresults on WN18, while embedding based methods benefiting the task on FB15k.\n"]},
{"authors": ["Brijnesh J. Jain", "David Schultz"], "title": ["Optimal Warping Paths are unique for almost every Pair of Time Series"], "date": ["2017-05-16T12:41:25Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1705.05681v2"], "summary": ["  Update rules for learning in dynamic time warping spaces are based on optimal\nwarping paths between parameter and input time series. In general, optimal\nwarping paths are not unique resulting in adverse effects in theory and\npractice. Under the assumption of squared error local costs, we show that no\ntwo warping paths have identical costs almost everywhere in a measure-theoretic\nsense. Two direct consequences of this result are: (i) optimal warping paths\nare unique almost everywhere, and (ii) the set of all pairs of time series with\nmultiple equal-cost warping paths coincides with the union of exponentially\nmany zero sets of quadratic forms. One implication of the proposed results is\nthat typical distance-based cost functions such as the k-means objective are\ndifferentiable almost everywhere and can be minimized by subgradient methods.\n"]},
{"authors": ["Yu Gong", "Kaiqi Zhao", "Kenny Q. Zhu"], "title": ["Representing Verbs as Argument Concepts"], "date": ["2018-03-02T06:18:40Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.00729v1"], "summary": ["  Verbs play an important role in the understanding of natural language text.\nThis paper studies the problem of abstracting the subject and object arguments\nof a verb into a set of noun concepts, known as the \"argument concepts\". This\nset of concepts, whose size is parameterized, represents the fine-grained\nsemantics of a verb. For example, the object of \"enjoy\" can be abstracted into\ntime, hobby and event, etc. We present a novel framework to automatically infer\nhuman readable and machine computable action concepts with high accuracy.\n"]},
{"authors": ["Pedro Quaresma", "Walther Neuper"], "title": ["Proceedings 6th International Workshop on Theorem proving components for\n  Educational software"], "date": ["2018-03-02T05:23:45Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.00722v1"], "summary": ["  The 6th International Workshop on Theorem proving components for Educational\nsoftware (ThEdu'17) was held in Gothenburg, Sweden, on 6 Aug 2017. It was\nassociated to the conference CADE26. Topics of interest include: methods of\nautomated deduction applied to checking students' input; methods of automated\ndeduction applied to prove post-conditions for particular problem solutions;\ncombinations of deduction and computation enabling systems to propose next\nsteps; automated provers specific for dynamic geometry systems; proof and\nproving in mathematics education.\n  ThEdu'17 was a vibrant workshop, with one invited talk and eight\ncontributions. It triggered the post-proceedings at hand.\n"]},
{"authors": ["Alexander Trott", "Caiming Xiong", "Richard Socher"], "title": ["Interpretable Counting for Visual Question Answering"], "date": ["2017-12-23T01:44:45Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1712.08697v2"], "summary": ["  Questions that require counting a variety of objects in images remain a major\nchallenge in visual question answering (VQA). The most common approaches to VQA\ninvolve either classifying answers based on fixed length representations of\nboth the image and question or summing fractional counts estimated from each\nsection of the image. In contrast, we treat counting as a sequential decision\nprocess and force our model to make discrete choices of what to count.\nSpecifically, the model sequentially selects from detected objects and learns\ninteractions between objects that influence subsequent selections. A\ndistinction of our approach is its intuitive and interpretable output, as\ndiscrete counts are automatically grounded in the image. Furthermore, our\nmethod outperforms the state of the art architecture for VQA on multiple\nmetrics that evaluate counting.\n"]},
{"authors": ["Eric Wong", "J. Zico Kolter"], "title": ["Provable defenses against adversarial examples via the convex outer\n  adversarial polytope"], "date": ["2017-11-02T17:59:24Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.00851v2"], "summary": ["  We propose a method to learn deep ReLU-based classifiers that are provably\nrobust against norm-bounded adversarial perturbations on the training data. For\npreviously unseen examples, the approach is guaranteed to detect all\nadversarial examples, though it may flag some non-adversarial examples as well.\nThe basic idea is to consider a convex outer approximation of the set of\nactivations reachable through a norm-bounded perturbation, and we develop a\nrobust optimization procedure that minimizes the worst case loss over this\nouter region (via a linear program). Crucially, we show that the dual problem\nto this linear program can be represented itself as a deep network similar to\nthe backpropagation network, leading to very efficient optimization approaches\nthat produce guaranteed bounds on the robust loss. The end result is that by\nexecuting a few more forward and backward passes through a slightly modified\nversion of the original network (though possibly with much larger batch sizes),\nwe can learn a classifier that is provably robust to any norm-bounded\nadversarial attack. We illustrate the approach on a number of tasks to train\nclassifiers with robust adversarial guarantees (e.g. for MNIST, we produce a\nconvolutional classifier that provably has less than 5.8% test error for any\nadversarial attack with bounded $\\ell_\\infty$ norm less than $\\epsilon = 0.1$).\nCode for all experiments in the paper is available at\nhttps://github.com/locuslab/convex_adversarial.\n"]},
{"authors": ["Nikolay Savinov", "Alexey Dosovitskiy", "Vladlen Koltun"], "title": ["Semi-parametric Topological Memory for Navigation"], "date": ["2018-03-01T22:50:35Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.00653v1"], "summary": ["  We introduce a new memory architecture for navigation in previously unseen\nenvironments, inspired by landmark-based navigation in animals. The proposed\nsemi-parametric topological memory (SPTM) consists of a (non-parametric) graph\nwith nodes corresponding to locations in the environment and a (parametric)\ndeep network capable of retrieving nodes from the graph based on observations.\nThe graph stores no metric information, only connectivity of locations\ncorresponding to the nodes. We use SPTM as a planning module in a navigation\nsystem. Given only 5 minutes of footage of a previously unseen maze, an\nSPTM-based navigation agent can build a topological map of the environment and\nuse it to confidently navigate towards goals. The average success rate of the\nSPTM agent in goal-directed navigation across test environments is higher than\nthe best-performing baseline by a factor of three. A video of the agent is\navailable at https://youtu.be/vRF7f4lhswo\n"]},
{"authors": ["Mitsuru Igami"], "title": ["Artificial Intelligence as Structural Estimation: Economic\n  Interpretations of Deep Blue, Bonanza, and AlphaGo"], "date": ["2017-10-30T14:25:39Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.10967v3"], "summary": ["  Artificial intelligence (AI) has achieved superhuman performance in a growing\nnumber of tasks, but understanding and explaining AI remain challenging. This\npaper clarifies the connections between machine-learning algorithms to develop\nAIs and the econometrics of dynamic structural models through the case studies\nof three famous game AIs. Chess-playing Deep Blue is a calibrated value\nfunction, whereas shogi-playing Bonanza is an estimated value function via\nRust's (1987) nested fixed-point method. AlphaGo's \"supervised-learning policy\nnetwork\" is a deep neural network implementation of Hotz and Miller's (1993)\nconditional choice probability estimation; its \"reinforcement-learning value\nnetwork\" is equivalent to Hotz, Miller, Sanders, and Smith's (1994) conditional\nchoice simulation method. Relaxing these AIs' implicit econometric assumptions\nwould improve their structural interpretability.\n"]},
{"authors": ["Haowen Deng", "Tolga Birdal", "Slobodan Ilic"], "title": ["PPFNet: Global Context Aware Local Features for Robust 3D Point Matching"], "date": ["2018-02-07T23:01:52Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.02669v2"], "summary": ["  We present PPFNet - Point Pair Feature NETwork for deeply learning a globally\ninformed 3D local feature descriptor to find correspondences in unorganized\npoint clouds. PPFNet learns local descriptors on pure geometry and is highly\naware of the global context, an important cue in deep learning. Our 3D\nrepresentation is computed as a collection of point-pair-features combined with\nthe points and normals within a local vicinity. Our permutation invariant\nnetwork design is inspired by PointNet and sets PPFNet to be ordering-free. As\nopposed to voxelization, our method is able to consume raw point clouds to\nexploit the full sparsity. PPFNet uses a novel $\\textit{N-tuple}$ loss and\narchitecture injecting the global information naturally into the local\ndescriptor. It shows that context awareness also boosts the local feature\nrepresentation. Qualitative and quantitative evaluations of our network suggest\nincreased recall, improved robustness and invariance as well as a vital step in\nthe 3D descriptor extraction performance.\n"]},
{"authors": ["Hoang M. Le", "Nan Jiang", "Alekh Agarwal", "Miroslav Dud\u00edk", "Yisong Yue", "Hal Daum\u00e9 III"], "title": ["Hierarchical Imitation and Reinforcement Learning"], "date": ["2018-03-01T19:12:27Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.00590v1"], "summary": ["  We study the problem of learning policies over long time horizons. We present\na framework that leverages and integrates two key concepts. First, we utilize\nhierarchical policy classes that enable planning over different time scales,\ni.e., the high level planner proposes a sequence of subgoals for the low level\nplanner to achieve. Second, we utilize expert demonstrations within the\nhierarchical action space to dramatically reduce cost of exploration. Our\nframework is flexible and can incorporate different combinations of imitation\nlearning (IL) and reinforcement learning (RL) at different levels of the\nhierarchy. Using long-horizon benchmarks, including Montezuma's Revenge, we\nempirically demonstrate that our approach can learn significantly faster\ncompared to hierarchical RL, and can be significantly more label- and\nsample-efficient compared to flat IL. We also provide theoretical analysis of\nthe labeling cost for certain instantiations of our framework.\n"]},
{"authors": ["Nathaniel Thomas", "Tess Smidt", "Steven Kearnes", "Lusann Yang", "Li Li", "Kai Kohlhoff", "Patrick Riley"], "title": ["Tensor Field Networks: Rotation- and Translation-Equivariant Neural\n  Networks for 3D Point Clouds"], "date": ["2018-02-22T18:17:31Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08219v2"], "summary": ["  We introduce tensor field networks, which are locally equivariant to 3D\nrotations, translations, and permutations of points at every layer. 3D rotation\nequivariance removes the need for data augmentation to identify features in\narbitrary orientations. Our network uses filters built from spherical\nharmonics; due to the mathematical consequences of this filter choice, each\nlayer accepts as input (and guarantees as output) scalars, vectors, and\nhigher-order tensors, in the geometric sense of these terms. We demonstrate how\ntensor field networks learn to model simple physics (Newtonian gravitation and\nmoment of inertia), classify simple 3D shapes (trained on one orientation and\ntested on shapes in arbitrary orientations), and, given a small organic\nmolecule with an atom removed, replace the correct element at the correct\nlocation in space.\n"]},
{"authors": ["Evangelos Michelioudakis", "Alexander Artikis", "Georgios Paliouras"], "title": ["Semi-Supervised Online Structure Learning for Composite Event\n  Recognition"], "date": ["2018-03-01T18:31:07Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.00546v1"], "summary": ["  Online structure learning approaches, such as those stemming from Statistical\nRelational Learning, enable the discovery of complex relations in noisy data\nstreams. However, these methods assume the existence of fully-labelled training\ndata, which is unrealistic for most real-world applications. We present a novel\napproach for completing the supervision of a semi-supervised structure learning\ntask. We incorporate graph cut minimisation, a technique that derives labels\nfor unlabelled data, based on their distance to their labelled counterparts. In\norder to adapt graph cut minimisation to first order logic, we employ a\nsuitable structural distance for measuring the distance between sets of logical\natoms. The labelling process is achieved online (single-pass) by means of a\ncaching mechanism and the Hoeffding bound, a statistical tool to approximate\nglobally-optimal decisions from locally-optimal ones. We evaluate our approach\non the task of composite event recognition by using a benchmark dataset for\nhuman activity recognition, as well as a real dataset for maritime monitoring.\nThe evaluation suggests that our approach can effectively complete the missing\nlabels and eventually, improve the accuracy of the underlying structure\nlearning system.\n"]},
{"authors": ["Wajdi Dhifli", "Abdoulaye Banir\u00e9 Diallo"], "title": ["Toward an Efficient Multi-class Classification in an Open Universe"], "date": ["2015-11-02T22:04:00Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1511.00725v3"], "summary": ["  Classification is a fundamental task in machine learning and data mining.\nExisting classification methods are designed to classify unknown instances\nwithin a set of previously known training classes. Such a classification takes\nthe form of a prediction within a closed-set of classes. However, a more\nrealistic scenario that fits real-world applications is to consider the\npossibility of encountering instances that do not belong to any of the training\nclasses, $i.e.$, an open-set classification. In such situation, existing\nclosed-set classifiers will assign a training label to these instances\nresulting in a misclassification. In this paper, we introduce Galaxy-X, a novel\nmulti-class classification approach for open-set recognition problems. For each\nclass of the training set, Galaxy-X creates a minimum bounding hyper-sphere\nthat encompasses the distribution of the class by enclosing all of its\ninstances. In such manner, our method is able to distinguish instances\nresembling previously seen classes from those that are of unknown ones. To\nadequately evaluate open-set classification, we introduce a novel evaluation\nprocedure. Experimental results on benchmark datasets show the efficiency of\nour approach in classifying novel instances from known as well as unknown\nclasses.\n"]},
{"authors": ["Amy Zhang", "Adam Lerer", "Sainbayar Sukhbaatar", "Rob Fergus", "Arthur Szlam"], "title": ["Composable Planning with Attributes"], "date": ["2018-03-01T17:21:03Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.00512v1"], "summary": ["  The tasks that an agent will need to solve often are not known during\ntraining. However, if the agent knows which properties of the environment are\nimportant then, after learning how its actions affect those properties, it may\nbe able to use this knowledge to solve complex tasks without training\nspecifically for them. Towards this end, we consider a setup in which an\nenvironment is augmented with a set of user defined attributes that\nparameterize the features of interest. We propose a method that learns a policy\nfor transitioning between \"nearby\" sets of attributes, and maintains a graph of\npossible transitions. Given a task at test time that can be expressed in terms\nof a target set of attributes, and a current state, our model infers the\nattributes of the current state and searches over paths through attribute space\nto get a high level plan, and then uses its low level policy to execute the\nplan. We show in 3D block stacking, grid-world games, and StarCraft that our\nmodel is able to generalize to longer, more complex tasks at test time by\ncomposing simpler learned policies.\n"]},
{"authors": ["Benjamin Eysenbach", "Abhishek Gupta", "Julian Ibarz", "Sergey Levine"], "title": ["Diversity is All You Need: Learning Skills without a Reward Function"], "date": ["2018-02-16T18:57:57Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06070v4"], "summary": ["  Intelligent creatures can explore their environments and learn useful skills\nwithout supervision. In this paper, we propose DIAYN (\"Diversity is All You\nNeed\"), a method for learning useful skills without a reward function. Our\nproposed method learns skills by maximizing an information theoretic objective\nusing a maximum entropy policy. On a variety of simulated robotic tasks, we\nshow that this simple objective results in the unsupervised emergence of\ndiverse skills, such as walking and jumping. In a number of reinforcement\nlearning benchmark environments, our method is able to learn a skill that\nsolves the benchmark task despite never receiving the true task reward. In\nthese environments, some of the learned skills correspond to solving the task,\nand each skill that solves the task does so in a distinct manner. Our results\nsuggest that unsupervised discovery of skills can serve as an effective\npretraining mechanism for overcoming challenges of exploration and data\nefficiency in reinforcement learning\n"]},
{"authors": ["Jose M. Pe\u00f1a"], "title": ["Unifying DAGs and UGs"], "date": ["2017-08-29T12:17:59Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1708.08722v8"], "summary": ["  We introduce a new class of graphical models that generalizes\nLauritzen-Wermuth-Frydenberg chain graphs by relaxing the semi-directed\nacyclity constraint so that only directed cycles are forbidden. Moreover, up to\ntwo edges are allowed between any pair of nodes. Specifically, we present\nlocal, pairwise and global Markov properties for the new graphical models and\nprove their equivalence. We also present an equivalent factorization property.\nFinally, we present a causal interpretation of the new models.\n"]},
{"authors": ["Kieran Greer"], "title": ["Adding Context to Concept Trees"], "date": ["2016-06-17T17:32:11Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1606.05597v3"], "summary": ["  Concept Trees are a type of database that can organise arbitrary textual\ninformation using a very simple rule. Each tree tries to represent a single\ncohesive concept and the trees can link with each other for navigation and\nsemantic purposes. The trees are therefore a type of semantic network and would\nbenefit from having a consistent level of context for each of the nodes. The\nConcept Tree nodes have a mathematical basis allowing for a consistent build\nprocess. These would represent nouns or verbs in a text sentence, for example.\nNew to the design can then be lists of descriptive elements for each of the\nnodes. The descriptors can also be weighted, but do not have to follow the\nstrict counting rule of the tree nodes. With the new descriptive layers, a much\nricher type of knowledge can be achieved and a consistent method for adding\ncontext is suggested. It is also suggested to use the linking structure of the\nlicas system as basis for the context links. The mathematical model is extended\nfurther and to finish, a query language is suggested for practical\napplications.\n"]},
{"authors": ["Adrian \u0160o\u0161i\u0107", "Elmar Rueckert", "Jan Peters", "Abdelhak M. Zoubir", "Heinz Koeppl"], "title": ["Inverse Reinforcement Learning via Nonparametric Spatio-Temporal Subgoal\n  Modeling"], "date": ["2018-03-01T15:31:28Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.00444v1"], "summary": ["  Recent advances in the field of inverse reinforcement learning (IRL) have\nyielded sophisticated frameworks which relax the original modeling assumption\nthat the behavior of an observed agent reflects only a single intention.\nInstead, the demonstration data is typically divided into parts, to account for\nthe fact that different trajectories may correspond to different intentions,\ne.g., because they were generated by different domain experts. In this work, we\ngo one step further: using the intuitive concept of subgoals, we build upon the\npremise that even a single trajectory can be explained more efficiently locally\nwithin a certain context than globally, enabling a more compact representation\nof the observed behavior. Based on this assumption, we build an implicit\nintentional model of the agent's goals to forecast its behavior in unobserved\nsituations. The result is an integrated Bayesian prediction framework which\nprovides smooth policy estimates that are consistent with the expert's plan and\nsignificantly outperform existing IRL solutions. Most notably, our framework\nnaturally handles situations where the intentions of the agent change with time\nand classical IRL algorithms fail. In addition, due to its probabilistic\nnature, the model can be straightforwardly applied in an active learning\nsetting to guide the demonstration process of the expert.\n"]},
{"authors": ["William Fedus", "Ian Goodfellow", "Andrew M. Dai"], "title": ["MaskGAN: Better Text Generation via Filling in the______"], "date": ["2018-01-23T19:22:21Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.07736v3"], "summary": ["  Neural text generation models are often autoregressive language models or\nseq2seq models. These models generate text by sampling words sequentially, with\neach word conditioned on the previous word, and are state-of-the-art for\nseveral machine translation and summarization benchmarks. These benchmarks are\noften defined by validation perplexity even though this is not a direct measure\nof the quality of the generated text. Additionally, these models are typically\ntrained via maxi- mum likelihood and teacher forcing. These methods are\nwell-suited to optimizing perplexity but can result in poor sample quality\nsince generating text requires conditioning on sequences of words that may have\nnever been observed at training time. We propose to improve sample quality\nusing Generative Adversarial Networks (GANs), which explicitly train the\ngenerator to produce high quality samples and have shown a lot of success in\nimage generation. GANs were originally designed to output differentiable\nvalues, so discrete language generation is challenging for them. We claim that\nvalidation perplexity alone is not indicative of the quality of text generated\nby a model. We introduce an actor-critic conditional GAN that fills in missing\ntext conditioned on the surrounding context. We show qualitatively and\nquantitatively, evidence that this produces more realistic conditional and\nunconditional text samples compared to a maximum likelihood trained model.\n"]},
{"authors": ["Joris Tavernier", "Jaak Simm", "Karl Meerbergen", "Joerg Kurt Wegner", "Hugo Ceulemans", "Yves Moreau"], "title": ["Fast semi-supervised discriminant analysis for binary classification of\n  large data-sets"], "date": ["2017-09-14T13:53:49Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1709.04794v2"], "summary": ["  High-dimensional data requires scalable algorithms. We propose and analyze\nthree scalable and related algorithms for semi-supervised discriminant analysis\n(SDA). These methods are based on Krylov subspace methods which exploit the\ndata sparsity and the shift-invariance of Krylov subspaces. In addition, the\nproblem definition was improved by adding centralization to the semi-supervised\nsetting. The proposed methods are evaluated on a industry-scale data set from a\npharmaceutical company to predict compound activity on target proteins. The\nresults show that SDA achieves good predictive performance and our methods only\nrequire a few seconds, significantly improving computation time on previous\nstate of the art.\n"]},
{"authors": ["Gangeshwar Krishnamurthy", "Navonil Majumder", "Soujanya Poria", "Erik Cambria"], "title": ["A Deep Learning Approach for Multimodal Deception Detection"], "date": ["2018-03-01T12:38:13Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.00344v1"], "summary": ["  Automatic deception detection is an important task that has gained momentum\nin computational linguistics due to its potential applications. In this paper,\nwe propose a simple yet tough to beat multi-modal neural model for deception\ndetection. By combining features from different modalities such as video,\naudio, and text along with Micro-Expression features, we show that detecting\ndeception in real life videos can be more accurate. Experimental results on a\ndataset of real-life deception videos show that our model outperforms existing\ntechniques for deception detection with an accuracy of 96.14% and ROC-AUC of\n0.9799.\n"]},
{"authors": ["Francesco Riccio", "Roberto Capobianco", "Daniele Nardi"], "title": ["Q-CP: Learning Action Values for Cooperative Planning"], "date": ["2018-03-01T10:53:04Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.00297v1"], "summary": ["  Research on multi-robot systems has demonstrated promising results in\nmanifold applications and domains. Still, efficiently learning an effective\nrobot behaviors is very difficult, due to unstructured scenarios, high\nuncertainties, and large state dimensionality (e.g. hyper-redundant and groups\nof robot). To alleviate this problem, we present Q-CP a cooperative model-based\nreinforcement learning algorithm, which exploits action values to both (1)\nguide the exploration of the state space and (2) generate effective policies.\nSpecifically, we exploit Q-learning to attack the curse-of-dimensionality in\nthe iterations of a Monte-Carlo Tree Search. We implement and evaluate Q-CP on\ndifferent stochastic cooperative (general-sum) games: (1) a simple cooperative\nnavigation problem among 3 robots, (2) a cooperation scenario between a pair of\nKUKA YouBots performing hand-overs, and (3) a coordination task between two\nmobile robots entering a door. The obtained results show the effectiveness of\nQ-CP in the chosen applications, where action values drive the exploration and\nreduce the computational demand of the planning process while achieving good\nperformance.\n"]},
{"authors": ["Thibaut Kulak", "Michael Garcia Ortiz"], "title": ["Representation Learning in Partially Observable Environments using\n  Sensorimotor Prediction"], "date": ["2018-03-01T09:28:56Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.00268v1"], "summary": ["  In order to explore and act autonomously in an environment, an agent needs to\nlearn from the sensorimotor information that is captured while acting. By\nextracting the regularities in this sensorimotor stream, it can learn a model\nof the world, which in turn can be used as a basis for action and exploration.\n  This requires the acquisition of compact representations from a possibly high\ndimensional raw observation, which is noisy and ambiguous. In this paper, we\nlearn sensory representations from sensorimotor prediction. We propose a model\nwhich integrates sensorimotor information over time, and project it in a\nsensory representation which is useful for prediction. We emphasize on a simple\nexample the role of motor and memory for learning sensory representations.\n"]},
{"authors": ["Jun Zhao", "Guang Qiu", "Ziyu Guan", "Wei Zhao", "Xiaofei He"], "title": ["Deep Reinforcement Learning for Sponsored Search Real-time Bidding"], "date": ["2018-03-01T09:04:37Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.00259v1"], "summary": ["  Bidding optimization is one of the most critical problems in online\nadvertising. Sponsored search (SS) auction, due to the randomness of user query\nbehavior and platform nature, usually adopts keyword-level bidding strategies.\nIn contrast, the display advertising (DA), as a relatively simpler scenario for\nauction, has taken advantage of real-time bidding (RTB) to boost the\nperformance for advertisers. In this paper, we consider the RTB problem in\nsponsored search auction, named SS-RTB. SS-RTB has a much more complex dynamic\nenvironment, due to stochastic user query behavior and more complex bidding\npolicies based on multiple keywords of an ad. Most previous methods for DA\ncannot be applied. We propose a reinforcement learning (RL) solution for\nhandling the complex dynamic environment. Although some RL methods have been\nproposed for online advertising, they all fail to address the \"environment\nchanging\" problem: the state transition probabilities vary between two days.\nMotivated by the observation that auction sequences of two days share similar\ntransition patterns at a proper aggregation level, we formulate a robust MDP\nmodel at hour-aggregation level of the auction data and propose a\ncontrol-by-model framework for SS-RTB. Rather than generating bid prices\ndirectly, we decide a bidding model for impressions of each hour and perform\nreal-time bidding accordingly. We also extend the method to handle the\nmulti-agent problem. We deployed the SS-RTB system in the e-commerce search\nauction platform of Alibaba. Empirical experiments of offline evaluation and\nonline A/B test demonstrate the effectiveness of our method.\n"]},
{"authors": ["Mengjing Chen", "Weiran Shen", "Pingzhong Tang", "Song Zuo"], "title": ["Optimal Vehicle Dispatching Schemes via Dynamic Pricing"], "date": ["2017-07-06T03:46:09Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1707.01625v2"], "summary": ["  Over the past few years, ride-sharing has emerged as an effective way to\nrelieve traffic congestion. A key problem for these platforms is to come up\nwith a revenue-optimal (or GMV-optimal) pricing scheme and an induced vehicle\ndispatching policy that incorporate geographic and temporal information. In\nthis paper, we aim to tackle this problem via an economic approach.\n  Modeled naively, the underlying optimization problem may be non-convex and\nthus hard to compute. To this end, we use a so-called \"ironing\" technique to\nconvert the problem into an equivalent convex optimization one via a clean\nMarkov decision process (MDP) formulation, where the states are the driver\ndistributions and the decision variables are the prices for each pair of\nlocations. Our main finding is an efficient algorithm that computes the exact\nrevenue-optimal (or GMV-optimal) randomized pricing schemes. We characterize\nthe optimal solution of the MDP by a primal-dual analysis of a corresponding\nconvex program. We also conduct empirical evaluations of our solution through\nreal data of a major ride-sharing platform and show its advantages over fixed\npricing schemes as well as several prevalent surge-based pricing schemes.\n"]},
{"authors": ["Jiajiong Ma", "Guihua Wen", "Yang Hu", "Tianyuan Chang", "Haibin Zeng", "Lijun Jiang", "Jianzeng Qin"], "title": ["Tongue image constitution recognition based on Complexity Perception\n  method"], "date": ["2018-03-01T05:32:43Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.00219v1"], "summary": ["  Background and Object: In China, body constitution is highly related to\nphysiological and pathological functions of human body and determines the\ntendency of the disease, which is of great importance for treatment in clinical\nmedicine. Tongue diagnosis, as a key part of Traditional Chinese Medicine\ninspection, is an important way to recognize the type of constitution.In order\nto deploy tongue image constitution recognition system on non-invasive mobile\ndevice to achieve fast, efficient and accurate constitution recognition, an\nefficient method is required to deal with the challenge of this kind of complex\nenvironment. Methods: In this work, we perform the tongue area detection,\ntongue area calibration and constitution classification using methods which are\nbased on deep convolutional neural network. Subject to the variation of\ninconstant environmental condition, the distribution of the picture is uneven,\nwhich has a bad effect on classification performance. To solve this problem, we\npropose a method based on the complexity of individual instances to divide\ndataset into two subsets and classify them separately, which is capable of\nimproving classification accuracy. To evaluate the performance of our proposed\nmethod, we conduct experiments on three sizes of tongue datasets, in which deep\nconvolutional neural network method and traditional digital image analysis\nmethod are respectively applied to extract features for tongue images. The\nproposed method is combined with the base classifier Softmax, SVM, and\nDecisionTree respectively. Results: As the experiments results shown, our\nproposed method improves the classification accuracy by 1.135% on average and\nachieves 59.99% constitution classification accuracy. Conclusions: Experimental\nresults on three datasets show that our proposed method can effectively improve\nthe classification accuracy of tongue constitution recognition.\n"]},
{"authors": ["Mengying Sun", "Inci M. Baytas", "Liang Zhan", "Zhangyang Wang", "Jiayu Zhou"], "title": ["Subspace Network: Deep Multi-Task Censored Regression for Modeling\n  Neurodegenerative Diseases"], "date": ["2018-02-19T04:50:14Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06516v2"], "summary": ["  Over the past decade a wide spectrum of machine learning models have been\ndeveloped to model the neurodegenerative diseases, associating biomarkers,\nespecially non-intrusive neuroimaging markers, with key clinical scores\nmeasuring the cognitive status of patients. Multi-task learning (MTL) has been\ncommonly utilized by these studies to address high dimensionality and small\ncohort size challenges. However, most existing MTL approaches are based on\nlinear models and suffer from two major limitations: 1) they cannot explicitly\nconsider upper/lower bounds in these clinical scores; 2) they lack the\ncapability to capture complicated non-linear interactions among the variables.\nIn this paper, we propose Subspace Network, an efficient deep modeling approach\nfor non-linear multi-task censored regression. Each layer of the subspace\nnetwork performs a multi-task censored regression to improve upon the\npredictions from the last layer via sketching a low-dimensional subspace to\nperform knowledge transfer among learning tasks. Under mild assumptions, for\neach layer the parametric subspace can be recovered using only one pass of\ntraining data. Empirical results demonstrate that the proposed subspace network\nquickly picks up the correct parameter subspaces, and outperforms\nstate-of-the-arts in predicting neurodegenerative clinical scores using\ninformation in brain imaging.\n"]},
{"authors": ["Adria Ruiz", "Ognjen Rudovic", "Xavier Binefa", "Maja Pantic"], "title": ["Multi-Instance Dynamic Ordinal Random Fields for Weakly-supervised\n  Facial Behavior Analysis"], "date": ["2018-03-01T04:13:47Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.00907v1"], "summary": ["  We propose a Multi-Instance-Learning (MIL) approach for weakly-supervised\nlearning problems, where a training set is formed by bags (sets of feature\nvectors or instances) and only labels at bag-level are provided. Specifically,\nwe consider the Multi-Instance Dynamic-Ordinal-Regression (MI-DOR) setting,\nwhere the instance labels are naturally represented as ordinal variables and\nbags are structured as temporal sequences. To this end, we propose\nMulti-Instance Dynamic Ordinal Random Fields (MI-DORF). In this framework, we\ntreat instance-labels as temporally-dependent latent variables in an Undirected\nGraphical Model. Different MIL assumptions are modelled via newly introduced\nhigh-order potentials relating bag and instance-labels within the energy\nfunction of the model. We also extend our framework to address the\nPartially-Observed MI-DOR problems, where a subset of instance labels are\navailable during training. We show on the tasks of weakly-supervised facial\nbehavior analysis, Facial Action Unit (DISFA dataset) and Pain (UNBC dataset)\nIntensity estimation, that the proposed framework outperforms alternative\nlearning approaches. Furthermore, we show that MIDORF can be employed to reduce\nthe data annotation efforts in this context by large-scale.\n"]},
{"authors": ["Chen Wang", "Ruisen Luo"], "title": ["Vector Quantization as Sparse Least Square Optimization"], "date": ["2018-03-01T04:07:40Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.00204v1"], "summary": ["  Vector quantization aims to form new vectors/matrices with shared values\nclose to the original. It could compress data with acceptable information loss,\nand could be of great usefulness in areas like Image Processing, Pattern\nRecognition and Machine Learning. In recent years, the importance of\nquantization has been soaring as it has been discovered huge potentials in\ndeploying practical neural networks, which is among one of the most popular\nresearch topics. Conventional vector quantization methods usually suffer from\ntheir own flaws: hand-coding domain rules quantization could produce poor\nresults when encountering complex data, and clustering-based algorithms have\nthe problem of inexact solution and high time consumption. In this paper, we\nexplored vector quantization problem from a new perspective of sparse least\nsquare optimization and designed multiple algorithms with their program\nimplementations. Specifically, deriving from a sparse form of coefficient\nmatrix, three types of sparse least squares, with $l_0$, $l_1$, and generalized\n$l_1 + l_2$ penalizations, are designed and implemented respectively. In\naddition, to produce quantization results with given amount of quantized\nvalues(instead of penalization coefficient $\\lambda$), this paper proposed a\ncluster-based least square quantization method, which could also be regarded as\nan improvement of information preservation of conventional clustering\nalgorithm. The algorithms were tested on various data and tasks and their\ncomputational properties were analyzed. The paper offers a new perspective to\nprobe the area of vector quantization, while the algorithms proposed could\nprovide more appropriate options for quantization tasks under different\ncircumstances.\n"]},
{"authors": ["Brian Yang", "Grant Wang", "Roberto Calandra", "Daniel Contreras", "Sergey Levine", "Kristofer Pister"], "title": ["Learning Flexible and Reusable Locomotion Primitives for a Microrobot"], "date": ["2018-03-01T03:48:06Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.00196v1"], "summary": ["  The design of gaits for robot locomotion can be a daunting process which\nrequires significant expert knowledge and engineering. This process is even\nmore challenging for robots that do not have an accurate physical model, such\nas compliant or micro-scale robots. Data-driven gait optimization provides an\nautomated alternative to analytical gait design. In this paper, we propose a\nnovel approach to efficiently learn a wide range of locomotion tasks with\nwalking robots. This approach formalizes locomotion as a contextual policy\nsearch task to collect data, and subsequently uses that data to learn\nmulti-objective locomotion primitives that can be used for planning. As a\nproof-of-concept we consider a simulated hexapod modeled after a recently\ndeveloped microrobot, and we thoroughly evaluate the performance of this\nmicrorobot on different tasks and gaits. Our results validate the proposed\ncontroller and learning scheme on single and multi-objective locomotion tasks.\nMoreover, the experimental simulations show that without any prior knowledge\nabout the robot used (e.g., dynamics model), our approach is capable of\nlearning locomotion primitives within 250 trials and subsequently using them to\nsuccessfully navigate through a maze.\n"]},
{"authors": ["Tianyuan Chang", "Guihua Wen", "Yang Hu", "JiaJiong Ma"], "title": ["Facial Expression Recognition Based on Complexity Perception\n  Classification Algorithm"], "date": ["2018-03-01T03:05:50Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.00185v1"], "summary": ["  Facial expression recognition (FER) has always been a challenging issue in\ncomputer vision. The different expressions of emotion and uncontrolled\nenvironmental factors lead to inconsistencies in the complexity of FER and\nvariability of between expression categories, which is often overlooked in most\nfacial expression recognition systems. In order to solve this problem\neffectively, we presented a simple and efficient CNN model to extract facial\nfeatures, and proposed a complexity perception classification (CPC) algorithm\nfor FER. The CPC algorithm divided the dataset into an easy classification\nsample subspace and a complex classification sample subspace by evaluating the\ncomplexity of facial features that are suitable for classification. The\nexperimental results of our proposed algorithm on Fer2013 and CK-plus datasets\ndemonstrated the algorithm's effectiveness and superiority over other\nstate-of-the-art approaches.\n"]},
{"authors": ["Weixun Wang", "Jianye Hao", "Yixi Wang", "Matthew Taylor"], "title": ["Towards Cooperation in Sequential Prisoner's Dilemmas: a Deep Multiagent\n  Reinforcement Learning Approach"], "date": ["2018-03-01T01:53:52Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.00162v1"], "summary": ["  The Iterated Prisoner's Dilemma has guided research on social dilemmas for\ndecades. However, it distinguishes between only two atomic actions: cooperate\nand defect. In real-world prisoner's dilemmas, these choices are temporally\nextended and different strategies may correspond to sequences of actions,\nreflecting grades of cooperation. We introduce a Sequential Prisoner's Dilemma\n(SPD) game to better capture the aforementioned characteristics. In this work,\nwe propose a deep multiagent reinforcement learning approach that investigates\nthe evolution of mutual cooperation in SPD games. Our approach consists of two\nphases. The first phase is offline: it synthesizes policies with different\ncooperation degrees and then trains a cooperation degree detection network. The\nsecond phase is online: an agent adaptively selects its policy based on the\ndetected degree of opponent cooperation. The effectiveness of our approach is\ndemonstrated in two representative SPD 2D games: the Apple-Pear game and the\nFruit Gathering game. Experimental results show that our strategy can avoid\nbeing exploited by exploitative opponents and achieve cooperation with\ncooperative opponents.\n"]},
{"authors": ["Li Huihui", "Wen Guihua"], "title": ["Modeling reverse thinking for machine learning"], "date": ["2018-03-01T01:45:30Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.00158v1"], "summary": ["  Human inertial thinking schemes can be formed through learning, which are\nthen applied to quickly solve similar problems later. However, when problems\nare significantly different, inertial thinking generally presents the solutions\nthat are definitely imperfect. In such cases, people will apply creative\nthinking, such as reverse thinking, to solve problems. Similarly, machine\nlearning methods also form inertial thinking schemes through learning the\nknowledge from a large amount of data. However, when the testing data are\nvastly difference, the formed inertial thinking schemes will inevitably\ngenerate errors. This kind of inertial thinking is called illusion inertial\nthinking. Because all machine learning methods do not consider illusion\ninertial thinking, in this paper we propose a new method that uses reverse\nthinking to correct illusion inertial thinking, which increases the\ngeneralization ability of machine learning methods. Experimental results on\nbenchmark datasets are used to validate the proposed method.\n"]},
{"authors": ["Trieu H. Trinh", "Andrew M. Dai", "Thang Luong", "Quoc V. Le"], "title": ["Learning Longer-term Dependencies in RNNs with Auxiliary Losses"], "date": ["2018-03-01T00:28:07Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.00144v1"], "summary": ["  Despite recent advances in training recurrent neural networks (RNNs),\ncapturing long-term dependencies in sequences remains a fundamental challenge.\nMost approaches use backpropagation through time (BPTT), which is difficult to\nscale to very long sequences. This paper proposes a simple method that improves\nthe ability to capture long term dependencies in RNNs by adding an unsupervised\nauxiliary loss to the original objective. This auxiliary loss forces RNNs to\neither reconstruct previous events or predict next events in a sequence, making\ntruncated backpropagation feasible for long sequences and also improving full\nBPTT. We evaluate our method on a variety of settings, including pixel-by-pixel\nimage classification with sequence lengths up to 16\\,000, and a real document\nclassification benchmark. Our results highlight good performance and resource\nefficiency of this approach over competitive baselines, including other\nrecurrent models and a comparable sized Transformer. Further analyses reveal\nbeneficial effects of the auxiliary loss on optimization and regularization, as\nwell as extreme cases where there is little to no backpropagation.\n"]},
{"authors": ["Esteban Real", "Alok Aggarwal", "Yanping Huang", "Quoc V Le"], "title": ["Regularized Evolution for Image Classifier Architecture Search"], "date": ["2018-02-05T18:20:52Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.01548v3"], "summary": ["  The effort devoted to hand-crafting image classifiers has motivated the use\nof architecture search to discover them automatically. Reinforcement learning\nand evolution have both shown promise for this purpose. This study employs a\nregularized version of a popular asynchronous evolutionary algorithm. We\nrigorously compare it to the non-regularized form and to a highly-successful\nreinforcement learning baseline. Using the same hardware, compute effort and\nneural network training code, we conduct repeated experiments side-by-side,\nexploring different datasets, search spaces and scales. We show regularized\nevolution consistently produces models with similar or higher accuracy, across\na variety of contexts without need for re-tuning parameters. In addition,\nevolution exhibits considerably better performance than reinforcement learning\nat early search stages, suggesting it may be the better choice when fewer\ncompute resources are available. This constitutes the first controlled\ncomparison of the two search algorithms in this context. Finally, we present\nnew architectures discovered with evolution that we nickname AmoebaNets. These\nmodels achieve state-of-the-art results for CIFAR-10 (mean test error = 2.13%),\nmobile-size ImageNet (top-1 accuracy = 75.1% with 5.1 M parameters) and\nImageNet (top-1 accuracy = 83.1%). This is the first time evolutionary\nalgorithms produce state-of-the-art image classifiers.\n"]},
{"authors": ["Rohan Chitnis", "Leslie Pack Kaelbling", "Tom\u00e1s Lozano-P\u00e9rez"], "title": ["Integrating Human-Provided Information Into Belief State Representation\n  Using Dynamic Factorization"], "date": ["2018-02-28T22:29:29Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.00119v1"], "summary": ["  In partially observed environments, it can be useful for a human to provide\nthe robot with declarative information that augments its direct sensory\nobservations. For instance, given a robot on a search-and-rescue mission, a\nhuman operator might suggest locations of interest. We provide a representation\nfor the robot's internal knowledge that supports efficient combination of raw\nsensory information with high-level declarative information presented in a\nformal language. Computational efficiency is achieved by dynamically selecting\nan appropriate factoring of the belief state, combining aspects of the belief\nwhen they are correlated through information and separating them when they are\nnot. This strategy works in open domains, in which the set of possible objects\nis not known in advance, and provides significant improvements in inference\ntime, leading to more efficient planning for complex partially observable\ntasks. We validate our approach experimentally in two open-domain planning\nproblems: a 2D discrete gridworld task and a 3D continuous cooking task.\n"]},
{"authors": ["Vladimir Feinberg", "Alvin Wan", "Ion Stoica", "Michael I. Jordan", "Joseph E. Gonzalez", "Sergey Levine"], "title": ["Model-Based Value Estimation for Efficient Model-Free Reinforcement\n  Learning"], "date": ["2018-02-28T21:43:37Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.00101v1"], "summary": ["  Recent model-free reinforcement learning algorithms have proposed\nincorporating learned dynamics models as a source of additional data with the\nintention of reducing sample complexity. Such methods hold the promise of\nincorporating imagined data coupled with a notion of model uncertainty to\naccelerate the learning of continuous control tasks. Unfortunately, they rely\non heuristics that limit usage of the dynamics model. We present model-based\nvalue expansion, which controls for uncertainty in the model by only allowing\nimagination to fixed depth. By enabling wider use of learned dynamics models\nwithin a model-free reinforcement learning algorithm, we improve value\nestimation, which, in turn, reduces the sample complexity of learning.\n"]},
{"authors": ["Quynh Nguyen", "Mahesh Mukkamala", "Matthias Hein"], "title": ["Neural Networks Should Be Wide Enough to Learn Disconnected Decision\n  Regions"], "date": ["2018-02-28T21:28:28Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.00094v1"], "summary": ["  In the recent literature the important role of depth in deep learning has\nbeen emphasized. In this paper we argue that sufficient width of a feedforward\nnetwork is equally important by answering the simple question under which\nconditions the decision regions of a neural network are connected. It turns out\nthat for a class of activation functions including leaky ReLU, neural networks\nhaving a pyramidal structure, that is no layer has more hidden units than the\ninput dimension, produce necessarily connected decision regions. This implies\nthat a sufficiently wide layer is necessary to produce disconnected decision\nregions. We discuss the implications of this result for the construction of\nneural networks, in particular the relation to the problem of adversarial\nmanipulation of classifiers.\n"]},
{"authors": ["Murat Cubuktepe", "Ufuk Topcu"], "title": ["Verification of Markov Decision Processes with Risk-Sensitive Measures"], "date": ["2018-02-28T21:14:37Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.00091v1"], "summary": ["  We develop a method for computing policies in Markov decision processes with\nrisk-sensitive measures subject to temporal logic constraints. Specifically, we\nuse a particular risk-sensitive measure from cumulative prospect theory, which\nhas been previously adopted in psychology and economics. The nonlinear\ntransformation of the probabilities and utility functions yields a nonlinear\nprogramming problem, which makes computation of optimal policies typically\nchallenging. We show that this nonlinear weighting function can be accurately\napproximated by the difference of two convex functions. This observation\nenables efficient policy computation using convex-concave programming. We\ndemonstrate the effectiveness of the approach on several scenarios.\n"]},
{"authors": ["Thanard Kurutach", "Ignasi Clavera", "Yan Duan", "Aviv Tamar", "Pieter Abbeel"], "title": ["Model-Ensemble Trust-Region Policy Optimization"], "date": ["2018-02-28T18:58:22Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.10592v1"], "summary": ["  Model-free reinforcement learning (RL) methods are succeeding in a growing\nnumber of tasks, aided by recent advances in deep learning. However, they tend\nto suffer from high sample complexity, which hinders their use in real-world\ndomains. Alternatively, model-based reinforcement learning promises to reduce\nsample complexity, but tends to require careful tuning and to date have\nsucceeded mainly in restrictive domains where simple models are sufficient for\nlearning. In this paper, we analyze the behavior of vanilla model-based\nreinforcement learning methods when deep neural networks are used to learn both\nthe model and the policy, and show that the learned policy tends to exploit\nregions where insufficient data is available for the model to be learned,\ncausing instability in training. To overcome this issue, we propose to use an\nensemble of models to maintain the model uncertainty and regularize the\nlearning process. We further show that the use of likelihood ratio derivatives\nyields much more stable learning than backpropagation through time. Altogether,\nour approach Model-Ensemble Trust-Region Policy Optimization (ME-TRPO)\nsignificantly reduces the sample complexity compared to model-free deep RL\nmethods on challenging continuous control benchmark tasks.\n"]},
{"authors": ["Andrew Levy", "Robert Platt", "Kate Saenko"], "title": ["Hierarchical Actor-Critic"], "date": ["2017-12-04T08:18:08Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1712.00948v3"], "summary": ["  The ability to learn at different resolutions in time may help overcome one\nof the main challenges in deep reinforcement learning -- sample efficiency.\nHierarchical agents that operate at different levels of temporal abstraction\ncan learn tasks more quickly because they can divide the work of learning\nbehaviors among multiple policies and can also explore the environment at a\nhigher level. In this paper, we present a novel approach to hierarchical\nreinforcement learning called Hierarchical Actor-Critic (HAC) that enables\nagents to learn to break down problems involving continuous action spaces into\nsimpler subproblems belonging to different time scales. HAC has two key\nadvantages over most existing hierarchical learning methods: (i) the potential\nfor faster learning as agents learn short policies at each level of the\nhierarchy and (ii) an end-to-end approach. We demonstrate that HAC\nsignificantly accelerates learning in a series of tasks that require behavior\nover a relatively long time horizon and involve sparse rewards.\n"]},
{"authors": ["Pierre-Yves Oudeyer"], "title": ["Computational Theories of Curiosity-Driven Learning"], "date": ["2018-02-28T17:28:25Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.10546v1"], "summary": ["  What are the functions of curiosity? What are the mechanisms of\ncuriosity-driven learning? We approach these questions using concepts and tools\nfrom machine learning and developmental robotics. We argue that\ncuriosity-driven learning enables organisms to make discoveries to solve\ncomplex problems with rare or deceptive rewards. By fostering exploration and\ndiscovery of a diversity of behavioural skills, and ignoring these rewards,\ncuriosity can be efficient to bootstrap learning when there is no information,\nor deceptive information, about local improvement towards these problems. We\nreview both normative and heuristic computational frameworks used to understand\nthe mechanisms of curiosity in humans, conceptualizing the child as a\nsense-making organism. These frameworks enable us to discuss the bi-directional\ncausal links between curiosity and learning, and to provide new hypotheses\nabout the fundamental role of curiosity in self-organizing developmental\nstructures through curriculum learning. We present various developmental\nrobotics experiments that study these mechanisms in action, both supporting\nthese hypotheses and opening new research avenues in machine learning and\nartificial intelligence. Finally, we discuss challenges for the design of\nexperimental paradigms for studying curiosity in psychology and cognitive\nneuroscience. Keywords: Curiosity, intrinsic motivation, lifelong learning,\npredictions, world model, rewards, free-energy principle, learning progress,\nmachine learning, AI, developmental robotics, development, curriculum learning,\nself-organization.\n"]},
{"authors": ["Zachary C. Lipton", "Yu-Xiang Wang", "Alex Smola"], "title": ["Detecting and Correcting for Label Shift with Black Box Predictors"], "date": ["2018-02-12T07:16:03Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.03916v2"], "summary": ["  Faced with distribution shift between training and test set, we wish to\ndetect and quantify the shift, and to correct our classifiers without test set\nlabels. Motivated by medical diagnosis, where diseases (targets), cause\nsymptoms (observations), we focus on label shift, where the label marginal\n$p(y)$ changes but the conditional $p(x|y)$ does not. We propose Black Box\nShift Estimation (BBSE) to estimate the test distribution $p(y)$. BBSE exploits\narbitrary black box predictors to reduce dimensionality prior to shift\ncorrection. While better predictors give tighter estimates, BBSE works even\nwhen predictors are biased, inaccurate, or uncalibrated, so long as their\nconfusion matrices are invertible. We prove BBSE's consistency, bound its\nerror, and introduce a statistical test that uses BBSE to detect shift. We also\nleverage BBSE to correct classifiers. Experiments demonstrate accurate\nestimates and improved prediction, even on high-dimensional datasets of natural\nimages.\n"]},
{"authors": ["Simon S. Du", "Jason D. Lee", "Yuandong Tian"], "title": ["When is a Convolutional Filter Easy To Learn?"], "date": ["2017-09-18T19:09:24Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1709.06129v2"], "summary": ["  We analyze the convergence of (stochastic) gradient descent algorithm for\nlearning a convolutional filter with Rectified Linear Unit (ReLU) activation\nfunction. Our analysis does not rely on any specific form of the input\ndistribution and our proofs only use the definition of ReLU, in contrast with\nprevious works that are restricted to standard Gaussian input. We show that\n(stochastic) gradient descent with random initialization can learn the\nconvolutional filter in polynomial time and the convergence rate depends on the\nsmoothness of the input distribution and the closeness of patches. To the best\nof our knowledge, this is the first recovery guarantee of gradient-based\nalgorithms for convolutional filter on non-Gaussian input distributions. Our\ntheory also justifies the two-stage learning rate strategy in deep neural\nnetworks. While our focus is theoretical, we also present experiments that\nillustrate our theoretical findings.\n"]},
{"authors": ["Garrett Andersen", "Peter Vrancx", "Haitham Bou-Ammar"], "title": ["Learning High-level Representations from Demonstrations"], "date": ["2018-02-19T12:11:16Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06604v3"], "summary": ["  Hierarchical learning (HL) is key to solving complex sequential decision\nproblems with long horizons and sparse rewards. It allows learning agents to\nbreak-up large problems into smaller, more manageable subtasks. A common\napproach to HL, is to provide the agent with a number of high-level skills that\nsolve small parts of the overall problem. A major open question, however, is\nhow to identify a suitable set of reusable skills. We propose a principled\napproach that uses human demonstrations to infer a set of subgoals based on\nchanges in the demonstration dynamics. Using these subgoals, we decompose the\nlearning problem into an abstract high-level representation and a set of\nlow-level subtasks. The abstract description captures the overall problem\nstructure, while subtasks capture desired skills. We demonstrate that we can\njointly optimize over both levels of learning. We show that the resulting\nmethod significantly outperforms previous baselines on two challenging\nproblems: the Atari 2600 game Montezuma's Revenge, and a simulated robotics\nproblem moving the ant robot through a maze.\n"]},
{"authors": ["Jonas Rothfuss", "Fabio Ferreira", "Eren Erdal Aksoy", "You Zhou", "Tamim Asfour"], "title": ["Deep Episodic Memory: Encoding, Recalling, and Predicting Episodic\n  Experiences for Robot Action Execution"], "date": ["2018-01-12T11:22:55Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.04134v2"], "summary": ["  We present a novel deep neural network architecture for representing robot\nexperiences in an episodic-like memory which facilitates encoding, recalling,\nand predicting action experiences. Our proposed unsupervised deep episodic\nmemory model 1) encodes observed actions in a latent vector space and, based on\nthis latent encoding, 2) infers most similar episodes previously experienced,\n3) reconstructs original episodes, and 4) predicts future frames in an\nend-to-end fashion. Results show that conceptually similar actions are mapped\ninto the same region of the latent vector space. Based on these results, we\nintroduce an action matching and retrieval mechanism, benchmark its performance\non two large-scale action datasets, 20BN-something-something and ActivityNet\nand evaluate its generalization capability in a real-world scenario on a\nhumanoid robot.\n"]},
{"authors": ["Paul Schydlo", "Mirko Rakovic", "Lorenzo Jamone", "Jos\u00e9 Santos-Victor"], "title": ["Anticipation in Human-Robot Cooperation: A Recurrent Neural Network\n  Approach for Multiple Action Sequences Prediction"], "date": ["2018-02-28T16:10:20Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.10503v1"], "summary": ["  Close human-robot cooperation is a key enabler for new developments in\nadvanced manufacturing and assistive applications. Close cooperation require\nrobots that can predict human actions and intent, and understand human\nnon-verbal cues. Recent approaches based on neural networks have led to\nencouraging results in the human action prediction problem both in continuous\nand discrete spaces. Our approach extends the research in this direction. Our\ncontributions are three-fold. First, we validate the use of gaze and body pose\ncues as a means of predicting human action through a feature selection method.\nNext, we address two shortcomings of existing literature: predicting multiple\nand variable-length action sequences. This is achieved by introducing an\nencoder-decoder recurrent neural network topology in the discrete action\nprediction problem. In addition, we theoretically demonstrate the importance of\npredicting multiple action sequences as a means of estimating the stochastic\nreward in a human robot cooperation scenario. Finally, we show the ability to\neffectively train the prediction model on a action prediction dataset,\ninvolving human motion data, and explore the influence of the model's\nparameters on its performance.\n"]},
{"authors": ["Yu-Siang Huang", "Szu-Yu Chou", "Yi-Hsuan Yang"], "title": ["Pop Music Highlighter: Marking the Emotion Keypoints"], "date": ["2018-02-28T16:02:47Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.10495v1"], "summary": ["  The goal of music highlight extraction is to get a short consecutive segment\nof a piece of music that provides an effective representation of the whole\npiece. In a previous work, we introduced an attention-based convolutional\nrecurrent neural network that uses music emotion classification as a surrogate\ntask for music highlight extraction, for Pop songs. The rationale behind that\napproach is that the highlight of a song is usually the most emotional part.\nThis paper extends our previous work in the following two aspects. First,\nmethodology-wise we experiment with a new architecture that does not need any\nrecurrent layers, making the training process faster. Moreover, we compare a\nlate-fusion variant and an early-fusion variant to study which one better\nexploits the attention mechanism. Second, we conduct and report an extensive\nset of experiments comparing the proposed attention-based methods against a\nheuristic energy-based method, a structural repetition-based method, and a few\nother simple feature-based methods for this task. Due to the lack of\npublic-domain labeled data for highlight extraction, following our previous\nwork we use the RWC POP 100-song data set to evaluate how the detected\nhighlights overlap with any chorus sections of the songs. The experiments\ndemonstrate the effectiveness of our methods over competing methods. For\nreproducibility, we open source the code and pre-trained model at\nhttps://github.com/remyhuang/pop-music-highlighter/.\n"]},
{"authors": ["Henrique X. Goulart", "Guilherme A. Wachs-Lopes"], "title": ["A Bayesian Model for Activities Recommendation and Event Structure\n  Optimization Using Visitors Tracking"], "date": ["2018-02-28T12:59:43Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.10393v1"], "summary": ["  In events that are composed by many activities, there is a problem that\ninvolves retrieve and management the information of visitors that are visiting\nthe activities. This management is crucial to find some activities that are\ndrawing attention of visitors; identify an ideal positioning for activities;\nwhich path is more frequented by visitors. In this work, these features are\nstudied using Complex Network theory. For the beginning, an artificial database\nwas generated to study the mentioned features. Secondly, this work shows a\nmethod to optimize the event structure that is better than a random method and\na recommendation system that achieves ~95% of accuracy.\n"]},
{"authors": ["Gal Dalal", "Balazs Szorenyi", "Gugan Thoppe", "Shie Mannor"], "title": ["Finite Sample Analysis of Two-Timescale Stochastic Approximation with\n  Applications to Reinforcement Learning"], "date": ["2017-03-15T20:23:45Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1703.05376v4"], "summary": ["  Two-timescale Stochastic Approximation (SA) algorithms are widely used in\nReinforcement Learning (RL). Their iterates have two parts that are updated\nusing distinct stepsizes. In this work, we develop a novel recipe for their\nfinite sample analysis. Using this, we provide a concentration bound, which is\nthe first such result for a two-timescale SA. The type of bound we obtain is\nknown as \"lock-in probability\". We also introduce a new projection scheme, in\nwhich the time between successive projections increases exponentially. This\nscheme allows one to elegantly transform a lock-in probability into a\nconvergence rate result for projected two-timescale SA. From this latter\nresult, we then extract key insights on stepsize selection. As an application,\nwe finally obtain convergence rates for the projected two-timescale RL\nalgorithms GTD(0), GTD2, and TDC.\n"]},
{"authors": ["Beishui Liao", "Nir Oren", "Leendert van der Torre", "Serena Villata"], "title": ["Prioritized Norms in Formal Argumentation"], "date": ["2017-09-23T10:21:56Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1709.08034v2"], "summary": ["  To resolve conflicts among norms, various nonmonotonic formalisms can be used\nto perform prioritized normative reasoning. Meanwhile, formal argumentation\nprovides a way to represent nonmonotonic logics. In this paper, we propose a\nrepresentation of prioritized normative reasoning by argumentation. Using\nhierarchical abstract normative systems, we define three kinds of prioritized\nnormative reasoning approaches, called Greedy, Reduction, and Optimization.\nThen, after formulating an argumentation theory for a hierarchical abstract\nnormative system, we show that for a totally ordered hierarchical abstract\nnormative system, Greedy and Reduction can be represented in argumentation by\napplying the weakest link and the last link principles respectively, and\nOptimization can be represented by introducing additional defeats capturing the\nidea that for each argument that contains a norm not belonging to the maximal\nobeyable set then this argument should be rejected.\n"]},
{"authors": ["Gal Dalal", "Elad Gilboa", "Shie Mannor", "Louis Wehenkel"], "title": ["Unit Commitment using Nearest Neighbor as a Short-Term Proxy"], "date": ["2016-11-30T15:24:55Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1611.10215v3"], "summary": ["  We devise the Unit Commitment Nearest Neighbor (UCNN) algorithm to be used as\na proxy for quickly approximating outcomes of short-term decisions, to make\ntractable hierarchical long-term assessment and planning for large power\nsystems. Experimental results on updated versions of IEEE-RTS79 and IEEE-RTS96\nshow high accuracy measured on operational cost, achieved in runtimes that are\nlower in several orders of magnitude than the traditional approach.\n"]},
{"authors": ["Diego Perez-Liebana", "Jialin Liu", "Ahmed Khalifa", "Raluca D. Gaina", "Julian Togelius", "Simon M. Lucas"], "title": ["General Video Game AI: a Multi-Track Framework for Evaluating Agents,\n  Games and Content Generation Algorithms"], "date": ["2018-02-28T11:23:16Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.10363v1"], "summary": ["  General Video Game Playing (GVGP) aims at designing an agent that is capable\nof playing multiple video games with no human intervention. In 2014, The\nGeneral Video Game AI (GVGAI) competition framework was created and released\nwith the purpose of providing researchers a common open-source and easy to use\nplatform for testing their AI methods with potentially infinity of games\ncreated using Video Game Description Language (VGDL). The framework has been\nexpanded into several tracks during the last few years to meet the demand of\ndifferent research directions. The agents are required to either play multiples\nunknown games with or without access to game simulations, or to design new game\nlevels or rules. This survey paper presents the VGDL, the GVGAI framework,\nexisting tracks, and reviews the wide use of GVGAI framework in research,\neducation and competitions five years after its birth. A future plan of\nframework improvements is also described.\n"]},
{"authors": ["Sjoerd van Steenkiste", "Michael Chang", "Klaus Greff", "J\u00fcrgen Schmidhuber"], "title": ["Relational Neural Expectation Maximization: Unsupervised Discovery of\n  Objects and their Interactions"], "date": ["2018-02-28T10:55:36Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.10353v1"], "summary": ["  Common-sense physical reasoning is an essential ingredient for any\nintelligent agent operating in the real-world. For example, it can be used to\nsimulate the environment, or to infer the state of parts of the world that are\ncurrently unobserved. In order to match real-world conditions this causal\nknowledge must be learned without access to supervised data. To address this\nproblem we present a novel method that learns to discover objects and model\ntheir physical interactions from raw visual images in a purely\n\\emph{unsupervised} fashion. It incorporates prior knowledge about the\ncompositional nature of human perception to factor interactions between\nobject-pairs and learn efficiently. On videos of bouncing balls we show the\nsuperior modelling capabilities of our method compared to other unsupervised\nneural approaches that do not incorporate such prior knowledge. We demonstrate\nits ability to handle occlusion and show that it can extrapolate learned\nknowledge to scenes with different numbers of objects.\n"]},
{"authors": ["David Isele", "Akansel Cosgun"], "title": ["Selective Experience Replay for Lifelong Learning"], "date": ["2018-02-28T06:02:31Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.10269v1"], "summary": ["  Deep reinforcement learning has emerged as a powerful tool for a variety of\nlearning tasks, however deep nets typically exhibit forgetting when learning\nmultiple tasks in sequence. To mitigate forgetting, we propose an experience\nreplay process that augments the standard FIFO buffer and selectively stores\nexperiences in a long-term memory. We explore four strategies for selecting\nwhich experiences will be stored: favoring surprise, favoring reward, matching\nthe global training distribution, and maximizing coverage of the state space.\nWe show that distribution matching successfully prevents catastrophic\nforgetting, and is consistently the best approach on all domains tested. While\ndistribution matching has better and more consistent performance, we identify\none case in which coverage maximization is beneficial - when tasks that receive\nless trained are more important. Overall, our results show that selective\nexperience replay, when suitable selection algorithms are employed, can prevent\ncatastrophic forgetting.\n"]},
{"authors": ["Raef Bassily", "Shay Moran", "Ido Nachum", "Jonathan Shafer", "Amir Yehudayoff"], "title": ["Learners that Use Little Information"], "date": ["2017-10-14T20:40:46Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.05233v3"], "summary": ["  We study learning algorithms that are restricted to using a small amount of\ninformation from their input sample. We introduce a category of learning\nalgorithms we term $d$-bit information learners, which are algorithms whose\noutput conveys at most $d$ bits of information of their input. A central theme\nin this work is that such algorithms generalize.\n  We focus on the learning capacity of these algorithms, and prove sample\ncomplexity bounds with tight dependencies on the confidence and error\nparameters. We also observe connections with well studied notions such as\nsample compression schemes, Occam's razor, PAC-Bayes and differential privacy.\n  We discuss an approach that allows us to prove upper bounds on the amount of\ninformation that algorithms reveal about their inputs, and also provide a lower\nbound by showing a simple concept class for which every (possibly randomized)\nempirical risk minimizer must reveal a lot of information. On the other hand,\nwe show that in the distribution-dependent setting every VC class has empirical\nrisk minimizers that do not reveal a lot of information.\n"]},
{"authors": ["Benjamin Shickel", "Tyler J. Loftus", "Tezcan Ozrazgat-Baslanti", "Ashkan Ebadi", "Azra Bihorac", "Parisa Rashidi"], "title": ["DeepSOFA: A Real-Time Continuous Acuity Score Framework using Deep\n  Learning"], "date": ["2018-02-28T02:39:02Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.10238v1"], "summary": ["  Traditional methods for assessing illness severity and predicting in-hospital\nmortality among critically ill patients require manual, time-consuming, and\nerror-prone calculations that are further hindered by the use of static\nvariable thresholds derived from aggregate patient populations. These coarse\nframeworks do not capture time-sensitive individual physiological patterns and\nare not suitable for instantaneous assessment of patients' acuity trajectories,\na critical task for the ICU where conditions often change rapidly. Furthermore,\nthey are ill-suited to capitalize on the emerging availability of streaming\nelectronic health record data. We propose a novel acuity score framework\n(DeepSOFA) that leverages temporal patient measurements in conjunction with\ndeep learning models to make accurate assessments of a patient's illness\nseverity at any point during their ICU stay. We compare DeepSOFA with SOFA\nbaseline models using the same predictors and find that at any point during an\nICU admission, DeepSOFA yields more accurate predictions of in-hospital\nmortality.\n"]},
{"authors": ["F. Zafari", "I. Moser", "T. Baarslag"], "title": ["Modelling and Analysis of Temporal Preference Drifts Using A\n  Component-Based Factorised Latent Approach"], "date": ["2018-02-27T06:00:49Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.09728v2"], "summary": ["  The changes in user preferences can originate from substantial reasons, like\npersonality shift, or transient and circumstantial ones, like seasonal changes\nin item popularities. Disregarding these temporal drifts in modelling user\npreferences can result in unhelpful recommendations. Moreover, different\ntemporal patterns can be associated with various preference domains, and\npreference components and their combinations. These components comprise\npreferences over features, preferences over feature values, conditional\ndependencies between features, socially-influenced preferences, and bias. For\nexample, in the movies domain, the user can change his rating behaviour (bias\nshift), her preference for genre over language (feature preference shift), or\nstart favouring drama over comedy (feature value preference shift). In this\npaper, we first propose a novel latent factor model to capture the\ndomain-dependent component-specific temporal patterns in preferences. The\ncomponent-based approach followed in modelling the aspects of preferences and\ntheir temporal effects enables us to arbitrarily switch components on and off.\nWe evaluate the proposed method on three popular recommendation datasets and\nshow that it significantly outperforms the most accurate state-of-the-art\nstatic models. The experiments also demonstrate the greater robustness and\nstability of the proposed dynamic model in comparison with the most successful\nmodels to date. We also analyse the temporal behaviour of different preference\ncomponents and their combinations and show that the dynamic behaviour of\npreference components is highly dependent on the preference dataset and domain.\nTherefore, the results also highlight the importance of modelling temporal\neffects but also underline the advantages of a component-based architecture\nthat is better suited to capture domain-specific balances in the contributions\nof the aspects.\n"]},
{"authors": ["Raman Arora", "Amitabh Basu", "Poorya Mianjy", "Anirbit Mukherjee"], "title": ["Understanding Deep Neural Networks with Rectified Linear Units"], "date": ["2016-11-04T18:54:50Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1611.01491v6"], "summary": ["  In this paper we investigate the family of functions representable by deep\nneural networks (DNN) with rectified linear units (ReLU). We give an algorithm\nto train a ReLU DNN with one hidden layer to *global optimality* with runtime\npolynomial in the data size albeit exponential in the input dimension. Further,\nwe improve on the known lower bounds on size (from exponential to super\nexponential) for approximating a ReLU deep net function by a shallower ReLU\nnet. Our gap theorems hold for smoothly parametrized families of \"hard\"\nfunctions, contrary to countable, discrete families known in the literature. An\nexample consequence of our gap theorems is the following: for every natural\nnumber $k$ there exists a function representable by a ReLU DNN with $k^2$\nhidden layers and total size $k^3$, such that any ReLU DNN with at most $k$\nhidden layers will require at least $\\frac{1}{2}k^{k+1}-1$ total nodes.\nFinally, for the family of $\\mathbb{R}^n\\to \\mathbb{R}$ DNNs with ReLU\nactivations, we show a new lowerbound on the number of affine pieces, which is\nlarger than previous constructions in certain regimes of the network\narchitecture and most distinctively our lowerbound is demonstrated by an\nexplicit construction of a *smoothly parameterized* family of functions\nattaining this scaling. Our construction utilizes the theory of zonotopes from\npolyhedral theory.\n"]},
{"authors": ["Suttinee Sawadsitang", "Siwei Jiang", "Dusit Niyato", "Ping Wang"], "title": ["Optimal Stochastic Package Delivery Planning with Deadline: A\n  Cardinality Minimization in Routing"], "date": ["2018-02-28T02:01:43Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.02232v1"], "summary": ["  Vehicle Routing Problem with Private fleet and common Carrier (VRPPC) has\nbeen proposed to help a supplier manage package delivery services from a single\ndepot to multiple customers. Most of the existing VRPPC works consider\ndeterministic parameters which may not be practical and uncertainty has to be\ntaken into account. In this paper, we propose the Optimal Stochastic Delivery\nPlanning with Deadline (ODPD) to help a supplier plan and optimize the package\ndelivery. The aim of ODPD is to service all customers within a given deadline\nwhile considering the randomness in customer demands and traveling time. We\nformulate the ODPD as a stochastic integer programming, and use the cardinality\nminimization approach for calculating the deadline violation probability. To\naccelerate computation, the L-shaped decomposition method is adopted. We\nconduct extensive performance evaluation based on real customer locations and\ntraveling time from Google Map.\n"]},
{"authors": ["Rachit Dubey", "Pulkit Agrawal", "Deepak Pathak", "Thomas L. Griffiths", "Alexei A. Efros"], "title": ["Investigating Human Priors for Playing Video Games"], "date": ["2018-02-28T00:26:44Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.10217v1"], "summary": ["  What makes humans so good at solving seemingly complex video games? Unlike\ncomputers, humans bring in a great deal of prior knowledge about the world,\nenabling efficient decision making. This paper investigates the role of human\npriors for solving video games. Given a sample game, we conduct a series of\nablation studies to quantify the importance of various priors on human\nperformance. We do this by modifying the video game environment to\nsystematically mask different types of visual information that could be used by\nhumans as priors. We find that removal of some prior knowledge causes a drastic\ndegradation in the speed with which human players solve the game, e.g. from 2\nminutes to over 20 minutes. Furthermore, our results indicate that general\npriors, such as the importance of objects and visual consistency, are critical\nfor efficient game-play. Videos and the game manipulations are available at\nhttps://rach0012.github.io/humanRL_website/\n"]},
{"authors": ["Jacob Schreiber"], "title": ["Pomegranate: fast and flexible probabilistic modeling in python"], "date": ["2017-10-31T22:53:20Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.00137v2"], "summary": ["  We present pomegranate, an open source machine learning package for\nprobabilistic modeling in Python. Probabilistic modeling encompasses a wide\nrange of methods that explicitly describe uncertainty using probability\ndistributions. Three widely used probabilistic models implemented in\npomegranate are general mixture models, hidden Markov models, and Bayesian\nnetworks. A primary focus of pomegranate is to abstract away the complexities\nof training models from their definition. This allows users to focus on\nspecifying the correct model for their application instead of being limited by\ntheir understanding of the underlying algorithms. An aspect of this focus\ninvolves the collection of additive sufficient statistics from data sets as a\nstrategy for training models. This approach trivially enables many useful\nlearning strategies, such as out-of-core learning, minibatch learning, and\nsemi-supervised learning, without requiring the user to consider how to\npartition data or modify the algorithms to handle these tasks themselves.\npomegranate is written in Cython to speed up calculations and releases the\nglobal interpreter lock to allow for built-in multithreaded parallelism, making\nit competitive with---or outperform---other implementations of similar\nalgorithms. This paper presents an overview of the design choices in\npomegranate, and how they have enabled complex features to be supported by\nsimple code.\n"]},
{"authors": ["Lisa Chalaguine", "Emmanuel Hadoux", "Fiona Hamilton", "Andrew Hayward", "Anthony Hunter", "Sylwia Polberg", "Henry W. W. Potts"], "title": ["Domain Modelling in Computational Persuasion for Behaviour Change in\n  Healthcare"], "date": ["2018-02-27T18:13:57Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.10054v1"], "summary": ["  The aim of behaviour change is to help people to change aspects of their\nbehaviour for the better (e.g., to decrease calorie intake, to drink in\nmoderation, to take more exercise, to complete a course of antibiotics once\nstarted, etc.). In current persuasion technology for behaviour change, the\nemphasis is on helping people to explore their issues (e.g., through\nquestionnaires or game playing) or to remember to follow a behaviour change\nplan (e.g., diaries and email reminders). However, recent developments in\ncomputational persuasion are leading to an argument-centric approach to\npersuasion that can potentially be harnessed in behaviour change applications.\nIn this paper, we review developments in computational persuasion, and then\nfocus on domain modelling as a key component. We present a multi-dimensional\napproach to domain modelling. At the core of this proposal is an ontology which\nprovides a representation of key factors, in particular kinds of belief, which\nwe have identified in the behaviour change literature as being important in\ndiverse behaviour change initiatives. Our proposal for domain modelling is\nintended to facilitate the acquisition and representation of the arguments that\ncan be used in persuasion dialogues, together with meta-level information about\nthem which can be used by the persuader to make strategic choices of argument\nto present.\n"]},
{"authors": ["Frank Z. Xing", "Erik Cambria", "Lorenzo Malandri", "Carlo Vercellis"], "title": ["Discovering Bayesian Market Views for Intelligent Asset Allocation"], "date": ["2018-02-27T14:37:54Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.09911v1"], "summary": ["  Along with the advance of opinion mining techniques, public mood has been\nfound to be a key element for stock market prediction. However, in what manner\nthe market participants are affected by public mood has been rarely discussed.\nAs a result, there has been little progress in leveraging public mood for the\nasset allocation problem, as the application is preferred in a trusted and\ninterpretable way. In order to address the issue of incorporating public mood\nanalyzed from social media, we propose to formalize it into market views that\ncan be integrated into the modern portfolio theory. In this framework, the\noptimal market views will maximize returns in each period with a Bayesian asset\nallocation model. We train two neural models to generate the market views, and\nbenchmark the performance of our model using market views on other popular\nasset allocation strategies. Our experimental results suggest that the\nformalization of market views significantly increases the profitability (5% to\n10%) of the simulated portfolio at a given risk level.\n"]},
{"authors": ["Markus M\u00fcller", "Sebastian St\u00fcker", "Alex Waibel"], "title": ["Multilingual Adaptation of RNN Based ASR Systems"], "date": ["2017-11-13T13:22:54Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.04569v2"], "summary": ["  In this work, we focus on multilingual systems based on recurrent neural\nnetworks (RNNs), trained using the Connectionist Temporal Classification (CTC)\nloss function. Using a multilingual set of acoustic units poses difficulties.\nTo address this issue, we proposed Language Feature Vectors (LFVs) to train\nlanguage adaptive multilingual systems. Language adaptation, in contrast to\nspeaker adaptation, needs to be applied not only on the feature level, but also\nto deeper layers of the network. In this work, we therefore extended our\nprevious approach by introducing a novel technique which we call \"modulation\".\nBased on this method, we modulated the hidden layers of RNNs using LFVs. We\nevaluated this approach in both full and low resource conditions, as well as\nfor grapheme and phone based systems. Lower error rates throughout the\ndifferent conditions could be achieved by the use of the modulation.\n"]},
{"authors": ["Ivan Habernal", "Henning Wachsmuth", "Iryna Gurevych", "Benno Stein"], "title": ["The Argument Reasoning Comprehension Task: Identification and\n  Reconstruction of Implicit Warrants"], "date": ["2017-08-04T08:46:03Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1708.01425v4"], "summary": ["  Reasoning is a crucial part of natural language argumentation. To comprehend\nan argument, one must analyze its warrant, which explains why its claim follows\nfrom its premises. As arguments are highly contextualized, warrants are usually\npresupposed and left implicit. Thus, the comprehension does not only require\nlanguage understanding and logic skills, but also depends on common sense. In\nthis paper we develop a methodology for reconstructing warrants systematically.\nWe operationalize it in a scalable crowdsourcing process, resulting in a freely\nlicensed dataset with warrants for 2k authentic arguments from news comments.\nOn this basis, we present a new challenging task, the argument reasoning\ncomprehension task. Given an argument with a claim and a premise, the goal is\nto choose the correct implicit warrant from two options. Both warrants are\nplausible and lexically close, but lead to contradicting claims. A solution to\nthis task will define a substantial step towards automatic warrant\nreconstruction. However, experiments with several neural attention and language\nmodels reveal that current approaches do not suffice.\n"]},
{"authors": ["Armand Zampieri", "Guillaume Charpiat", "Yuliya Tarabalka"], "title": ["Coarse to fine non-rigid registration: a chain of scale-specific neural\n  networks for multimodal image alignment with application to remote sensing"], "date": ["2018-02-27T10:47:06Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.09816v1"], "summary": ["  We tackle here the problem of multimodal image non-rigid registration, which\nis of prime importance in remote sensing and medical imaging. The difficulties\nencountered by classical registration approaches include feature design and\nslow optimization by gradient descent. By analyzing these methods, we note the\nsignificance of the notion of scale. We design easy-to-train,\nfully-convolutional neural networks able to learn scale-specific features. Once\nchained appropriately, they perform global registration in linear time, getting\nrid of gradient descent schemes by predicting directly the deformation.We show\ntheir performance in terms of quality and speed through various tasks of remote\nsensing multimodal image alignment. In particular, we are able to register\ncorrectly cadastral maps of buildings as well as road polylines onto RGB\nimages, and outperform current keypoint matching methods.\n"]},
{"authors": ["Steven Carr", "Nils Jansen", "Ralf Wimmer", "Jie Fu", "Ufuk Topcu"], "title": ["Human-in-the-Loop Synthesis for Partially Observable Markov Decision\n  Processes"], "date": ["2018-02-27T10:29:56Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.09810v1"], "summary": ["  We study planning problems where autonomous agents operate inside\nenvironments that are subject to uncertainties and not fully observable.\nPartially observable Markov decision processes (POMDPs) are a natural formal\nmodel to capture such problems. Because of the potentially huge or even\ninfinite belief space in POMDPs, synthesis with safety guarantees is, in\ngeneral, computationally intractable. We propose an approach that aims to\ncircumvent this difficulty: in scenarios that can be partially or fully\nsimulated in a virtual environment, we actively integrate a human user to\ncontrol an agent. While the user repeatedly tries to safely guide the agent in\nthe simulation, we collect data from the human input. Via behavior cloning, we\ntranslate the data into a strategy for the POMDP. The strategy resolves all\nnondeterminism and non-observability of the POMDP, resulting in a discrete-time\nMarkov chain (MC). The efficient verification of this MC gives quantitative\ninsights into the quality of the inferred human strategy by proving or\ndisproving given system specifications. For the case that the quality of the\nstrategy is not sufficient, we propose a refinement method using\ncounterexamples presented to the human. Experiments show that by including\nhumans into the POMDP verification loop we improve the state of the art by\norders of magnitude in terms of scalability.\n"]},
{"authors": ["Parijat Dewangan", "S Phaniteja", "K Madhava Krishna", "Abhishek Sarkar", "Balaraman Ravindran"], "title": ["DiGrad: Multi-Task Reinforcement Learning with Shared Actions"], "date": ["2018-02-27T10:26:08Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.10463v1"], "summary": ["  Most reinforcement learning algorithms are inefficient for learning multiple\ntasks in complex robotic systems, where different tasks share a set of actions.\nIn such environments a compound policy may be learnt with shared neural network\nparameters, which performs multiple tasks concurrently. However such compound\npolicy may get biased towards a task or the gradients from different tasks\nnegate each other, making the learning unstable and sometimes less data\nefficient. In this paper, we propose a new approach for simultaneous training\nof multiple tasks sharing a set of common actions in continuous action spaces,\nwhich we call as DiGrad (Differential Policy Gradient). The proposed framework\nis based on differential policy gradients and can accommodate multi-task\nlearning in a single actor-critic network. We also propose a simple heuristic\nin the differential policy gradient update to further improve the learning. The\nproposed architecture was tested on 8 link planar manipulator and 27 degrees of\nfreedom(DoF) Humanoid for learning multi-goal reachability tasks for 3 and 2\nend effectors respectively. We show that our approach supports efficient\nmulti-task learning in complex robotic systems, outperforming related methods\nin continuous action spaces.\n"]},
{"authors": ["Riccardo Polvara", "Massimiliano Patacchiola", "Sanjay Sharma", "Jian Wan", "Andrew Manning", "Robert Sutton", "Angelo Cangelosi"], "title": ["Autonomous Quadrotor Landing using Deep Reinforcement Learning"], "date": ["2017-09-11T11:39:47Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1709.03339v3"], "summary": ["  Landing an unmanned aerial vehicle (UAV) on a ground marker is an open\nproblem despite the effort of the research community. Previous attempts mostly\nfocused on the analysis of hand-crafted geometric features and the use of\nexternal sensors in order to allow the vehicle to approach the land-pad. In\nthis article, we propose a method based on deep reinforcement learning that\nonly requires low-resolution images taken from a down-looking camera in order\nto identify the position of the marker and land the UAV on it. The proposed\napproach is based on a hierarchy of Deep Q-Networks (DQNs) used as high-level\ncontrol policy for the navigation toward the marker. We implemented different\ntechnical solutions, such as the combination of vanilla and double DQNs, and a\npartitioned buffer replay. Using domain randomization we trained the vehicle on\nuniform textures and we tested it on a large variety of simulated and\nreal-world environments. The overall performance is comparable with a\nstate-of-the-art algorithm and human pilots.\n"]},
{"authors": ["Gregory Palmer", "Karl Tuyls", "Daan Bloembergen", "Rahul Savani"], "title": ["Lenient Multi-Agent Deep Reinforcement Learning"], "date": ["2017-07-14T07:33:20Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1707.04402v2"], "summary": ["  Much of the success of single agent deep reinforcement learning (DRL) in\nrecent years can be attributed to the use of experience replay memories (ERM),\nwhich allow Deep Q-Networks (DQNs) to be trained efficiently through sampling\nstored state transitions. However, care is required when using ERMs for\nmulti-agent deep reinforcement learning (MA-DRL), as stored transitions can\nbecome outdated because agents update their policies in parallel [11]. In this\nwork we apply leniency [23] to MA-DRL. Lenient agents map state-action pairs to\ndecaying temperature values that control the amount of leniency applied towards\nnegative policy updates that are sampled from the ERM. This introduces optimism\nin the value-function update, and has been shown to facilitate cooperation in\ntabular fully-cooperative multi-agent reinforcement learning problems. We\nevaluate our Lenient-DQN (LDQN) empirically against the related Hysteretic-DQN\n(HDQN) algorithm [22] as well as a modified version we call scheduled-HDQN,\nthat uses average reward learning near terminal states. Evaluations take place\nin extended variations of the Coordinated Multi-Agent Object Transportation\nProblem (CMOTP) [8] which include fully-cooperative sub-tasks and stochastic\nrewards. We find that LDQN agents are more likely to converge to the optimal\npolicy in a stochastic reward CMOTP compared to standard and scheduled-HDQN\nagents.\n"]},
{"authors": ["Junqi Jin", "Chengru Song", "Han Li", "Kun Gai", "Jun Wang", "Weinan Zhang"], "title": ["Real-Time Bidding with Multi-Agent Reinforcement Learning in Display\n  Advertising"], "date": ["2018-02-27T07:52:35Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.09756v1"], "summary": ["  Real-time advertising allows advertisers to bid for each impression for a\nvisiting user. To optimize a specific goal such as maximizing the revenue led\nby ad placements, advertisers not only need to estimate the relevance between\nthe ads and user's interests, but most importantly require a strategic response\nwith respect to other advertisers bidding in the market. In this paper, we\nformulate bidding optimization with multi-agent reinforcement learning. To deal\nwith a large number of advertisers, we propose a clustering method and assign\neach cluster with a strategic bidding agent. A practical Distributed\nCoordinated Multi-Agent Bidding (DCMAB) has been proposed and implemented to\nbalance the tradeoff between the competition and cooperation among advertisers.\nThe empirical study on our industry-scaled real-world data has demonstrated the\neffectiveness of our modeling methods. Our results show that a cluster based\nbidding would largely outperform single-agent and bandit approaches, and the\ncoordinated bidding achieves better overall objectives than the purely\nself-interested bidding agents.\n"]},
{"authors": ["Azlan Iqbal"], "title": ["Estimating Total Search Space Size for Specific Piece Sets in Chess"], "date": ["2018-02-27T07:35:55Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.00874v1"], "summary": ["  Automatic chess problem or puzzle composition typically involves generating\nand testing various different positions, sometimes using particular piece sets.\nOnce a position has been generated, it is then usually tested for positional\nlegality based on the game rules. However, it is useful to be able to estimate\nwhat the search space size for particular piece combinations is to begin with.\nSo if a desirable chess problem was successfully generated by examining\n'merely' 100,000 or so positions in a theoretical search space of about 100\nbillion, this would imply the composing approach used was quite viable and\nperhaps even impressive. In this article, I explain a method of calculating the\nsize of this search space using a combinatorics and permutations approach.\nWhile the mathematics itself may already be established, a precise method and\njustification of applying it with regard to the chessboard and chess pieces has\nnot been documented, to the best of our knowledge. Additionally, the method\ncould serve as a useful starting point for further estimations of search space\nsize which filter out positions for legality and rotation, depending on how the\nautomatic composer is allowed to place pieces on the board (because this\naffects its total search space size).\n"]},
{"authors": ["Stephen Mussmann", "Percy Liang"], "title": ["Generalized Binary Search For Split-Neighborly Problems"], "date": ["2018-02-27T07:30:32Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.09751v1"], "summary": ["  In sequential hypothesis testing, Generalized Binary Search (GBS) greedily\nchooses the test with the highest information gain at each step. It is known\nthat GBS obtains the gold standard query cost of $O(\\log n)$ for problems\nsatisfying the $k$-neighborly condition, which requires any two tests to be\nconnected by a sequence of tests where neighboring tests disagree on at most\n$k$ hypotheses. In this paper, we introduce a weaker condition,\nsplit-neighborly, which requires that for the set of hypotheses two neighbors\ndisagree on, any subset is splittable by some test. For four problems that are\nnot $k$-neighborly for any constant $k$, we prove that they are\nsplit-neighborly, which allows us to obtain the optimal $O(\\log n)$ worst-case\nquery cost.\n"]},
{"authors": ["Qingpeng Cai", "Aris Filos-Ratsikas", "Pingzhong Tang", "Yiwei Zhang"], "title": ["Reinforcement Mechanism Design for e-commerce"], "date": ["2017-08-25T03:55:21Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1708.07607v3"], "summary": ["  We study the problem of allocating impressions to sellers in e-commerce\nwebsites, such as Amazon, eBay or Taobao, aiming to maximize the total revenue\ngenerated by the platform. We employ a general framework of reinforcement\nmechanism design, which uses deep reinforcement learning to design efficient\nalgorithms, taking the strategic behaviour of the sellers into account.\nSpecifically, we model the impression allocation problem as a Markov decision\nprocess, where the states encode the history of impressions, prices,\ntransactions and generated revenue and the actions are the possible impression\nallocations in each round. To tackle the problem of continuity and\nhigh-dimensionality of states and actions, we adopt the ideas of the DDPG\nalgorithm to design an actor-critic policy gradient algorithm which takes\nadvantage of the problem domain in order to achieve convergence and stability.\nWe evaluate our proposed algorithm, coined IA(GRU), by comparing it against\nDDPG, as well as several natural heuristics, under different rationality models\nfor the sellers - we assume that sellers follow well-known no-regret type\nstrategies which may vary in their degree of sophistication. We find that\nIA(GRU) outperforms all algorithms in terms of the total revenue.\n"]},
{"authors": ["David Isele", "Reza Rahimi", "Akansel Cosgun", "Kaushik Subramanian", "Kikuo Fujimura"], "title": ["Navigating Occluded Intersections with Autonomous Vehicles using Deep\n  Reinforcement Learning"], "date": ["2017-05-02T22:57:36Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1705.01196v2"], "summary": ["  Providing an efficient strategy to navigate safely through unsignaled\nintersections is a difficult task that requires determining the intent of other\ndrivers. We explore the effectiveness of Deep Reinforcement Learning to handle\nintersection problems. Using recent advances in Deep RL, we are able to learn\npolicies that surpass the performance of a commonly-used heuristic approach in\nseveral metrics including task completion time and goal success rate and have\nlimited ability to generalize. We then explore a system's ability to learn\nactive sensing behaviors to enable navigating safely in the case of occlusions.\nOur analysis, provides insight into the intersection handling problem, the\nsolutions learned by the network point out several shortcomings of current\nrule-based methods, and the failures of our current deep reinforcement learning\nsystem point to future research directions.\n"]},
{"authors": ["Kaiqing Zhang", "Zhuoran Yang", "Han Liu", "Tong Zhang", "Tamer Ba\u015far"], "title": ["Fully Decentralized Multi-Agent Reinforcement Learning with Networked\n  Agents"], "date": ["2018-02-23T22:53:32Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08757v2"], "summary": ["  We consider the problem of \\emph{fully decentralized} multi-agent\nreinforcement learning (MARL), where the agents are located at the nodes of a\ntime-varying communication network. Specifically, we assume that the reward\nfunctions of the agents might correspond to different tasks, and are only known\nto the corresponding agent. Moreover, each agent makes individual decisions\nbased on both the information observed locally and the messages received from\nits neighbors over the network. Within this setting, the collective goal of the\nagents is to maximize the globally averaged return over the network through\nexchanging information with their neighbors. To this end, we propose two\ndecentralized actor-critic algorithms with function approximation, which are\napplicable to large-scale MARL problems where both the number of states and the\nnumber of agents are massively large. Under the decentralized structure, the\nactor step is performed individually by each agent with no need to infer the\npolicies of others. For the critic step, we propose a consensus update via\ncommunication over the network. Our algorithms are fully incremental and can be\nimplemented in an online fashion. Convergence analyses of the algorithms are\nprovided when the value functions are approximated within the class of linear\nfunctions. Extensive simulation results with both linear and nonlinear function\napproximations are presented to validate the proposed algorithms. Our work\nappears to be the first study of fully decentralized MARL algorithms for\nnetworked agents with function approximation, with provable convergence\nguarantees.\n"]},
{"authors": ["Jie Tang", "Shaoshan Liu", "Songwen Pei", "Stephane Zuckerman", "Chen Liu", "Weisong Shi", "Jean-Luc Gaudiot"], "title": ["Teaching Autonomous Driving Using a Modular and Integrated Approach"], "date": ["2018-02-22T04:01:51Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.09355v2"], "summary": ["  Autonomous driving is not one single technology but rather a complex system\nintegrating many technologies, which means that teaching autonomous driving is\na challenging task. Indeed, most existing autonomous driving classes focus on\none of the technologies involved. This not only fails to provide a\ncomprehensive coverage, but also sets a high entry barrier for students with\ndifferent technology backgrounds. In this paper, we present a modular,\nintegrated approach to teaching autonomous driving. Specifically, we organize\nthe technologies used in autonomous driving into modules. This is described in\nthe textbook we have developed as well as a series of multimedia online\nlectures designed to provide technical overview for each module. Then, once the\nstudents have understood these modules, the experimental platforms for\nintegration we have developed allow the students to fully understand how the\nmodules interact with each other. To verify this teaching approach, we present\nthree case studies: an introductory class on autonomous driving for students\nwith only a basic technology background; a new session in an existing embedded\nsystems class to demonstrate how embedded system technologies can be applied to\nautonomous driving; and an industry professional training session to quickly\nbring up experienced engineers to work in autonomous driving. The results show\nthat students can maintain a high interest level and make great progress by\nstarting with familiar concepts before moving onto other modules.\n"]},
{"authors": ["George Leu", "Hussein Abbass"], "title": ["A Multi-Disciplinary Review of Knowledge Acquisition Methods: From Human\n  to Autonomous Eliciting Agents"], "date": ["2018-02-27T01:21:46Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.09669v1"], "summary": ["  This paper offers a multi-disciplinary review of knowledge acquisition\nmethods in human activity systems. The review captures the degree of\ninvolvement of various types of agencies in the knowledge acquisition process,\nand proposes a classification with three categories of methods: the human\nagent, the human-inspired agent, and the autonomous machine agent methods. In\nthe first two categories, the acquisition of knowledge is seen as a cognitive\ntask analysis exercise, while in the third category knowledge acquisition is\ntreated as an autonomous knowledge-discovery endeavour. The motivation for this\nclassification stems from the continuous change over time of the structure,\nmeaning and purpose of human activity systems, which are seen as the factor\nthat fuelled researchers' and practitioners' efforts in knowledge acquisition\nfor more than a century.\n  We show through this review that the KA field is increasingly active due to\nthe higher and higher pace of change in human activity, and conclude by\ndiscussing the emergence of a fourth category of knowledge acquisition methods,\nwhich are based on red-teaming and co-evolution.\n"]},
{"authors": ["Jiangjun Tang", "Eleni Petraki", "Hussein Abbass"], "title": ["Shaping Influence and Influencing Shaping: A Computational Red Teaming\n  Trust-based Swarm Intelligence Model"], "date": ["2018-02-26T23:53:40Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.09647v1"], "summary": ["  Sociotechnical systems are complex systems, where nonlinear interaction among\ndifferent players can obscure causal relationships. The absence of mechanisms\nto help us understand how to create a change in the system makes it hard to\nmanage these systems.\n  Influencing and shaping are social operators acting on sociotechnical systems\nto design a change. However, the two operators are usually discussed in an\nad-hoc manner, without proper guiding models and metrics which assist in\nadopting these models successfully. Moreover, both social operators rely on\naccurate understanding of the concept of trust. Without such understanding,\nneither of these operators can create the required level to create a change in\na desirable direction.\n  In this paper, we define these concepts in a concise manner suitable for\nmodelling the concepts and understanding their dynamics. We then introduce a\nmodel for influencing and shaping and use Computational Red Teaming principles\nto design and demonstrate how this model operates. We validate the results\ncomputationally through a simulation environment to show social influencing and\nshaping in an artificial society.\n"]},
{"authors": ["Kui Yu", "Lin Liu", "Jiuyong Li"], "title": ["A Unified View of Causal and Non-causal Feature Selection"], "date": ["2018-02-16T06:18:06Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.05844v2"], "summary": ["  In this paper, we unify causal and non-causal feature selection methods based\non the Bayesian network framework. We first show that the objectives of causal\nand non-causal feature selection methods are equal and are to find the Markov\nblanket of a class attribute, the theoretically optimal feature set for\nclassification. We demonstrate that causal and non-causal feature selection\ntake different assumptions of dependency among features to find Markov blanket,\nand their algorithms are shown different level of approximation for finding\nMarkov blanket. In this framework, we are able to analyze the sample and error\nbounds of casual and non-causal methods. We conducted extensive experiments to\nshow the correctness of our theoretical analysis.\n"]},
{"authors": ["Falk Lieder", "Frederick Callaway", "Sayan Gul", "Paul M. Krueger", "Thomas L. Griffiths"], "title": ["Learning to select computations"], "date": ["2017-11-18T16:42:48Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.06892v2"], "summary": ["  Efficient use of limited computational resources is essential to\nintelligence. Selecting computations optimally according to rational\nmetareasoning would achieve this, but rational metareasoning is computationally\nintractable. Inspired by psychology and neuroscience, we propose the first\nlearning algorithm for approximating the optimal selection of computations. We\nderive a general, sample-efficient reinforcement learning algorithm for\nlearning to select computations from the insight that the value of computation\nlies between the myopic value of computation and the value of perfect\ninformation. We evaluate the performance of our method against two\nstate-of-the-art methods for approximate metareasoning--the meta-greedy\nheuristic and the blinkered policy--on three increasingly difficult\nmetareasoning problems: metareasoning about when to terminate computation,\nmetareasoning about how to choose between multiple actions, and metareasoning\nabout planning. Across all three domains, our method achieved near-optimal\nperformance and significantly outperformed the meta-greedy heuristic. The\nblinkered policy performed on par with our method in metareasoning about\ndecision-making, but it is not directly applicable to metareasoning about\nplanning where our method outperformed both the meta-greedy heuristic and a\ngeneralization of the blinkered policy. Our results are a step towards building\nself-improving AI systems that can learn to make optimal use of their limited\ncomputational resources to efficiently solve complex problems in real-time.\n"]},
{"authors": ["Jiongqian Liang", "Saket Gurukar", "Srinivasan Parthasarathy"], "title": ["MILE: A Multi-Level Framework for Scalable Graph Embedding"], "date": ["2018-02-26T21:18:43Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.09612v1"], "summary": ["  Recently there has been a surge of interest in designing graph embedding\nmethods. Few, if any, can scale to a large-sized graph with millions of nodes\ndue to both computational complexity and memory requirements. In this paper, we\nrelax this limitation by introducing the MultI-Level Embedding (MILE) framework\n-- a generic methodology allowing contemporary graph embedding methods to scale\nto large graphs. MILE repeatedly coarsens the graph into smaller ones using a\nhybrid matching technique to maintain the backbone structure of the graph. It\nthen applies existing embedding methods on the coarsest graph and refines the\nembeddings to the original graph through a novel graph convolution neural\nnetwork that it learns. The proposed MILE framework is agnostic to the\nunderlying graph embedding techniques and can be applied to many existing graph\nembedding methods without modifying them. We employ our framework on several\npopular graph embedding techniques and conduct embedding for real-world graphs.\nExperimental results on five large-scale datasets demonstrate that MILE\nsignificantly boosts the speed (order of magnitude) of graph embedding while\nalso often generating embeddings of better quality for the task of node\nclassification. MILE can comfortably scale to a graph with 9 million nodes and\n40 million edges, on which existing methods run out of memory or take too long\nto compute on a modern workstation.\n"]},
{"authors": ["Yuke Zhu", "Ziyu Wang", "Josh Merel", "Andrei Rusu", "Tom Erez", "Serkan Cabi", "Saran Tunyasuvunakool", "J\u00e1nos Kram\u00e1r", "Raia Hadsell", "Nando de Freitas", "Nicolas Heess"], "title": ["Reinforcement and Imitation Learning for Diverse Visuomotor Skills"], "date": ["2018-02-26T19:25:25Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.09564v1"], "summary": ["  We propose a model-free deep reinforcement learning method that leverages a\nsmall amount of demonstration data to assist a reinforcement learning agent. We\napply this approach to robotic manipulation tasks and train end-to-end\nvisuomotor policies that map directly from RGB camera inputs to joint\nvelocities. We demonstrate that our approach can solve a wide variety of\nvisuomotor tasks, for which engineering a scripted controller would be\nlaborious. Our experiments indicate that our reinforcement and imitation agent\nachieves significantly better performances than agents trained with\nreinforcement learning or imitation learning alone. We also illustrate that\nthese policies, trained with large visual and dynamics variations, can achieve\npreliminary successes in zero-shot sim2real transfer. A brief visual\ndescription of this work can be viewed in https://youtu.be/EDl8SQUNjj0\n"]},
{"authors": ["Scott Fujimoto", "Herke van Hoof", "Dave Meger"], "title": ["Addressing Function Approximation Error in Actor-Critic Methods"], "date": ["2018-02-26T17:54:49Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.09477v1"], "summary": ["  In value-based reinforcement learning methods such as deep Q-learning,\nfunction approximation errors are known to lead to overestimated value\nestimates and suboptimal policies. We show that this problem persists in an\nactor-critic setting and propose novel mechanisms to minimize its effects on\nboth the actor and critic. Our algorithm takes the minimum value between a pair\nof critics to restrict overestimation and delays policy updates to reduce\nper-update error. We evaluate our method on the suite of OpenAI gym tasks,\noutperforming the state of the art in every environment tested.\n"]},
{"authors": ["Dominik Wojtczak"], "title": ["On Strong NP-Completeness of Rational Problems"], "date": ["2018-02-26T17:23:02Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.09465v1"], "summary": ["  The computational complexity of the partition, 0-1 subset sum, unbounded\nsubset sum, 0-1 knapsack and unbounded knapsack problems and their multiple\nvariants were studied in numerous papers in the past where all the weights and\nprofits were assumed to be integers. We re-examine here the computational\ncomplexity of all these problems in the setting where the weights and profits\nare allowed to be any rational numbers. We show that all of these problems in\nthis setting become strongly NP-complete and, as a result, no pseudo-polynomial\nalgorithm can exist for solving them unless P=NP. Despite this result we show\nthat they all still admit a fully polynomial-time approximation scheme.\n"]},
{"authors": ["Mikel Artetxe", "Gorka Labaka", "Eneko Agirre", "Kyunghyun Cho"], "title": ["Unsupervised Neural Machine Translation"], "date": ["2017-10-30T16:17:34Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.11041v2"], "summary": ["  In spite of the recent success of neural machine translation (NMT) in\nstandard benchmarks, the lack of large parallel corpora poses a major practical\nproblem for many language pairs. There have been several proposals to alleviate\nthis issue with, for instance, triangulation and semi-supervised learning\ntechniques, but they still require a strong cross-lingual signal. In this work,\nwe completely remove the need of parallel data and propose a novel method to\ntrain an NMT system in a completely unsupervised manner, relying on nothing but\nmonolingual corpora. Our model builds upon the recent work on unsupervised\nembedding mappings, and consists of a slightly modified attentional\nencoder-decoder model that can be trained on monolingual corpora alone using a\ncombination of denoising and backtranslation. Despite the simplicity of the\napproach, our system obtains 15.56 and 10.21 BLEU points in WMT 2014\nFrench-to-English and German-to-English translation. The model can also profit\nfrom small parallel corpora, and attains 21.81 and 15.24 points when combined\nwith 100,000 parallel sentences, respectively. Our implementation is released\nas an open source project.\n"]},
{"authors": ["David Rolnick", "Andreas Veit", "Serge Belongie", "Nir Shavit"], "title": ["Deep Learning is Robust to Massive Label Noise"], "date": ["2017-05-30T15:10:51Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1705.10694v3"], "summary": ["  Deep neural networks trained on large supervised datasets have led to\nimpressive results in image classification and other tasks. However,\nwell-annotated datasets can be time-consuming and expensive to collect, lending\nincreased interest to larger but noisy datasets that are more easily obtained.\nIn this paper, we show that deep neural networks are capable of generalizing\nfrom training data for which true labels are massively outnumbered by incorrect\nlabels. We demonstrate remarkably high test performance after training on\ncorrupted data from MNIST, CIFAR, and ImageNet. For example, on MNIST we obtain\ntest accuracy above 90 percent even after each clean training example has been\ndiluted with 100 randomly-labeled examples. Such behavior holds across multiple\npatterns of label noise, even when erroneous labels are biased towards\nconfusing classes. We show that training in this regime requires a significant\nbut manageable increase in dataset size that is related to the factor by which\ncorrect labels have been diluted. Finally, we provide an analysis of our\nresults that shows how increasing noise decreases the effective batch size.\n"]},
{"authors": ["Valentina Gliozzi", "Kim Plunkett"], "title": ["Self-organizing maps and generalization: an algorithmic description of\n  Numerosity and Variability Effects"], "date": ["2018-02-26T16:38:42Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.09442v1"], "summary": ["  Category, or property generalization is a central function in the human\ncognition. It plays a crucial role in a variety of domains, such as learning,\neveryday reasoning, specialized reasoning, and decision making. Judging the\ncontent of a dish as edible, a hormone level as healthy, a building as\nbelonging to the same architectural style as previously seen buildings, are\nexamples of category generalization. In this paper, we propose self-organizing\nmaps as candidates to explain the psychological mechanisms underlying category\ngeneralization. Self-organizing maps are psychologically and biologically\nplausible neural network models that learn after limited exposure to positive\ncategory examples, without any need of contrastive information. Just like\nhumans. They reproduce human behavior in category generalization, in particular\nfor what concerns the well-known Numerosity and Variability effects, which are\nusually explained with Bayesian tools. Where category generalization is\nconcerned, self-organizing maps are good candidates to bridge the gap between\nthe computational level of analysis in Marr's hierarchy (where Bayesian models\nare situated) and the algorithmic level of aanalysis in Marr's hierarchy (where\nBayesian models are situated) and the algorithmic level of analysis in which\nplausible mechanisms are described.\n"]},
{"authors": ["Jakub M. Tomczak", "Max Welling"], "title": ["VAE with a VampPrior"], "date": ["2017-05-19T10:07:00Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1705.07120v5"], "summary": ["  Many different methods to train deep generative models have been introduced\nin the past. In this paper, we propose to extend the variational auto-encoder\n(VAE) framework with a new type of prior which we call \"Variational Mixture of\nPosteriors\" prior, or VampPrior for short. The VampPrior consists of a mixture\ndistribution (e.g., a mixture of Gaussians) with components given by\nvariational posteriors conditioned on learnable pseudo-inputs. We further\nextend this prior to a two layer hierarchical model and show that this\narchitecture with a coupled prior and posterior, learns significantly better\nmodels. The model also avoids the usual local optima issues related to useless\nlatent dimensions that plague VAEs. We provide empirical studies on six\ndatasets, namely, static and binary MNIST, OMNIGLOT, Caltech 101 Silhouettes,\nFrey Faces and Histopathology patches, and show that applying the hierarchical\nVampPrior delivers state-of-the-art results on all datasets in the unsupervised\npermutation invariant setting and the best results or comparable to SOTA\nmethods for the approach with convolutional networks.\n"]},
{"authors": ["Matthew Riemer", "Tim Klinger", "Michele Franceschini", "Djallel Bouneffouf"], "title": ["Scalable Recollections for Continual Lifelong Learning"], "date": ["2017-11-17T23:00:11Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.06761v3"], "summary": ["  Given the recent success of Deep Learning applied to a variety of single\ntasks, it is natural to consider more human-realistic settings. Perhaps the\nmost difficult of these settings is that of continual lifelong learning, where\nthe model must learn online over a continuous stream of non-stationary data. A\ncontinual lifelong learning system must have three primary capabilities to\nsucceed: it must learn and adapt over time, it must not forget what it has\nlearned, and it must be efficient in both training time and memory. Recent\ntechniques have focused their efforts largely on the first two capabilities\nwhile the third capability remains largely unexplored. In this paper, we\nconsider the problem of efficient and effective storage of experiences over\nvery large time-frames. In particular we consider the case where typical\nexperiences are n bits and memories are limited to k bits for k << n. We\npresent a novel scalable architecture and training algorithm in this\nchallenging domain and provide an extensive evaluation of its performance. Our\nresults show that we can achieve considerable gains on top of state-of-the-art\nmethods such as GEM.\n"]},
{"authors": ["Eric Sanchis"], "title": ["A Model of Free Will for Artificial Entities"], "date": ["2018-02-26T14:29:03Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.09317v1"], "summary": ["  The impression of free will is the feeling according to which our choices are\nneither imposed from our inside nor from outside. It is the sense we are the\nultimate cause of our acts. In direct opposition with the universal\ndeterminism, the existence of free will continues to be discussed. In this\npaper, free will is linked to a decisional mechanism: an agent is provided with\nfree will if having performed a predictable choice Cp, it can immediately\nperform another choice Cr in a random way. The intangible feeling of free will\nis replaced by a decision-making process including a predictable\ndecision-making process immediately followed by an unpredictable decisional\none.\n"]},
{"authors": ["Sherzod Hakimov", "Soufian Jebbara", "Philipp Cimiano"], "title": ["AMUSE: Multilingual Semantic Parsing for Question Answering over Linked\n  Data"], "date": ["2018-02-26T13:50:14Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.09296v1"], "summary": ["  The task of answering natural language questions over RDF data has received\nwide interest in recent years, in particular in the context of the series of\nQALD benchmarks. The task consists of mapping a natural language question to an\nexecutable form, e.g. SPARQL, so that answers from a given KB can be extracted.\nSo far, most systems proposed are i) monolingual and ii) rely on a set of\nhard-coded rules to interpret questions and map them into a SPARQL query. We\npresent the first multilingual QALD pipeline that induces a model from training\ndata for mapping a natural language question into logical form as probabilistic\ninference. In particular, our approach learns to map universal syntactic\ndependency representations to a language-independent logical form based on\nDUDES (Dependency-based Underspecified Discourse Representation Structures)\nthat are then mapped to a SPARQL query as a deterministic second step. Our\nmodel builds on factor graphs that rely on features extracted from the\ndependency graph and corresponding semantic representations. We rely on\napproximate inference techniques, Markov Chain Monte Carlo methods in\nparticular, as well as Sample Rank to update parameters using a ranking\nobjective. Our focus lies on developing methods that overcome the lexical gap\nand present a novel combination of machine translation and word embedding\napproaches for this purpose. As a proof of concept for our approach, we\nevaluate our approach on the QALD-6 datasets for English, German & Spanish.\n"]},
{"authors": ["Rajesh Misra", "Kumar S. Ray"], "title": ["A Modification of Particle Swarm Optimization using Random Walk"], "date": ["2017-11-16T10:59:34Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.10401v2"], "summary": ["  Particle swarm optimization comes under lot of changes after James Kennedy\nand Russell Eberhart first proposes the idea in 1995. The changes has been done\nmainly on Inertia parameters in velocity updating equation so that the\nconvergence rate will be higher. We are proposing a novel approach where\nparticles movement will not be depend on its velocity rather it will be decided\nby constrained biased random walk of particles. In random walk every particles\nmovement based on two significant parameters, one is random process like toss\nof a coin and other is how much displacement a particle should have. In our\napproach we exploit this idea by performing a biased random operation and based\non the outcome of that random operation, PSO particles choose the direction of\nthe path and move non-uniformly into the solution space. This constrained,\nnon-uniform movement helps the random walking particle to converge quicker then\nclassical PSO. In our constrained biased random walking approach, we no longer\nneeded velocity term (Vi), rather we introduce a new parameter (K) which is a\nprobabilistic function. No global best particle (PGbest), local best particle\n(PLbest), Constriction parameter (W) are required rather we use a new term\ncalled Ptarg which is loosely influenced by PGbest.We test our algorithm on\nfive different benchmark functions, and also compare its performance with\nclassical PSO and Quantum Particle Swarm Optimization (QPSO).This new approach\nhave been shown significantly better than basic PSO and sometime outperform\nQPSO in terms of convergence, search space, number of iterations.\n"]},
{"authors": ["Miguel Rios", "Wilker Aziz", "Khalil Sima'an"], "title": ["Deep Generative Model for Joint Alignment and Word Representation"], "date": ["2018-02-16T10:11:39Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.05883v2"], "summary": ["  This work exploits translation data as a source of semantically relevant\nlearning signal for models of word representation. In particular, we exploit\nequivalence through translation as a form of distributed context and jointly\nlearn how to embed and align with a deep generative model. Our EmbedAlign model\nembeds words in their complete observed context and learns by marginalisation\nof latent lexical alignments. Besides, it embeds words as posterior probability\ndensities, rather than point estimates, which allows us to compare words in\ncontext using a measure of overlap between distributions (e.g. KL divergence).\nWe investigate our model's performance on a range of lexical semantics tasks\nachieving competitive results on several standard benchmarks including natural\nlanguage inference, paraphrasing, and text similarity.\n"]},
{"authors": ["Stuart Armstrong"], "title": ["'Indifference' methods for managing agent rewards"], "date": ["2017-12-18T12:28:45Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1712.06365v3"], "summary": ["  `Indifference' refers to a class of methods that are used to control a reward\nbased agent. These methods of control work even if the implications of the\nagent's reward are otherwise not fully understood. Though they all come out of\nsimilar ideas, indifference techniques can be classified as way of achieving\none or more of three distinct goals: rewards dependent on certain events (with\nno motivation for the agent to manipulate the probability of those events),\neffective disbelief that an event will ever occur, and seamless transition from\none behaviour to another. This paper analyses methods of achieving these goals\nin the POMDP setting, and establishes their uses, strengths, and limitations.\nIt aims to make the tools of indifference generally accessible and usable to\nagent designers.\n"]},
{"authors": ["Weipeng He", "Petr Motlicek", "Jean-Marc Odobez"], "title": ["Deep Neural Networks for Multiple Speaker Detection and Localization"], "date": ["2017-11-30T18:35:22Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.11565v3"], "summary": ["  We propose to use neural networks for simultaneous detection and localization\nof multiple sound sources in human-robot interaction. In contrast to\nconventional signal processing techniques, neural network-based sound source\nlocalization methods require fewer strong assumptions about the environment.\nPrevious neural network-based methods have been focusing on localizing a single\nsound source, which do not extend to multiple sources in terms of detection and\nlocalization. In this paper, we thus propose a likelihood-based encoding of the\nnetwork output, which naturally allows the detection of an arbitrary number of\nsources. In addition, we investigate the use of sub-band cross-correlation\ninformation as features for better localization in sound mixtures, as well as\nthree different network architectures based on different motivations.\nExperiments on real data recorded from a robot show that our proposed methods\nsignificantly outperform the popular spatial spectrum-based approaches.\n"]},
{"authors": ["Sham Kakade", "Mengdi Wang", "Lin F. Yang"], "title": ["Variance Reduction Methods for Sublinear Reinforcement Learning"], "date": ["2018-02-26T07:01:24Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.09184v1"], "summary": ["  This work considers the problem of provably optimal reinforcement learning\nfor (episodic) finite horizon MDPs, i.e. how an agent learns to maximize\nhis/her (long term) reward in an uncertain environment. The main contribution\nis in providing a novel algorithm --- Variance-reduced Upper Confidence\nQ-learning (vUCQ) --- which enjoys a regret bound of $\\widetilde{O}(\\sqrt{HSAT}\n+ H^5SA)$, where the $T$ is the number of time steps the agent acts in the MDP,\n$S$ is the number of states, $A$ is the number of actions, and $H$ is the\n(episodic) horizon time.\n  This is the first regret bound that is both sub-linear in the model size and\nasymptotically optimal. The algorithm is sub-linear in that the time to achieve\n$\\epsilon$-average regret (for any constant $\\epsilon$) is $O(SA)$, which is a\nnumber of samples that is far less than that required to learn any\n(non-trivial) estimate of the transition model (the transition model is\nspecified by $O(S^2A)$ parameters). The importance of sub-linear algorithms is\nlargely the motivation for algorithms such as $Q$-learning and other \"model\nfree\" approaches. vUCQ algorithm also enjoys minimax optimal regret in the long\nrun, matching the $\\Omega(\\sqrt{HSAT})$ lower bound.\n  Variance-reduced Upper Confidence Q-learning (vUCQ) is a successive\nrefinement method in which the algorithm reduces the variance in $Q$-value\nestimates and couples this estimation scheme with an upper confidence based\nalgorithm. Technically, the coupling of both of these techniques is what leads\nto the algorithm enjoying both the sub-linear regret property and the\n(asymptotically) optimal regret.\n"]},
{"authors": ["Lei Tai", "Jingwei Zhang", "Ming Liu", "Wolfram Burgard"], "title": ["Socially Compliant Navigation through Raw Depth Inputs with Generative\n  Adversarial Imitation Learning"], "date": ["2017-10-06T18:29:44Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.02543v2"], "summary": ["  We present an approach for mobile robots to learn to navigate in dynamic\nenvironments with pedestrians via raw depth inputs, in a socially compliant\nmanner. To achieve this, we adopt a generative adversarial imitation learning\n(GAIL) strategy, which improves upon a pre-trained behavior cloning policy. Our\napproach overcomes the disadvantages of previous methods, as they heavily\ndepend on the full knowledge of the location and velocity information of nearby\npedestrians, which not only requires specific sensors, but also the extraction\nof such state information from raw sensory input could consume much computation\ntime. In this paper, our proposed GAIL-based model performs directly on raw\ndepth inputs and plans in real-time. Experiments show that our GAIL-based\napproach greatly improves the safety and efficiency of the behavior of mobile\nrobots from pure behavior cloning. The real-world deployment also shows that\nour method is capable of guiding autonomous vehicles to navigate in a socially\ncompliant manner directly through raw depth inputs. In addition, we release a\nsimulation plugin for modeling pedestrian behaviors based on the social force\nmodel.\n"]},
{"authors": ["Di Wu", "Xiujun Chen", "Xun Yang", "Hao Wang", "Qing Tan", "Xiaoxun Zhang", "Kun Gai"], "title": ["Budget Constrained Bidding by Model-free Reinforcement Learning in\n  Display Advertising"], "date": ["2018-02-23T02:29:06Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08365v2"], "summary": ["  Real-time bidding (RTB) is almost the most important mechanism in online\ndisplay advertising, where proper bid for each page view plays a vital and\nessential role for good marketing results. Budget constrained bidding is a\ntypical scenario in RTB mechanism where the advertisers hope to maximize total\nvalue of winning impressions under a pre-set budget constraint. However, the\noptimal strategy is hard to be derived due to complexity and volatility of the\nauction environment. To address the challenges, in this paper, we formulate\nbudget constrained bidding as a Markov Decision Process. Quite different from\nprior model-based work, we propose a novel framework based on model-free\nreinforcement learning which sequentially regulates the bidding parameter\nrather than directly producing bid. Along this line, we further innovate a\nreward function which deploys a deep neural network to learn appropriate reward\nand thus leads the agent to deliver the optimal policy effectively; we also\ndesign an adaptive $\\epsilon$-greedy strategy which adjusts the exploration\nbehaviour dynamically and further improves the performance. Experimental\nresults on real dataset demonstrate the effectiveness of our framework.\n"]},
{"authors": ["Anusha Mujumdar", "Swarup Kumar Mohalik", "Ramamurthy Badrinath"], "title": ["Antifragility for Intelligent Autonomous Systems"], "date": ["2018-02-26T04:58:55Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.09159v1"], "summary": ["  Antifragile systems grow measurably better in the presence of hazards. This\nis in contrast to fragile systems which break down in the presence of hazards,\nrobust systems that tolerate hazards up to a certain degree, and resilient\nsystems that -- like self-healing systems -- revert to their earlier expected\nbehavior after a period of convalescence. The notion of antifragility was\nintroduced by Taleb for economics systems, but its applicability has been\nillustrated in biological and engineering domains as well. In this paper, we\npropose an architecture that imparts antifragility to intelligent autonomous\nsystems, specifically those that are goal-driven and based on AI-planning. We\nargue that this architecture allows the system to self-improve by uncovering\nnew capabilities obtained either through the hazards themselves (opportunistic)\nor through deliberation (strategic). An AI planning-based case study of an\nautonomous wheeled robot is presented. We show that with the proposed\narchitecture, the robot develops antifragile behaviour with respect to an oil\nspill hazard.\n"]},
{"authors": ["Yang Liu", "Yiling Chen"], "title": ["Surrogate Scoring Rules and a Dominant Truth Serum for Information\n  Elicitation"], "date": ["2018-02-26T04:52:48Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.09158v1"], "summary": ["  We study information elicitation without verification (IEWV) and ask the\nfollowing question: Can we achieve truthfulness in dominant strategy in IEWV?\nThis paper considers two elicitation settings. The first setting is when the\nmechanism designer has access to a random variable that is a noisy or proxy\nversion of the ground truth, with known biases. The second setting is the\nstandard peer prediction setting where agents' reports are the only source of\ninformation that the mechanism designer has. We introduce surrogate scoring\nrules (SSR) for the first setting, which use the noisy ground truth to evaluate\nquality of elicited information, and show that SSR achieve truthful elicitation\nin dominant strategy. Built upon SSR, we develop a multi-task mechanism,\ndominant truth serum (DTS), to achieve truthful elicitation in dominant\nstrategy when the mechanism designer only has access to agents' reports (the\nsecond setting). The method relies on an estimation procedure to accurately\nestimate the average bias in the reports of other agents. With the accurate\nestimation, a random peer agent's report serves as a noisy ground truth and SSR\ncan then be applied to achieve truthfulness in dominant strategy. A salient\nfeature of SSR and DTS is that they both quantify the quality or value of\ninformation despite lack of ground truth, just as proper scoring rules do for\nthe with verification setting. Our work complements both the strictly proper\nscoring rule literature by solving the case where the mechanism designer only\nhas access to a noisy or proxy version of the ground truth, and the peer\nprediction literature by achieving truthful elicitation in dominant strategy.\n"]},
{"authors": ["Fangchang Ma", "Sertac Karaman"], "title": ["Sparse-to-Dense: Depth Prediction from Sparse Depth Samples and a Single\n  Image"], "date": ["2017-09-21T18:50:04Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1709.07492v2"], "summary": ["  We consider the problem of dense depth prediction from a sparse set of depth\nmeasurements and a single RGB image. Since depth estimation from monocular\nimages alone is inherently ambiguous and unreliable, to attain a higher level\nof robustness and accuracy, we introduce additional sparse depth samples, which\nare either acquired with a low-resolution depth sensor or computed via visual\nSimultaneous Localization and Mapping (SLAM) algorithms. We propose the use of\na single deep regression network to learn directly from the RGB-D raw data, and\nexplore the impact of number of depth samples on prediction accuracy. Our\nexperiments show that, compared to using only RGB images, the addition of 100\nspatially random depth samples reduces the prediction root-mean-square error by\n50% on the NYU-Depth-v2 indoor dataset. It also boosts the percentage of\nreliable prediction from 59% to 92% on the KITTI dataset. We demonstrate two\napplications of the proposed algorithm: a plug-in module in SLAM to convert\nsparse maps to dense maps, and super-resolution for LiDARs. Software and video\ndemonstration are publicly available.\n"]},
{"authors": ["Weifeng Ge", "Sibei Yang", "Yizhou Yu"], "title": ["Multi-Evidence Filtering and Fusion for Multi-Label Classification,\n  Object Detection and Semantic Segmentation Based on Weakly Supervised\n  Learning"], "date": ["2018-02-26T02:07:19Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.09129v1"], "summary": ["  Supervised object detection and semantic segmentation require object or even\npixel level annotations. When there exist image level labels only, it is\nchallenging for weakly supervised algorithms to achieve accurate predictions.\nThe accuracy achieved by top weakly supervised algorithms is still\nsignificantly lower than their fully supervised counterparts. In this paper, we\npropose a novel weakly supervised curriculum learning pipeline for multi-label\nobject recognition, detection and semantic segmentation. In this pipeline, we\nfirst obtain intermediate object localization and pixel labeling results for\nthe training images, and then use such results to train task-specific deep\nnetworks in a fully supervised manner. The entire process consists of four\nstages, including object localization in the training images, filtering and\nfusing object instances, pixel labeling for the training images, and\ntask-specific network training. To obtain clean object instances in the\ntraining images, we propose a novel algorithm for filtering, fusing and\nclassifying object instances collected from multiple solution mechanisms. In\nthis algorithm, we incorporate both metric learning and density-based\nclustering to filter detected object instances. Experiments show that our\nweakly supervised pipeline achieves state-of-the-art results in multi-label\nimage classification as well as weakly supervised object detection and very\ncompetitive results in weakly supervised semantic segmentation on MS-COCO,\nPASCAL VOC 2007 and PASCAL VOC 2012.\n"]},
{"authors": ["Lifeng Jin", "Finale Doshi-Velez", "Timothy Miller", "William Schuler", "Lane Schwartz"], "title": ["Unsupervised Grammar Induction with Depth-bounded PCFG"], "date": ["2018-02-23T14:30:00Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08545v2"], "summary": ["  There has been recent interest in applying cognitively or empirically\nmotivated bounds on recursion depth to limit the search space of grammar\ninduction models (Ponvert et al., 2011; Noji and Johnson, 2016; Shain et al.,\n2016). This work extends this depth-bounding approach to probabilistic\ncontext-free grammar induction (DB-PCFG), which has a smaller parameter space\nthan hierarchical sequence models, and therefore more fully exploits the space\nreductions of depth-bounding. Results for this model on grammar acquisition\nfrom transcribed child-directed speech and newswire text exceed or are\ncompetitive with those of other models when evaluated on parse accuracy.\nMoreover, gram- mars acquired from this model demonstrate a consistent use of\ncategory labels, something which has not been demonstrated by other acquisition\nmodels.\n"]},
{"authors": ["Ruggiero Lovreglio", "Vicente Gonzalez", "Zhenan Feng", "Robert Amor", "Michael Spearpoint", "Jared Thomas", "Margaret Trotter", "Rafael Sacks"], "title": ["Prototyping Virtual Reality Serious Games for Building Earthquake\n  Preparedness: The Auckland City Hospital Case Study"], "date": ["2018-02-26T01:08:51Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.09119v1"], "summary": ["  Enhancing evacuee safety is a key factor in reducing the number of injuries\nand deaths that result from earthquakes. One way this can be achieved is by\ntraining occupants. Virtual Reality (VR) and Serious Games (SGs), represent\nnovel techniques that may overcome the limitations of traditional training\napproaches. VR and SGs have been examined in the fire emergency context,\nhowever, their application to earthquake preparedness has not yet been\nextensively examined. We provide a theoretical discussion of the advantages and\nlimitations of using VR SGs to investigate how building occupants behave during\nearthquake evacuations and to train building occupants to cope with such\nemergencies. We explore key design components for developing a VR SG framework:\n(a) what features constitute an earthquake event, (b) which building types can\nbe selected and represented within the VR environment, (c) how damage to the\nbuilding can be determined and represented, (d) how non-player characters (NPC)\ncan be designed, and (e) what level of interaction there can be between NPC and\nthe human participants. We illustrate the above by presenting the Auckland City\nHospital, New Zealand as a case study, and propose a possible VR SG training\ntool to enhance earthquake preparedness in public buildings.\n"]},
{"authors": ["Ke Wang", "Rishabh Singh", "Zhendong Su"], "title": ["Dynamic Neural Program Embedding for Program Repair"], "date": ["2017-11-20T06:02:06Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.07163v3"], "summary": ["  Neural program embeddings have shown much promise recently for a variety of\nprogram analysis tasks, including program synthesis, program repair, fault\nlocalization, etc. However, most existing program embeddings are based on\nsyntactic features of programs, such as raw token sequences or abstract syntax\ntrees. Unlike images and text, a program has an unambiguous semantic meaning\nthat can be difficult to capture by only considering its syntax (i.e.\nsyntactically similar pro- grams can exhibit vastly different run-time\nbehavior), which makes syntax-based program embeddings fundamentally limited.\nThis paper proposes a novel semantic program embedding that is learned from\nprogram execution traces. Our key insight is that program states expressed as\nsequential tuples of live variable values not only captures program semantics\nmore precisely, but also offer a more natural fit for Recurrent Neural Networks\nto model. We evaluate different syntactic and semantic program embeddings on\npredicting the types of errors that students make in their submissions to an\nintroductory programming class and two exercises on the CodeHunt education\nplatform. Evaluation results show that our new semantic program embedding\nsignificantly outperforms the syntactic program embeddings based on token\nsequences and abstract syntax trees. In addition, we augment a search-based\nprogram repair system with the predictions obtained from our se- mantic\nembedding, and show that search efficiency is also significantly improved.\n"]},
{"authors": ["Ahmed Fadhil"], "title": ["Can a Chatbot Determine My Diet?: Addressing Challenges of Chatbot\n  Application for Meal Recommendation"], "date": ["2018-02-25T22:30:10Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.09100v1"], "summary": ["  Poor nutrition can lead to reduced immunity, increased susceptibility to\ndisease, impaired physical and mental development, and reduced productivity. A\nconversational agent can support people as a virtual coach, however building\nsuch systems still have its associated challenges and limitations. This paper\ndescribes the background and motivation for chatbot systems in the context of\nhealthy nutrition recommendation. We discuss current challenges associated with\nchatbot application, we tackled technical, theoretical, behavioural, and social\naspects of the challenges. We then propose a pipeline to be used as guidelines\nby developers to implement theoretically and technically robust chatbot\nsystems.\n"]},
{"authors": ["Yisroel Mirsky", "Tomer Doitshman", "Yuval Elovici", "Asaf Shabtai"], "title": ["Kitsune: An Ensemble of Autoencoders for Online Network Intrusion\n  Detection"], "date": ["2018-02-25T21:42:56Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.09089v1"], "summary": ["  Neural networks have become an increasingly popular solution for network\nintrusion detection systems (NIDS). Their capability of learning complex\npatterns and behaviors make them a suitable solution for differentiating\nbetween normal traffic and network attacks. However, a drawback of neural\nnetworks is the amount of resources needed to train them. Many network gateways\nand routers devices, which could potentially host an NIDS, simply do not have\nthe memory or processing power to train and sometimes even execute such models.\nMore importantly, the existing neural network solutions are trained in a\nsupervised manner. Meaning that an expert must label the network traffic and\nupdate the model manually from time to time.\n  In this paper, we present Kitsune: a plug and play NIDS which can learn to\ndetect attacks on the local network, without supervision, and in an efficient\nonline manner. Kitsune's core algorithm (KitNET) uses an ensemble of neural\nnetworks called autoencoders to collectively differentiate between normal and\nabnormal traffic patterns. KitNET is supported by a feature extraction\nframework which efficiently tracks the patterns of every network channel. Our\nevaluations show that Kitsune can detect various attacks with a performance\ncomparable to offline anomaly detectors, even on a Raspberry PI. This\ndemonstrates that Kitsune can be a practical and economic NIDS.\n"]},
{"authors": ["Rediet Abebe", "Jon Kleinberg", "David Parkes"], "title": ["Fair Division via Social Comparison"], "date": ["2016-11-20T20:42:07Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1611.06589v2"], "summary": ["  In the classical cake cutting problem, a resource must be divided among\nagents with different utilities so that each agent believes they have received\na fair share of the resource relative to the other agents. We introduce a\nvariant of the problem in which we model an underlying social network on the\nagents with a graph, and agents only evaluate their shares relative to their\nneighbors' in the network. This formulation captures many situations in which\nit is unrealistic to assume a global view, and also exposes interesting\nphenomena in the original problem.\n  Specifically, we say an allocation is locally envy-free if no agent envies a\nneighbor's allocation and locally proportional if each agent values her own\nallocation as much as the average value of her neighbor's allocations, with the\nformer implying the latter. While global envy-freeness implies local\nenvy-freeness, global proportionality does not imply local proportionality, or\nvice versa. A general result is that for any two distinct graphs on the same\nset of nodes and an allocation, there exists a set of valuation functions such\nthat the allocation is locally proportional on one but not the other.\n  We fully characterize the set of graphs for which an oblivious single-cutter\nprotocol-- a protocol that uses a single agent to cut the cake into pieces\n--admits a bounded protocol with $O(n^2)$ query complexity for locally\nenvy-free allocations in the Robertson-Webb model. We also consider the price\nof envy-freeness, which compares the total utility of an optimal allocation to\nthe best utility of an allocation that is envy-free. We show that a lower bound\nof $\\Omega(\\sqrt{n})$ on the price of envy-freeness for global allocations in\nfact holds for local envy-freeness in any connected undirected graph. Thus,\nsparse graphs surprisingly do not provide more flexibility with respect to the\nquality of envy-free allocations.\n"]},
{"authors": ["Uri Patish", "Shimon Ullman"], "title": ["Cakewalk Sampling"], "date": ["2018-02-25T16:15:32Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.09030v1"], "summary": ["  Combinatorial optimization is a common theme in computer science which\nunderlies a considerable variety of problems. In contrast to the continuous\nsetting, combinatorial problems require special solution strategies, and it's\nhard to come by generic schemes like gradient methods for continuous domains.\nWe follow a standard construction of a parametric sampling distribution that\ntransforms the problem to the continuous domain, allowing us to optimize the\nexpectation of a given objective using estimates of the gradient. In spite of\nthe apparent generality, such constructions are known to suffer from highly\nvariable gradient estimates, and thus require careful tuning that is done in a\nproblem specific manner. We show that a simple trick of converting the\nobjective values to their cumulative probabilities fixes the distribution of\nthe objective, allowing us to derive an online optimization algorithm that can\nbe applied in a generic fashion. As an experimental benchmark we use the task\nof finding cliques in undirected graphs, and we show that our method, even when\nblindly applied, consistently outperforms related methods. Notably, on the\nDIMACS clique benchmark, our method approaches the performance of the best\nclique finding algorithms without access to the graph structure, and only\nthrough objective function evaluations, thus providing significant evidence to\nthe generality and effectivity of our method.\n"]},
{"authors": ["Kun Hu", "Zhe Li", "Ying Liu", "Luyin Cheng", "Qi Yang", "Yan Li"], "title": ["A Framework in CRM Customer Lifecycle: Identify Downward Trend and\n  Potential Issues Detection"], "date": ["2018-02-25T09:28:52Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08974v1"], "summary": ["  Customer retention is one of the primary goals in the area of customer\nrelationship management. A mass of work exists in which machine learning models\nor business rules are established to predict churn. However, targeting users at\nan early stage when they start to show a downward trend is a better strategy.\nIn downward trend prediction, the reasons why customers show a downward trend\nis of great interest in the industry as it helps the business to understand the\npain points that customers suffer and to take early action to prevent them from\nchurning. A commonly used method is to collect feedback from customers by\neither aggressively reaching out to them or by passively hearing from them.\nHowever, it is believed that there are a large number of customers who have\nunpleasant experiences and never speak out. In the literature, there is limited\nresearch work that provides a comprehensive and scientific approach to identify\nthese \"silent suffers\". In this study, we propose a novel two-part framework:\ndeveloping the downward prediction process and establishing the methodology to\nidentify the reasons why customers are in the downward trend. In the first\nprediction part, we focus on predicting the downward trend, which is an earlier\nstage of the customer lifecycle compared to churn. In the second part, we\npropose an approach to figuring out the cause (of the downward trend) based on\na causal inference method and semi-supervised learning. The proposed approach\nis capable of identifying potential silent sufferers. We take bad shopping\nexperiences as inputs to develop the framework and validate it via a marketing\nA/B test in the real world. The test readout demonstrates the effectiveness of\nthe framework by driving 88.5% incremental lift in purchase volume.\n"]},
{"authors": ["Junkun Chen", "Xipeng Qiu", "Pengfei Liu", "Xuanjing Huang"], "title": ["Meta Multi-Task Learning for Sequence Modeling"], "date": ["2018-02-25T09:01:25Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08969v1"], "summary": ["  Semantic composition functions have been playing a pivotal role in neural\nrepresentation learning of text sequences. In spite of their success, most\nexisting models suffer from the underfitting problem: they use the same shared\ncompositional function on all the positions in the sequence, thereby lacking\nexpressive power due to incapacity to capture the richness of compositionality.\nBesides, the composition functions of different tasks are independent and\nlearned from scratch. In this paper, we propose a new sharing scheme of\ncomposition function across multiple tasks. Specifically, we use a shared\nmeta-network to capture the meta-knowledge of semantic composition and generate\nthe parameters of the task-specific semantic composition models. We conduct\nextensive experiments on two types of tasks, text classification and sequence\ntagging, which demonstrate the benefits of our approach. Besides, we show that\nthe shared meta-knowledge learned by our proposed model can be regarded as\noff-the-shelf knowledge and easily transferred to new tasks.\n"]},
{"authors": ["Ashvin Nair", "Bob McGrew", "Marcin Andrychowicz", "Wojciech Zaremba", "Pieter Abbeel"], "title": ["Overcoming Exploration in Reinforcement Learning with Demonstrations"], "date": ["2017-09-28T17:51:48Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1709.10089v2"], "summary": ["  Exploration in environments with sparse rewards has been a persistent problem\nin reinforcement learning (RL). Many tasks are natural to specify with a sparse\nreward, and manually shaping a reward function can result in suboptimal\nperformance. However, finding a non-zero reward is exponentially more difficult\nwith increasing task horizon or action dimensionality. This puts many\nreal-world tasks out of practical reach of RL methods. In this work, we use\ndemonstrations to overcome the exploration problem and successfully learn to\nperform long-horizon, multi-step robotics tasks with continuous control such as\nstacking blocks with a robot arm. Our method, which builds on top of Deep\nDeterministic Policy Gradients and Hindsight Experience Replay, provides an\norder of magnitude of speedup over RL on simulated robotics tasks. It is simple\nto implement and makes only the additional assumption that we can collect a\nsmall set of demonstrations. Furthermore, our method is able to solve tasks not\nsolvable by either RL or behavior cloning alone, and often ends up\noutperforming the demonstrator policy.\n"]},
{"authors": ["Nikhil Mishra", "Mostafa Rohaninejad", "Xi Chen", "Pieter Abbeel"], "title": ["A Simple Neural Attentive Meta-Learner"], "date": ["2017-07-11T06:21:31Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1707.03141v3"], "summary": ["  Deep neural networks excel in regimes with large amounts of data, but tend to\nstruggle when data is scarce or when they need to adapt quickly to changes in\nthe task. In response, recent work in meta-learning proposes training a\nmeta-learner on a distribution of similar tasks, in the hopes of generalization\nto novel but related tasks by learning a high-level strategy that captures the\nessence of the problem it is asked to solve. However, many recent meta-learning\napproaches are extensively hand-designed, either using architectures\nspecialized to a particular application, or hard-coding algorithmic components\nthat constrain how the meta-learner solves the task. We propose a class of\nsimple and generic meta-learner architectures that use a novel combination of\ntemporal convolutions and soft attention; the former to aggregate information\nfrom past experience and the latter to pinpoint specific pieces of information.\nIn the most extensive set of meta-learning experiments to date, we evaluate the\nresulting Simple Neural AttentIve Learner (or SNAIL) on several\nheavily-benchmarked tasks. On all tasks, in both supervised and reinforcement\nlearning, SNAIL attains state-of-the-art performance by significant margins.\n"]},
{"authors": ["Yuzhe Ma", "Robert Nowak", "Philippe Rigollet", "Xuezhou Zhang", "Xiaojin Zhu"], "title": ["Teacher Improves Learning by Selecting a Training Subset"], "date": ["2018-02-25T02:47:46Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08946v1"], "summary": ["  We call a learner super-teachable if a teacher can trim down an iid training\nset while making the learner learn even better. We provide sharp super-teaching\nguarantees on two learners: the maximum likelihood estimator for the mean of a\nGaussian, and the large margin classifier in 1D. For general learners, we\nprovide a mixed-integer nonlinear programming-based algorithm to find a super\nteaching set. Empirical experiments show that our algorithm is able to find\ngood super-teaching sets for both regression and classification problems.\n"]},
{"authors": ["Tianxiang Gao", "Chris Chu"], "title": ["DID: Distributed Incremental Block Coordinate Descent for Nonnegative\n  Matrix Factorization"], "date": ["2018-02-25T01:23:23Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08938v1"], "summary": ["  Nonnegative matrix factorization (NMF) has attracted much attention in the\nlast decade as a dimension reduction method in many applications. Due to the\nexplosion in the size of data, naturally the samples are collected and stored\ndistributively in local computational nodes. Thus, there is a growing need to\ndevelop algorithms in a distributed memory architecture. We propose a novel\ndistributed algorithm, called \\textit{distributed incremental block coordinate\ndescent} (DID), to solve the problem. By adapting the block coordinate descent\nframework, closed-form update rules are obtained in DID. Moreover, DID performs\nupdates incrementally based on the most recently updated residual matrix. As a\nresult, only one communication step per iteration is required. The correctness,\nefficiency, and scalability of the proposed algorithm are verified in a series\nof numerical experiments.\n"]},
{"authors": ["Yewen Pu", "Zachery Miranda", "Armando Solar-Lezama", "Leslie Pack Kaelbling"], "title": ["Discovering Representative Examples for Program Synthesis"], "date": ["2017-11-09T03:38:15Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.03243v2"], "summary": ["  Program synthesis is a class of regression problems where one seeks a\nsolution, in the form of a source-code program, mapping the inputs to their\ncorresponding outputs exactly. Due to its precise and combinatorial nature,\nprogram synthesis is commonly formulated as a constraint satisfaction problem,\nwhere input-output examples are encoded as constraints and solved with a\nconstraint solver. A key challenge of this formulation is scalability: while\nconstraint solvers work well with a few well-chosen examples, a large set of\nexamples can incur significant overhead in both time and memory. We describe a\nmethod to discover a subset of examples that is both small and representative:\nthe subset is constructed iteratively, using a neural network to predict the\nprobability of unchosen examples conditioned on the chosen examples in the\nsubset, and greedily adding the least probable example. We empirically evaluate\nthe representativeness of the subsets constructed by our method, and\ndemonstrate such subsets can significantly improve synthesis time and\nstability.\n"]},
{"authors": ["Cecilia S. Lee", "Ariel J. Tyring", "Yue Wu", "Sa Xiao", "Ariel S. Rokem", "Nicolaas P. Deruyter", "Qinqin Zhang", "Adnan Tufail", "Ruikang K. Wang", "Aaron Y. Lee"], "title": ["Generating retinal flow maps from structural optical coherence\n  tomography with artificial intelligence"], "date": ["2018-02-24T22:51:43Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08925v1"], "summary": ["  Despite significant advances in artificial intelligence (AI) for computer\nvision, its application in medical imaging has been limited by the burden and\nlimits of expert-generated labels. We used images from optical coherence\ntomography angiography (OCTA), a relatively new imaging modality that measures\nperfusion of the retinal vasculature, to train an AI algorithm to generate\nvasculature maps from standard structural optical coherence tomography (OCT)\nimages of the same retinae, both exceeding the ability and bypassing the need\nfor expert labeling. Deep learning was able to infer perfusion of\nmicrovasculature from structural OCT images with similar fidelity to OCTA and\nsignificantly better than expert clinicians (P < 0.00001). OCTA suffers from\nneed of specialized hardware, laborious acquisition protocols, and motion\nartifacts; whereas our model works directly from standard OCT which are\nubiquitous and quick to obtain, and allows unlocking of large volumes of\npreviously collected standard OCT data both in existing clinical trials and\nclinical practice. This finding demonstrates a novel application of AI to\nmedical imaging, whereby subtle regularities between different modalities are\nused to image the same body part and AI is used to generate detailed and\naccurate inferences of tissue function from structure imaging.\n"]},
{"authors": ["Lin Chen", "Christopher Harshaw", "Hamed Hassani", "Amin Karbasi"], "title": ["Projection-Free Online Optimization with Stochastic Gradient: From\n  Convexity to Submodularity"], "date": ["2018-02-22T17:13:36Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08183v2"], "summary": ["  Online optimization has been a successful framework for solving large-scale\nproblems under computational constraints and partial information. Current\nmethods for online convex optimization require either a projection or exact\ngradient computation at each step, both of which can be prohibitively expensive\nfor large-scale applications. At the same time, there is a growing trend of\nnon-convex optimization in machine learning community and a need for online\nmethods. Continuous submodular functions, which exhibit a natural diminishing\nreturns condition, have recently been proposed as a broad class of non-convex\nfunctions which may be efficiently optimized. Although online methods have been\nintroduced, they suffer from similar problems. In this work, we propose\nMeta-Frank-Wolfe, the first online projectionfree algorithm that uses\nstochastic gradient estimates. The algorithm relies on a careful sampling of\ngradients in each round and achieves the optimal $O(\\sqrt{T})$ adversarial\nregret bounds for convex and continuous submodular optimization. We also\npropose One-Shot Frank-Wolfe, a simpler algorithm which requires only a single\nstochastic gradient estimate in each round and achieves a $O(T^{2/3})$\nstochastic regret bound for convex and continuous submodular optimization. We\napply our methods to develop a novel \"lifting\" framework for the online\ndiscrete submodular maximization and also see that they outperform current\nstate of the art techniques on an extensive set of experiments.\n"]},
{"authors": ["J Gerard Wolff"], "title": ["Introduction to the SP theory of intelligence"], "date": ["2018-02-24T17:25:43Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.09924v1"], "summary": ["  This article provides a brief introduction to the \"Theory of Intelligence\"\nand its realisation in the \"SP Computer Model\". The overall goal of the SP\nprogramme of research, in accordance with long-established principles in\nscience, has been the simplification and integration of observations and\nconcepts across artificial intelligence, mainstream computing, mathematics, and\nhuman learning, perception, and cognition. In broad terms, the SP system is a\nbrain-like system that takes in \"New\" information through its senses and stores\nsome or all of it as \"Old\" information. A central idea in the system is the\npowerful concept of \"SP-multiple-alignment\", borrowed and adapted from\nbioinformatics. This the key to the system's versatility in aspects of\nintelligence, in the representation of diverse kinds of knowledge, and in the\nseamless integration of diverse aspects of intelligence and diverse kinds of\nknowledge, in any combination. There are many potential benefits and\napplications of the SP system. It is envisaged that the system will be\ndeveloped as the \"SP Machine\", which will initially be a software virtual\nmachine, hosted on a high-performance computer, a vehicle for further research\nand a step towards the development of an industrial-strength SP Machine.\n"]},
{"authors": ["Hector Zenil", "Liliana Badillo", "Santiago Hern\u00e1ndez-Orozco", "Francisco Hern\u00e1ndez-Quiroz"], "title": ["Coding-theorem Like Behaviour and Emergence of the Universal\n  Distribution from Resource-bounded Algorithmic Probability"], "date": ["2017-11-06T03:37:46Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.01711v10"], "summary": ["  Previously referred to as `miraculous' in the scientific literature because\nof its powerful properties and its wide application as optimal solution to the\nproblem of induction/inference, (approximations to) Algorithmic Probability\n(AP) and the associated Universal Distribution are (or should be) of the\ngreatest importance in science. Here we investigate the emergence, the rates of\nemergence and convergence, and the Coding-theorem like behaviour of AP in\nTuring-subuniversal models of computation. We investigate empirical\ndistributions of computing models in the Chomsky hierarchy. We introduce\nmeasures of algorithmic probability and algorithmic complexity based upon\nresource-bounded computation, in contrast to previously thoroughly investigated\ndistributions produced from the output distribution of Turing machines. This\napproach allows for numerical approximations to algorithmic\n(Kolmogorov-Chaitin) complexity-based estimations at each of the levels of a\ncomputational hierarchy. We demonstrate that all these estimations are\ncorrelated in rank and that they converge both in rank and values as a function\nof computational power, despite fundamental differences between computational\nmodels. In the context of natural processes that operate below the Turing\nuniversal level because of finite resources and physical degradation, the\ninvestigation of natural biases stemming from algorithmic rules may shed light\non the distribution of outcomes. We show that up to 60\\% of the\nsimplicity/complexity bias in distributions produced even by the weakest of the\ncomputational models can be accounted for by Algorithmic Probability in its\napproximation to the Universal Distribution.\n"]},
{"authors": ["Juergen Schmidhuber"], "title": ["One Big Net For Everything"], "date": ["2018-02-24T15:23:46Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08864v1"], "summary": ["  I apply recent work on \"learning to think\" (2015) and on PowerPlay (2011) to\nthe incremental training of an increasingly general problem solver, continually\nlearning to solve new tasks without forgetting previous skills. The problem\nsolver is a single recurrent neural network (or similar general purpose\ncomputer) called ONE. ONE is unusual in the sense that it is trained in various\nways, e.g., by black box optimization / reinforcement learning / artificial\nevolution as well as supervised / unsupervised learning. For example, ONE may\nlearn through neuroevolution to control a robot through environment-changing\nactions, and learn through unsupervised gradient descent to predict future\ninputs and vector-valued reward signals as suggested in 1990. User-given tasks\ncan be defined through extra goal-defining input patterns, also proposed in\n1990. Suppose ONE has already learned many skills. Now a copy of ONE can be\nre-trained to learn a new skill, e.g., through neuroevolution without a\nteacher. Here it may profit from re-using previously learned subroutines, but\nit may also forget previous skills. Then ONE is retrained in PowerPlay style\n(2011) on stored input/output traces of (a) ONE's copy executing the new skill\nand (b) previous instances of ONE whose skills are still considered worth\nmemorizing. Simultaneously, ONE is retrained on old traces (even those of\nunsuccessful trials) to become a better predictor, without additional expensive\ninteraction with the enviroment. More and more control and prediction skills\nare thus collapsed into ONE, like in the chunker-automatizer system of the\nneural history compressor (1991). This forces ONE to relate partially analogous\nskills (with shared algorithmic information) to each other, creating common\nsubroutines in form of shared subnetworks of ONE, to greatly speed up\nsubsequent learning of additional, novel but algorithmically related skills.\n"]},
{"authors": ["Stephane Le Roux", "Guillermo A. Perez"], "title": ["The Complexity of Graph-Based Reductions for Reachability in Markov\n  Decision Processes"], "date": ["2017-10-22T07:40:11Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.07903v4"], "summary": ["  We study the never-worse relation (NWR) for Markov decision processes with an\ninfinite-horizon reachability objective. A state q is never worse than a state\np if the maximal probability of reaching the target set of states from p is at\nmost the same value from q, regard- less of the probabilities labelling the\ntransitions. Extremal-probability states, end components, and essential states\nare all special cases of the equivalence relation induced by the NWR. Using the\nNWR, states in the same equivalence class can be collapsed. Then, actions\nleading to sub- optimal states can be removed. We show the natural decision\nproblem associated to computing the NWR is coNP-complete. Finally, we ex- tend\na previously known incomplete polynomial-time iterative algorithm to\nunder-approximate the NWR.\n"]},
{"authors": ["Chang-Shing Lee", "Mei-Hui Wang", "Chi-Shiang Wang", "Olivier Teytaud", "Jialin Liu", "Su-Wei Lin", "Pi-Hsia Hung"], "title": ["PSO-based Fuzzy Markup Language for Student Learning Performance\n  Evaluation and Educational Application"], "date": ["2018-02-24T09:26:46Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08822v1"], "summary": ["  This paper proposes an agent with particle swarm optimization (PSO) based on\na Fuzzy Markup Language (FML) for students learning performance evaluation and\neducational applications, and the proposed agent is according to the response\ndata from a conventional test and an item response theory. First, we apply a\nGS-based parameter estimation mechanism to estimate the items parameters\naccording to the response data, and then to compare its results with those of\nan IRT-based Bayesian parameter estimation mechanism. In addition, we propose a\nstatic-IRT test assembly mechanism to assemble a form for the conventional\ntest. The presented FML-based dynamic assessment mechanism infers the\nprobability of making a correct response to the item for a student with various\nabilities. Moreover, this paper also proposes a novel PFML learning mechanism\nfor optimizing the parameters between items and students. Finally, we adopt a\nK-fold cross validation mechanism to evaluate the performance of the proposed\nagent. Experimental results show that the novel PFML learning mechanism for the\nparameter estimation and learning optimization performs favorably. We believe\nthe proposed PFML will be a reference for education research and pedagogy and\nan important co-learning mechanism for future human-machine educational\napplications.\n"]},
{"authors": ["Diederik Aerts", "Massimiliano Sassoli de Bianchi", "Sandro Sozzo", "Tomas Veloz"], "title": ["Quantum cognition goes beyond-quantum: modeling the collective\n  participant in psychological measurements"], "date": ["2018-02-24T08:23:11Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.10448v1"], "summary": ["  In psychological measurements, two levels should be distinguished: the\n'individual level', relative to the different participants in a given cognitive\nsituation, and the 'collective level', relative to the overall statistics of\ntheir outcomes, which we propose to associate with a notion of 'collective\nparticipant'. When the distinction between these two levels is properly\nformalized, it reveals why the modeling of the collective participant generally\nrequires beyond-quantum - non-Bornian - probabilistic models, when sequential\nmeasurements at the individual level are considered, and this though a pure\nquantum description remains valid for single measurement situations.\n"]},
{"authors": ["Sahisnu Mazumder", "Nianzu Ma", "Bing Liu"], "title": ["Towards a Continuous Knowledge Learning Engine for Chatbots"], "date": ["2018-02-16T16:50:27Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06024v2"], "summary": ["  Although chatbots have been very popular in recent years, they still have\nsome serious weaknesses which limit the scope of their applications. One major\nweakness is that they cannot learn new knowledge during the conversation\nprocess, i.e., their knowledge is fixed beforehand and cannot be expanded or\nupdated during conversation. In this paper, we propose to build a general\nknowledge learning engine for chatbots to enable them to continuously and\ninteractively learn new knowledge during conversations. As time goes by, they\nbecome more and more knowledgeable and better and better at learning and\nconversation. We model the task as an open-world knowledge base completion\nproblem and propose a novel technique called lifelong interactive learning and\ninference (LiLi) to solve it. LiLi works by imitating how humans acquire\nknowledge and perform inference during an interactive conversation. Our\nexperimental results show LiLi is highly promising.\n"]},
{"authors": ["Raghuram Bharadwaj Diddigi", "Prabuchandran K. J.", "Shalabh Bhatnagar"], "title": ["Novel Sensor Scheduling Scheme for Intruder Tracking in Energy Efficient\n  Sensor Networks"], "date": ["2017-08-27T17:19:17Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1708.08113v3"], "summary": ["  We consider the problem of tracking an intruder using a network of wireless\nsensors. For tracking the intruder at each instant, the optimal number and the\nright configuration of sensors has to be powered. As powering the sensors\nconsumes energy, there is a trade off between accurately tracking the position\nof the intruder at each instant and the energy consumption of sensors. This\nproblem has been formulated in the framework of Partially Observable Markov\nDecision Process (POMDP). Even for the state-of-the-art algorithm in the\nliterature, the curse of dimensionality renders the problem intractable. In\nthis paper, we formulate the Intrusion Detection (ID) problem with a suitable\nstate-action space in the framework of POMDP and develop a Reinforcement\nLearning (RL) algorithm utilizing the Upper Confidence Tree Search (UCT) method\nto solve the ID problem. Through simulations, we show that our algorithm\nperforms and scales well with the increasing state and action spaces.\n"]},
{"authors": ["Evan Zheran Liu", "Kelvin Guu", "Panupong Pasupat", "Tianlin Shi", "Percy Liang"], "title": ["Reinforcement Learning on Web Interfaces Using Workflow-Guided\n  Exploration"], "date": ["2018-02-24T05:32:47Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08802v1"], "summary": ["  Reinforcement learning (RL) agents improve through trial-and-error, but when\nreward is sparse and the agent cannot discover successful action sequences,\nlearning stagnates. This has been a notable problem in training deep RL agents\nto perform web-based tasks, such as booking flights or replying to emails,\nwhere a single mistake can ruin the entire sequence of actions. A common remedy\nis to \"warm-start\" the agent by pre-training it to mimic expert demonstrations,\nbut this is prone to overfitting. Instead, we propose to constrain exploration\nusing demonstrations. From each demonstration, we induce high-level \"workflows\"\nwhich constrain the allowable actions at each time step to be similar to those\nin the demonstration (e.g., \"Step 1: click on a textbox; Step 2: enter some\ntext\"). Our exploration policy then learns to identify successful workflows and\nsamples actions that satisfy these workflows. Workflows prune out bad\nexploration directions and accelerate the agent's ability to discover rewards.\nWe use our approach to train a novel neural policy designed to handle the\nsemi-structured nature of websites, and evaluate on a suite of web tasks,\nincluding the recent World of Bits benchmark. We achieve new state-of-the-art\nresults, and show that workflow-guided exploration improves sample efficiency\nover behavioral cloning by more than 100x.\n"]},
{"authors": ["Sarah Tan", "Rich Caruana", "Giles Hooker", "Yin Lou"], "title": ["Auditing Black-Box Models Using Transparent Model Distillation With Side\n  Information"], "date": ["2017-10-17T08:58:59Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.06169v3"], "summary": ["  Black-box risk scoring models permeate our lives, yet are typically\nproprietary or opaque. We propose a transparent model distillation approach to\naudit such models. Model distillation was first introduced to transfer\nknowledge from a large, complex teacher model to a faster, simpler student\nmodel without significant loss in prediction accuracy. To this we add a third\ncriterion - transparency. To gain insight into black-box models, we treat them\nas teachers, training transparent student models to mimic the risk scores\nassigned by the teacher. Moreover, we use side information in the form of the\nactual outcomes the teacher scoring model was intended to predict in the first\nplace. By training a second transparent model on the outcomes, we can compare\nthe two models to each other. When comparing models trained on risk scores to\nmodels trained on outcomes, we show that it is necessary to calibrate the\nrisk-scoring model's predictions to remove distortion that may have been added\nto the black-box risk-scoring model during or after its training process. We\nalso show how to compute confidence intervals for the particular class of\ntransparent student models we use - tree-based additive models with pairwise\ninteractions (GA2Ms) - to support comparison of the two transparent models. We\ndemonstrate the methods on four public datasets: COMPAS, Lending Club,\nStop-and-Frisk, and Chicago Police.\n"]},
{"authors": ["Jiaxuan You", "Rex Ying", "Xiang Ren", "William L. Hamilton", "Jure Leskovec"], "title": ["GraphRNN: A Deep Generative Model for Graphs"], "date": ["2018-02-24T00:39:09Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08773v1"], "summary": ["  Modeling and generating graphs is fundamental for studying networks in\nbiology, engineering, and social sciences. However, modeling complex\ndistributions over graphs and then efficiently sampling from these\ndistributions is challenging due to the non-unique, high-dimensional nature of\ngraphs and the complex, non-local dependencies that exist between edges in a\ngiven graph. Here we propose GraphRNN, a deep autoregressive model that\naddresses the above challenges and approximates any distribution of graphs with\nminimal assumptions about their structure. GraphRNN learns to generate graphs\nby training on a representative set of graphs and decomposes the graph\ngeneration process into a sequence of node and edge formations, conditioned on\nthe graph structure generated so far.\n  In order to quantitatively evaluate the performance of GraphRNN, we introduce\na benchmark suite of datasets, baselines and novel evaluation metrics based on\nMaximum Mean Discrepancy, which measure distances between sets of graphs. Our\nexperiments show that GraphRNN significantly outperforms all baselines,\nlearning to generate diverse graphs that match the structural characteristics\nof a target set, while also scaling to graphs 50 times larger than previous\ndeep models.\n"]},
{"authors": ["Maxime Lenormand"], "title": ["Generating OWA weights using truncated distributions"], "date": ["2017-09-13T13:43:43Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1709.04328v2"], "summary": ["  Ordered weighted averaging (OWA) operators have been widely used in decision\nmaking these past few years. An important issue facing the OWA operators' users\nis the determination of the OWA weights. This paper introduces an OWA\ndetermination method based on truncated distributions that enables intuitive\ngeneration of OWA weights according to a certain level of risk and trade-off.\nThese two dimensions are represented by the two first moments of the truncated\ndistribution. We illustrate our approach with the well-know normal distribution\nand the definition of a continuous parabolic decision-strategy space. We\nfinally study the impact of the number of criteria on the results.\n"]},
{"authors": ["Zhengli Zhao", "Dheeru Dua", "Sameer Singh"], "title": ["Generating Natural Adversarial Examples"], "date": ["2017-10-31T06:22:26Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.11342v2"], "summary": ["  Due to their complex nature, it is hard to characterize the ways in which\nmachine learning models can misbehave or be exploited when deployed. Recent\nwork on adversarial examples, i.e. inputs with minor perturbations that result\nin substantially different model predictions, is helpful in evaluating the\nrobustness of these models by exposing the adversarial scenarios where they\nfail. However, these malicious perturbations are often unnatural, not\nsemantically meaningful, and not applicable to complicated domains such as\nlanguage. In this paper, we propose a framework to generate natural and legible\nadversarial examples that lie on the data manifold, by searching in semantic\nspace of dense and continuous data representation, utilizing the recent\nadvances in generative adversarial networks. We present generated adversaries\nto demonstrate the potential of the proposed approach for black-box classifiers\nfor a wide range of applications such as image classification, textual\nentailment, and machine translation. We include experiments to show that the\ngenerated adversaries are natural, legible to humans, and useful in evaluating\nand analyzing black-box classifiers.\n"]},
{"authors": ["Roman Novak", "Yasaman Bahri", "Daniel A. Abolafia", "Jeffrey Pennington", "Jascha Sohl-Dickstein"], "title": ["Sensitivity and Generalization in Neural Networks: an Empirical Study"], "date": ["2018-02-23T23:11:07Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08760v1"], "summary": ["  In practice it is often found that large over-parameterized neural networks\ngeneralize better than their smaller counterparts, an observation that appears\nto conflict with classical notions of function complexity, which typically\nfavor smaller models. In this work, we investigate this tension between\ncomplexity and generalization through an extensive empirical exploration of two\nnatural metrics of complexity related to sensitivity to input perturbations.\nOur experiments survey thousands of models with various fully-connected\narchitectures, optimizers, and other hyper-parameters, as well as four\ndifferent image classification datasets.\n  We find that trained neural networks are more robust to input perturbations\nin the vicinity of the training data manifold, as measured by the norm of the\ninput-output Jacobian of the network, and that it correlates well with\ngeneralization. We further establish that factors associated with poor\ngeneralization $-$ such as full-batch training or using random labels $-$\ncorrespond to lower robustness, while factors associated with good\ngeneralization $-$ such as data augmentation and ReLU non-linearities $-$ give\nrise to more robust functions. Finally, we demonstrate how the input-output\nJacobian norm can be predictive of generalization at the level of individual\ntest points.\n"]},
{"authors": ["Peter Sch\u00fcller", "Mishal Benz"], "title": ["Best-Effort Inductive Logic Programming via Fine-grained Cost-based\n  Hypothesis Generation"], "date": ["2017-07-10T07:50:04Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1707.02729v2"], "summary": ["  We describe the Inspire system which participated in the first competition on\nInductive Logic Programming (ILP). Inspire is based on Answer Set Programming\n(ASP). The distinguishing feature of Inspire is an ASP encoding for hypothesis\nspace generation: given a set of facts representing the mode bias, and a set of\ncost configuration parameters, each answer set of this encoding represents a\nsingle rule that is considered for finding a hypothesis that entails the given\nexamples. Compared with state-of-the-art methods that use the length of the\nrule body as a metric for rule complexity, our approach permits a much more\nfine-grained specification of the shape of hypothesis candidate rules. The\nInspire system iteratively increases the rule cost limit and thereby increases\nthe search space until it finds a suitable hypothesis. The system searches for\na hypothesis that entails a single example at a time, utilizing an ASP encoding\nderived from the encoding used in XHAIL. We perform experiments with the\ndevelopment and test set of the ILP competition. For comparison we also adapted\nthe ILASP system to process competition instances. Experimental results show\nthat the cost parameters for the hypothesis search space are an important\nfactor for finding hypotheses to competition instances within tight resource\nbounds.\n"]},
{"authors": ["Marlos C. Machado", "Clemens Rosenbaum", "Xiaoxiao Guo", "Miao Liu", "Gerald Tesauro", "Murray Campbell"], "title": ["Eigenoption Discovery through the Deep Successor Representation"], "date": ["2017-10-30T17:36:19Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.11089v3"], "summary": ["  Options in reinforcement learning allow agents to hierarchically decompose a\ntask into subtasks, having the potential to speed up learning and planning.\nHowever, autonomously learning effective sets of options is still a major\nchallenge in the field. In this paper we focus on the recently introduced idea\nof using representation learning methods to guide the option discovery process.\nSpecifically, we look at eigenoptions, options obtained from representations\nthat encode diffusive information flow in the environment. We extend the\nexisting algorithms for eigenoption discovery to settings with stochastic\ntransitions and in which handcrafted features are not available. We propose an\nalgorithm that discovers eigenoptions while learning non-linear state\nrepresentations from raw pixels. It exploits recent successes in the deep\nreinforcement learning literature and the equivalence between proto-value\nfunctions and the successor representation. We use traditional tabular domains\nto provide intuition about our approach and Atari 2600 games to demonstrate its\npotential.\n"]},
{"authors": ["Rajat Sen", "Karthikeyan Shanmugam", "Sanjay Shakkottai"], "title": ["Contextual Bandits with Stochastic Experts"], "date": ["2018-02-23T21:03:49Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08737v1"], "summary": ["  We consider the problem of contextual bandits with stochastic experts, which\nis a variation of the traditional stochastic contextual bandit with experts\nproblem. In our problem setting, we assume access to a class of stochastic\nexperts, where each expert is a conditional distribution over the arms given a\ncontext. We propose upper-confidence bound (UCB) algorithms for this problem,\nwhich employ two different importance sampling based estimators for the mean\nreward for each expert. Both these estimators leverage information leakage\namong the experts, thus using samples collected under all the experts to\nestimate the mean reward of any given expert. This leads to instance dependent\nregret bounds of $\\mathcal{O}\\left(\\lambda(\\pmb{\\mu})\\mathcal{M}\\log T/\\Delta\n\\right)$, where $\\lambda(\\pmb{\\mu})$ is a term that depends on the mean rewards\nof the experts, $\\Delta$ is the smallest gap between the mean reward of the\noptimal expert and the rest, and $\\mathcal{M}$ quantifies the information\nleakage among the experts. We show that under some assumptions\n$\\lambda(\\pmb{\\mu})$ is typically $\\mathcal{O}(\\log N)$. We implement our\nalgorithm with stochastic experts generated from cost-sensitive classification\noracles and show superior empirical performance on real-world datasets, when\ncompared to other state of the art contextual bandit algorithms.\n"]},
{"authors": ["Ronald Kemker", "Christopher Kanan"], "title": ["FearNet: Brain-Inspired Model for Incremental Learning"], "date": ["2017-11-28T21:26:15Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.10563v2"], "summary": ["  Incremental class learning involves sequentially learning classes in bursts\nof examples from the same class. This violates the assumptions that underlie\nmethods for training standard deep neural networks, and will cause them to\nsuffer from catastrophic forgetting. Arguably, the best method for incremental\nclass learning is iCaRL, but it requires storing training examples for each\nclass, making it challenging to scale. Here, we propose FearNet for incremental\nclass learning. FearNet is a generative model that does not store previous\nexamples, making it memory efficient. FearNet uses a brain-inspired dual-memory\nsystem in which new memories are consolidated from a network for recent\nmemories inspired by the mammalian hippocampal complex to a network for\nlong-term storage inspired by medial prefrontal cortex. Memory consolidation is\ninspired by mechanisms that occur during sleep. FearNet also uses a module\ninspired by the basolateral amygdala for determining which memory system to use\nfor recall. FearNet achieves state-of-the-art performance at incremental class\nlearning on image (CIFAR-100, CUB-200) and audio classification (AudioSet)\nbenchmarks.\n"]},
{"authors": ["Ramesh Johari", "Sven Schmit"], "title": ["Learning with Abandonment"], "date": ["2018-02-23T19:59:39Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08718v1"], "summary": ["  Consider a platform that wants to learn a personalized policy for each user,\nbut the platform faces the risk of a user abandoning the platform if she is\ndissatisfied with the actions of the platform. For example, a platform is\ninterested in personalizing the number of newsletters it sends, but faces the\nrisk that the user unsubscribes forever. We propose a general thresholded\nlearning model for scenarios like this, and discuss the structure of optimal\npolicies. We describe salient features of optimal personalization algorithms\nand how feedback the platform receives impacts the results. Furthermore, we\ninvestigate how the platform can efficiently learn the heterogeneity across\nusers by interacting with a population and provide performance guarantees.\n"]},
{"authors": ["Caelan Reed Garrett", "Tom\u00e1s Lozano-P\u00e9rez", "Leslie Pack Kaelbling"], "title": ["STRIPStream: Integrating Symbolic Planners and Blackbox Samplers"], "date": ["2018-02-23T19:26:46Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08705v1"], "summary": ["  Many planning applications involve complex relationships defined on\nhigh-dimensional, continuous variables. For example, robotic manipulation\nrequires planning with kinematic, collision, and motion constraints involving\nrobot configurations, object transforms, and robot trajectories. These\nconstraints typically require specialized procedures to sample satisfying\nvalues. We extend the STRIPS planning language to support a generic,\ndeclarative specification for these procedures while treating their\nimplementation as blackboxes. We provide several domain-independent algorithms\nthat reduce STRIPStream problems to a sequence of finite-domain STRIPS planning\nproblems. Additionally, we describe cost-sensitive planning within this\nframework. Finally, we evaluate our algorithms on three robotic task and motion\nplanning domains.\n"]},
{"authors": ["Onur Atan", "William R. Zame", "M van der Schaar"], "title": ["Learning Optimal Policies from Observational Data"], "date": ["2018-02-23T18:56:32Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08679v1"], "summary": ["  Choosing optimal (or at least better) policies is an important problem in\ndomains from medicine to education to finance and many others. One approach to\nthis problem is through controlled experiments/trials - but controlled\nexperiments are expensive. Hence it is important to choose the best policies on\nthe basis of observational data. This presents two difficult challenges: (i)\nmissing counterfactuals, and (ii) selection bias. This paper presents\ntheoretical bounds on estimation errors of counterfactuals from observational\ndata by making connections to domain adaptation theory. It also presents a\nprincipled way of choosing optimal policies using domain adversarial neural\nnetworks. We illustrate the effectiveness of domain adversarial training\ntogether with various features of our algorithm on a semi-synthetic breast\ncancer dataset and a supervised UCI dataset (Statlog).\n"]},
{"authors": ["L. Elisa Celis", "Sayash Kapoor", "Farnood Salehi", "Nisheeth K. Vishnoi"], "title": ["An Algorithmic Framework to Control Bias in Bandit-based Personalization"], "date": ["2018-02-23T18:44:01Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08674v1"], "summary": ["  Personalization is pervasive in the online space as it leads to higher\nefficiency and revenue by allowing the most relevant content to be served to\neach user. However, recent studies suggest that personalization methods can\npropagate societal or systemic biases and polarize opinions; this has led to\ncalls for regulatory mechanisms and algorithms to combat bias and inequality.\nAlgorithmically, bandit optimization has enjoyed great success in learning user\npreferences and personalizing content or feeds accordingly. We propose an\nalgorithmic framework that allows for the possibility to control bias or\ndiscrimination in such bandit-based personalization. Our model allows for the\nspecification of general fairness constraints on the sensitive types of the\ncontent that can be displayed to a user. The challenge, however, is to come up\nwith a scalable and low regret algorithm for the constrained optimization\nproblem that arises. Our main technical contribution is a provably fast and\nlow-regret algorithm for the fairness-constrained bandit optimization problem.\nOur proofs crucially leverage the special structure of our problem. Experiments\non synthetic and real-world data sets show that our algorithmic framework can\ncontrol bias with only a minor loss to revenue.\n"]},
{"authors": ["Maruan Al-Shedivat", "Trapit Bansal", "Yuri Burda", "Ilya Sutskever", "Igor Mordatch", "Pieter Abbeel"], "title": ["Continuous Adaptation via Meta-Learning in Nonstationary and Competitive\n  Environments"], "date": ["2017-10-10T15:00:37Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.03641v2"], "summary": ["  Ability to continuously learn and adapt from limited experience in\nnonstationary environments is an important milestone on the path towards\ngeneral intelligence. In this paper, we cast the problem of continuous\nadaptation into the learning-to-learn framework. We develop a simple\ngradient-based meta-learning algorithm suitable for adaptation in dynamically\nchanging and adversarial scenarios. Additionally, we design a new multi-agent\ncompetitive environment, RoboSumo, and define iterated adaptation games for\ntesting various aspects of continuous adaptation strategies. We demonstrate\nthat meta-learning enables significantly more efficient adaptation than\nreactive baselines in the few-shot regime. Our experiments with a population of\nagents that learn and compete suggest that meta-learners are the fittest.\n"]},
{"authors": ["M. Andrecut"], "title": ["High-Dimensional Vector Semantics"], "date": ["2018-02-23T16:50:16Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.09914v1"], "summary": ["  In this paper we explore the \"vector semantics\" problem from the perspective\nof \"almost orthogonal\" property of high-dimensional random vectors. We show\nthat this intriguing property can be used to \"memorize\" random vectors by\nsimply adding them, and we provide an efficient probabilistic solution to the\nset membership problem. Also, we discuss several applications to word context\nvector embeddings, document sentences similarity, and spam filtering.\n"]},
{"authors": ["Baoxu Shi", "Tim Weninger"], "title": ["Visualizing the Flow of Discourse with a Concept Ontology"], "date": ["2018-02-23T15:56:07Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08614v1"], "summary": ["  Understanding and visualizing human discourse has long being a challenging\ntask. Although recent work on argument mining have shown success in classifying\nthe role of various sentences, the task of recognizing concepts and\nunderstanding the ways in which they are discussed remains challenging. Given\nan email thread or a transcript of a group discussion, our task is to extract\nthe relevant concepts and understand how they are referenced and re-referenced\nthroughout the discussion. In the present work, we present a preliminary\napproach for extracting and visualizing group discourse by adapting Wikipedia's\ncategory hierarchy to be an external concept ontology. From a user study, we\nfound that our method achieved better results than 4 strong alternative\napproaches, and we illustrate our visualization method based on the extracted\ndiscourse flows.\n"]},
{"authors": ["Jiaxin Shi", "Shengyang Sun", "Jun Zhu"], "title": ["Kernel Implicit Variational Inference"], "date": ["2017-05-29T11:11:35Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1705.10119v3"], "summary": ["  Recent progress in variational inference has paid much attention to the\nflexibility of variational posteriors. One promising direction is to use\nimplicit distributions, i.e., distributions without tractable densities as the\nvariational posterior. However, existing methods on implicit posteriors still\nface challenges of noisy estimation and computational infeasibility when\napplied to models with high-dimensional latent variables. In this paper, we\npresent a new approach named Kernel Implicit Variational Inference that\naddresses these challenges. As far as we know, for the first time implicit\nvariational inference is successfully applied to Bayesian neural networks,\nwhich shows promising results on both regression and classification tasks.\n"]},
{"authors": ["Douglas Summers Stay"], "title": ["Semantic Vector Spaces for Broadening Consideration of Consequences"], "date": ["2018-02-23T14:41:33Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08554v1"], "summary": ["  Reasoning systems with too simple a model of the world and human intent are\nunable to consider potential negative side effects of their actions and modify\ntheir plans to avoid them (e.g., avoiding potential errors). However,\nhand-encoding the enormous and subtle body of facts that constitutes common\nsense into a knowledge base has proved too difficult despite decades of work.\nDistributed semantic vector spaces learned from large text corpora, on the\nother hand, can learn representations that capture shades of meaning of\ncommon-sense concepts and perform analogical and associational reasoning in\nways that knowledge bases are too rigid to perform, by encoding concepts and\nthe relations between them as geometric structures. These have, however, the\ndisadvantage of being unreliable, poorly understood, and biased in their view\nof the world by the source material. This chapter will discuss how these\napproaches may be combined in a way that combines the best properties of each\nfor understanding the world and human intentions in a richer way.\n"]},
{"authors": ["Richard Evans", "David Saxton", "David Amos", "Pushmeet Kohli", "Edward Grefenstette"], "title": ["Can Neural Networks Understand Logical Entailment?"], "date": ["2018-02-23T14:04:30Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08535v1"], "summary": ["  We introduce a new dataset of logical entailments for the purpose of\nmeasuring models' ability to capture and exploit the structure of logical\nexpressions against an entailment prediction task. We use this task to compare\na series of architectures which are ubiquitous in the sequence-processing\nliterature, in addition to a new model class---PossibleWorldNets---which\ncomputes entailment as a \"convolution over possible worlds\". Results show that\nconvolutional networks present the wrong inductive bias for this class of\nproblems relative to LSTM RNNs, tree-structured neural networks outperform LSTM\nRNNs due to their enhanced ability to exploit the syntax of logic, and\nPossibleWorldNets outperform all benchmarks.\n"]},
{"authors": ["Yan Zheng", "Jianye Hao", "Zongzhang Zhang"], "title": ["Weighted Double Deep Multiagent Reinforcement Learning in Stochastic\n  Cooperative Environments"], "date": ["2018-02-23T14:03:22Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08534v1"], "summary": ["  Despite single agent deep reinforcement learning has achieved significant\nsuccess due to the experience replay mechanism, Concerns should be reconsidered\nin multiagent environments. This work focus on the stochastic cooperative\nenvironment. We apply a specific adaptation to one recently proposed weighted\ndouble estimator and propose a multiagent deep reinforcement learning\nframework, named Weighted Double Deep Q-Network (WDDQN). To achieve efficient\ncooperation, \\textit{Lenient Reward Network} and \\textit{Mixture Replay\nStrategy} are introduced. By utilizing the deep neural network and the weighted\ndouble estimator, WDDQN can not only reduce the bias effectively but also be\nextended to many deep RL scenarios with only raw pixel images as input.\nEmpirically, the WDDQN outperforms the existing DRL algorithm (double DQN) and\nmultiagent RL algorithm (lenient Q-learning) in terms of performance and\nconvergence within stochastic cooperative environments.\n"]},
{"authors": ["Wlodzislaw Duch"], "title": ["Coloring black boxes: visualization of neural network decisions"], "date": ["2018-02-23T10:59:40Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08478v1"], "summary": ["  Neural networks are commonly regarded as black boxes performing\nincomprehensible functions. For classification problems networks provide maps\nfrom high dimensional feature space to K-dimensional image space. Images of\ntraining vector are projected on polygon vertices, providing visualization of\nnetwork function. Such visualization may show the dynamics of learning, allow\nfor comparison of different networks, display training vectors around which\npotential problems may arise, show differences due to regularization and\noptimization procedures, investigate stability of network classification under\nperturbation of original vectors, and place new data sample in relation to\ntraining data, allowing for estimation of confidence in classification of a\ngiven sample. An illustrative example for the three-class Wine data and\nfive-class Satimage data is described. The visualization method proposed here\nis applicable to any black box system that provides continuous outputs.\n"]},
{"authors": ["Nathanael Perraudin", "Nicki Holighaus", "Piotr Majdak", "Peter Balazs"], "title": ["Inpainting of long audio segments with similarity graphs"], "date": ["2016-07-22T13:12:33Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1607.06667v4"], "summary": ["  We present a novel method for the compensation of long duration data loss in\naudio signals, in particular music. The concealment of such signal defects is\nbased on a graph that encodes signal structure in terms of time-persistent\nspectral similarity. A suitable candidate segment for the substitution of the\nlost content is proposed by an intuitive optimization scheme and smoothly\ninserted into the gap, i.e. the lost or distorted signal region. Extensive\nlistening tests show that the proposed algorithm provides highly promising\nresults when applied to a variety of real-world music signals.\n"]},
{"authors": ["Marcin Andrychowicz", "Filip Wolski", "Alex Ray", "Jonas Schneider", "Rachel Fong", "Peter Welinder", "Bob McGrew", "Josh Tobin", "Pieter Abbeel", "Wojciech Zaremba"], "title": ["Hindsight Experience Replay"], "date": ["2017-07-05T17:55:53Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1707.01495v3"], "summary": ["  Dealing with sparse rewards is one of the biggest challenges in Reinforcement\nLearning (RL). We present a novel technique called Hindsight Experience Replay\nwhich allows sample-efficient learning from rewards which are sparse and binary\nand therefore avoid the need for complicated reward engineering. It can be\ncombined with an arbitrary off-policy RL algorithm and may be seen as a form of\nimplicit curriculum.\n  We demonstrate our approach on the task of manipulating objects with a\nrobotic arm. In particular, we run experiments on three different tasks:\npushing, sliding, and pick-and-place, in each case using only binary rewards\nindicating whether or not the task is completed. Our ablation studies show that\nHindsight Experience Replay is a crucial ingredient which makes training\npossible in these challenging environments. We show that our policies trained\non a physics simulation can be deployed on a physical robot and successfully\ncomplete the task.\n"]},
{"authors": ["Stefano Bistarelli", "Alessandra Tappini", "Carlo Taticchi"], "title": ["A Matrix Approach for Weighted Argumentation Frameworks: a Preliminary\n  Report"], "date": ["2018-02-23T09:00:09Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08445v1"], "summary": ["  The assignment of weights to attacks in a classical Argumentation Framework\nallows to compute semantics by taking into account the different importance of\neach argument. We represent a Weighted Argumentation Framework by a non-binary\nmatrix, and we characterize the basic extensions (such as w-admissible, w-\nstable, w-complete) by analysing sub-blocks of this matrix. Also, we show how\nto reduce the matrix into another one of smaller size, that is equivalent to\nthe original one for the determination of extensions. Furthermore, we provide\ntwo algorithms that allow to build incrementally w-grounded and w-preferred\nextensions starting from a w-admissible extension.\n"]},
{"authors": ["Tu-Hoa Pham", "Giovanni De Magistris", "Ryuki Tachibana"], "title": ["OptLayer - Practical Constrained Optimization for Deep Reinforcement\n  Learning in the Real World"], "date": ["2017-09-22T09:10:10Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1709.07643v2"], "summary": ["  While deep reinforcement learning techniques have recently produced\nconsiderable achievements on many decision-making problems, their use in\nrobotics has largely been limited to simulated worlds or restricted motions,\nsince unconstrained trial-and-error interactions in the real world can have\nundesirable consequences for the robot or its environment. To overcome such\nlimitations, we propose a novel reinforcement learning architecture, OptLayer,\nthat takes as inputs possibly unsafe actions predicted by a neural network and\noutputs the closest actions that satisfy chosen constraints. While learning\ncontrol policies often requires carefully crafted rewards and penalties while\nexploring the range of possible actions, OptLayer ensures that only safe\nactions are actually executed and unsafe predictions are penalized during\ntraining. We demonstrate the effectiveness of our approach on robot reaching\ntasks, both simulated and in the real world.\n"]},
{"authors": ["Wanling Gao", "Jianfeng Zhan", "Lei Wang", "Chunjie Luo", "Daoyi Zheng", "Rui Ren", "Chen Zheng", "Gang Lu", "Jingwei Li", "Zheng Cao", "Shujie Zhang", "Haoning Tang"], "title": ["BigDataBench: A Dwarf-based Big Data and AI Benchmark Suite"], "date": ["2018-02-23T01:28:44Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08254v1"], "summary": ["  As architecture, system, data management, and machine learning communities\npay greater attention to innovative big data and data-driven artificial\nintelligence (in short, AI) algorithms, architecture, and systems, the pressure\nof benchmarking rises. However, complexity, diversity, frequently changed\nworkloads, and rapid evolution of big data, especially AI systems raise great\nchallenges in benchmarking. First, for the sake of conciseness, benchmarking\nscalability, portability cost, reproducibility, and better interpretation of\nperformance data, we need understand what are the abstractions of\nfrequently-appearing units of computation, which we call dwarfs, among big data\nand AI workloads. Second, for the sake of fairness, the benchmarks must include\ndiversity of data and workloads. Third, for co-design of software and hardware,\nthe benchmarks should be consistent across different communities. Other than\ncreating a new benchmark or proxy for every possible workload, we propose using\ndwarf-based benchmarks--the combination of eight dwarfs--to represent diversity\nof big data and AI workloads. The current version--BigDataBench 4.0 provides 13\nrepresentative real-world data sets and 47 big data and AI benchmarks,\nincluding seven workload types: online service, offline analytics, graph\nanalytics, AI, data warehouse, NoSQL, and streaming. BigDataBench 4.0 is\npublicly available from http://prof.ict.ac.cn/BigDataBench. Also, for the first\ntime, we comprehensively characterize the benchmarks of seven workload types in\nBigDataBench 4.0 in addition to traditional benchmarks like SPECCPU, PARSEC and\nHPCC in a hierarchical manner and drill down on five levels, using the Top-Down\nanalysis from an architecture perspective.\n"]},
{"authors": ["Phi Vu Tran"], "title": ["Learning to Make Predictions on Graphs with Autoencoders"], "date": ["2018-02-23T00:02:59Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08352v1"], "summary": ["  We examine two fundamental tasks associated with graph representation\nlearning: link prediction and semi-supervised node classification. We present a\ndensely connected autoencoder architecture capable of learning a joint\nrepresentation of both local graph structure and available external node\nfeatures for the multi-task learning of link prediction and node\nclassification. To the best of our knowledge, this is the first architecture\nthat can be efficiently trained end-to-end in a single learning stage to\nsimultaneously perform link prediction and node classification. We provide\ncomprehensive empirical evaluation of our models on a range of challenging\nbenchmark graph-structured datasets, and demonstrate significant improvement in\naccuracy over related methods for graph representation learning. Code\nimplementation is available at\nhttps://github.com/vuptran/graph-representation-learning\n"]},
{"authors": ["Kenji Kawaguchi", "Leslie Pack Kaelbling", "Yoshua Bengio"], "title": ["Generalization in Deep Learning"], "date": ["2017-10-16T02:21:24Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.05468v3"], "summary": ["  With a direct analysis of neural networks, this paper presents a\nmathematically tight generalization theory to partially address an open problem\nregarding the generalization of deep learning. Unlike previous bound-based\ntheory, our main theory is quantitatively as tight as possible for every\ndataset individually, while producing qualitative insights competitively. Our\nresults give insight into why and how deep learning can generalize well,\ndespite its large capacity, complexity, possible algorithmic instability,\nnonrobustness, and sharp minima, answering to an open question in the\nliterature. We also discuss limitations of our results and propose additional\nopen problems.\n"]},
{"authors": ["Stefano Bistarelli", "Francesco Santini", "Carlo Taticchi"], "title": ["On Looking for Local Expansion Invariants in Argumentation Semantics"], "date": ["2018-02-22T22:18:53Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08328v1"], "summary": ["  We study invariant local expansion operators for conflict-free and admissible\nsets in Abstract Argumentation Frameworks (AFs). Such operators are directly\napplied on AFs, and are invariant with respect to a chosen \"semantics\" (that is\nw.r.t. each of the conflict free/admissible set of arguments). Accordingly, we\nderive a definition of robustness for AFs in terms of the number of times such\noperators can be applied without producing any change in the chosen semantics.\n"]},
{"authors": ["Chao Zhang", "Philip Woodland"], "title": ["High Order Recurrent Neural Networks for Acoustic Modelling"], "date": ["2018-02-22T22:01:05Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08314v1"], "summary": ["  Vanishing long-term gradients are a major issue in training standard\nrecurrent neural networks (RNNs), which can be alleviated by long short-term\nmemory (LSTM) models with memory cells. However, the extra parameters\nassociated with the memory cells mean an LSTM layer has four times as many\nparameters as an RNN with the same hidden vector size. This paper addresses the\nvanishing gradient problem using a high order RNN (HORNN) which has additional\nconnections from multiple previous time steps. Speech recognition experiments\nusing British English multi-genre broadcast (MGB3) data showed that the\nproposed HORNN architectures for rectified linear unit and sigmoid activation\nfunctions reduced word error rates (WER) by 4.2% and 6.3% over the\ncorresponding RNNs, and gave similar WERs to a (projected) LSTM while using\nonly 20%--50% of the recurrent layer parameters and computation.\n"]},
{"authors": ["Mario Srouji", "Jian Zhang", "Ruslan Salakhutdinov"], "title": ["Structured Control Nets for Deep Reinforcement Learning"], "date": ["2018-02-22T21:31:34Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08311v1"], "summary": ["  In recent years, Deep Reinforcement Learning has made impressive advances in\nsolving several important benchmark problems for sequential decision making.\nMany control applications use a generic multilayer perceptron (MLP) for\nnon-vision parts of the policy network. In this work, we propose a new neural\nnetwork architecture for the policy network representation that is simple yet\neffective. The proposed Structured Control Net (SCN) splits the generic MLP\ninto two separate sub-modules: a nonlinear control module and a linear control\nmodule. Intuitively, the nonlinear control is for forward-looking and global\ncontrol, while the linear control stabilizes the local dynamics around the\nresidual of global control. We hypothesize that this will bring together the\nbenefits of both linear and nonlinear policies: improve training sample\nefficiency, final episodic reward, and generalization of learned policy, while\nrequiring a smaller network and being generally applicable to different\ntraining methods. We validated our hypothesis with competitive results on\nsimulations from OpenAI MuJoCo, Roboschool, Atari, and a custom 2D urban\ndriving environment, with various ablation and generalization tests, trained\nwith multiple black-box and policy gradient training methods. The proposed\narchitecture has the potential to improve upon broader control tasks by\nincorporating problem specific priors into the architecture. As a case study,\nwe demonstrate much improved performance for locomotion tasks by emulating the\nbiological central pattern generators (CPGs) as the nonlinear part of the\narchitecture.\n"]},
{"authors": ["Ofir Nachum", "Mohammad Norouzi", "Kelvin Xu", "Dale Schuurmans"], "title": ["Trust-PCL: An Off-Policy Trust Region Method for Continuous Control"], "date": ["2017-07-06T17:50:19Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1707.01891v3"], "summary": ["  Trust region methods, such as TRPO, are often used to stabilize policy\noptimization algorithms in reinforcement learning (RL). While current trust\nregion strategies are effective for continuous control, they typically require\na prohibitively large amount of on-policy interaction with the environment. To\naddress this problem, we propose an off-policy trust region method, Trust-PCL.\nThe algorithm is the result of observing that the optimal policy and state\nvalues of a maximum reward objective with a relative-entropy regularizer\nsatisfy a set of multi-step pathwise consistencies along any path. Thus,\nTrust-PCL is able to maintain optimization stability while exploiting\noff-policy data to improve sample efficiency. When evaluated on a number of\ncontinuous control tasks, Trust-PCL improves the solution quality and sample\nefficiency of TRPO.\n"]},
{"authors": ["Adam D. Cobb", "Richard Everett", "Andrew Markham", "Stephen J. Roberts"], "title": ["Identifying Sources and Sinks in the Presence of Multiple Agents with\n  Gaussian Process Vector Calculus"], "date": ["2018-02-22T21:14:46Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.10446v1"], "summary": ["  In systems of multiple agents, identifying the cause of observed agent\ndynamics is challenging. Often, these agents operate in diverse, non-stationary\nenvironments, where models rely on hand-crafted environment-specific features\nto infer influential regions in the system's surroundings. To overcome the\nlimitations of these inflexible models, we present GP-LAPLACE, a technique for\nlocating sources and sinks from trajectories in time-varying fields. Using\nGaussian processes, we jointly infer a spatio-temporal vector field, as well as\ncanonical vector calculus operations on that field. Notably, we do this from\nonly agent trajectories without requiring knowledge of the environment, and\nalso obtain a metric for denoting the significance of inferred causal features\nin the environment by exploiting our probabilistic method. To evaluate our\napproach, we apply it to both synthetic and real-world GPS data, demonstrating\nthe applicability of our technique in the presence of multiple agents, as well\nas its superiority over existing methods.\n"]},
{"authors": ["Chris Donahue", "Zachary C. Lipton", "Akshay Balsubramani", "Julian McAuley"], "title": ["Semantically Decomposing the Latent Spaces of Generative Adversarial\n  Networks"], "date": ["2017-05-22T18:00:02Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1705.07904v3"], "summary": ["  We propose a new algorithm for training generative adversarial networks that\njointly learns latent codes for both identities (e.g. individual humans) and\nobservations (e.g. specific photographs). By fixing the identity portion of the\nlatent codes, we can generate diverse images of the same subject, and by fixing\nthe observation portion, we can traverse the manifold of subjects while\nmaintaining contingent aspects such as lighting and pose. Our algorithm\nfeatures a pairwise training scheme in which each sample from the generator\nconsists of two images with a common identity code. Corresponding samples from\nthe real dataset consist of two distinct photographs of the same subject. In\norder to fool the discriminator, the generator must produce pairs that are\nphotorealistic, distinct, and appear to depict the same individual. We augment\nboth the DCGAN and BEGAN approaches with Siamese discriminators to facilitate\npairwise training. Experiments with human judges and an off-the-shelf face\nverification system demonstrate our algorithm's ability to generate convincing,\nidentity-matched photographs.\n"]},
{"authors": ["Tomasz Tajmajer"], "title": ["Modular Multi-Objective Deep Reinforcement Learning with Decision Values"], "date": ["2017-04-21T18:42:02Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1704.06676v2"], "summary": ["  In this work we present a method for using Deep Q-Networks (DQNs) in\nmulti-objective environments. Deep Q-Networks provide remarkable performance in\nsingle objective problems learning from high-level visual state\nrepresentations. However, in many scenarios (e.g in robotics, games), the agent\nneeds to pursue multiple objectives simultaneously. We propose an architecture\nin which separate DQNs are used to control the agent's behaviour with respect\nto particular objectives. In this architecture we introduce decision values to\nimprove the scalarization of multiple DQNs into a single action. Our\narchitecture enables the decomposition of the agent's behaviour into\ncontrollable and replaceable sub-behaviours learned by distinct modules.\nMoreover, it allows to change the priorities of particular objectives\npost-learning, while preserving the overall performance of the agent. To\nevaluate our solution we used a game-like simulator in which an agent -\nprovided with high-level visual input - pursues multiple objectives in a 2D\nworld.\n"]},
{"authors": ["Daniel Vieira", "Fabio Rangel", "Fabricio Firmino", "Joao Paixao"], "title": ["Vector Field Based Neural Networks"], "date": ["2018-02-22T18:46:15Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08235v1"], "summary": ["  A novel Neural Network architecture is proposed using the mathematically and\nphysically rich idea of vector fields as hidden layers to perform nonlinear\ntransformations in the data. The data points are interpreted as particles\nmoving along a flow defined by the vector field which intuitively represents\nthe desired movement to enable classification. The architecture moves the data\npoints from their original configuration to anew one following the streamlines\nof the vector field with the objective of achieving a final configuration where\nclasses are separable. An optimization problem is solved through gradient\ndescent to learn this vector field.\n"]},
{"authors": ["Nicholas Carlini", "Chang Liu", "Jernej Kos", "\u00dalfar Erlingsson", "Dawn Song"], "title": ["The Secret Sharer: Measuring Unintended Neural Network Memorization &\n  Extracting Secrets"], "date": ["2018-02-22T18:42:41Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08232v1"], "summary": ["  Machine learning models based on neural networks and deep learning are being\nrapidly adopted for many purposes. What those models learn, and what they may\nshare, is a significant concern when the training data may contain secrets and\nthe models are public -- e.g., when a model helps users compose text messages\nusing models trained on all users' messages.\n  This paper presents exposure: a simple-to-compute metric that can be applied\nto any deep learning model for measuring the memorization of secrets. Using\nthis metric, we show how to extract those secrets efficiently using black-box\nAPI access. Further, we show that unintended memorization occurs early, is not\ndue to over-fitting, and is a persistent issue across different types of\nmodels, hyperparameters, and training strategies. We experiment with both\nreal-world models (e.g., a state-of-the-art translation model) and datasets\n(e.g., the Enron email dataset, which contains users' credit card numbers) to\ndemonstrate both the utility of measuring exposure and the ability to extract\nsecrets.\n  Finally, we consider many defenses, finding some ineffective (like\nregularization), and others to lack guarantees. However, by instantiating our\nown differentially-private recurrent model, we validate that by appropriately\ninvesting in the use of state-of-the-art techniques, the problem can be\nresolved, with high utility.\n"]},
{"authors": ["Giovanni Casini", "Umberto Straccia", "Thomas Meyer"], "title": ["A Polynomial Time Subsumption Algorithm for Nominal Safe\n  $\\mathcal{ELO}_\\bot$ under Rational Closure"], "date": ["2018-02-22T17:54:00Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08201v1"], "summary": ["  Description Logics (DLs) under Rational Closure (RC) is a well-known\nframework for non-monotonic reasoning in DLs. In this paper, we address the\nconcept subsumption decision problem under RC for nominal safe\n$\\mathcal{ELO}_\\bot$, a notable and practically important DL representative of\nthe OWL 2 profile OWL 2 EL.\n  Our contribution here is to define a polynomial time subsumption procedure\nfor nominal safe $\\mathcal{ELO}_\\bot$ under RC that relies entirely on a series\nof classical, monotonic $\\mathcal{EL}_\\bot$ subsumption tests. Therefore, any\nexisting classical monotonic $\\mathcal{EL}_\\bot$ reasoner can be used as a\nblack box to implement our method. We then also adapt the method to one of the\nknown extensions of RC for DLs, namely Defeasible Inheritance-based DLs without\nlosing the computational tractability.\n"]},
{"authors": ["Muhammed O. Sayin", "Chung-Wei Lin", "Shinichi Shiraishi", "Tamer Ba\u015far"], "title": ["Reliable Intersection Control in Non-cooperative Environments"], "date": ["2018-02-22T16:23:39Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08138v1"], "summary": ["  We propose a reliable intersection control mechanism for strategic autonomous\nand connected vehicles (agents) in non-cooperative environments. Each agent has\naccess to his/her earliest possible and desired passing times, and reports a\npassing time to the intersection manager, who allocates the intersection\ntemporally to the agents in a First-Come-First-Serve basis. However, the agents\nmight have conflicting interests and can take actions strategically. To this\nend, we analyze the strategic behaviors of the agents and formulate Nash\nequilibria for all possible scenarios. Furthermore, among all Nash equilibria\nwe identify a socially optimal equilibrium that leads to a fair intersection\nallocation, and correspondingly we describe a strategy-proof intersection\nmechanism, which achieves reliable intersection control such that the strategic\nagents do not have any incentive to misreport their passing times\nstrategically.\n"]},
{"authors": ["Daniel Karapetyan", "Andrew J. Parkes", "Gregory Gutin", "Andrei Gagarin"], "title": ["Pattern-Based Approach to the Workflow Satisfiability Problem with\n  User-Independent Constraints"], "date": ["2016-04-19T16:08:33Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1604.05636v2"], "summary": ["  The fixed parameter tractable (FPT) approach is a powerful tool in tackling\ncomputationally hard problems. In this paper, we link FPT results to classic\nartificial intelligence (AI) techniques to show how they complement each other.\nSpecifically, we consider the workflow satisfiability problem (WSP) which asks\nwhether there exists an assignment of authorised users to the steps in a\nworkflow specification, subject to certain constraints on the assignment. It\nwas shown by Cohen et al. (JAIR 2014) that WSP restricted to the class of\nuser-independent constraints (UI), covering many practical cases, admits FPT\nalgorithms, i.e. can be solved in time exponential only in the number of steps\n$k$ and polynomial in the number of users $n$. Since usually $k \\ll n$ in WSP,\nsuch FPT algorithms are of great practical interest as they significantly\nextend the size of the problem that can be routinely solved.\n  We give a new view of the FPT nature of the WSP with UI constraints, showing\nthat it decomposes the problem into two levels. Exploiting this two-level\nsplit, we develop a new FPT algorithm that is by many orders of magnitude\nfaster than the previous state-of-the-art WSP algorithm; and it also has only\npolynomial space complexity whereas the old algorithm takes memory exponential\nin $k$, which limits its application.\n  We also provide a new pseudo-boolean (PB) formulation of the WSP with UI\nconstraints which exploits this new decomposition of the problem into two\nlevels. Our experiments show that efficiency of solving this new PB formulation\nof the problem by a general purpose PB solver can be close to the bespoke FPT\nalgorithm, which raises the potential of using general purpose solvers to\ntackle FPT problems efficiently.\n  We also study the computational performance of various algorithms to\ncomplement the overly-pessimistic worst-case analysis that is usually done in\nFPT studies.\n"]},
{"authors": ["A. V. Palagin", "N. G. Petrenko", "V. Yu. Velychko", "K. S. Malakhov"], "title": ["The problem of the development ontology-driven architecture of\n  intellectual software systems"], "date": ["2018-02-17T10:24:01Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06767v2"], "summary": ["  The paper describes the architecture of the intelligence system for automated\ndesign of ontological knowledge bases of domain areas and the software model of\nthe management GUI (Graphical User Interface) subsystem\n"]},
{"authors": ["Daniel Tanneberg", "Jan Peters", "Elmar Rueckert"], "title": ["Intrinsic Motivation and Mental Replay enable Efficient Online\n  Adaptation in Stochastic Recurrent Networks"], "date": ["2018-02-22T12:41:06Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08013v1"], "summary": ["  Autonomous robots need to interact with unknown, unstructured and changing\nenvironments, constantly facing novel challenges. Therefore, continuous online\nadaptation for lifelong-learning and the need of sample-efficient mechanisms to\nadapt to changes in the environment, the constraints, the tasks, or the robot\nitself are crucial. In this work, we propose a novel framework for\nprobabilistic online motion planning with online adaptation based on a\nbio-inspired stochastic recurrent neural network. By using learning signals\nwhich mimic the intrinsic motivation signal cognitive dissonance in addition\nwith a mental replay strategy to intensify experiences, the stochastic\nrecurrent network can learn from few physical interactions and adapts to novel\nenvironments in seconds. We evaluate our online planning and adaptation\nframework on an anthropomorphic KUKA LWR arm. The rapid online adaptation is\nshown by learning unknown workspace constraints sample-efficiently from few\nphysical interactions while following given via points.\n"]},
{"authors": ["Dar\u00edo Garigliotti", "Krisztian Balog"], "title": ["Towards an Understanding of Entity-Oriented Search Intents"], "date": ["2018-02-22T12:30:13Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08010v1"], "summary": ["  Entity-oriented search deals with a wide variety of information needs, from\ndisplaying direct answers to interacting with services. In this work, we aim to\nunderstand what are prominent entity-oriented search intents and how they can\nbe fulfilled. We develop a scheme of entity intent categories, and use them to\nannotate a sample of queries. Specifically, we annotate unique query refiners\non the level of entity types. We observe that, on average, over half of those\nrefiners seek to interact with a service, while over a quarter of the refiners\nsearch for information that may be looked up in a knowledge base.\n"]},
{"authors": ["Miltiadis Allamanis", "Marc Brockschmidt", "Mahmoud Khademi"], "title": ["Learning to Represent Programs with Graphs"], "date": ["2017-11-01T09:48:06Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.00740v2"], "summary": ["  Learning tasks on source code (i.e., formal languages) have been considered\nrecently, but most work has tried to transfer natural language methods and does\nnot capitalize on the unique opportunities offered by code's known syntax. For\nexample, long-range dependencies induced by using the same variable or function\nin distant locations are often not considered. We propose to use graphs to\nrepresent both the syntactic and semantic structure of code and use graph-based\ndeep learning methods to learn to reason over program structures.\n  In this work, we present how to construct graphs from source code and how to\nscale Gated Graph Neural Networks training to such large graphs. We evaluate\nour method on two tasks: VarNaming, in which a network attempts to predict the\nname of a variable given its usage, and VarMisuse, in which the network learns\nto reason about selecting the correct variable that should be used at a given\nprogram location. Our comparison to methods that use less structured program\nrepresentations shows the advantages of modeling known structure, and suggests\nthat our models learn to infer meaningful names and to solve the VarMisuse task\nin many cases. Additionally, our testing showed that VarMisuse identifies a\nnumber of bugs in mature open-source projects.\n"]},
{"authors": ["Heng Ding", "Shuo Zhang", "Dar\u00edo Garigliotti", "Krisztian Balog"], "title": ["Generating High-Quality Query Suggestion Candidates for Task-Based\n  Search"], "date": ["2018-02-22T11:55:28Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.07997v1"], "summary": ["  We address the task of generating query suggestions for task-based search.\nThe current state of the art relies heavily on suggestions provided by a major\nsearch engine. In this paper, we solve the task without reliance on search\nengines. Specifically, we focus on the first step of a two-stage pipeline\napproach, which is dedicated to the generation of query suggestion candidates.\nWe present three methods for generating candidate suggestions and apply them on\nmultiple information sources. Using a purpose-built test collection, we find\nthat these methods are able to generate high-quality suggestion candidates.\n"]},
{"authors": ["Arindam Mitra", "Chitta Baral"], "title": ["Incremental and Iterative Learning of Answer Set Programs from Mutually\n  Distinct Examples"], "date": ["2018-02-22T10:22:58Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.07966v1"], "summary": ["  Over these years the Artificial Intelligence (AI) community has produced\nseveral datasets which have given the machine learning algorithms the\nopportunity to learn various skills across various domains. However, a subclass\nof these machine learning algorithms that aimed at learning logic programs,\nnamely the Inductive Logic Programming algorithms, have often failed at the\ntask due to the vastness of these datasets. This has impacted the usability of\nknowledge representation and reasoning techniques in the development of AI\nsystems. In this research, we try to address this scalability issue for the\nalgorithms that learn Answer Set Programs. We present a sound and complete\nalgorithm which takes the input in a slightly different manner and perform an\nefficient and more user controlled search for a solution. We show via\nexperiments that our algorithm can learn from two popular datasets from machine\nlearning community, namely bAbl (a question answering dataset) and MNIST (a\ndataset for handwritten digit recognition), which to the best of our knowledge\nwas not previously possible. The system is publicly available at\nhttps://goo.gl/KdWAcV.\n"]},
{"authors": ["Wei Ping", "Kainan Peng", "Andrew Gibiansky", "Sercan O. Arik", "Ajay Kannan", "Sharan Narang", "Jonathan Raiman", "John Miller"], "title": ["Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence\n  Learning"], "date": ["2017-10-20T18:17:23Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.07654v3"], "summary": ["  We present Deep Voice 3, a fully-convolutional attention-based neural\ntext-to-speech (TTS) system. Deep Voice 3 matches state-of-the-art neural\nspeech synthesis systems in naturalness while training ten times faster. We\nscale Deep Voice 3 to data set sizes unprecedented for TTS, training on more\nthan eight hundred hours of audio from over two thousand speakers. In addition,\nwe identify common error modes of attention-based speech synthesis networks,\ndemonstrate how to mitigate them, and compare several different waveform\nsynthesis methods. We also describe how to scale inference to ten million\nqueries per day on one single-GPU server.\n"]},
{"authors": ["Eric Martin", "Chris Cundy"], "title": ["Parallelizing Linear Recurrent Neural Nets Over Sequence Length"], "date": ["2017-09-12T20:52:22Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1709.04057v2"], "summary": ["  Recurrent neural networks (RNNs) are widely used to model sequential data but\ntheir non-linear dependencies between sequence elements prevent parallelizing\ntraining over sequence length. We show the training of RNNs with only linear\nsequential dependencies can be parallelized over the sequence length using the\nparallel scan algorithm, leading to rapid training on long sequences even with\nsmall minibatch size. We develop a parallel linear recurrence CUDA kernel and\nshow that it can be applied to immediately speed up training and inference of\nseveral state of the art RNN architectures by up to 9x. We abstract recent work\non linear RNNs into a new framework of linear surrogate RNNs and develop a\nlinear surrogate model for the long short-term memory unit, the GILR-LSTM, that\nutilizes parallel linear recurrence. We extend sequence learning to new\nextremely long sequence regimes that were previously out of reach by\nsuccessfully training a GILR-LSTM on a synthetic sequence classification task\nwith a one million timestep dependency.\n"]},
{"authors": ["Alireza Bagheri", "Osvaldo Simeone", "Bipin Rajendran"], "title": ["Training Probabilistic Spiking Neural Networks with First-to-spike\n  Decoding"], "date": ["2017-10-29T22:13:53Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.10704v3"], "summary": ["  Third-generation neural networks, or Spiking Neural Networks (SNNs), aim at\nharnessing the energy efficiency of spike-domain processing by building on\ncomputing elements that operate on, and exchange, spikes. In this paper, the\nproblem of training a two-layer SNN is studied for the purpose of\nclassification, under a Generalized Linear Model (GLM) probabilistic neural\nmodel that was previously considered within the computational neuroscience\nliterature. Conventional classification rules for SNNs operate offline based on\nthe number of output spikes at each output neuron. In contrast, a novel\ntraining method is proposed here for a first-to-spike decoding rule, whereby\nthe SNN can perform an early classification decision once spike firing is\ndetected at an output neuron. Numerical results bring insights into the optimal\nparameter selection for the GLM neuron and on the accuracy-complexity trade-off\nperformance of conventional and first-to-spike decoding.\n"]},
{"authors": ["Avi Ben-Cohen", "Eyal Klang", "Stephen P. Raskin", "Shelly Soffer", "Simona Ben-Haim", "Eli Konen", "Michal Marianne Amitai", "Hayit Greenspan"], "title": ["Cross-Modality Synthesis from CT to PET using FCN and GAN Networks for\n  Improved Automated Lesion Detection"], "date": ["2018-02-21T23:25:19Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.07846v1"], "summary": ["  In this work we present a novel system for generation of virtual PET images\nusing CT scans. We combine a fully convolutional network (FCN) with a\nconditional generative adversarial network (GAN) to generate simulated PET data\nfrom given input CT data. The synthesized PET can be used for false-positive\nreduction in lesion detection solutions. Clinically, such solutions may enable\nlesion detection and drug treatment evaluation in a CT-only environment, thus\nreducing the need for the more expensive and radioactive PET/CT scan. Our\ndataset includes 60 PET/CT scans from Sheba Medical center. We used 23 scans\nfor training and 37 for testing. Different schemes to achieve the synthesized\noutput were qualitatively compared. Quantitative evaluation was conducted using\nan existing lesion detection software, combining the synthesized PET as a false\npositive reduction layer for the detection of malignant lesions in the liver.\nCurrent results look promising showing a 28% reduction in the average false\npositive per case from 2.9 to 2.1. The suggested solution is comprehensive and\ncan be expanded to additional body organs, and different modalities.\n"]},
{"authors": ["Hamid Reza Maei"], "title": ["Convergent Actor-Critic Algorithms Under Off-Policy Training and\n  Function Approximation"], "date": ["2018-02-21T23:14:44Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.07842v1"], "summary": ["  We present the first class of policy-gradient algorithms that work with both\nstate-value and policy function-approximation, and are guaranteed to converge\nunder off-policy training. Our solution targets problems in reinforcement\nlearning where the action representation adds to the-curse-of-dimensionality;\nthat is, with continuous or large action sets, thus making it infeasible to\nestimate state-action value functions (Q functions). Using state-value\nfunctions helps to lift the curse and as a result naturally turn our\npolicy-gradient solution into classical Actor-Critic architecture whose Actor\nuses state-value function for the update. Our algorithms, Gradient Actor-Critic\nand Emphatic Actor-Critic, are derived based on the exact gradient of averaged\nstate-value function objective and thus are guaranteed to converge to its\noptimal solution, while maintaining all the desirable properties of classical\nActor-Critic methods with no additional hyper-parameters. To our knowledge,\nthis is the first time that convergent off-policy learning methods have been\nextended to classical Actor-Critic methods with function approximation.\n"]},
{"authors": ["Haonan Yu", "Haichao Zhang", "Wei Xu"], "title": ["Interactive Grounded Language Acquisition and Generalization in a 2D\n  World"], "date": ["2018-01-31T01:35:46Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.01433v2"], "summary": ["  We build a virtual agent for learning language in a 2D maze-like world. The\nagent sees images of the surrounding environment, listens to a virtual teacher,\nand takes actions to receive rewards. It interactively learns the teacher's\nlanguage from scratch based on two language use cases: sentence-directed\nnavigation and question answering. It learns simultaneously the visual\nrepresentations of the world, the language, and the action control. By\ndisentangling language grounding from other computational routines and sharing\na concept detection function between language grounding and prediction, the\nagent reliably interpolates and extrapolates to interpret sentences that\ncontain new word combinations or new words missing from training sentences. The\nnew words are transferred from the answers of language prediction. Such a\nlanguage ability is trained and evaluated on a population of over 1.6 million\ndistinct sentences consisting of 119 object words, 8 color words, 9\nspatial-relation words, and 50 grammatical words. The proposed model\nsignificantly outperforms five comparison methods for interpreting zero-shot\nsentences. In addition, we demonstrate human-interpretable intermediate outputs\nof the model in the appendix.\n"]},
{"authors": ["Jianbo Chen", "Le Song", "Martin J. Wainwright", "Michael I. Jordan"], "title": ["Learning to Explain: An Information-Theoretic Perspective on Model\n  Interpretation"], "date": ["2018-02-21T21:16:21Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.07814v1"], "summary": ["  We introduce instancewise feature selection as a methodology for model\ninterpretation. Our method is based on learning a function to extract a subset\nof features that are most informative for each given example. This feature\nselector is trained to maximize the mutual information between selected\nfeatures and the response variable, where the conditional distribution of the\nresponse variable given the input is the model to be explained. We develop an\nefficient variational approximation to the mutual information, and show that\nthe resulting method compares favorably to other model explanation methods on a\nvariety of synthetic and real data sets using both quantitative metrics and\nhuman evaluation.\n"]},
{"authors": ["Forough Poursabzi-Sangdeh", "Daniel G. Goldstein", "Jake M. Hofman", "Jennifer Wortman Vaughan", "Hanna Wallach"], "title": ["Manipulating and Measuring Model Interpretability"], "date": ["2018-02-21T21:11:36Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.07810v1"], "summary": ["  Despite a growing body of research focused on creating interpretable machine\nlearning methods, there have been few empirical studies verifying whether\ninterpretable methods achieve their intended effects on end users. We present a\nframework for assessing the effects of model interpretability on users via\npre-registered experiments in which participants are shown functionally\nidentical models that vary in factors thought to influence interpretability.\nUsing this framework, we ran a sequence of large-scale randomized experiments,\nvarying two putative drivers of interpretability: the number of features and\nthe model transparency (clear or black-box). We measured how these factors\nimpact trust in model predictions, the ability to simulate a model, and the\nability to detect a model's mistakes. We found that participants who were shown\na clear model with a small number of features were better able to simulate the\nmodel's predictions. However, we found no difference in multiple measures of\ntrust and found that clear models did not improve the ability to correct\nmistakes. These findings suggest that interpretability research could benefit\nfrom more emphasis on empirically verifying that interpretable models achieve\nall their intended effects.\n"]},
{"authors": ["John Kingston"], "title": ["Artificial Intelligence and Legal Liability"], "date": ["2018-02-21T20:11:28Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.07782v1"], "summary": ["  A recent issue of a popular computing journal asked which laws would apply if\na self-driving car killed a pedestrian. This paper considers the question of\nlegal liability for artificially intelligent computer systems. It discusses\nwhether criminal liability could ever apply; to whom it might apply; and, under\ncivil law, whether an AI program is a product that is subject to product design\nlegislation or a service to which the tort of negligence applies. The issue of\nsales warranties is also considered. A discussion of some of the practical\nlimitations that AI systems are subject to is also included.\n"]},
{"authors": ["Matthew Streeter"], "title": ["Approximation Algorithms for Cascading Prediction Models"], "date": ["2018-02-21T17:56:05Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.07697v1"], "summary": ["  We present an approximation algorithm that takes a pool of pre-trained models\nas input and produces from it a cascaded model with similar accuracy but lower\naverage-case cost. Applied to state-of-the-art ImageNet classification models,\nthis yields up to a 2x reduction in floating point multiplications, and up to a\n6x reduction in average-case memory I/O. The auto-generated cascades exhibit\nintuitive properties, such as using lower-resolution input for easier images\nand requiring higher prediction confidence when using a computationally cheaper\nmodel.\n"]},
{"authors": ["Matthias Rauter", "Daniel Winkler"], "title": ["Predicting Natural Hazards with Neuronal Networks"], "date": ["2018-02-21T17:43:56Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.07257v1"], "summary": ["  Gravitational mass flows, such as avalanches, debris flows and rockfalls are\ncommon events in alpine regions with high impact on transport routes. Within\nthe last few decades, hazard zone maps have been developed to systematically\napproach this threat. These maps mark vulnerable zones in habitable areas to\nallow effective planning of hazard mitigation measures and development of\nsettlements. Hazard zone maps have shown to be an effective tool to reduce\nfatalities during extreme events. They are created in a complex process, based\non experience, empirical models, physical simulations and historical data. The\ngeneration of such maps is therefore expensive and limited to crucially\nimportant regions, e.g. permanently inhabited areas.\n  In this work we interpret the task of hazard zone mapping as a classification\nproblem. Every point in a specific area has to be classified according to its\nvulnerability. On a regional scale this leads to a segmentation problem, where\nthe total area has to be divided in the respective hazard zones. The recent\ndevelopments in artificial intelligence, namely convolutional neuronal\nnetworks, have led to major improvement in a very similar task, image\nclassification and semantic segmentation, i.e. computer vision. We use a\nconvolutional neuronal network to identify terrain formations with the\npotential for catastrophic snow avalanches and label points in their reach as\nvulnerable. Repeating this procedure for all points allows us to generate an\nartificial hazard zone map. We demonstrate that the approach is feasible and\npromising based on the hazard zone map of the Tirolean Oberland. However, more\ntraining data and further improvement of the method is required before such\ntechniques can be applied reliably.\n"]},
{"authors": ["Amit Dhurandhar", "Pin-Yu Chen", "Ronny Luss", "Chun-Chen Tu", "Paishun Ting", "Karthikeyan Shanmugam", "Payel Das"], "title": ["Explanations based on the Missing: Towards Contrastive Explanations with\n  Pertinent Negatives"], "date": ["2018-02-21T15:51:38Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.07623v1"], "summary": ["  In this paper we propose a novel method that provides contrastive\nexplanations justifying the classification of an input by a black box\nclassifier such as a deep neural network. Given an input we find what should be\nminimally and sufficiently present (viz. important object pixels in an image)\nto justify its classification and analogously what should be minimally and\nnecessarily \\emph{absent} (viz. certain background pixels). We argue that such\nexplanations are natural for humans and are used commonly in domains such as\nhealth care and criminology. What is minimally but critically \\emph{absent} is\nan important part of an explanation, which to the best of our knowledge, has\nnot been touched upon by current explanation methods that attempt to explain\npredictions of neural networks. We validate our approach on three real datasets\nobtained from diverse domains; namely, a handwritten digits dataset MNIST, a\nlarge procurement fraud dataset and an fMRI brain imaging dataset. In all three\ncases, we witness the power of our approach in generating precise explanations\nthat are also easy for human experts to understand and evaluate.\n"]},
{"authors": ["Jacob W. Crandall", "Mayada Oudah", " Tennom", "Fatimah Ishowo-Oloko", "Sherief Abdallah", "Jean-Fran\u00e7ois Bonnefon", "Manuel Cebrian", "Azim Shariff", "Michael A. Goodrich", "Iyad Rahwan"], "title": ["Cooperating with Machines"], "date": ["2017-03-17T21:50:16Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1703.06207v5"], "summary": ["  Since Alan Turing envisioned Artificial Intelligence (AI) [1], a major\ndriving force behind technical progress has been competition with human\ncognition. Historical milestones have been frequently associated with computers\nmatching or outperforming humans in difficult cognitive tasks (e.g. face\nrecognition [2], personality classification [3], driving cars [4], or playing\nvideo games [5]), or defeating humans in strategic zero-sum encounters (e.g.\nChess [6], Checkers [7], Jeopardy! [8], Poker [9], or Go [10]). In contrast,\nless attention has been given to developing autonomous machines that establish\nmutually cooperative relationships with people who may not share the machine's\npreferences. A main challenge has been that human cooperation does not require\nsheer computational power, but rather relies on intuition [11], cultural norms\n[12], emotions and signals [13, 14, 15, 16], and pre-evolved dispositions\ntoward cooperation [17], common-sense mechanisms that are difficult to encode\nin machines for arbitrary contexts. Here, we combine a state-of-the-art\nmachine-learning algorithm with novel mechanisms for generating and acting on\nsignals to produce a new learning algorithm that cooperates with people and\nother machines at levels that rival human cooperation in a variety of\ntwo-player repeated stochastic games. This is the first general-purpose\nalgorithm that is capable, given a description of a previously unseen game\nenvironment, of learning to cooperate with people within short timescales in\nscenarios previously unanticipated by algorithm designers. This is achieved\nwithout complex opponent modeling or higher-order theories of mind, thus\nshowing that flexible, fast, and general human-machine cooperation is\ncomputationally achievable using a non-trivial, but ultimately simple, set of\nalgorithmic mechanisms.\n"]},
{"authors": ["Luisa M Zintgraf", "Diederik M Roijers", "Sjoerd Linders", "Catholijn M Jonker", "Ann Now\u00e9"], "title": ["Ordered Preference Elicitation Strategies for Supporting Multi-Objective\n  Decision Making"], "date": ["2018-02-21T15:05:15Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.07606v1"], "summary": ["  In multi-objective decision planning and learning, much attention is paid to\nproducing optimal solution sets that contain an optimal policy for every\npossible user preference profile. We argue that the step that follows, i.e,\ndetermining which policy to execute by maximising the user's intrinsic utility\nfunction over this (possibly infinite) set, is under-studied. This paper aims\nto fill this gap. We build on previous work on Gaussian processes and pairwise\ncomparisons for preference modelling, extend it to the multi-objective decision\nsupport scenario, and propose new ordered preference elicitation strategies\nbased on ranking and clustering. Our main contribution is an in-depth\nevaluation of these strategies using computer and human-based experiments. We\nshow that our proposed elicitation strategies outperform the currently used\npairwise methods, and found that users prefer ranking most. Our experiments\nfurther show that utilising monotonicity information in GPs by using a linear\nprior mean at the start and virtual comparisons to the nadir and ideal points,\nincreases performance. We demonstrate our decision support framework in a\nreal-world study on traffic regulation, conducted with the city of Amsterdam.\n"]},
{"authors": ["Yasuhiro Fujita", "Shin-ichi Maeda"], "title": ["Clipped Action Policy Gradient"], "date": ["2018-02-21T13:39:28Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.07564v1"], "summary": ["  Many continuous control tasks have bounded action spaces and clip\nout-of-bound actions before execution. Policy gradient methods often optimize\npolicies as if actions were not clipped. We propose clipped action policy\ngradient (CAPG) as an alternative policy gradient estimator that exploits the\nknowledge of actions being clipped to reduce the variance in estimation. We\nprove that CAPG is unbiased and achieves lower variance than the original\nestimator that ignores action bounds. Experimental results demonstrate that\nCAPG generally outperforms the original estimator, indicating its promise as a\nbetter policy gradient estimator for continuous control tasks.\n"]},
{"authors": ["Maryam Sabzevari", "Gonzalo Mart\u00ednez-Mu\u00f1oz", "Alberto Su\u00e1rez"], "title": ["Pooling homogeneous ensembles to build heterogeneous ensembles"], "date": ["2018-02-21T13:17:42Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.07877v1"], "summary": ["  In ensemble methods, the outputs of a collection of diverse classifiers are\ncombined in the expectation that the global prediction be more accurate than\nthe individual ones. Heterogeneous ensembles consist of predictors of different\ntypes, which are likely to have different biases. If these biases are\ncomplementary, the combination of their decisions is beneficial. In this work,\na family of heterogeneous ensembles is built by pooling classifiers from M\nhomogeneous ensembles of different types of size T. Depending on the fraction\nof base classifiers of each type, a particular heterogeneous combination in\nthis family is represented by a point in a regular simplex in M dimensions. The\nM vertices of this simplex represent the different homogeneous ensembles. A\ndisplacement away from one of these vertices effects a smooth transformation of\nthe corresponding homogeneous ensemble into a heterogeneous one. The optimal\ncomposition of such heterogeneous ensemble can be determined using\ncross-validation or, if bootstrap samples are used to build the individual\nclassifiers, out-of-bag data. An empirical analysis of such combinations of\nbootstraped ensembles composed of neural networks, SVMs, and random trees (i.e.\nfrom a standard random forest) illustrates the gains that can be achieved by\nthis heterogeneous ensemble creation method.\n"]},
{"authors": ["O. V. Palagin", "K. S. Malakhov", "V. Yu. Velichko", "O. S. Shurov"], "title": ["Design and software implementation of subsystems for creating and using\n  the ontological base of a research scientist"], "date": ["2018-02-17T10:46:22Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06768v2"], "summary": ["  Creation of the information systems and tools for scientific research and\ndevelopment support has always been one of the central directions of the\ndevelopment of computer science. The main features of the modern evolution of\nscientific research and development are the transdisciplinary approach and the\ndeep intellectualisation of all stages of the life cycle of formulation and\nsolution of scientific problems. The theoretical and practical aspects of the\ndevelopment of perspective complex knowledge-oriented information systems and\ntheir components are considered in the paper. The analysis of existing\nscientific information systems (or current research information systems, CRIS)\nand synthesis of general principles of design of the research and development\nworkstation environment of a researcher and its components are carried out in\nthe work. The functional components of knowledge-oriented information system\nresearch and development workstation environment of a researcher are designed.\nDesigned and developed functional components of knowledge-oriented information\nsystem developing research and development workstation environment,including\nfunctional models and software implementation of the software subsystem for\ncreation and use of ontological knowledge base for research fellow\npublications, as part of personalized knowledge base of scientific researcher.\nResearch in modern conditions of e-Science paradigm requires pooling scientific\ncommunity and intensive exchange of research results that may be achieved\nthrough the use of scientific information systems. research and development\nworkstation environment allows to solve problems of contructivisation and\nformalisation of knowledge representation, obtained during the research process\nand collective accomplices interaction.\n"]},
{"authors": ["A. V. Palagin", "N. G. Petrenko", "V. Yu. Velychko", "K. S. Malakhov", "Yu. L. Tikhonov"], "title": ["To the problem of \"The Instrumental complex for ontological engineering\n  purpose\" software system design"], "date": ["2018-02-10T08:13:54Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.03544v2"], "summary": ["  The given work describes methodological principles of design instrumental\ncomplex of ontological purpose. Instrumental complex intends for the\nimplementation of the integrated information technologies automated build of\ndomain ontologies. Results focus on enhancing the effectiveness of the\nautomatic analysis and understanding of natural-language texts, building of\nknowledge description of subject areas (primarily in the area of science and\ntechnology) and for interdisciplinary research in conjunction with the solution\nof complex problems.\n"]},
{"authors": ["Ligang Zhang", "Brijesh Verma", "David Stockwell", "Sujan Chowdhury"], "title": ["Density Weighted Connectivity of Grass Pixels in Image Frames for\n  Biomass Estimation"], "date": ["2018-02-21T11:07:05Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.07512v1"], "summary": ["  Accurate estimation of the biomass of roadside grasses plays a significant\nrole in applications such as fire-prone region identification. Current\nsolutions heavily depend on field surveys, remote sensing measurements and\nimage processing using reference markers, which often demand big investments of\ntime, effort and cost. This paper proposes Density Weighted Connectivity of\nGrass Pixels (DWCGP) to automatically estimate grass biomass from roadside\nimage data. The DWCGP calculates the length of continuously connected grass\npixels along a vertical orientation in each image column, and then weights the\nlength by the grass density in a surrounding region of the column. Grass pixels\nare classified using feedforward artificial neural networks and the dominant\ntexture orientation at every pixel is computed using multi-orientation Gabor\nwavelet filter vote. Evaluations on a field survey dataset show that the DWCGP\nreduces Root-Mean-Square Error from 5.84 to 5.52 by additionally considering\ngrass density on top of grass height. The DWCGP shows robustness to\nnon-vertical grass stems and to changes of both Gabor filter parameters and\nsurrounding region widths. It also has performance close to human observation\nand higher than eight baseline approaches, as well as promising results for\nclassifying low vs. high fire risk and identifying fire-prone road regions.\n"]},
{"authors": ["Anthony Hunter", "Sylwia Polberg", "Matthias Thimm"], "title": ["Epistemic Graphs for Representing and Reasoning with Positive and\n  Negative Influences of Arguments"], "date": ["2018-02-21T10:05:49Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.07489v1"], "summary": ["  This paper introduces epistemic graphs as a generalization of the epistemic\napproach to probabilistic argumentation. In these graphs, an argument can be\nbelieved or disbelieved up to a given degree, thus providing a more\nfine--grained alternative to the standard Dung's approaches when it comes to\ndetermining the status of a given argument. Furthermore, the flexibility of the\nepistemic approach allows us to both model the rationale behind the existing\nsemantics as well as completely deviate from them when required. Epistemic\ngraphs can model both attack and support as well as relations that are neither\nsupport nor attack. The way other arguments influence a given argument is\nexpressed by the epistemic constraints that can restrict the belief we have in\nan argument with a varying degree of specificity. The fact that we can specify\nthe rules under which arguments should be evaluated and we can include\nconstraints between unrelated arguments permits the framework to be more\ncontext--sensitive. It also allows for better modelling of imperfect agents,\nwhich can be important in multi--agent applications.\n"]},
{"authors": ["Nick Haber", "Damian Mrowca", "Li Fei-Fei", "Daniel L. K. Yamins"], "title": ["Emergence of Structured Behaviors from Curiosity-Based Intrinsic\n  Motivation"], "date": ["2018-02-21T08:13:12Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.07461v1"], "summary": ["  Infants are experts at playing, with an amazing ability to generate novel\nstructured behaviors in unstructured environments that lack clear extrinsic\nreward signals. We seek to replicate some of these abilities with a neural\nnetwork that implements curiosity-driven intrinsic motivation. Using a simple\nbut ecologically naturalistic simulated environment in which the agent can move\nand interact with objects it sees, the agent learns a world model predicting\nthe dynamic consequences of its actions. Simultaneously, the agent learns to\ntake actions that adversarially challenge the developing world model, pushing\nthe agent to explore novel and informative interactions with its environment.\nWe demonstrate that this policy leads to the self-supervised emergence of a\nspectrum of complex behaviors, including ego motion prediction, object\nattention, and object gathering. Moreover, the world model that the agent\nlearns supports improved performance on object dynamics prediction and\nlocalization tasks. Our results are a proof-of-principle that computational\nmodels of intrinsic motivation might account for key features of developmental\nvisuomotor learning in infants.\n"]},
{"authors": ["Nick Haber", "Damian Mrowca", "Li Fei-Fei", "Daniel L. K. Yamins"], "title": ["Learning to Play with Intrinsically-Motivated Self-Aware Agents"], "date": ["2018-02-21T07:01:43Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.07442v1"], "summary": ["  Infants are experts at playing, with an amazing ability to generate novel\nstructured behaviors in unstructured environments that lack clear extrinsic\nreward signals. We seek to mathematically formalize these abilities using a\nneural network that implements curiosity-driven intrinsic motivation. Using a\nsimple but ecologically naturalistic simulated environment in which an agent\ncan move and interact with objects it sees, we propose a \"world-model\" network\nthat learns to predict the dynamic consequences of the agent's actions.\nSimultaneously, we train a separate explicit \"self-model\" that allows the agent\nto track the error map of its own world-model, and then uses the self-model to\nadversarially challenge the developing world-model. We demonstrate that this\npolicy causes the agent to explore novel and informative interactions with its\nenvironment, leading to the generation of a spectrum of complex behaviors,\nincluding ego-motion prediction, object attention, and object gathering.\nMoreover, the world-model that the agent learns supports improved performance\non object dynamics prediction, detection, localization and recognition tasks.\nTaken together, our results are initial steps toward creating flexible\nautonomous agents that self-supervise in complex novel physical environments.\n"]},
{"authors": ["Kenji Kawaguchi", "Yoshua Bengio"], "title": ["Generalization in Machine Learning via Analytical Learning Theory"], "date": ["2018-02-21T05:03:52Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.07426v1"], "summary": ["  This paper introduces a novel measure-theoretic learning theory to analyze\ngeneralization behaviors of practical interest. The proposed learning theory\nhas the following abilities: 1) to utilize the qualities of each learned\nrepresentation on the path from raw inputs to outputs in representation\nlearning, 2) to guarantee good generalization errors possibly with arbitrarily\nrich hypothesis spaces (e.g., arbitrarily large capacity and Rademacher\ncomplexity) and non-stable/non-robust learning algorithms, and 3) to clearly\ndistinguish each individual problem instance from each other. Our\ngeneralization bounds are relative to a representation of the data, and hold\ntrue even if the representation is learned. We discuss several consequences of\nour results on deep learning, one-shot learning and curriculum learning. Unlike\nstatistical learning theory, the proposed learning theory analyzes each problem\ninstance individually via measure theory, rather than a set of problem\ninstances via statistics. Because of the differences in the assumptions and the\nobjectives, the proposed learning theory is meant to be complementary to\nprevious learning theory and is not designed to compete with it.\n"]},
{"authors": ["Xin Zhang", "Armando Solar-Lezama", "Rishabh Singh"], "title": ["Interpreting Neural Network Judgments via Minimal, Stable, and Symbolic\n  Corrections"], "date": ["2018-02-21T00:47:32Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.07384v1"], "summary": ["  The paper describes a new algorithm to generate minimal, stable, and symbolic\ncorrections to an input that will cause a neural network with ReLU neurons to\nchange its output. We argue that such a correction is a useful way to provide\nfeedback to a user when the neural network produces an output that is different\nfrom a desired output. Our algorithm generates such a correction by solving a\nseries of linear constraint satisfaction problems. The technique is evaluated\non a neural network that has been trained to predict whether an applicant will\npay a mortgage.\n"]},
{"authors": ["Siddhartha Brahma"], "title": ["On the scaling of polynomial features for representation matching"], "date": ["2018-02-20T23:22:25Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.07374v1"], "summary": ["  In many neural models, new features as polynomial functions of existing ones\nare used to augment representations. Using the natural language inference task\nas an example, we investigate the use of scaled polynomials of degree 2 and\nabove as matching features. We find that scaling degree 2 features has the\nhighest impact on performance, reducing classification error by 5% in the best\nmodels.\n"]},
{"authors": ["Siddhartha Brahma"], "title": ["SufiSent - Universal Sentence Representations Using Suffix Encodings"], "date": ["2018-02-20T23:08:19Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.07370v1"], "summary": ["  Computing universal distributed representations of sentences is a fundamental\ntask in natural language processing. We propose a method to learn such\nrepresentations by encoding the suffixes of word sequences in a sentence and\ntraining on the Stanford Natural Language Inference (SNLI) dataset. We\ndemonstrate the effectiveness of our approach by evaluating it on the SentEval\nbenchmark, improving on existing approaches on several transfer tasks.\n"]},
{"authors": ["Yanhong A. Liu"], "title": ["Logic Programming Applications: What Are the Abstractions and\n  Implementations?"], "date": ["2018-02-20T19:04:14Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.07284v1"], "summary": ["  This article presents an overview of applications of logic programming,\nclassifying them based on the abstractions and implementations of logic\nlanguages that support the applications. The three key abstractions are join,\nrecursion, and constraint. Their essential implementations are for-loops, fixed\npoints, and backtracking, respectively. The corresponding kinds of applications\nare database queries, inductive analysis, and combinatorial search,\nrespectively. We also discuss language extensions and programming paradigms,\nsummarize example application problems by application areas, and touch on\nexample systems that support variants of the abstractions with different\nimplementations.\n"]},
{"authors": ["Abhishek Gupta", "Russell Mendonca", "YuXuan Liu", "Pieter Abbeel", "Sergey Levine"], "title": ["Meta-Reinforcement Learning of Structured Exploration Strategies"], "date": ["2018-02-20T18:40:57Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.07245v1"], "summary": ["  Exploration is a fundamental challenge in reinforcement learning (RL). Many\nof the current exploration methods for deep RL use task-agnostic objectives,\nsuch as information gain or bonuses based on state visitation. However, many\npractical applications of RL involve learning more than a single task, and\nprior tasks can be used to inform how exploration should be performed in new\ntasks. In this work, we explore how prior tasks can inform an agent about how\nto explore effectively in new situations. We introduce a novel gradient-based\nfast adaptation algorithm -- model agnostic exploration with structured noise\n(MAESN) -- to learn exploration strategies from prior experience. The prior\nexperience is used both to initialize a policy and to acquire a latent\nexploration space that can inject structured stochasticity into a policy,\nproducing exploration strategies that are informed by prior knowledge and are\nmore effective than random action-space noise. We show that MAESN is more\neffective at learning exploration strategies when compared to prior meta-RL\nmethods, RL without learned exploration strategies, and task-agnostic\nexploration methods. We evaluate our method on a variety of simulated tasks:\nlocomotion with a wheeled robot, locomotion with a quadrupedal walker, and\nobject manipulation.\n"]},
{"authors": ["Christos Kaplanis", "Murray Shanahan", "Claudia Clopath"], "title": ["Continual Reinforcement Learning with Complex Synapses"], "date": ["2018-02-20T18:36:57Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.07239v1"], "summary": ["  Unlike humans, who are capable of continual learning over their lifetimes,\nartificial neural networks have long been known to suffer from a phenomenon\nknown as catastrophic forgetting, whereby new learning can lead to abrupt\nerasure of previously acquired knowledge. Whereas in a neural network the\nparameters are typically modelled as scalar values, an individual synapse in\nthe brain comprises a complex network of interacting biochemical components\nthat evolve at different timescales. In this paper, we show that by equipping\ntabular and deep reinforcement learning agents with a synaptic model that\nincorporates this biological complexity (Benna & Fusi, 2016), catastrophic\nforgetting can be mitigated at multiple timescales. In particular, we find that\nas well as enabling continual learning across sequential training of two simple\ntasks, it can also be used to overcome within-task forgetting by reducing the\nneed for an experience replay database.\n"]},
{"authors": ["Miles Brundage", "Shahar Avin", "Jack Clark", "Helen Toner", "Peter Eckersley", "Ben Garfinkel", "Allan Dafoe", "Paul Scharre", "Thomas Zeitzoff", "Bobby Filar", "Hyrum Anderson", "Heather Roff", "Gregory C. Allen", "Jacob Steinhardt", "Carrick Flynn", "Se\u00e1n \u00d3 h\u00c9igeartaigh", "Simon Beard", "Haydn Belfield", "Sebastian Farquhar", "Clare Lyle", "Rebecca Crootof", "Owain Evans", "Michael Page", "Joanna Bryson", "Roman Yampolskiy", "Dario Amodei"], "title": ["The Malicious Use of Artificial Intelligence: Forecasting, Prevention,\n  and Mitigation"], "date": ["2018-02-20T18:07:50Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.07228v1"], "summary": ["  This report surveys the landscape of potential security threats from\nmalicious uses of AI, and proposes ways to better forecast, prevent, and\nmitigate these threats. After analyzing the ways in which AI may influence the\nthreat landscape in the digital, physical, and political domains, we make four\nhigh-level recommendations for AI researchers and other stakeholders. We also\nsuggest several promising areas for further research that could expand the\nportfolio of defenses, or make attacks less effective or harder to execute.\nFinally, we discuss, but do not conclusively resolve, the long-term equilibrium\nof attackers and defenders.\n"]},
{"authors": ["Anuj Karpatne", "William Watkins", "Jordan Read", "Vipin Kumar"], "title": ["Physics-guided Neural Networks (PGNN): An Application in Lake\n  Temperature Modeling"], "date": ["2017-10-31T12:24:26Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.11431v2"], "summary": ["  This paper introduces a novel framework for combining scientific knowledge of\nphysics-based models with neural networks to advance scientific discovery. This\nframework, termed as physics-guided neural network (PGNN), leverages the output\nof physics-based model simulations along with observational features to\ngenerate predictions using a neural network architecture. Further, this paper\npresents a novel framework for using physics-based loss functions in the\nlearning objective of neural networks, to ensure that the model predictions not\nonly show lower errors on the training set but are also scientifically\nconsistent with the known physics on the unlabeled set. We illustrate the\neffectiveness of PGNN for the problem of lake temperature modeling, where\nphysical relationships between the temperature, density, and depth of water are\nused to design a physics-based loss function. By using scientific knowledge to\nguide the construction and learning of neural networks, we are able to show\nthat the proposed framework ensures better generalizability as well as\nscientific consistency of results.\n"]},
{"authors": ["Amritanshu Agrawal", "Wei Fu", "Tim Menzies"], "title": ["What is Wrong with Topic Modeling? (and How to Fix it Using Search-based\n  Software Engineering)"], "date": ["2016-08-29T18:45:00Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1608.08176v4"], "summary": ["  Context: Topic modeling finds human-readable structures in unstructured\ntextual data. A widely used topic modeler is Latent Dirichlet allocation. When\nrun on different datasets, LDA suffers from \"order effects\" i.e. different\ntopics are generated if the order of training data is shuffled. Such order\neffects introduce a systematic error for any study. This error can relate to\nmisleading results;specifically, inaccurate topic descriptions and a reduction\nin the efficacy of text mining classification results. Objective: To provide a\nmethod in which distributions generated by LDA are more stable and can be used\nfor further analysis. Method: We use LDADE, a search-based software engineering\ntool that tunes LDA's parameters using DE (Differential Evolution). LDADE is\nevaluated on data from a programmer information exchange site (Stackoverflow),\ntitle and abstract text of thousands ofSoftware Engineering (SE) papers, and\nsoftware defect reports from NASA. Results were collected across different\nimplementations of LDA (Python+Scikit-Learn, Scala+Spark); across different\nplatforms (Linux, Macintosh) and for different kinds of LDAs (VEM,or using\nGibbs sampling). Results were scored via topic stability and text mining\nclassification accuracy. Results: In all treatments: (i) standard LDA exhibits\nvery large topic instability; (ii) LDADE's tunings dramatically reduce cluster\ninstability; (iii) LDADE also leads to improved performances for supervised as\nwell as unsupervised learning. Conclusion: Due to topic instability, using\nstandard LDA with its \"off-the-shelf\" settings should now be depreciated. Also,\nin future, we should require SE papers that use LDA to test and (if needed)\nmitigate LDA topic instability. Finally, LDADE is a candidate technology for\neffectively and efficiently reducing that instability.\n"]},
{"authors": ["Florian Kreyssig", "Chao Zhang", "Philip Woodland"], "title": ["Improved TDNNs using Deep Kernels and Frequency Dependent Grid-RNNs"], "date": ["2018-02-18T17:54:19Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06412v2"], "summary": ["  Time delay neural networks (TDNNs) are an effective acoustic model for large\nvocabulary speech recognition. The strength of the model can be attributed to\nits ability to effectively model long temporal contexts. However, current TDNN\nmodels are relatively shallow, which limits the modelling capability. This\npaper proposes a method of increasing the network depth by deepening the kernel\nused in the TDNN temporal convolutions. The best performing kernel consists of\nthree fully connected layers with a residual (ResNet) connection from the\noutput of the first to the output of the third. The addition of\nspectro-temporal processing as the input to the TDNN in the form of a\nconvolutional neural network (CNN) and a newly designed Grid-RNN was\ninvestigated. The Grid-RNN strongly outperforms a CNN if different sets of\nparameters for different frequency bands are used and can be further enhanced\nby using a bi-directional Grid-RNN. Experiments using the multi-genre broadcast\n(MGB3) English data (275h) show that deep kernel TDNNs reduces the word error\nrate (WER) by 6% relative and when combined with the frequency dependent\nGrid-RNN gives a relative WER reduction of 9%.\n"]},
{"authors": ["Ziming Li", "Artem Grotov", "Julia Kiseleva", "Maarten de Rijke", "Harrie Oosterhuis"], "title": ["Optimizing Interactive Systems with Data-Driven Objectives"], "date": ["2018-02-17T23:04:15Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06306v2"], "summary": ["  Effective optimization is essential for interactive systems to provide a\nsatisfactory user experience. However, it is often challenging to find an\nobjective to optimize for. Generally, such objectives are manually crafted and\nrarely capture complex user needs accurately. Conversely, we propose an\napproach that infers the objective directly from observed user interactions.\nThese inferences can be made regardless of prior knowledge and across different\ntypes of user behavior. Then we introduce: Interactive System Optimizer (ISO),\na novel algorithm that uses these inferred objectives for optimization. Our\nmain contribution is a new general principled approach to optimizing\ninteractive systems using data-driven objectives. We demonstrate the high\neffectiveness of ISO over several GridWorld simulations.\n"]},
{"authors": ["Rodrigo Marcos", "Oliva Garc\u00eda-Cant\u00fa", "Ricardo Herranz"], "title": ["A Machine Learning Approach to Air Traffic Route Choice Modelling"], "date": ["2018-02-19T11:25:18Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06588v2"], "summary": ["  Air Traffic Flow and Capacity Management (ATFCM) is one of the constituent\nparts of Air Traffic Management (ATM). The goal of ATFCM is to make airport and\nairspace capacity meet traffic demand and, when capacity opportunities are\nexhausted, optimise traffic flows to meet the available capacity. One of the\nkey enablers of ATFCM is the accurate estimation of future traffic demand. The\navailable information (schedules, flight plans, etc.) and its associated level\nof uncertainty differ across the different ATFCM planning phases, leading to\nqualitative differences between the types of forecasting that are feasible at\neach time horizon. While abundant research has been conducted on tactical\ntrajectory prediction (i.e., during the day of operations), trajectory\nprediction in the pre-tactical phase, when few or no flight plans are\navailable, has received much less attention. As a consequence, the methods\ncurrently in use for pre-tactical traffic forecast are still rather\nrudimentary, often resulting in suboptimal ATFCM decision making. This paper\nproposes a machine learning approach for the prediction of airlines route\nchoices between two airports as a function of route characteristics, such as\nflight efficiency, air navigation charges and expected level of congestion.\nDifferent predictive models based on multinomial logistic regression and\ndecision trees are formulated and calibrated with historical traffic data, and\na critical evaluation of each model is conducted. We analyse the predictive\npower of each model in terms of its ability to forecast traffic volumes at the\nlevel of charging zones, proving significant potential to enhance pre-tactical\ntraffic forecast. We conclude by discussing the limitations and room for\nimprovement of the proposed approach, as well as the future developments\nrequired to produce reliable traffic forecasts at a higher spatial and temporal\nresolution.\n"]},
{"authors": ["Baohan Xu", "Yanwei Fu", "Yu-Gang Jiang", "Boyang Li", "Leonid Sigal"], "title": ["Heterogeneous Knowledge Transfer in Video Emotion Recognition,\n  Attribution and Summarization"], "date": ["2015-11-16T01:40:15Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1511.04798v2"], "summary": ["  Emotion is a key element in user-generated videos. However, it is difficult\nto understand emotions conveyed in such videos due to the complex and\nunstructured nature of user-generated content and the sparsity of video frames\nexpressing emotion. In this paper, for the first time, we study the problem of\ntransferring knowledge from heterogeneous external sources, including image and\ntextual data, to facilitate three related tasks in understanding video emotion:\nemotion recognition, emotion attribution and emotion-oriented summarization.\nSpecifically, our framework (1) learns a video encoding from an auxiliary\nemotional image dataset in order to improve supervised video emotion\nrecognition, and (2) transfers knowledge from an auxiliary textual corpora for\nzero-shot recognition of emotion classes unseen during training. The proposed\ntechnique for knowledge transfer facilitates novel applications of emotion\nattribution and emotion-oriented summarization. A comprehensive set of\nexperiments on multiple datasets demonstrate the effectiveness of our\nframework.\n"]},
{"authors": ["Nicholas Carlini", "Guy Katz", "Clark Barrett", "David L. Dill"], "title": ["Provably Minimally-Distorted Adversarial Examples"], "date": ["2017-09-29T00:57:12Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1709.10207v2"], "summary": ["  The ability to deploy neural networks in real-world, safety-critical systems\nis severely limited by the presence of adversarial examples: slightly perturbed\ninputs that are misclassified by the network. In recent years, several\ntechniques have been proposed for increasing robustness to adversarial examples\n--- and yet most of these have been quickly shown to be vulnerable to future\nattacks. For example, over half of the defenses proposed by papers accepted at\nICLR 2018 have already been broken. We propose to address this difficulty\nthrough formal verification techniques. We show how to construct provably\nminimally distorted adversarial examples: given an arbitrary neural network and\ninput sample, we can construct adversarial examples which we prove are of\nminimal distortion. Using this approach, we demonstrate that one of the recent\nICLR defense proposals, adversarial retraining, provably succeeds at increasing\nthe distortion required to construct adversarial examples by a factor of 4.2.\n"]},
{"authors": ["Anagha Kulkarni", "Siddharth Srivastava", "Subbarao Kambhampati"], "title": ["Implicit Robot-Human Communication in Adversarial and Collaborative\n  Environments"], "date": ["2018-02-16T21:53:59Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06137v2"], "summary": ["  Users of AI systems may rely upon them to produce plans for achieving desired\nobjectives. Such AI systems should be able to compute obfuscated plans whose\nexecution in adversarial situations protects privacy as well as legible plans\nwhich are easy for team-members to understand in collaborative situations. We\ndevelop a unified framework that addresses these dual problems by computing\nplans with a desired level of comprehensibility from the point of view of a\npartially informed observer. Our approach produces obfuscated plans with\nobservations that are consistent with at least 'k' goals from a given set of\ndecoy goals. In addition, when the goal is known to the observer, our approach\ngenerates obfuscated plans with observations that are diverse with at least 'l'\ncandidate plans. Our approach for plan legibility produces plans that achieve a\ngoal while being consistent with at most 'j' goals in a given set of\nconfounding goals. We provide an empirical evaluation to show the feasibility\nand usefulness of our approaches.\n"]},
{"authors": ["Karim Said Barsim", "Lukas Mauch", "Bin Yang"], "title": ["Neural Network Ensembles to Real-time Identification of Plug-level\n  Appliance Measurements"], "date": ["2018-02-20T04:32:35Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06963v1"], "summary": ["  The problem of identifying end-use electrical appliances from their\nindividual consumption profiles, known as the appliance identification problem,\nis a primary stage in both Non-Intrusive Load Monitoring (NILM) and automated\nplug-wise metering. Therefore, appliance identification has received dedicated\nstudies with various electric appliance signatures, classification models, and\nevaluation datasets. In this paper, we propose a neural network ensembles\napproach to address this problem using high resolution measurements. The models\nare trained on the raw current and voltage waveforms, and thus, eliminating the\nneed for well engineered appliance signatures. We evaluate the proposed model\non a publicly available appliance dataset from 55 residential buildings, 11\nappliance categories, and over 1000 measurements. We further study the\nstability of the trained models with respect to training dataset, sampling\nfrequency, and variations in the steady-state operation of appliances.\n"]},
{"authors": ["Gribanova Irina", "Semenov Alexander"], "title": ["Using Automatic Generation of Relaxation Constraints to Improve the\n  Preimage Attack on 39-step MD4"], "date": ["2018-02-20T02:47:41Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06940v1"], "summary": ["  In this paper we construct preimage attack on the truncated variant of the\nMD4 hash function. Specifically, we study the MD4-39 function defined by the\nfirst 39 steps of the MD4 algorithm. We suggest a new attack on MD4-39, which\ndevelops the ideas proposed by H. Dobbertin in 1998. Namely, the special\nrelaxation constraints are introduced in order to simplify the equations\ncorresponding to the problem of finding a preimage for an arbitrary MD4-39 hash\nvalue. The equations supplemented with the relaxation constraints are then\nreduced to the Boolean Satisfiability Problem (SAT) and solved using the\nstate-of-the-art SAT solvers. We show that the effectiveness of a set of\nrelaxation constraints can be evaluated using the black-box function of a\nspecial kind. Thus, we suggest automatic method of relaxation constraints\ngeneration by applying the black-box optimization to this function. The\nproposed method made it possible to find new relaxation constraints that\ncontribute to a SAT-based preimage attack on MD4-39 which significantly\noutperforms the competition.\n"]},
{"authors": ["Liwei Cai", "William Yang Wang"], "title": ["KBGAN: Adversarial Learning for Knowledge Graph Embeddings"], "date": ["2017-11-11T03:46:53Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.04071v2"], "summary": ["  We introduce KBGAN, an adversarial learning framework to improve the\nperformances of a wide range of existing knowledge graph embedding models.\nBecause knowledge graphs typically only contain positive facts, sampling useful\nnegative training examples is a non-trivial task. Replacing the head or tail\nentity of a fact with a uniformly randomly selected entity is a conventional\nmethod for generating negative facts, but the majority of the generated\nnegative facts can be easily discriminated from positive facts, and will\ncontribute little towards the training. Inspired by generative adversarial\nnetworks (GANs), we use one knowledge graph embedding model as a negative\nsample generator to assist the training of our desired model, which acts as the\ndiscriminator in GANs. This framework is independent of the concrete form of\ngenerator and discriminator, and therefore can utilize a wide variety of\nknowledge graph embedding models as its building blocks. In experiments, we\nadversarially train two translation-based models, TransE and TransD, each with\nassistance from one of the two probability-based models, DistMult and ComplEx.\nWe evaluate the performances of KBGAN on the link prediction task, using three\nknowledge base completion datasets: FB15k-237, WN18 and WN18RR. Experimental\nresults show that adversarial training substantially improves the performances\nof target embedding models under various settings.\n"]},
{"authors": ["Yang Gao", "Shouyan Guo", "Kaimin Huang", "Jiaxin Chen", "Qian Gong", "Yang Zou", "Tong Bai", "Gary Overett"], "title": ["Scale Optimization for Full-Image-CNN Vehicle Detection"], "date": ["2018-02-20T00:54:15Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06926v1"], "summary": ["  Many state-of-the-art general object detection methods make use of shared\nfull-image convolutional features (as in Faster R-CNN). This achieves a\nreasonable test-phase computation time while enjoys the discriminative power\nprovided by large Convolutional Neural Network (CNN) models. Such designs excel\non benchmarks which contain natural images but which have very unnatural\ndistributions, i.e. they have an unnaturally high-frequency of the target\nclasses and a bias towards a \"friendly\" or \"dominant\" object scale. In this\npaper we present further study of the use and adaptation of the Faster R-CNN\nobject detection method for datasets presenting natural scale distribution and\nunbiased real-world object frequency. In particular, we show that better\nalignment of the detector scale sensitivity to the extant distribution improves\nvehicle detection performance. We do this by modifying both the selection of\nRegion Proposals, and through using more scale-appropriate full-image\nconvolution features within the CNN model. By selecting better scales in the\nregion proposal input and by combining feature maps through careful design of\nthe convolutional neural network, we improve performance on smaller objects. We\nsignificantly increase detection AP for the KITTI dataset car class from 76.3%\non our baseline Faster R-CNN detector to 83.6% in our improved detector.\n"]},
{"authors": ["James Foulds"], "title": ["Mixed Membership Word Embeddings for Computational Social Science"], "date": ["2017-05-20T23:45:54Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1705.07368v3"], "summary": ["  Word embeddings improve the performance of NLP systems by revealing the\nhidden structural relationships between words. Despite their success in many\napplications, word embeddings have seen very little use in computational social\nscience NLP tasks, presumably due to their reliance on big data, and to a lack\nof interpretability. I propose a probabilistic model-based word embedding\nmethod which can recover interpretable embeddings, without big data. The key\ninsight is to leverage mixed membership modeling, in which global\nrepresentations are shared, but individual entities (i.e. dictionary words) are\nfree to use these representations to uniquely differing degrees. I show how to\ntrain the model using a combination of state-of-the-art training techniques for\nword embeddings and topic models. The experimental results show an improvement\nin predictive language modeling of up to 63% in MRR over the skip-gram, and\ndemonstrate that the representations are beneficial for supervised learning. I\nillustrate the interpretability of the models with computational social science\ncase studies on State of the Union addresses and NIPS articles.\n"]},
{"authors": ["Sarath Sreedharan", "Siddharth Srivastava", "Subbarao Kambhampati"], "title": ["Hierarchical Expertise-Level Modeling for User Specific Robot-Behavior\n  Explanations"], "date": ["2018-02-19T22:35:13Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06895v1"], "summary": ["  There is a growing interest within the AI research community to develop\nautonomous systems capable of explaining their behavior to users. One aspect of\nthe explanation generation problem that has yet to receive much attention is\nthe task of explaining plans to users whose level of expertise differ from that\nof the explainer. We propose an approach for addressing this problem by\nrepresenting the user's model as an abstraction of the domain model that the\nplanner uses. We present algorithms for generating minimal explanations in\ncases where this abstract human model is not known. We reduce the problem of\ngenerating explanation to a search over the space of abstract models and\ninvestigate possible greedy approximations for minimal explanations. We also\nempirically show that our approach can efficiently compute explanations for a\nvariety of problems.\n"]},
{"authors": ["Matthew Fellows", "Kamil Ciosek", "Shimon Whiteson"], "title": ["Fourier Policy Gradients"], "date": ["2018-02-19T22:28:56Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06891v1"], "summary": ["  We propose a new way of deriving policy gradient updates for reinforcement\nlearning. Our technique, based on Fourier analysis, recasts integrals that\narise with expected policy gradients as convolutions and turns them into\nmultiplications. The obtained analytical solutions allow us to capture the low\nvariance benefits of EPG in a broad range of settings. For the critic, we treat\ntrigonometric and radial basis functions, two function families with the\nuniversal approximation property. The choice of policy can be almost arbitrary,\nincluding mixtures or hybrid continuous-discrete probability distributions.\nMoreover, we derive a general family of sample-based estimators for stochastic\npolicy gradients, which unifies existing results on sample-based approximation.\nWe believe that this technique has the potential to shape the next generation\nof policy gradient approaches, powered by analytical results.\n"]},
{"authors": ["Christoffer Holmg\u00e5rd", "Michael Cerny Green", "Antonios Liapis", "Julian Togelius"], "title": ["Automated Playtesting with Procedural Personas through MCTS with Evolved\n  Heuristics"], "date": ["2018-02-19T22:13:20Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06881v1"], "summary": ["  This paper describes a method for generative player modeling and its\napplication to the automatic testing of game content using archetypal player\nmodels called procedural personas. Theoretically grounded in psychological\ndecision theory, procedural personas are implemented using a variation of Monte\nCarlo Tree Search (MCTS) where the node selection criteria are developed using\nevolutionary computation, replacing the standard UCB1 criterion of MCTS. Using\nthese personas we demonstrate how generative player models can be applied to a\nvaried corpus of game levels and demonstrate how different play styles can be\nenacted in each level. In short, we use artificially intelligent personas to\nconstruct synthetic playtesters. The proposed approach could be used as a tool\nfor automatic play testing when human feedback is not readily available or when\nquick visualization of potential interactions is necessary. Possible\napplications include interactive tools during game development or procedural\ncontent generation systems where many evaluations must be conducted within a\nshort time span.\n"]},
{"authors": ["Ismail Kayali"], "title": ["Expert System for Diagnosis of Chest Diseases Using Neural Networks"], "date": ["2018-02-19T21:41:32Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06866v1"], "summary": ["  This article represents one of the contemporary trends in the application of\nthe latest methods of information and communication technology for medicine\nthrough an expert system helps the doctor to diagnose some chest diseases which\nis important because of the frequent spread of chest diseases nowadays in\naddition to the overlap symptoms of these diseases, which is difficult to right\ndiagnose by doctors with several algorithms: Forward Chaining, Backward\nChaining, Neural Network(Back Propagation). However, this system cannot replace\nthe doctor function, but it can help the doctor to avoid wrong diagnosis and\ntreatments. It can also be developed in such a way to help the novice doctors.\n"]},
{"authors": ["Nariman Farsad", "Milind Rao", "Andrea Goldsmith"], "title": ["Deep Learning for Joint Source-Channel Coding of Text"], "date": ["2018-02-19T20:11:36Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06832v1"], "summary": ["  We consider the problem of joint source and channel coding of structured data\nsuch as natural language over a noisy channel. The typical approach to this\nproblem in both theory and practice involves performing source coding to first\ncompress the text and then channel coding to add robustness for the\ntransmission across the channel. This approach is optimal in terms of\nminimizing end-to-end distortion with arbitrarily large block lengths of both\nthe source and channel codes when transmission is over discrete memoryless\nchannels. However, the optimality of this approach is no longer ensured for\ndocuments of finite length and limitations on the length of the encoding. We\nwill show in this scenario that we can achieve lower word error rates by\ndeveloping a deep learning based encoder and decoder. While the approach of\nseparate source and channel coding would minimize bit error rates, our approach\npreserves semantic information of sentences by first embedding sentences in a\nsemantic space where sentences closer in meaning are located closer together,\nand then performing joint source and channel coding on these embeddings.\n"]},
{"authors": ["V. Yu. Velychko", "K. S. Malakhov", "V. V. Semenkov", "A. E. Strizhak"], "title": ["Integrated Tools for Engineering Ontologies"], "date": ["2018-02-19T19:35:14Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06821v1"], "summary": ["  The article presents an overview of current specialized ontology engineering\ntools, as well as texts' annotation tools based on ontologies. The main\nfunctions and features of these tools, their advantages and disadvantages are\ndiscussed. A systematic comparative analysis of means for engineering\nontologies is presented.\n"]},
{"authors": ["Nilaksh Das", "Madhuri Shanbhogue", "Shang-Tse Chen", "Fred Hohman", "Siwei Li", "Li Chen", "Michael E. Kounavis", "Duen Horng Chau"], "title": ["Shield: Fast, Practical Defense and Vaccination for Deep Learning using\n  JPEG Compression"], "date": ["2018-02-19T19:13:42Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06816v1"], "summary": ["  The rapidly growing body of research in adversarial machine learning has\ndemonstrated that deep neural networks (DNNs) are highly vulnerable to\nadversarially generated images. This underscores the urgent need for practical\ndefense that can be readily deployed to combat attacks in real-time. Observing\nthat many attack strategies aim to perturb image pixels in ways that are\nvisually imperceptible, we place JPEG compression at the core of our proposed\nShield defense framework, utilizing its capability to effectively \"compress\naway\" such pixel manipulation. To immunize a DNN model from artifacts\nintroduced by compression, Shield \"vaccinates\" a model by re-training it with\ncompressed images, where different compression levels are applied to generate\nmultiple vaccinated models that are ultimately used together in an ensemble\ndefense. On top of that, Shield adds an additional layer of protection by\nemploying randomization at test time that compresses different regions of an\nimage using random compression levels, making it harder for an adversary to\nestimate the transformation performed. This novel combination of vaccination,\nensembling, and randomization makes Shield a fortified multi-pronged\nprotection. We conducted extensive, large-scale experiments using the ImageNet\ndataset, and show that our approaches eliminate up to 94% of black-box attacks\nand 98% of gray-box attacks delivered by the recent, strongest attacks, such as\nCarlini-Wagner's L2 and DeepFool. Our approaches are fast and work without\nrequiring knowledge about the model.\n"]},
{"authors": ["Seyed-Mohsen Moosavi-Dezfooli", "Ashish Shrivastava", "Oncel Tuzel"], "title": ["Divide, Denoise, and Defend against Adversarial Attacks"], "date": ["2018-02-19T19:01:56Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06806v1"], "summary": ["  Deep neural networks, although shown to be a successful class of machine\nlearning algorithms, are known to be extremely unstable to adversarial\nperturbations. Improving the robustness of neural networks against these\nattacks is important, especially for security-critical applications. To defend\nagainst such attacks, we propose dividing the input image into multiple\npatches, denoising each patch independently, and reconstructing the image,\nwithout losing significant image content. This proposed defense mechanism is\nnon-differentiable which makes it non-trivial for an adversary to apply\ngradient-based attacks. Moreover, we do not fine-tune the network with\nadversarial examples, making it more robust against unknown attacks. We present\na thorough analysis of the tradeoff between accuracy and robustness against\nadversarial attacks. We evaluate our method under black-box, grey-box, and\nwhite-box settings. The proposed method outperforms the state-of-the-art by a\nsignificant margin on the ImageNet dataset under grey-box attacks while\nmaintaining good accuracy on clean images. We also establish a strong baseline\nfor a novel white-box attack.\n"]},
{"authors": ["Patrick Bl\u00f6baum", "Dominik Janzing", "Takashi Washio", "Shohei Shimizu", "Bernhard Sch\u00f6lkopf"], "title": ["Analysis of Cause-Effect Inference via Regression Errors"], "date": ["2018-02-19T16:50:05Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06698v1"], "summary": ["  We address the problem of inferring the causal relation between two variables\nby comparing the least-squares errors of the predictions in both possible\ncausal directions. Under the assumption of an independence between the function\nrelating cause and effect, the conditional noise distribution, and the\ndistribution of the cause, we show that the errors are smaller in causal\ndirection if both variables are equally scaled and the causal relation is close\nto deterministic. Based on this, we provide an easily applicable algorithm that\nonly requires a regression in both possible causal directions and a comparison\nof the errors. The performance of the algorithm is compared with different\nrelated causal inference methods in various artificial and real-world data\nsets.\n"]},
{"authors": ["Mohammad Mehdi Keikha", "Maseud Rahgozar", "Masoud Asadpour"], "title": ["Community Aware Random Walk for Network Embedding"], "date": ["2017-10-14T15:37:07Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.05199v2"], "summary": ["  Social network analysis provides meaningful information about behavior of\nnetwork members that can be used for diverse applications such as\nclassification, link prediction. However, network analysis is computationally\nexpensive because of feature learning for different applications. In recent\nyears, many researches have focused on feature learning methods in social\nnetworks. Network embedding represents the network in a lower dimensional\nrepresentation space with the same properties which presents a compressed\nrepresentation of the network. In this paper, we introduce a novel algorithm\nnamed \"CARE\" for network embedding that can be used for different types of\nnetworks including weighted, directed and complex. Current methods try to\npreserve local neighborhood information of nodes, whereas the proposed method\nutilizes local neighborhood and community information of network nodes to cover\nboth local and global structure of social networks. CARE builds customized\npaths, which are consisted of local and global structure of network nodes, as a\nbasis for network embedding and uses the Skip-gram model to learn\nrepresentation vector of nodes. Subsequently, stochastic gradient descent is\napplied to optimize our objective function and learn the final representation\nof nodes. Our method can be scalable when new nodes are appended to network\nwithout information loss. Parallelize generation of customized random walks is\nalso used for speeding up CARE. We evaluate the performance of CARE on multi\nlabel classification and link prediction tasks. Experimental results on various\nnetworks indicate that the proposed method outperforms others in both Micro and\nMacro-f1 measures for different size of training data.\n"]},
{"authors": ["Riccardo Guidotti", "Anna Monreale", "Franco Turini", "Dino Pedreschi", "Fosca Giannotti"], "title": ["A Survey Of Methods For Explaining Black Box Models"], "date": ["2018-02-06T13:20:02Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.01933v2"], "summary": ["  In the last years many accurate decision support systems have been\nconstructed as black boxes, that is as systems that hide their internal logic\nto the user. This lack of explanation constitutes both a practical and an\nethical issue. The literature reports many approaches aimed at overcoming this\ncrucial weakness sometimes at the cost of scarifying accuracy for\ninterpretability. The applications in which black box decision systems can be\nused are various, and each approach is typically developed to provide a\nsolution for a specific problem and, as a consequence, delineating explicitly\nor implicitly its own definition of interpretability and explanation. The aim\nof this paper is to provide a classification of the main problems addressed in\nthe literature with respect to the notion of explanation and the type of black\nbox system. Given a problem definition, a black box type, and a desired\nexplanation this survey should help the researcher to find the proposals more\nuseful for his own work. The proposed classification of approaches to open\nblack box models should also be useful for putting the many research open\nquestions in perspective.\n"]},
{"authors": ["Filipe Alves Neto Verri", "Paulo Roberto Urio", "Liang Zhao"], "title": ["Network Unfolding Map by Edge Dynamics Modeling"], "date": ["2016-03-03T17:11:23Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1603.01182v2"], "summary": ["  The emergence of collective dynamics in neural networks is a mechanism of the\nanimal and human brain for information processing. In this paper, we develop a\ncomputational technique using distributed processing elements in a complex\nnetwork, which are called particles, to solve semi-supervised learning\nproblems. Three actions govern the particles' dynamics: generation, walking,\nand absorption. Labeled vertices generate new particles that compete against\nrival particles for edge domination. Active particles randomly walk in the\nnetwork until they are absorbed by either a rival vertex or an edge currently\ndominated by rival particles. The result from the model evolution consists of\nsets of edges arranged by the label dominance. Each set tends to form a\nconnected subnetwork to represent a data class. Although the intrinsic dynamics\nof the model is a stochastic one, we prove there exists a deterministic version\nwith largely reduced computational complexity; specifically, with linear\ngrowth. Furthermore, the edge domination process corresponds to an unfolding\nmap in such way that edges \"stretch\" and \"shrink\" according to the vertex-edge\ndynamics. Consequently, the unfolding effect summarizes the relevant\nrelationships between vertices and the uncovered data classes. The proposed\nmodel captures important details of connectivity patterns over the vertex-edge\ndynamics evolution, in contrast to previous approaches which focused on only\nvertex or only edge dynamics. Computer simulations reveal that the new model\ncan identify nonlinear features in both real and artificial data, including\nboundaries between distinct classes and overlapping structures of data.\n"]},
{"authors": ["Lars Mescheder", "Andreas Geiger", "Sebastian Nowozin"], "title": ["Which Training Methods for GANs do actually Converge?"], "date": ["2018-01-13T09:42:26Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.04406v2"], "summary": ["  Recent work has shown local convergence of GAN training for absolutely\ncontinuous data and generator distributions. In this paper, we show that the\nrequirement of absolute continuity is necessary: we describe a simple yet\nprototypical counterexample showing that in the more realistic case of\ndistributions that are not absolutely continuous, unregularized GAN training is\nnot always convergent. Furthermore, we discuss regularization strategies that\nwere recently proposed to stabilize GAN training. Our analysis shows that GAN\ntraining with instance noise or zero-centered gradient penalties converges. On\nthe other hand, we show that Wasserstein-GANs and WGAN-GP with a finite number\nof discriminator updates per generator update do not always converge to the\nequilibrium point. We discuss these results, leading us to a new explanation\nfor the stability problems of GAN training. Based on our analysis, we extend\nour convergence results to more general GANs and prove local convergence for\nsimplified gradient penalties even if the generator and data distribution lie\non lower dimensional manifolds. We find these penalties to work well in\npractice and use them to learn a generative image model of all 1000 Imagenet\nclasses in a single GAN with little hyperparameter tuning.\n"]},
{"authors": ["Vladimir Marochko", "Leonard Johard", "Manuel Mazzara", "Luca Longo"], "title": ["Pseudorehearsal in actor-critic agents with neural network function\n  approximation"], "date": ["2017-12-20T19:53:23Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1712.07686v2"], "summary": ["  Catastrophic forgetting has a significant negative impact in reinforcement\nlearning. The purpose of this study is to investigate how pseudorehearsal can\nchange performance of an actor-critic agent with neural-network function\napproximation. We tested agent in a pole balancing task and compared different\npseudorehearsal approaches. We have found that pseudorehearsal can assist\nlearning and decrease forgetting.\n"]},
{"authors": ["Chang-Shing Lee", "Mei-Hui Wang", "Li-Wei Ko", "Naoyuki Kubota", "Lu-An Lin", "Shinya Kitaoka", "Yu-Te Wang", "Shun-Feng Su"], "title": ["Human and Smart Machine Co-Learning with Brain Computer Interface"], "date": ["2018-02-19T05:42:09Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06521v1"], "summary": ["  Machine learning has become a very popular approach for cybernetics systems,\nand it has always been considered important research in the Computational\nIntelligence area. Nevertheless, when it comes to smart machines, it is not\njust about the methodologies. We need to consider systems and cybernetics as\nwell as include human in the loop. The purpose of this article is as follows:\n(1) To integrate the open source Facebook AI Research (FAIR) DarkForest program\nof Facebook with Item Response Theory (IRT), to the new open learning system,\nnamely, DDF learning system; (2) To integrate DDF Go with Robot namely Robotic\nDDF Go system; (3) To invite the professional Go players to attend the activity\nto play Go games on site with a smart machine. The research team will apply\nthis technology to education, such as, playing games to enhance the children\nconcentration on learning mathematics, languages, and other topics. With the\ndetected brainwaves, the robot will be able to speak some words that are very\nmuch to the point for the students and to assist the teachers in classroom in\nthe future.\n"]},
{"authors": ["Yikang Shen", "Zhouhan Lin", "Chin-Wei Huang", "Aaron Courville"], "title": ["Neural Language Modeling by Jointly Learning Syntax and Lexicon"], "date": ["2017-11-02T23:02:52Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.02013v2"], "summary": ["  We propose a neural language model capable of unsupervised syntactic\nstructure induction. The model leverages the structure information to form\nbetter semantic representations and better language modeling. Standard\nrecurrent neural networks are limited by their structure and fail to\nefficiently use syntactic information. On the other hand, tree-structured\nrecursive networks usually require additional structural supervision at the\ncost of human expert annotation. In this paper, We propose a novel neural\nlanguage model, called the Parsing-Reading-Predict Networks (PRPN), that can\nsimultaneously induce the syntactic structure from unannotated sentences and\nleverage the inferred structure to learn a better language model. In our model,\nthe gradient can be directly back-propagated from the language model loss into\nthe neural parsing network. Experiments show that the proposed model can\ndiscover the underlying syntactic structure and achieve state-of-the-art\nperformance on word/character-level language model tasks.\n"]},
{"authors": ["Alexander Wong", "Mohammad Javad Shafiee", "Francis Li", "Brendan Chwyl"], "title": ["Tiny SSD: A Tiny Single-shot Detection Deep Convolutional Neural Network\n  for Real-time Embedded Object Detection"], "date": ["2018-02-19T01:57:46Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06488v1"], "summary": ["  Object detection is a major challenge in computer vision, involving both\nobject classification and object localization within a scene. While deep neural\nnetworks have been shown in recent years to yield very powerful techniques for\ntackling the challenge of object detection, one of the biggest challenges with\nenabling such object detection networks for widespread deployment on embedded\ndevices is high computational and memory requirements. Recently, there has been\nan increasing focus in exploring small deep neural network architectures for\nobject detection that are more suitable for embedded devices, such as Tiny YOLO\nand SqueezeDet. Inspired by the efficiency of the Fire microarchitecture\nintroduced in SqueezeNet and the object detection performance of the\nsingle-shot detection macroarchitecture introduced in SSD, this paper\nintroduces Tiny SSD, a single-shot detection deep convolutional neural network\nfor real-time embedded object detection that is composed of a highly optimized,\nnon-uniform Fire sub-network stack and a non-uniform sub-network stack of\nhighly optimized SSD-based auxiliary convolutional feature layers designed\nspecifically to minimize model size while maintaining object detection\nperformance. The resulting Tiny SSD possess a model size of 2.3MB (~26X smaller\nthan Tiny YOLO) while still achieving an mAP of 61.3% on VOC 2007 (~4.2% higher\nthan Tiny YOLO). These experimental results show that very small deep neural\nnetwork architectures can be designed for real-time object detection that are\nwell-suited for embedded scenarios.\n"]},
{"authors": ["Adarsh Prasad", "Arun Sai Suggala", "Sivaraman Balakrishnan", "Pradeep Ravikumar"], "title": ["Robust Estimation via Robust Gradient Estimation"], "date": ["2018-02-19T01:49:31Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06485v1"], "summary": ["  We provide a new computationally-efficient class of estimators for risk\nminimization. We show that these estimators are robust for general statistical\nmodels: in the classical Huber epsilon-contamination model and in heavy-tailed\nsettings. Our workhorse is a novel robust variant of gradient descent, and we\nprovide conditions under which our gradient descent variant provides accurate\nestimators in a general convex risk minimization problem. We provide specific\nconsequences of our theory for linear regression, logistic regression and for\nestimation of the canonical parameters in an exponential family. These results\nprovide some of the first computationally tractable and provably robust\nestimators for these canonical statistical models. Finally, we study the\nempirical performance of our proposed methods on synthetic and real datasets,\nand find that our methods convincingly outperform a variety of baselines.\n"]},
{"authors": ["Qingkai Liang", "Fanyu Que", "Eytan Modiano"], "title": ["Accelerated Primal-Dual Policy Optimization for Safe Reinforcement\n  Learning"], "date": ["2018-02-19T01:25:26Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06480v1"], "summary": ["  Constrained Markov Decision Process (CMDP) is a natural framework for\nreinforcement learning tasks with safety constraints, where agents learn a\npolicy that maximizes the long-term reward while satisfying the constraints on\nthe long-term cost. A canonical approach for solving CMDPs is the primal-dual\nmethod which updates parameters in primal and dual spaces in turn. Existing\nmethods for CMDPs only use on-policy data for dual updates, which results in\nsample inefficiency and slow convergence. In this paper, we propose a policy\nsearch method for CMDPs called Accelerated Primal-Dual Optimization (APDO),\nwhich incorporates an off-policy trained dual variable in the dual update\nprocedure while updating the policy in primal space with on-policy likelihood\nratio gradient. Experimental results on a simulated robot locomotion task show\nthat APDO achieves better sample efficiency and faster convergence than\nstate-of-the-art approaches for CMDPs.\n"]},
{"authors": ["Bin Liu", "Ying Li", "Soumya Ghosh", "Zhaonan Sun", "Kenney Ng", "Jianying Hu"], "title": ["Simultaneous Modeling of Multiple Complications for Risk Profiling in\n  Diabetes Care"], "date": ["2018-02-19T01:01:33Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06476v1"], "summary": ["  Type 2 diabetes mellitus (T2DM) is a chronic disease that often results in\nmultiple complications. Risk prediction and profiling of T2DM complications is\ncritical for healthcare professionals to design personalized treatment plans\nfor patients in diabetes care for improved outcomes. In this paper, we study\nthe risk of developing complications after the initial T2DM diagnosis from\nlongitudinal patient records. We propose a novel multi-task learning approach\nto simultaneously model multiple complications where each task corresponds to\nthe risk modeling of one complication. Specifically, the proposed method\nstrategically captures the relationships (1) between the risks of multiple T2DM\ncomplications, (2) between the different risk factors, and (3) between the risk\nfactor selection patterns. The method uses coefficient shrinkage to identify an\ninformative subset of risk factors from high-dimensional data, and uses a\nhierarchical Bayesian framework to allow domain knowledge to be incorporated as\npriors. The proposed method is favorable for healthcare applications because in\nadditional to improved prediction performance, relationships among the\ndifferent risks and risk factors are also identified. Extensive experimental\nresults on a large electronic medical claims database show that the proposed\nmethod outperforms state-of-the-art models by a significant margin.\nFurthermore, we show that the risk associations learned and the risk factors\nidentified lead to meaningful clinical insights.\n"]},
{"authors": ["Adam Li\u0161ka", "Germ\u00e1n Kruszewski", "Marco Baroni"], "title": ["Memorize or generalize? Searching for a compositional RNN in a haystack"], "date": ["2018-02-18T23:15:26Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06467v1"], "summary": ["  Neural networks are very powerful learning systems, but they do not readily\ngeneralize from one task to the other. This is partly due to the fact that they\ndo not learn in a compositional way, that is, by discovering skills that are\nshared by different tasks, and recombining them to solve new problems. In this\npaper, we explore the compositional generalization capabilities of recurrent\nneural networks (RNNs). We first propose the lookup table composition domain as\na simple setup to test compositional behaviour and show that it is\ntheoretically possible for a standard RNN to learn to behave compositionally in\nthis domain when trained with standard gradient descent and provided with\nadditional supervision. We then remove this additional supervision and perform\na search over a large number of model initializations to investigate the\nproportion of RNNs that can still converge to a compositional solution. We\ndiscover that a small but non-negligible proportion of RNNs do reach partial\ncompositional solutions even without special architectural constraints. This\nsuggests that a combination of gradient descent and evolutionary strategies\ndirectly favouring the minority models that developed more compositional\napproaches might suffice to lead standard RNNs towards compositional solutions.\n"]},
{"authors": ["Kaixiang Lin", "Renyu Zhao", "Zhe Xu", "Jiayu Zhou"], "title": ["Efficient Large-Scale Fleet Management via Multi-Agent Deep\n  Reinforcement Learning"], "date": ["2018-02-18T21:06:19Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06444v1"], "summary": ["  Large-scale online ride-sharing platforms have substantially transformed our\nlives by reallocating transportation resources to alleviate traffic congestion\nand promote transportation efficiency. An efficient fleet management strategy\nnot only can significantly improve the utilization of transportation resources\nbut also increase the revenue and customer satisfaction. It is a challenging\ntask to design an effective fleet management strategy that can adapt to an\nenvironment involving complex dynamics between demand and supply. Existing\nstudies usually work on a simplified problem setting that can hardly capture\nthe complicated stochastic demand-supply variations in high-dimensional space.\nIn this paper we propose to tackle the large-scale fleet management problem\nusing reinforcement learning, and propose a contextual multi-agent\nreinforcement learning framework including two concrete algorithms, namely\ncontextual deep Q-learning and contextual multi-agent actor-critic, to achieve\nexplicit coordination among a large number of agents adaptive to different\ncontexts. We show significant improvements of the proposed framework over\nstate-of-the-art approaches through extensive empirical studies.\n"]},
{"authors": ["Zoran Tiganj", "Samuel J. Gershman", "Per B. Sederberg", "Marc W. Howard"], "title": ["Estimating scale-invariant future in continuous time"], "date": ["2018-02-18T19:09:28Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06426v1"], "summary": ["  Natural learners must compute an estimate of future outcomes that follow from\na stimulus in continuous time. Critically, the learner cannot in general know a\npriori the relevant time scale over which meaningful relationships will be\nobserved. Widely used reinforcement learning algorithms discretize continuous\ntime and use the Bellman equation to estimate exponentially-discounted future\nreward. However, exponential discounting introduces a time scale to the\ncomputation of value. Scaling is a serious problem in continuous time:\nefficient learning with scaled algorithms requires prior knowledge of the\nrelevant scale. That is, with scaled algorithms one must know at least part of\nthe solution to a problem prior to attempting a solution. We present a\ncomputational mechanism, developed based on work in psychology and\nneuroscience, for computing a scale-invariant timeline of future events. This\nmechanism efficiently computes a model for future time on a\nlogarithmically-compressed scale, and can be used to generate a scale-invariant\npower-law-discounted estimate of expected future reward. Moreover, the\nrepresentation of future time retains information about what will happen when,\nenabling flexible decision making based on future events. The entire timeline\ncan be constructed in a single parallel operation.\n"]},
{"authors": ["Yongxi Tan", "Jin Yang", "Xin Chen", "Qitao Song", "Yunjun Chen", "Zhangxiang Ye", "Zhenqiang Su"], "title": ["Sim-To-Real Optimization Of Complex Real World Mobile Network with\n  Imperfect Information via Deep Reinforcement Learning from Self-play"], "date": ["2018-02-18T18:03:39Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06416v1"], "summary": ["  Mobile network that millions of people use every day is one of the most\ncomplex systems in real world. Optimization of mobile network to meet exploding\ncustomer demand and reduce CAPEX/OPEX poses greater challenges than in prior\nworks. Learning to solve complex problems in real world to benefit everyone and\nmake the world better has long been ultimate goal of AI. However, it still\nremains an unsolved problem for deep reinforcement learning (DRL), given\nimperfect information in real world, huge state/action space, lots of data\nneeded for training, associated time/cost, multi-agent interactions, potential\nnegative impact to real world, etc. To bridge this reality gap, we proposed a\nDRL framework to direct transfer optimal policy learned from multi-tasks in\nsource domain to unseen similar tasks in target domain without any further\ntraining in both domains. First, we distilled temporal-spatial relationships\nbetween cells and mobile users to scalable 3D image-like tensor to best\ncharacterize partially observed mobile network. Second, inspired by AlphaGo, we\nused a novel self-play mechanism to empower DRL agent to gradually improve its\nintelligence by competing for best record on multiple tasks. Third, a\ndecentralized DRL method is proposed to coordinate multi-agents to compete and\ncooperate as a team to maximize global reward and minimize potential negative\nimpact. Using 7693 unseen test tasks over 160 unseen simulated mobile networks\nand 6 field trials over 4 commercial mobile networks in real world, we\ndemonstrated the capability of our approach to direct transfer the learning\nfrom one simulator to another simulator, and from simulation to real world.\nThis is the first time that a DRL agent successfully transfers its learning\ndirectly from simulation to very complex real world problems with incomplete\nand imperfect information, huge state/action space and multi-agent\ninteractions.\n"]},
{"authors": ["Yunwen Lei", "Ding-Xuan Zhou"], "title": ["Convergence of Online Mirror Descent Algorithms"], "date": ["2018-02-18T09:36:09Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06357v1"], "summary": ["  In this paper we consider online mirror descent (OMD) algorithms, a class of\nscalable online learning algorithms exploiting data geometric structures\nthrough mirror maps. Necessary and sufficient conditions are presented in terms\nof the step size sequence $\\{\\eta_t\\}_{t}$ for the convergence of an OMD\nalgorithm with respect to the expected Bregman distance induced by the mirror\nmap. The condition is $\\lim_{t\\to\\infty}\\eta_t=0,\n\\sum_{t=1}^{\\infty}\\eta_t=\\infty$ in the case of positive variances. It is\nreduced to $\\sum_{t=1}^{\\infty}\\eta_t=\\infty$ in the case of zero variances for\nwhich the linear convergence may be achieved by taking a constant step size\nsequence. A sufficient condition on the almost sure convergence is also given.\nWe establish tight error bounds under mild conditions on the mirror map, the\nloss function, and the regularizer. Our results are achieved by some novel\nanalysis on the one-step progress of the OMD algorithm using smoothness and\nstrong convexity of the mirror map and the loss function.\n"]},
{"authors": ["Sneha Kudugunta", "Emilio Ferrara"], "title": ["Deep Neural Networks for Bot Detection"], "date": ["2018-02-12T19:00:15Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04289v2"], "summary": ["  The problem of detecting bots, automated social media accounts governed by\nsoftware but disguising as human users, has strong implications. For example,\nbots have been used to sway political elections by distorting online discourse,\nto manipulate the stock market, or to push anti-vaccine conspiracy theories\nthat caused health epidemics. Most techniques proposed to date detect bots at\nthe account level, by processing large amount of social media posts, and\nleveraging information from network structure, temporal dynamics, sentiment\nanalysis, etc.\n  In this paper, we propose a deep neural network based on contextual long\nshort-term memory (LSTM) architecture that exploits both content and metadata\nto detect bots at the tweet level: contextual features are extracted from user\nmetadata and fed as auxiliary input to LSTM deep nets processing the tweet\ntext.\n  Another contribution that we make is proposing a technique based on synthetic\nminority oversampling to generate a large labeled dataset, suitable for deep\nnets training, from a minimal amount of labeled data (roughly 3,000 examples of\nsophisticated Twitter bots). We demonstrate that, from just one single tweet,\nour architecture can achieve high classification accuracy (AUC > 96%) in\nseparating bots from humans.\n  We apply the same architecture to account-level bot detection, achieving\nnearly perfect classification accuracy (AUC > 99%). Our system outperforms\nprevious state of the art while leveraging a small and interpretable set of\nfeatures yet requiring minimal training data.\n"]},
{"authors": ["Matheus Nohra Haddad", "Rafael Martinelli", "Thibaut Vidal", "Luiz Satoru Ochi", "Simone Martins", "Marcone Jamilson Freitas Souza", "Richard Hartl"], "title": ["Large Neighborhood-Based Metaheuristic and Branch-and-Price for the\n  Pickup and Delivery Problem with Split Loads"], "date": ["2018-02-18T02:09:20Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06318v1"], "summary": ["  We consider the multi-vehicle one-to-one pickup and delivery problem with\nsplit loads, a NP-hard problem linked with a variety of applications for bulk\nproduct transportation, bike-sharing systems and inventory re-balancing. This\nproblem is notoriously difficult due to the interaction of two challenging\nvehicle routing attributes, \"pickups and deliveries\" and \"split deliveries\".\nThis possibly leads to optimal solutions of a size that grows exponentially\nwith the instance size, containing multiple visits per customer pair, even in\nthe same route. To solve this problem, we propose an iterated local search\nmetaheuristic as well as a branch-and-price algorithm. The core of the\nmetaheuristic consists of a new large neighborhood search, which reduces the\nproblem of finding the best insertion combination of a pickup and delivery pair\ninto a route (with possible splits) to a resource-constrained shortest path and\nknapsack problem. Similarly, the branch-and-price algorithm uses sophisticated\nlabeling techniques, route relaxations, pre-processing and branching rules for\nan efficient resolution. Our computational experiments on classical\nsingle-vehicle instances demonstrate the excellent performance of the\nmetaheuristic, which produces new best known solutions for 92 out of 93 test\ninstances, and outperforms all previous algorithms. Experimental results on new\nmulti-vehicle instances with distance constraints are also reported. The\nbranch-and-price algorithm produces optimal solutions for instances with up to\n20 pickup-and-delivery pairs, and very accurate solutions are found by the\nmetaheuristic.\n"]},
{"authors": ["Sarah Thornton"], "title": ["Autonomous Vehicle Speed Control for Safe Navigation of Occluded\n  Pedestrian Crosswalk"], "date": ["2018-02-18T00:18:01Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06314v1"], "summary": ["  Both humans and the sensors on an autonomous vehicle have limited sensing\ncapabilities. When these limitations coincide with scenarios involving\nvulnerable road users, it becomes important to account for these limitations in\nthe motion planner. For the scenario of an occluded pedestrian crosswalk, the\nspeed of the approaching vehicle should be a function of the amount of\nuncertainty on the roadway. In this work, the longitudinal controller is\nformulated as a partially observable Markov decision process and dynamic\nprogramming is used to compute the control policy. The control policy scales\nthe speed profile to be used by a model predictive steering controller.\n"]},
{"authors": ["Lingyang Chu", "Xia Hu", "Juhua Hu", "Lanjun Wang", "Jian Pei"], "title": ["Exact and Consistent Interpretation for Piecewise Linear Neural\n  Networks: A Closed Form Solution"], "date": ["2018-02-17T16:47:32Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06259v1"], "summary": ["  Strong intelligent machines powered by deep neural networks are increasingly\ndeployed as black boxes to make decisions in risk-sensitive domains, such as\nfinance and medical. To reduce potential risk and build trust with users, it is\ncritical to interpret how such machines make their decisions. Existing works\ninterpret a pre-trained neural network by analyzing hidden neurons, mimicking\npre-trained models or approximating local predictions. However, these methods\ndo not provide a guarantee on the exactness and consistency of their\ninterpretation. In this paper, we propose an elegant closed form solution named\n$OpenBox$ to compute exact and consistent interpretations for the family of\nPiecewise Linear Neural Networks (PLNN). The major idea is to first transform a\nPLNN into a mathematically equivalent set of linear classifiers, then interpret\neach linear classifier by the features that dominate its prediction. We further\napply $OpenBox$ to demonstrate the effectiveness of non-negative and sparse\nconstraints on improving the interpretability of PLNNs. The extensive\nexperiments on both synthetic and real world data sets clearly demonstrate the\nexactness and consistency of our interpretation.\n"]},
{"authors": ["Dheeraj Mekala", "Vivek Gupta", "Purushottam Kar", "Harish Karnick"], "title": ["Bayes-optimal Hierarchical Classification over Asymmetric Tree-Distance\n  Loss"], "date": ["2018-02-17T12:51:06Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06771v1"], "summary": ["  Hierarchical classification is supervised multi-class classification problem\nover the set of class labels organized according to a hierarchy. In this\nreport, we study the work by Ramaswamy et. al. on hierarchical classification\nover symmetric tree distance loss. We extend the consistency of hierarchical\nclassification algorithm over asymmetric tree distance loss. We design a\n$\\mathcal{O}(nk\\log{}n)$ algorithm to find Bayes optimal classification for a\nk-ary tree as a hierarchy. We show that under reasonable assumptions over\nasymmetric loss function, the Bayes optimal classification over this asymmetric\nloss can be found in $\\mathcal{O}(k\\log{}n)$. We exploit this insight and\nattempt to extend the Ova-Cascade algorithm \\citet{ramaswamy2015convex} for\nhierarchical classification over the asymmetric loss.\n"]},
{"authors": ["Petros Giannakopoulos", "Yannis Cotronis"], "title": ["A Deep Q-Learning Agent for the L-Game with Variable Batch Training"], "date": ["2018-02-17T11:45:09Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06225v1"], "summary": ["  We employ the Deep Q-Learning algorithm with Experience Replay to train an\nagent capable of achieving a high-level of play in the L-Game while\nself-learning from low-dimensional states. We also employ variable batch size\nfor training in order to mitigate the loss of the rare reward signal and\nsignificantly accelerate training. Despite the large action space due to the\nnumber of possible moves, the low-dimensional state space and the rarity of\nrewards, which only come at the end of a game, DQL is successful in training an\nagent capable of strong play without the use of any search methods or domain\nknowledge.\n"]},
{"authors": ["A. V. Palagin", "N. G. Petrenko", "K. S. Malakhov"], "title": ["Technique for designing a domain ontology"], "date": ["2018-02-17T10:58:59Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06769v1"], "summary": ["  The article describes the technique for designing a domain ontology, shows\nthe flowchart of algorithm design and example of constructing a fragment of the\nontology of the subject area of Computer Science is considered.\n"]},
{"authors": ["Panpan Cai", "Yuanfu Luo", "David Hsu", "Wee Sun Lee"], "title": ["HyP-DESPOT: A Hybrid Parallel Algorithm for Online Planning under\n  Uncertainty"], "date": ["2018-02-17T08:59:56Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06215v1"], "summary": ["  Planning under uncertainty is critical for robust robot performance in\nuncertain, dynamic environments, but it incurs high computational cost.\nState-of-the-art online search algorithms, such as DESPOT, have vastly improved\nthe computational efficiency of planning under uncertainty and made it a\nvaluable tool for robotics in practice. This work takes one step further by\nleveraging both CPU and GPU parallelization in order to achieve near real-time\nonline planning performance for complex tasks with large state, action, and\nobservation spaces. Specifically, we propose Hybrid Parallel DESPOT\n(HyP-DESPOT), a massively parallel online planning algorithm that integrates\nCPU and GPU parallelism in a multi-level scheme. It performs parallel DESPOT\ntree search by simultaneously traversing multiple independent paths using\nmulti-core CPUs and performs parallel Monte-Carlo simulations at the leaf nodes\nof the search tree using GPUs. Experimental results show that HyP-DESPOT speeds\nup online planning by up to several hundred times, compared with the original\nDESPOT algorithm, in several challenging robotic tasks in simulation.\n"]},
{"authors": ["Rafael Oliveira", "Lionel Ott", "Vitor Guizilini", "Fabio Ramos"], "title": ["Bayesian Optimisation for Safe Navigation under Localisation Uncertainty"], "date": ["2017-09-07T10:17:52Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1709.02169v2"], "summary": ["  In outdoor environments, mobile robots are required to navigate through\nterrain with varying characteristics, some of which might significantly affect\nthe integrity of the platform. Ideally, the robot should be able to identify\nareas that are safe for navigation based on its own percepts about the\nenvironment while avoiding damage to itself. Bayesian optimisation (BO) has\nbeen successfully applied to the task of learning a model of terrain\ntraversability while guiding the robot through more traversable areas. An\nissue, however, is that localisation uncertainty can end up guiding the robot\nto unsafe areas and distort the model being learnt. In this paper, we address\nthis problem and present a novel method that allows BO to consider localisation\nuncertainty by applying a Gaussian process model for uncertain inputs as a\nprior. We evaluate the proposed method in simulation and in experiments with a\nreal robot navigating over rough terrain and compare it against standard BO\nmethods.\n"]},
{"authors": ["Scott M. Lundberg", "Su-In Lee"], "title": ["Consistent feature attribution for tree ensembles"], "date": ["2017-06-19T17:03:46Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1706.06060v6"], "summary": ["  Note that a newer expanded version of this paper is now available at:\narXiv:1802.03888\n  It is critical in many applications to understand what features are important\nfor a model, and why individual predictions were made. For tree ensemble\nmethods these questions are usually answered by attributing importance values\nto input features, either globally or for a single prediction. Here we show\nthat current feature attribution methods are inconsistent, which means changing\nthe model to rely more on a given feature can actually decrease the importance\nassigned to that feature. To address this problem we develop fast exact\nsolutions for SHAP (SHapley Additive exPlanation) values, which were recently\nshown to be the unique additive feature attribution method based on conditional\nexpectations that is both consistent and locally accurate. We integrate these\nimprovements into the latest version of XGBoost, demonstrate the\ninconsistencies of current methods, and show how using SHAP values results in\nsignificantly improved supervised clustering performance. Feature importance\nvalues are a key part of understanding widely used models such as gradient\nboosting trees and random forests, so improvements to them have broad practical\nimplications.\n"]},
{"authors": ["Vijay Kamble", "David Marn", "Nihar Shah", "Abhay Parekh", "Kannan Ramachandran"], "title": ["A Truth Serum for Large-Scale Evaluations"], "date": ["2015-07-25T00:41:00Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1507.07045v4"], "summary": ["  A major challenge in obtaining large-scale evaluations, e.g., product or\nservice reviews on online platforms, labeling images, grading in online\ncourses, etc., is that of eliciting honest responses from agents in the absence\nof verifiability. We propose a new reward mechanism with strong incentive\nproperties applicable in a wide variety of such settings. This mechanism has a\nsimple and intuitive output agreement structure: an agent gets a reward only if\nher response for an evaluation matches that of her peer. But instead of the\nreward being the same across different answers, it is inversely proportional to\na popularity index of each answer. This index is a second order population\nstatistic that captures how frequently two agents performing the same\nevaluation agree on the particular answer. Rare agreements thus earn a higher\nreward than agreements that are relatively more common.\n  In the regime where there are a large number of evaluation tasks, we show\nthat truthful behavior is a strict Bayes-Nash equilibrium of the game induced\nby the mechanism. Further, we show that the truthful equilibrium is\napproximately optimal in terms of expected payoffs to the agents across all\nsymmetric equilibria, where the approximation error vanishes in the number of\nevaluation tasks. Moreover, under a mild condition on strategy space, we show\nthat any symmetric equilibrium that gives a higher expected payoff than the\ntruthful equilibrium must be close to being fully informative if the number of\nevaluations is large. These last two results are driven by a new notion of an\nagreement measure that is shown to be monotonic in information loss. This\nnotion and its properties are of independent interest.\n"]},
{"authors": ["Jaden B. Travnik", "Kory W. Mathewson", "Richard S. Sutton", "Patrick M. Pilarski"], "title": ["Reactive Reinforcement Learning in Asynchronous Environments"], "date": ["2018-02-16T21:55:01Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06139v1"], "summary": ["  The relationship between a reinforcement learning (RL) agent and an\nasynchronous environment is often ignored. Frequently used models of the\ninteraction between an agent and its environment, such as Markov Decision\nProcesses (MDP) or Semi-Markov Decision Processes (SMDP), do not capture the\nfact that, in an asynchronous environment, the state of the environment may\nchange during computation performed by the agent. In an asynchronous\nenvironment, minimizing reaction time---the time it takes for an agent to react\nto an observation---also minimizes the time in which the state of the\nenvironment may change following observation. In many environments, the\nreaction time of an agent directly impacts task performance by permitting the\nenvironment to transition into either an undesirable terminal state or a state\nwhere performing the chosen action is inappropriate. We propose a class of\nreactive reinforcement learning algorithms that address this problem of\nasynchronous environments by immediately acting after observing new state\ninformation. We compare a reactive SARSA learning algorithm with the\nconventional SARSA learning algorithm on two asynchronous robotic tasks\n(emergency stopping and impact prevention), and show that the reactive RL\nalgorithm reduces the reaction time of the agent by approximately the duration\nof the algorithm's learning update. This new class of reactive algorithms may\nfacilitate safer control and faster decision making without any change to\nstandard learning guarantees.\n"]},
{"authors": ["Ismael T. Freire", "Clement Moulin-Frier", "Marti Sanchez-Fibla", "Xerxes D. Arsiwalla", "Paul Verschure"], "title": ["Modeling the Formation of Social Conventions in Multi-Agent Populations"], "date": ["2018-02-16T20:22:41Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06108v1"], "summary": ["  In order to understand the formation of social conventions we need to know\nthe specific role of control and learning in multi-agent systems. To advance in\nthis direction, we propose, within the framework of the Distributed Adaptive\nControl (DAC) theory, a novel Control-based Reinforcement Learning architecture\n(CRL) that can account for the acquisition of social conventions in multi-agent\npopulations that are solving a benchmark social decision-making problem. Our\nnew CRL architecture, as a concrete realization of DAC multi-agent theory,\nimplements a low-level sensorimotor control loop handling the agent's reactive\nbehaviors (pre-wired reflexes), along with a layer based on model-free\nreinforcement learning that maximizes long-term reward. We apply CRL in a\nmulti-agent game-theoretic task in which coordination must be achieved in order\nto find an optimal solution. We show that our CRL architecture is able to both\nfind optimal solutions in discrete and continuous time and reproduce human\nexperimental data on standard game-theoretic metrics such as efficiency in\nacquiring rewards, fairness in reward distribution and stability of convention\nformation.\n"]},
{"authors": ["Amir Rosenfeld", "John K. Tsotsos"], "title": ["Bridging Cognitive Programs and Machine Learning"], "date": ["2018-02-16T19:19:00Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06091v1"], "summary": ["  While great advances are made in pattern recognition and machine learning,\nthe successes of such fields remain restricted to narrow applications and seem\nto break down when training data is scarce, a shift in domain occurs, or when\nintelligent reasoning is required for rapid adaptation to new environments. In\nthis work, we list several of the shortcomings of modern machine-learning\nsolutions, specifically in the contexts of computer vision and in reinforcement\nlearning and suggest directions to explore in order to try to ameliorate these\nweaknesses.\n"]},
{"authors": ["Peter Kokol", "Jernej Zavr\u0161nik", "Helena Bla\u017eun Vo\u0161ner"], "title": ["Artificial intelligence and pediatrics: A synthetic mini review"], "date": ["2018-02-16T18:51:27Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06068v1"], "summary": ["  The use of artificial intelligence intelligencein medicine can be traced back\nto 1968 when Paycha published his paper Le diagnostic a l'aide d'intelligences\nartificielle, presentation de la premiere machine diagnostri. Few years later\nShortliffe et al. presented an expert system named Mycin which was able to\nidentify bacteria causing severe blood infections and to recommend antibiotics.\nDespite the fact that Mycin outperformed members of the Stanford medical school\nin the reliability of diagnosis it was never used in practice due to a legal\nissue who do you sue if it gives a wrong diagnosis?. However only in 2016 when\nthe artificial intelligence software built into the IBM Watson AI platform\ncorrectly diagnosed and proposed an effective treatment for a 60-year-old\nwomans rare form of leukemia the AI use in medicine become really popular.On of\nfirst papers presenting the use of AI in paediatrics was published in 1984. The\npaper introduced a computer-assisted medical decision making system called\nSHELP.\n"]},
{"authors": ["Shaika Chowdhury", "Chenwei Zhang", "Philip S. Yu"], "title": ["Multi-Task Pharmacovigilance Mining from Social Media Posts"], "date": ["2018-01-19T05:04:21Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.06294v5"], "summary": ["  Social media has grown to be a crucial information source for\npharmacovigilance studies where an increasing number of people post adverse\nreactions to medical drugs that are previously unreported. Aiming to\neffectively monitor various aspects of Adverse Drug Reactions (ADRs) from\ndiversely expressed social medical posts, we propose a multi-task neural\nnetwork framework that learns several tasks associated with ADR monitoring with\ndifferent levels of supervisions collectively. Besides being able to correctly\nclassify ADR posts and accurately extract ADR mentions from online posts, the\nproposed framework is also able to further understand reasons for which the\ndrug is being taken, known as 'indication', from the given social media post. A\ncoverage-based attention mechanism is adopted in our framework to help the\nmodel properly identify 'phrasal' ADRs and Indications that are attentive to\nmultiple words in a post. Our framework is applicable in situations where\nlimited parallel data for different pharmacovigilance tasks are available.We\nevaluate the proposed framework on real-world Twitter datasets, where the\nproposed model outperforms the state-of-the-art alternatives of each individual\ntask consistently.\n"]},
{"authors": ["Lin Chen", "Hamed Hassani", "Amin Karbasi"], "title": ["Online Continuous Submodular Maximization"], "date": ["2018-02-16T17:56:48Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06052v1"], "summary": ["  In this paper, we consider an online optimization process, where the\nobjective functions are not convex (nor concave) but instead belong to a broad\nclass of continuous submodular functions. We first propose a variant of the\nFrank-Wolfe algorithm that has access to the full gradient of the objective\nfunctions. We show that it achieves a regret bound of $O(\\sqrt{T})$ (where $T$\nis the horizon of the online optimization problem) against a\n$(1-1/e)$-approximation to the best feasible solution in hindsight. However, in\nmany scenarios, only an unbiased estimate of the gradients are available. For\nsuch settings, we then propose an online stochastic gradient ascent algorithm\nthat also achieves a regret bound of $O(\\sqrt{T})$ regret, albeit against a\nweaker $1/2$-approximation to the best feasible solution in hindsight. We also\ngeneralize our results to $\\gamma$-weakly submodular functions and prove the\nsame sublinear regret bounds. Finally, we demonstrate the efficiency of our\nalgorithms on a few problem instances, including non-convex/non-concave\nquadratic programs, multilinear extensions of submodular set functions, and\nD-optimal design.\n"]},
{"authors": ["Tom\u00e1s Teijeiro", "Constantino A. Garc\u00eda", "Daniel Castro", "Paulo F\u00e9lix"], "title": ["Abductive reasoning as the basis to reproduce expert criteria in ECG\n  Atrial Fibrillation identification"], "date": ["2018-02-16T16:06:42Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.05998v1"], "summary": ["  Objective: This work aims at providing a new method for the automatic\ndetection of atrial fibrillation, other arrhythmia and noise on short single\nlead ECG signals, emphasizing the importance of the interpretability of the\nclassification results.\n  Approach: A morphological and rhythm description of the cardiac behavior is\nobtained by a knowledge-based interpretation of the signal using the\n\\textit{Construe} abductive framework. Then, a set of meaningful features are\nextracted for each individual heartbeat and as a summary of the full record.\nThe feature distributions were used to elucidate the expert criteria underlying\nthe labeling of the 2017 Physionet/CinC Challenge dataset, enabling a manual\npartial relabeling to improve the consistency of the classification rules.\nFinally, state-of-the-art machine learning methods are combined to provide an\nanswer on the basis of the feature values.\n  Main results: The proposal tied for the first place in the official stage of\nthe Challenge, with a combined $F_1$ score of 0.83, and was even improved in\nthe follow-up stage to 0.85 with a significant simplification of the model.\n  Significance: This approach demonstrates the potential of \\textit{Construe}\nto provide robust and valuable descriptions of temporal data even with\nsignificant amounts of noise and artifacts. Also, we discuss the importance of\na consistent classification criteria in manually labeled training datasets, and\nthe fundamental advantages of knowledge-based approaches to formalize and\nvalidate that criteria.\n"]},
{"authors": ["Maciej Ja\u015bkowski", "Jakub \u015awi\u0105tkowski", "Micha\u0142 Zaj\u0105c", "Maciej Klimek", "Jarek Potiuk", "Piotr Rybicki", "Piotr Polatowski", "Przemys\u0142aw Walczyk", "Kacper Nowicki", "Marek Cygan"], "title": ["Improved GQ-CNN: Deep Learning Model for Planning Robust Grasps"], "date": ["2018-02-16T15:54:31Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.05992v1"], "summary": ["  Recent developments in the field of robot grasping have shown great\nimprovements in the grasp success rates when dealing with unknown objects. In\nthis work we improve on one of the most promising approaches, the Grasp Quality\nConvolutional Neural Network (GQ-CNN) trained on the DexNet 2.0 dataset. We\npropose a new architecture for the GQ-CNN and describe practical improvements\nthat increase the model validation accuracy from 92.2% to 95.8% and from 85.9%\nto 88.0% on respectively image-wise and object-wise training and validation\nsplits.\n"]},
{"authors": ["Simon M Lucas", "Jialin Liu", "Diego Perez-Liebana"], "title": ["The N-Tuple Bandit Evolutionary Algorithm for Game Agent Optimisation"], "date": ["2018-02-16T15:49:10Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.05991v1"], "summary": ["  This paper describes the N-Tuple Bandit Evolutionary Algorithm (NTBEA), an\noptimisation algorithm developed for noisy and expensive discrete\n(combinatorial) optimisation problems. The algorithm is applied to two\ngame-based hyper-parameter optimisation problems. The N-Tuple system directly\nmodels the statistics, approximating the fitness and number of evaluations of\neach modelled combination of parameters. The model is simple, efficient and\ninformative. Results show that the NTBEA significantly outperforms grid search\nand an estimation of distribution algorithm.\n"]},
{"authors": ["Hui Wang", "Michael Emmerich", "Aske Plaat"], "title": ["Monte Carlo Q-learning for General Game Playing"], "date": ["2018-02-16T14:18:46Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.05944v1"], "summary": ["  Recently, the interest in reinforcement learning in game playing has been\nrenewed. This is evidenced by the groundbreaking results achieved by AlphaGo.\nGeneral Game Playing (GGP) provides a good testbed for reinforcement learning,\ncurrently one of the hottest fields of AI. In GGP, a specification of games\nrules is given. The description specifies a reinforcement learning problem,\nleaving programs to find strategies for playing well. Q-learning is one of the\ncanonical reinforcement learning methods, which is used as baseline on some\nprevious work (Banerjee & Stone, IJCAI 2007). We implement Q-learning in GGP\nfor three small board games (Tic-Tac-Toe, Connect-Four, Hex). We find that\nQ-learning converges, and thus that this general reinforcement learning method\nis indeed applicable to General Game Playing. However, convergence is slow, in\ncomparison to MCTS (a reinforcement learning method reported to achieve good\nresults). We enhance Q-learning with Monte Carlo Search. This enhancement\nimproves performance of pure Q-learning, although it does not yet out-perform\nMCTS. Future work is needed into the relation between MCTS and Q-learning, and\non larger problem instances.\n"]},
{"authors": ["Vikas K. Garg", "Adam Kalai"], "title": ["Supervising Unsupervised Learning"], "date": ["2017-09-14T14:42:41Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1709.05262v2"], "summary": ["  We introduce a framework to leverage knowledge acquired from a repository of\n(heterogeneous) supervised datasets to new unsupervised datasets. Our\nperspective avoids the subjectivity inherent in unsupervised learning by\nreducing it to supervised learning, and provides a principled way to evaluate\nunsupervised algorithms. We demonstrate the versatility of our framework via\nsimple agnostic bounds on unsupervised problems. In the context of clustering,\nour approach helps choose the number of clusters and the clustering algorithm,\nremove the outliers, and provably circumvent the Kleinberg's impossibility\nresult. Experimental results across hundreds of problems demonstrate improved\nperformance on unsupervised data with simple algorithms, despite the fact that\nour problems come from heterogeneous domains. Additionally, our framework lets\nus leverage deep networks to learn common features from many such small\ndatasets, and perform zero shot learning.\n"]},
{"authors": ["Jesse Anderton", "Pavel Metrikov", "Virgil Pavlu", "Javed Aslam"], "title": ["Measuring Human-perceived Similarity in Heterogeneous Collections"], "date": ["2018-02-16T13:37:45Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.05929v1"], "summary": ["  We present a technique for estimating the similarity between objects such as\nmovies or foods whose proper representation depends on human perception. Our\ntechnique combines a modest number of human similarity assessments to infer a\npairwise similarity function between the objects. This similarity function\ncaptures some human notion of similarity which may be difficult or impossible\nto automatically extract, such as which movie from a collection would be a\nbetter substitute when the desired one is unavailable. In contrast to prior\ntechniques, our method does not assume that all similarity questions on the\ncollection can be answered or that all users perceive similarity in the same\nway. When combined with a user model, we find how each assessor's tastes vary,\naffecting their perception of similarity.\n"]},
{"authors": ["Alexander Scheidler", "Leon Thurner", "Martin Braun"], "title": ["Heuristic Optimization for Automated Distribution System Planning in\n  Network Integration Studies"], "date": ["2017-11-09T11:25:21Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.03331v2"], "summary": ["  Network integration studies try to assess the impact of future developments,\nsuch as the increase of Renewable Energy Sources or the introduction of Smart\nGrid Technologies, on large-scale network areas. Goals can be to support\nstrategic alignment in the regulatory framework or to adapt the network\nplanning principles of Distribution System Operators. This study outlines an\napproach for the automated distribution system planning that can calculate\nnetwork reconfiguration, reinforcement and extension plans in a fully automated\nfashion. This allows the estimation of the expected cost in massive\nprobabilistic simulations of large numbers of real networks and constitutes a\ncore component of a framework for large-scale network integration studies.\nExemplary case study results are presented that were performed in cooperation\nwith different major distribution system operators. The case studies cover the\nestimation of expected network reinforcement costs, technical and economical\nassessment of smart grid technologies and structural network optimisation.\n"]},
{"authors": ["Luca Pappalardo", "Paolo Cintia", "Paolo Ferragina", "Emanuele Massucco", "Dino Pedreschi", "Fosca Giannotti"], "title": ["PlayeRank: Multi-dimensional and role-aware rating of soccer player\n  performance"], "date": ["2018-02-14T08:43:43Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04987v2"], "summary": ["  The problem of rating the performance of soccer players is attracting the\ninterest of many companies, websites, and the scientific community, thanks to\nthe availability of massive data capturing all the events generated during a\ngame (e.g., tackles, passes, shots, etc.). Existing approaches fail to fully\nexploit the richness of the available data and lack of a proper validation. In\nthis paper, we design and implement PlayeRank, a data-driven framework that\noffers a principled multi-dimensional and role-aware evaluation of the\nperformance of soccer players. We validate the framework through an\nexperimental analysis advised by soccer experts, based on a massive dataset of\nmillions of events pertaining four seasons of the five prominent European\nleagues. Experiments show that PlayeRank is robust in agreeing with the\nexperts' evaluation of players, significantly improving the state of the art.\nWe also explore an application of PlayeRank --- i.e. searching players --- by\nintroducing a special form of spatial query on the soccer field. This shows its\nflexibility and efficiency, which makes it worth to be used in the design of a\nscalable platform for soccer analytics.\n"]},
{"authors": ["Chao Li", "Shohei Shimizu"], "title": ["Combining Linear Non-Gaussian Acyclic Model with Logistic Regression\n  Model for Estimating Causal Structure from Mixed Continuous and Discrete Data"], "date": ["2018-02-16T10:45:59Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.05889v1"], "summary": ["  Estimating causal models from observational data is a crucial task in data\nanalysis. For continuous-valued data, Shimizu et al. have proposed a linear\nacyclic non-Gaussian model to understand the data generating process, and have\nshown that their model is identifiable when the number of data is sufficiently\nlarge. However, situations in which continuous and discrete variables coexist\nin the same problem are common in practice. Most existing causal discovery\nmethods either ignore the discrete data and apply a continuous-valued algorithm\nor discretize all the continuous data and then apply a discrete Bayesian\nnetwork approach. These methods possibly loss important information when we\nignore discrete data or introduce the approximation error due to\ndiscretization. In this paper, we define a novel hybrid causal model which\nconsists of both continuous and discrete variables. The model assumes: (1) the\nvalue of a continuous variable is a linear function of its parent variables\nplus a non-Gaussian noise, and (2) each discrete variable is a logistic\nvariable whose distribution parameters depend on the values of its parent\nvariables. In addition, we derive the BIC scoring function for model selection.\nThe new discovery algorithm can learn causal structures from mixed continuous\nand discrete data without discretization. We empirically demonstrate the power\nof our method through thorough simulations.\n"]},
{"authors": ["Siddharth Srivastava", "Nishant Desai", "Richard Freedman", "Shlomo Zilberstein"], "title": ["An Anytime Algorithm for Task and Motion MDPs"], "date": ["2018-02-16T04:52:58Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.05835v1"], "summary": ["  Integrated task and motion planning has emerged as a challenging problem in\nsequential decision making, where a robot needs to compute high-level strategy\nand low-level motion plans for solving complex tasks. While high-level\nstrategies require decision making over longer time-horizons and scales, their\nfeasibility depends on low-level constraints based upon the geometries and\ncontinuous dynamics of the environment. The hybrid nature of this problem makes\nit difficult to scale; most existing approaches focus on deterministic, fully\nobservable scenarios. We present a new approach where the high-level decision\nproblem occurs in a stochastic setting and can be modeled as a Markov decision\nprocess. In contrast to prior efforts, we show that complete MDP policies, or\ncontingent behaviors, can be computed effectively in an anytime fashion. Our\nalgorithm continuously improves the quality of the solution and is guaranteed\nto be probabilistically complete. We evaluate the performance of our approach\non a challenging, realistic test problem: autonomous aircraft inspection. Our\nresults show that we can effectively compute consistent task and motion\npolicies for the most likely execution-time outcomes using only a fraction of\nthe computation required to develop the complete task and motion policy.\n"]},
{"authors": ["Shuai Wang", "Mianwei Zhou", "Sahisnu Mazumder", "Bing Liu", "Yi Chang"], "title": ["Disentangling Aspect and Opinion Words in Target-based Sentiment\n  Analysis using Lifelong Learning"], "date": ["2018-02-16T02:00:10Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.05818v1"], "summary": ["  Given a target name, which can be a product aspect or entity, identifying its\naspect words and opinion words in a given corpus is a fine-grained task in\ntarget-based sentiment analysis (TSA). This task is challenging, especially\nwhen we have no labeled data and we want to perform it for any given domain. To\naddress it, we propose a general two-stage approach. Stage one extracts/groups\nthe target-related words (call t-words) for a given target. This is relatively\neasy as we can apply an existing semantics-based learning technique. Stage two\nseparates the aspect and opinion words from the grouped t-words, which is\nchallenging because we often do not have enough word-level aspect and opinion\nlabels. In this work, we formulate this problem in a PU learning setting and\nincorporate the idea of lifelong learning to solve it. Experimental results\nshow the effectiveness of our approach.\n"]},
{"authors": ["Deboleena Roy", "Priyadarshini Panda", "Kaushik Roy"], "title": ["Tree-CNN: A Deep Convolutional Neural Network for Lifelong Learning"], "date": ["2018-02-15T23:36:56Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.05800v1"], "summary": ["  In recent years, Convolutional Neural Networks (CNNs) have shown remarkable\nperformance in many computer vision tasks such as object recognition and\ndetection. However, complex training issues, such as \"catastrophic forgetting\"\nand hyper-parameter tuning, make incremental learning in CNNs a difficult\nchallenge. In this paper, we propose a hierarchical deep neural network, with\nCNNs at multiple levels, and a corresponding training method for lifelong\nlearning. The network grows in a tree-like manner to accommodate the new\nclasses of data without losing the ability to identify the previously trained\nclasses. The proposed network was tested on CIFAR-10 and CIFAR-100 datasets,\nand compared against the method of fine tuning specific layers of a\nconventional CNN. We obtained comparable accuracies and achieved 40% and 20%\nreduction in training effort in CIFAR-10 and CIFAR 100 respectively. The\nnetwork was able to organize the incoming classes of data into feature-driven\nsuper-classes. Our model improves upon existing hierarchical CNN models by\nadding the capability of self-growth and also yields important observations on\nfeature selective classification.\n"]},
{"authors": ["Papis Wongchaisuwat", "Diego Klabjan"], "title": ["Truth Validation with Evidence"], "date": ["2018-02-15T23:01:04Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.05786v1"], "summary": ["  In the modern era, abundant information is easily accessible from various\nsources, however only a few of these sources are reliable as they mostly\ncontain unverified contents. We develop a system to validate the truthfulness\nof a given statement together with underlying evidence. The proposed system\nprovides supporting evidence when the statement is tagged as false. Our work\nrelies on an inference method on a knowledge graph (KG) to identify the\ntruthfulness of statements. In order to extract the evidence of falseness, the\nproposed algorithm takes into account combined knowledge from KG and\nontologies. The system shows very good results as it provides valid and concise\nevidence. The quality of KG plays a role in the performance of the inference\nmethod which explicitly affects the performance of our evidence-extracting\nalgorithm.\n"]},
{"authors": ["Joshua S. Gans"], "title": ["Self-Regulating Artificial General Intelligence"], "date": ["2017-11-12T15:19:56Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.04309v2"], "summary": ["  Here we examine the paperclip apocalypse concern for artificial general\nintelligence (or AGI) whereby a superintelligent AI with a simple goal (ie.,\nproducing paperclips) accumulates power so that all resources are devoted\ntowards that simple goal and are unavailable for any other use. We provide\nconditions under which a paper apocalypse can arise but also show that, under\ncertain architectures for recursive self-improvement of AIs, that a paperclip\nAI may refrain from allowing power capabilities to be developed. The reason is\nthat such developments pose the same control problem for the AI as they do for\nhumans (over AIs) and hence, threaten to deprive it of resources for its\nprimary goal.\n"]},
{"authors": ["Paulius Micikevicius", "Sharan Narang", "Jonah Alben", "Gregory Diamos", "Erich Elsen", "David Garcia", "Boris Ginsburg", "Michael Houston", "Oleksii Kuchaiev", "Ganesh Venkatesh", "Hao Wu"], "title": ["Mixed Precision Training"], "date": ["2017-10-10T17:42:04Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.03740v3"], "summary": ["  Deep neural networks have enabled progress in a wide variety of applications.\nGrowing the size of the neural network typically results in improved accuracy.\nAs model sizes grow, the memory and compute requirements for training these\nmodels also increases. We introduce a technique to train deep neural networks\nusing half precision floating point numbers. In our technique, weights,\nactivations and gradients are stored in IEEE half-precision format.\nHalf-precision floating numbers have limited numerical range compared to\nsingle-precision numbers. We propose two techniques to handle this loss of\ninformation. Firstly, we recommend maintaining a single-precision copy of the\nweights that accumulates the gradients after each optimizer step. This\nsingle-precision copy is rounded to half-precision format during training.\nSecondly, we propose scaling the loss appropriately to handle the loss of\ninformation with half-precision gradients. We demonstrate that this approach\nworks for a wide variety of models including convolution neural networks,\nrecurrent neural networks and generative adversarial networks. This technique\nworks for large scale models with more than 100 million parameters trained on\nlarge datasets. Using this approach, we can reduce the memory consumption of\ndeep learning models by nearly 2x. In future processors, we can also expect a\nsignificant computation speedup using half-precision hardware units.\n"]},
{"authors": ["Dong Huk Park", "Lisa Anne Hendricks", "Zeynep Akata", "Anna Rohrbach", "Bernt Schiele", "Trevor Darrell", "Marcus Rohrbach"], "title": ["Multimodal Explanations: Justifying Decisions and Pointing to the\n  Evidence"], "date": ["2018-02-15T19:12:03Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08129v1"], "summary": ["  Deep models that are both effective and explainable are desirable in many\nsettings; prior explainable models have been unimodal, offering either\nimage-based visualization of attention weights or text-based generation of\npost-hoc justifications. We propose a multimodal approach to explanation, and\nargue that the two modalities provide complementary explanatory strengths. We\ncollect two new datasets to define and evaluate this task, and propose a novel\nmodel which can provide joint textual rationale generation and attention\nvisualization. Our datasets define visual and textual justifications of a\nclassification decision for activity recognition tasks (ACT-X) and for visual\nquestion answering tasks (VQA-X). We quantitatively show that training with the\ntextual explanations not only yields better textual justification models, but\nalso better localizes the evidence that supports the decision. We also\nqualitatively show cases where visual explanation is more insightful than\ntextual explanation, and vice versa, supporting our thesis that multimodal\nexplanation models offer significant benefits over unimodal approaches.\n"]},
{"authors": ["Ajinkya Jain", "Scott Niekum"], "title": ["Efficient Hierarchical Robot Motion Planning Under Uncertainty and\n  Hybrid Dynamics"], "date": ["2018-02-12T17:47:13Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04205v2"], "summary": ["  Noisy observations coupled with nonlinear dynamics pose one of the biggest\nchallenges in robot motion planning. By decomposing the nonlinear dynamics into\na discrete set of local dynamics models, hybrid dynamics provide a natural way\nto model nonlinear dynamics, especially in systems with sudden \"jumps\" in the\ndynamics, due to factors such as contacts. We propose a hierarchical POMDP\nplanner that develops locally optimal motion plans for hybrid dynamics models.\nThe hierarchical planner first develops a high-level motion plan to sequence\nthe local dynamics models to be visited. The high-level plan is then converted\ninto a detailed cost-optimized continuous state plan. This hierarchical\nplanning approach results in a decomposition of the POMDP planning problem into\nsmaller sub-parts that can be solved with significantly lower computational\ncosts. The ability to sequence the visitation of local dynamics models also\nprovides a powerful way to leverage the hybrid dynamics to reduce state\nuncertainty. We evaluate the proposed planner for two navigation and\nlocalization tasks in simulated domains, as well as an assembly task with a\nreal robotic manipulator.\n"]},
{"authors": ["Anish Athalye", "Nicholas Carlini", "David Wagner"], "title": ["Obfuscated Gradients Give a False Sense of Security: Circumventing\n  Defenses to Adversarial Examples"], "date": ["2018-02-01T18:20:05Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.00420v2"], "summary": ["  We identify obfuscated gradients, a kind of gradient masking, as a phenomenon\nthat leads to a false sense of security in defenses against adversarial\nexamples. While defenses that cause obfuscated gradients appear to defeat\niterative optimization-based attacks, we find defenses relying on this effect\ncan be circumvented. For each of the three types of obfuscated gradients we\ndiscover, we describe characteristic behaviors of defenses exhibiting this\neffect and develop attack techniques to overcome it. In a case study, examining\nnon-certified white-box-secure defenses at ICLR 2018, we find obfuscated\ngradients are a common occurrence, with 7 of 8 defenses relying on obfuscated\ngradients. Our new attacks successfully circumvent 6 completely and 1\npartially.\n"]},
{"authors": ["Sabina Marchetti", "Alessandro Antonucci"], "title": ["Reliable Uncertain Evidence Modeling in Bayesian Networks by Credal\n  Networks"], "date": ["2018-02-15T16:25:47Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.05639v1"], "summary": ["  A reliable modeling of uncertain evidence in Bayesian networks based on a\nset-valued quantification is proposed. Both soft and virtual evidences are\nconsidered. We show that evidence propagation in this setup can be reduced to\nstandard updating in an augmented credal network, equivalent to a set of\nconsistent Bayesian networks. A characterization of the computational\ncomplexity for this task is derived together with an efficient exact procedure\nfor a subclass of instances. In the case of multiple uncertain evidences over\nthe same variable, the proposed procedure can provide a set-valued version of\nthe geometric approach to opinion pooling.\n"]},
{"authors": ["Ming-Yu Liu", "Thomas Breuel", "Jan Kautz"], "title": ["Unsupervised Image-to-Image Translation Networks"], "date": ["2017-03-02T16:29:30Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1703.00848v5"], "summary": ["  Unsupervised image-to-image translation aims at learning a joint distribution\nof images in different domains by using images from the marginal distributions\nin individual domains. Since there exists an infinite set of joint\ndistributions that can arrive the given marginal distributions, one could infer\nnothing about the joint distribution from the marginal distributions without\nadditional assumptions. To address the problem, we make a shared-latent space\nassumption and propose an unsupervised image-to-image translation framework\nbased on Coupled GANs. We compare the proposed framework with competing\napproaches and present high quality image translation results on various\nchallenging unsupervised image translation tasks, including street scene image\ntranslation, animal image translation, and face image translation. We also\napply the proposed framework to domain adaptation and achieve state-of-the-art\nperformance on benchmark datasets. Code and additional results are available in\nhttps://github.com/mingyuliutw/unit .\n"]},
{"authors": ["Lise Aubin", "Mehdi Khamassi", "Beno\u00eet Girard"], "title": ["Prioritized Sweeping Neural DynaQ with Multiple Predecessors, and\n  Hippocampal Replays"], "date": ["2018-02-15T15:15:19Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.05594v1"], "summary": ["  During sleep and awake rest, the hippocampus replays sequences of place cells\nthat have been activated during prior experiences. These have been interpreted\nas a memory consolidation process, but recent results suggest a possible\ninterpretation in terms of reinforcement learning. The Dyna reinforcement\nlearning algorithms use off-line replays to improve learning. Under limited\nreplay budget, a prioritized sweeping approach, which requires a model of the\ntransitions to the predecessors, can be used to improve performance. We\ninvestigate whether such algorithms can explain the experimentally observed\nreplays. We propose a neural network version of prioritized sweeping\nQ-learning, for which we developed a growing multiple expert algorithm, able to\ncope with multiple predecessors. The resulting architecture is able to improve\nthe learning of simulated agents confronted to a navigation task. We predict\nthat, in animals, learning the world model should occur during rest periods,\nand that the corresponding replays should be shuffled.\n"]},
{"authors": ["Yan Zhu", "Abdullah Mueen", "Eamonn Keogh"], "title": ["Admissible Time Series Motif Discovery with Missing Data"], "date": ["2018-02-15T10:45:46Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.05472v1"], "summary": ["  The discovery of time series motifs has emerged as one of the most useful\nprimitives in time series data mining. Researchers have shown its utility for\nexploratory data mining, summarization, visualization, segmentation,\nclassification, clustering, and rule discovery. Although there has been more\nthan a decade of extensive research, there is still no technique to allow the\ndiscovery of time series motifs in the presence of missing data, despite the\nwell-documented ubiquity of missing data in scientific, industrial, and medical\ndatasets. In this work, we introduce a technique for motif discovery in the\npresence of missing data. We formally prove that our method is admissible,\nproducing no false negatives. We also show that our method can piggy-back off\nthe fastest known motif discovery method with a small constant factor\ntime/space overhead. We will demonstrate our approach on diverse datasets with\nvarying amounts of missing data\n"]},
{"authors": ["Yaodong Yang", "Rui Luo", "Minne Li", "Ming Zhou", "Weinan Zhang", "Jun Wang"], "title": ["Mean Field Multi-Agent Reinforcement Learning"], "date": ["2018-02-15T09:07:57Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.05438v1"], "summary": ["  Existing multi-agent reinforcement learning methods are limited typically to\na small number of agents. When the agent number increases largely, the learning\nbecomes intractable due to the curse of the dimensionality and the exponential\ngrowth of user interactions. In this paper, we present Mean Field Reinforcement\nLearning where the interactions within the population of agents are\napproximated by those between a single agent and the average effect from the\noverall population or neighboring agents; the interplay between the two\nentities is mutually reinforced: the learning of the individual agent's optimal\npolicy depends on the dynamics of the population, while the dynamics of the\npopulation change according to the collective patterns of the individual\npolicies. We develop practical mean field Q-learning and mean field\nActor-Critic algorithms and analyze the convergence of the solution.\nExperiments on resource allocation, Ising model estimation, and battle game\ntasks verify the learning effectiveness of our mean field approaches in\nhandling many-agent interactions in population.\n"]},
{"authors": ["Shubham Toshniwal", "Tara N. Sainath", "Ron J. Weiss", "Bo Li", "Pedro Moreno", "Eugene Weinstein", "Kanishka Rao"], "title": ["Multilingual Speech Recognition With A Single End-To-End Model"], "date": ["2017-11-06T01:55:45Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.01694v2"], "summary": ["  Training a conventional automatic speech recognition (ASR) system to support\nmultiple languages is challenging because the sub-word unit, lexicon and word\ninventories are typically language specific. In contrast, sequence-to-sequence\nmodels are well suited for multilingual ASR because they encapsulate an\nacoustic, pronunciation and language model jointly in a single network. In this\nwork we present a single sequence-to-sequence ASR model trained on 9 different\nIndian languages, which have very little overlap in their scripts.\nSpecifically, we take a union of language-specific grapheme sets and train a\ngrapheme-based sequence-to-sequence model jointly on data from all languages.\nWe find that this model, which is not explicitly given any information about\nlanguage identity, improves recognition performance by 21% relative compared to\nanalogous sequence-to-sequence models trained on each language individually. By\nmodifying the model to accept a language identifier as an additional input\nfeature, we further improve performance by an additional 7% relative and\neliminate confusion between different languages.\n"]},
{"authors": ["Kelvin Loh", "Pejman Shoeibi Omrani", "Ruud van der Linden"], "title": ["Deep Learning and Data Assimilation for Real-Time Production Prediction\n  in Natural Gas Wells"], "date": ["2018-02-14T15:03:09Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.05141v2"], "summary": ["  The prediction of the gas production from mature gas wells, due to their\ncomplex end-of-life behavior, is challenging and crucial for operational\ndecision making. In this paper, we apply a modified deep LSTM model for\nprediction of the gas flow rates in mature gas wells, including the\nuncertainties in input parameters. Additionally, due to changes in the system\nin time and in order to increase the accuracy and robustness of the prediction,\nthe Ensemble Kalman Filter (EnKF) is used to update the flow rate predictions\nbased on new observations. The developed approach was tested on the data from\ntwo mature gas production wells in which their production is highly dynamic and\nsuffering from salt deposition. The results show that the flow predictions\nusing the EnKF updated model leads to better Jeffreys' J-divergences than the\npredictions without the EnKF model updating scheme.\n"]},
{"authors": ["Congzheng Song", "Vitaly Shmatikov"], "title": ["Fooling OCR Systems with Adversarial Text Images"], "date": ["2018-02-15T02:08:19Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.05385v1"], "summary": ["  We demonstrate that state-of-the-art optical character recognition (OCR)\nbased on deep learning is vulnerable to adversarial images. Minor modifications\nto images of printed text, which do not change the meaning of the text to a\nhuman reader, cause the OCR system to \"recognize\" a different text where\ncertain words chosen by the adversary are replaced by their semantic opposites.\nThis completely changes the meaning of the output produced by the OCR system\nand by the NLP applications that use OCR for preprocessing their inputs.\n"]},
{"authors": ["Kaizhi Qian", "Yang Zhang", "Shiyu Chang", "Xuesong Yang", "Dinei Florencio", "Mark Hasegawa-Johnson"], "title": ["Deep Learning Based Speech Beamforming"], "date": ["2018-02-15T02:00:54Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.05383v1"], "summary": ["  Multi-channel speech enhancement with ad-hoc sensors has been a challenging\ntask. Speech model guided beamforming algorithms are able to recover natural\nsounding speech, but the speech models tend to be oversimplified or the\ninference would otherwise be too complicated. On the other hand, deep learning\nbased enhancement approaches are able to learn complicated speech distributions\nand perform efficient inference, but they are unable to deal with variable\nnumber of input channels. Also, deep learning approaches introduce a lot of\nerrors, particularly in the presence of unseen noise types and settings. We\nhave therefore proposed an enhancement framework called DEEPBEAM, which\ncombines the two complementary classes of algorithms. DEEPBEAM introduces a\nbeamforming filter to produce natural sounding speech, but the filter\ncoefficients are determined with the help of a monaural speech enhancement\nneural network. Experiments on synthetic and real-world data show that DEEPBEAM\nis able to produce clean, dry and natural sounding speech, and is robust\nagainst unseen noise.\n"]},
{"authors": ["Himan Abdollahpouri", "Robin Burke", "Bamshad Mobasher"], "title": ["Value-Aware Item Weighting for Long-Tail Recommendation"], "date": ["2018-02-15T01:53:59Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.05382v1"], "summary": ["  Many recommender systems suffer from the popularity bias problem: popular\nitems are being recommended frequently while less popular, niche products, are\nrecommended rarely if not at all. However, those ignored products are exactly\nthe products that businesses need to find customers for and their\nrecommendations would be more beneficial. In this paper, we examine an item\nweighting approach to improve long-tail recommendation. Our approach works as a\nsimple yet powerful add-on to existing recommendation algorithms for making a\ntunable trade-off between accuracy and long-tail coverage.\n"]},
{"authors": ["Fei Wang", "Tiark Rompf"], "title": ["From Gameplay to Symbolic Reasoning: Learning SAT Solver Heuristics in\n  the Style of Alpha(Go) Zero"], "date": ["2018-02-14T22:25:47Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.05340v1"], "summary": ["  Despite the recent successes of deep neural networks in various fields such\nas image and speech recognition, natural language processing, and reinforcement\nlearning, we still face big challenges in bringing the power of numeric\noptimization to symbolic reasoning. Researchers have proposed different avenues\nsuch as neural machine translation for proof synthesis, vectorization of\nsymbols and expressions for representing symbolic patterns, and coupling of\nneural back-ends for dimensionality reduction with symbolic front-ends for\ndecision making. However, these initial explorations are still only point\nsolutions, and bear other shortcomings such as lack of correctness guarantees.\nIn this paper, we present our approach of casting symbolic reasoning as games,\nand directly harnessing the power of deep reinforcement learning in the style\nof Alpha(Go) Zero on symbolic problems. Using the Boolean Satisfiability (SAT)\nproblem as showcase, we demonstrate the feasibility of our method, and the\nadvantages of modularity, efficiency, and correctness guarantees.\n"]},
{"authors": ["Jian Zhang", "Ioannis Mitliagkas"], "title": ["YellowFin and the Art of Momentum Tuning"], "date": ["2017-06-12T05:43:56Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1706.03471v2"], "summary": ["  Hyperparameter tuning is one of the most time-consuming workloads in deep\nlearning. State-of-the-art optimizers, such as AdaGrad, RMSProp and Adam,\nreduce this labor by adaptively tuning an individual learning rate for each\nvariable. Recently researchers have shown renewed interest in simpler methods\nlike momentum SGD as they may yield better test metrics. Motivated by this\ntrend, we ask: can simple adaptive methods based on SGD perform as well or\nbetter? We revisit the momentum SGD algorithm and show that hand-tuning a\nsingle learning rate and momentum makes it competitive with Adam. We then\nanalyze its robustness to learning rate misspecification and objective\ncurvature variation. Based on these insights, we design YellowFin, an automatic\ntuner for momentum and learning rate in SGD. YellowFin optionally uses a\nnegative-feedback loop to compensate for the momentum dynamics in asynchronous\nsettings on the fly. We empirically show that YellowFin can converge in fewer\niterations than Adam on ResNets and LSTMs for image recognition, language\nmodeling and constituency parsing, with a speedup of up to 3.28x in synchronous\nand up to 2.69x in asynchronous settings.\n"]},
{"authors": ["Yang Gao", " Huazhe", " Xu", "Ji Lin", "Fisher Yu", "Sergey Levine", "Trevor Darrell"], "title": ["Reinforcement Learning from Imperfect Demonstrations"], "date": ["2018-02-14T20:37:38Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.05313v1"], "summary": ["  Robust real-world learning should benefit from both demonstrations and\ninteractions with the environment. Current approaches to learning from\ndemonstration and reward perform supervised learning on expert demonstration\ndata and use reinforcement learning to further improve performance based on the\nreward received from the environment. These tasks have divergent losses which\nare difficult to jointly optimize and such methods can be very sensitive to\nnoisy demonstrations. We propose a unified reinforcement learning algorithm,\nNormalized Actor-Critic (NAC), that effectively normalizes the Q-function,\nreducing the Q-values of actions unseen in the demonstration data. NAC learns\nan initial policy network from demonstrations and refines the policy in the\nenvironment, surpassing the demonstrator's performance. Crucially, both\nlearning from demonstration and interactive refinement use the same objective,\nunlike prior approaches that combine distinct supervised and reinforcement\nlosses. This makes NAC robust to suboptimal demonstration data since the method\nis not forced to mimic all of the examples in the dataset. We show that our\nunified reinforcement learning algorithm can learn robustly and outperform\nexisting baselines when evaluated on several realistic driving games.\n"]},
{"authors": ["Dipan K. Pal", "Marios Savvides"], "title": ["Non-Parametric Transformation Networks"], "date": ["2018-01-14T06:48:45Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.04520v3"], "summary": ["  ConvNets, through their architecture, only enforce invariance to translation.\nIn this paper, we introduce a new class of deep convolutional architectures\ncalled Non-Parametric Transformation Networks (NPTNs) which can learn\n\\textit{general} invariances and symmetries directly from data. NPTNs are a\nnatural generalization of ConvNets and can be optimized directly using gradient\ndescent. Unlike almost all previous works in deep architectures, they make no\nassumption regarding the structure of the invariances present in the data and\nin that aspect are flexible and powerful. We also model ConvNets and NPTNs\nunder a unified framework called Transformation Networks (TN), which yields a\nbetter understanding of the connection between the two. We demonstrate the\nefficacy of NPTNs on data such as MNIST and CIFAR10 where they outperform\nConvNet baselines with the same number of parameters. We show it is more\neffective than ConvNets in modelling symmetries from data, without the explicit\nknowledge of the added arbitrary nuisance transformations. Finally, we replace\nConvNets with NPTNs within Capsule Networks and show that this enables Capsule\nNets to perform even better.\n"]},
{"authors": ["Karl Ridgeway", "Michael C. Mozer"], "title": ["Learning Deep Disentangled Embeddings with the F-Statistic Loss"], "date": ["2018-02-14T20:28:38Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.05312v1"], "summary": ["  Deep-embedding methods aim to discover representations of a domain that make\nexplicit the domain's class structure. Disentangling methods aim to make\nexplicit compositional or factorial structure. We combine these two active but\nindependent lines of research and propose a new paradigm for discovering\ndisentangled representations of class structure; these representations reveal\nthe underlying factors that jointly determine class. We propose and evaluate a\nnovel loss function based on the $F$ statistic, which describes the separation\nof two or more distributions. By ensuring that distinct classes are well\nseparated on a subset of embedding dimensions, we obtain embeddings that are\nuseful for few-shot learning. By not requiring separation on all dimensions, we\nencourage the discovery of disentangled representations. Our embedding\nprocedure matches or beats state-of-the-art procedures on deep embeddings, as\nevaluated by performance on recall@$k$ and few-shot learning tasks. To evaluate\nalternative approaches on disentangling, we formalize two key properties of a\ndisentangled representation: modularity and explicitness. By these criteria,\nour procedure yields disentangled representations, whereas traditional\nprocedures fail. The goal of our work is to obtain more interpretable,\nmanipulable, and generalizable deep representations of concepts and categories.\n"]},
{"authors": ["Samuel L. Smith", "Quoc V. Le"], "title": ["A Bayesian Perspective on Generalization and Stochastic Gradient Descent"], "date": ["2017-10-17T18:08:04Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.06451v3"], "summary": ["  We consider two questions at the heart of machine learning; how can we\npredict if a minimum will generalize to the test set, and why does stochastic\ngradient descent find minima that generalize well? Our work responds to Zhang\net al. (2016), who showed deep neural networks can easily memorize randomly\nlabeled training data, despite generalizing well on real labels of the same\ninputs. We show that the same phenomenon occurs in small linear models. These\nobservations are explained by the Bayesian evidence, which penalizes sharp\nminima but is invariant to model parameterization. We also demonstrate that,\nwhen one holds the learning rate fixed, there is an optimum batch size which\nmaximizes the test set accuracy. We propose that the noise introduced by small\nmini-batches drives the parameters towards minima whose evidence is large.\nInterpreting stochastic gradient descent as a stochastic differential equation,\nwe identify the \"noise scale\" $g = \\epsilon (\\frac{N}{B} - 1) \\approx \\epsilon\nN/B$, where $\\epsilon$ is the learning rate, $N$ the training set size and $B$\nthe batch size. Consequently the optimum batch size is proportional to both the\nlearning rate and the size of the training set, $B_{opt} \\propto \\epsilon N$.\nWe verify these predictions empirically.\n"]},
{"authors": ["Chelsea Finn", "Sergey Levine"], "title": ["Meta-Learning and Universality: Deep Representations and Gradient\n  Descent can Approximate any Learning Algorithm"], "date": ["2017-10-31T17:55:42Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.11622v3"], "summary": ["  Learning to learn is a powerful paradigm for enabling models to learn from\ndata more effectively and efficiently. A popular approach to meta-learning is\nto train a recurrent model to read in a training dataset as input and output\nthe parameters of a learned model, or output predictions for new test inputs.\nAlternatively, a more recent approach to meta-learning aims to acquire deep\nrepresentations that can be effectively fine-tuned, via standard gradient\ndescent, to new tasks. In this paper, we consider the meta-learning problem\nfrom the perspective of universality, formalizing the notion of learning\nalgorithm approximation and comparing the expressive power of the\naforementioned recurrent models to the more recent approaches that embed\ngradient descent into the meta-learner. In particular, we seek to answer the\nfollowing question: does deep representation combined with standard gradient\ndescent have sufficient capacity to approximate any learning algorithm? We find\nthat this is indeed true, and further find, in our experiments, that\ngradient-based meta-learning consistently leads to learning strategies that\ngeneralize more widely compared to those represented by recurrent models.\n"]},
{"authors": ["Jaime F. Fisac", "Chang Liu", "Jessica B. Hamrick", "S. Shankar Sastry", "J. Karl Hedrick", "Thomas L. Griffiths", "Anca D. Dragan"], "title": ["Generating Plans that Predict Themselves"], "date": ["2018-02-14T18:20:19Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.05250v1"], "summary": ["  Collaboration requires coordination, and we coordinate by anticipating our\nteammates' future actions and adapting to their plan. In some cases, our\nteammates' actions early on can give us a clear idea of what the remainder of\ntheir plan is, i.e. what action sequence we should expect. In others, they\nmight leave us less confident, or even lead us to the wrong conclusion. Our\ngoal is for robot actions to fall in the first category: we want to enable\nrobots to select their actions in such a way that human collaborators can\neasily use them to correctly anticipate what will follow. While previous work\nhas focused on finding initial plans that convey a set goal, here we focus on\nfinding two portions of a plan such that the initial portion conveys the final\none. We introduce $t$-\\ACty{}: a measure that quantifies the accuracy and\nconfidence with which human observers can predict the remaining robot plan from\nthe overall task goal and the observed initial $t$ actions in the plan. We\ncontribute a method for generating $t$-predictable plans: we search for a full\nplan that accomplishes the task, but in which the first $t$ actions make it as\neasy as possible to infer the remaining ones. The result is often different\nfrom the most efficient plan, in which the initial actions might leave a lot of\nambiguity as to how the task will be completed. Through an online experiment\nand an in-person user study with physical robots, we find that our approach\noutperforms a traditional efficiency-based planner in objective and subjective\ncollaboration metrics.\n"]},
{"authors": ["Th\u00e9ophane Weber", "S\u00e9bastien Racani\u00e8re", "David P. Reichert", "Lars Buesing", "Arthur Guez", "Danilo Jimenez Rezende", "Adria Puigdom\u00e8nech Badia", "Oriol Vinyals", "Nicolas Heess", "Yujia Li", "Razvan Pascanu", "Peter Battaglia", "Demis Hassabis", "David Silver", "Daan Wierstra"], "title": ["Imagination-Augmented Agents for Deep Reinforcement Learning"], "date": ["2017-07-19T17:12:56Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1707.06203v2"], "summary": ["  We introduce Imagination-Augmented Agents (I2As), a novel architecture for\ndeep reinforcement learning combining model-free and model-based aspects. In\ncontrast to most existing model-based reinforcement learning and planning\nmethods, which prescribe how a model should be used to arrive at a policy, I2As\nlearn to interpret predictions from a learned environment model to construct\nimplicit plans in arbitrary ways, by using the predictions as additional\ncontext in deep policy networks. I2As show improved data efficiency,\nperformance, and robustness to model misspecification compared to several\nbaselines.\n"]},
{"authors": ["Gabriella A. B. Barros", "Michael Cerny Green", "Antonios Liapis", "Julian Togelius"], "title": ["Who Killed Albert Einstein? From Open Data to Murder Mystery Games"], "date": ["2018-02-14T17:17:54Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.05219v1"], "summary": ["  This paper presents a framework for generating adventure games from open\ndata. Focusing on the murder mystery type of adventure games, the generator is\nable to transform open data from Wikipedia articles, OpenStreetMap and images\nfrom Wikimedia Commons into WikiMysteries. Every WikiMystery game revolves\naround the murder of a person with a Wikipedia article and populates the game\nwith suspects who must be arrested by the player if guilty of the murder or\nabsolved if innocent. Starting from only one person as the victim, an extensive\ngenerative pipeline finds suspects, their alibis, and paths connecting them\nfrom open data, transforms open data into cities, buildings, non-player\ncharacters, locks and keys and dialog options. The paper describes in detail\neach generative step, provides a specific playthrough of one WikiMystery where\nAlbert Einstein is murdered, and evaluates the outcomes of games generated for\nthe 100 most influential people of the 20th century.\n"]},
{"authors": ["Craig Sherstan", "Brendan Bennett", "Kenny Young", "Dylan R. Ashley", "Adam White", "Martha White", "Richard S. Sutton"], "title": ["Directly Estimating the Variance of the \u03bb-Return Using\n  Temporal-Difference Methods"], "date": ["2018-01-25T06:48:14Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.08287v2"], "summary": ["  This paper investigates estimating the variance of a temporal-difference\nlearning agent's update target. Most reinforcement learning methods use an\nestimate of the value function, which captures how good it is for the agent to\nbe in a particular state and is mathematically expressed as the expected sum of\ndiscounted future rewards (called the return). These values can be\nstraightforwardly estimated by averaging batches of returns using Monte Carlo\nmethods. However, if we wish to update the agent's value estimates during\nlearning--before terminal outcomes are observed--we must use a different\nestimation target called the {\\lambda}-return, which truncates the return with\nthe agent's own estimate of the value function. Temporal difference learning\nmethods estimate the expected {\\lambda}-return for each state, allowing these\nmethods to update online and incrementally, and in most cases achieve better\ngeneralization error and faster learning than Monte Carlo methods. Naturally\none could attempt to estimate higher-order moments of the {\\lambda}-return.\nThis paper is about estimating the variance of the {\\lambda}-return. Prior work\nhas shown that given estimates of the variance of the {\\lambda}-return,\nlearning systems can be constructed to (1) mitigate risk in action selection,\nand (2) automatically adapt the parameters of the learning process itself to\nimprove performance. Unfortunately, existing methods for estimating the\nvariance of the {\\lambda}-return are complex and not well understood\nempirically. We contribute a method for estimating the variance of the\n{\\lambda}-return directly using policy evaluation methods from reinforcement\nlearning. Our approach is significantly simpler than prior methods that\nindependently estimate the second moment of the {\\lambda}-return. Empirically\nour new approach behaves at least as well as existing approaches, but is\ngenerally more robust.\n"]},
{"authors": ["Emmanuel Dupoux"], "title": ["Cognitive Science in the era of Artificial Intelligence: A roadmap for\n  reverse-engineering the infant language-learner"], "date": ["2016-07-29T08:33:10Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1607.08723v4"], "summary": ["  During their first years of life, infants learn the language(s) of their\nenvironment at an amazing speed despite large cross cultural variations in\namount and complexity of the available language input. Understanding this\nsimple fact still escapes current cognitive and linguistic theories. Recently,\nspectacular progress in the engineering science, notably, machine learning and\nwearable technology, offer the promise of revolutionizing the study of\ncognitive development. Machine learning offers powerful learning algorithms\nthat can achieve human-like performance on many linguistic tasks. Wearable\nsensors can capture vast amounts of data, which enable the reconstruction of\nthe sensory experience of infants in their natural environment. The project of\n'reverse engineering' language development, i.e., of building an effective\nsystem that mimics infant's achievements appears therefore to be within reach.\nHere, we analyze the conditions under which such a project can contribute to\nour scientific understanding of early language development. We argue that\ninstead of defining a sub-problem or simplifying the data, computational models\nshould address the full complexity of the learning situation, and take as input\nthe raw sensory signals available to infants. This implies that (1) accessible\nbut privacy-preserving repositories of home data be setup and widely shared,\nand (2) models be evaluated at different linguistic levels through a benchmark\nof psycholinguist tests that can be passed by machines and humans alike, (3)\nlinguistically and psychologically plausible learning architectures be scaled\nup to real data using probabilistic/optimization principles from machine\nlearning. We discuss the feasibility of this approach and present preliminary\nresults.\n"]},
{"authors": ["Smitha Milli", "Pieter Abbeel", "Igor Mordatch"], "title": ["Interpretable and Pedagogical Examples"], "date": ["2017-11-02T11:40:08Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.00694v2"], "summary": ["  Teachers intentionally pick the most informative examples to show their\nstudents. However, if the teacher and student are neural networks, the examples\nthat the teacher network learns to give, although effective at teaching the\nstudent, are typically uninterpretable. We show that training the student and\nteacher iteratively, rather than jointly, can produce interpretable teaching\nstrategies. We evaluate interpretability by (1) measuring the similarity of the\nteacher's emergent strategies to intuitive strategies in each domain and (2)\nconducting human experiments to evaluate how effective the teacher's strategies\nare at teaching humans. We show that the teacher network learns to select or\ngenerate interpretable, pedagogical examples to teach rule-based,\nprobabilistic, boolean, and hierarchical concepts.\n"]},
{"authors": ["Isabelle Bloch", "J\u00e9r\u00f4me Lang", "Ram\u00f3n Pino P\u00e9rez", "Carlos Uzc\u00e1tegui"], "title": ["Morphologic for knowledge dynamics: revision, fusion, abduction"], "date": ["2018-02-14T15:08:06Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.05142v1"], "summary": ["  Several tasks in artificial intelligence require to be able to find models\nabout knowledge dynamics. They include belief revision, fusion and belief\nmerging, and abduction. In this paper we exploit the algebraic framework of\nmathematical morphology in the context of propositional logic, and define\noperations such as dilation or erosion of a set of formulas. We derive concrete\noperators, based on a semantic approach, that have an intuitive interpretation\nand that are formally well behaved, to perform revision, fusion and abduction.\nComputation and tractability are addressed, and simple examples illustrate the\ntypical results that can be obtained.\n"]},
{"authors": ["James P. Bagrow"], "title": ["Crowd ideation of supervised learning problems"], "date": ["2018-02-14T14:16:13Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.05101v1"], "summary": ["  Crowdsourcing is an important avenue for collecting machine learning data,\nbut crowdsourcing can go beyond simple data collection by employing the\ncreativity and wisdom of crowd workers. Yet crowd participants are unlikely to\nbe experts in statistics or predictive modeling, and it is not clear how well\nnon-experts can contribute creatively to the process of machine learning. Here\nwe study an end-to-end crowdsourcing algorithm where groups of non-expert\nworkers propose supervised learning problems, rank and categorize those\nproblems, and then provide data to train predictive models on those problems.\nProblem proposal includes and extends feature engineering because workers\npropose the entire problem, not only the input features but also the target\nvariable. We show that workers without machine learning experience can\ncollectively construct useful datasets and that predictive models can be\nlearned on these datasets. In our experiments, the problems proposed by workers\ncovered a broad range of topics, from politics and current events to problems\ncapturing health behavior, demographics, and more. Workers also favored\nquestions showing positively correlated relationships, which has interesting\nimplications given many supervised learning methods perform as well with strong\nnegative correlations. Proper instructions are crucial for non-experts, so we\nalso conducted a randomized trial to understand how different instructions may\ninfluence the types of problems proposed by workers. In general, shifting the\nfocus of machine learning tasks from designing and training individual\npredictive models to problem proposal allows crowdsourcers to design\nrequirements for problems of interest and then guide workers towards\ncontributing to the most suitable problems.\n"]},
{"authors": ["Patrick Schwab", "Emanuela Keller", "Carl Muroi", "David J. Mack", "Christian Str\u00e4ssle", "Walter Karlen"], "title": ["Not to Cry Wolf: Distantly Supervised Multitask Learning in Critical\n  Care"], "date": ["2018-02-14T10:35:08Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.05027v1"], "summary": ["  Patients in the intensive care unit (ICU) require constant and close\nsupervision. To assist clinical staff in this task, hospitals use monitoring\nsystems that trigger audiovisual alarms if their algorithms indicate that a\npatient's condition may be worsening. However, current monitoring systems are\nextremely sensitive to movement artefacts and technical errors. As a result,\nthey typically trigger hundreds to thousands of false alarms per patient per\nday - drowning the important alarms in noise and adding to the exhaustion of\nclinical staff. In this setting, data is abundantly available, but obtaining\ntrustworthy annotations by experts is laborious and expensive. We frame the\nproblem of false alarm reduction from multivariate time series as a\nmachine-learning task and address it with a novel multitask network\narchitecture that utilises distant supervision through multiple related\nauxiliary tasks in order to reduce the number of expensive labels required for\ntraining. We show that our approach leads to significant improvements over\nseveral state-of-the-art baselines on real-world ICU data and provide new\ninsights on the importance of task selection and architectural choices in\ndistantly supervised multitask learning.\n"]},
{"authors": ["Joan Serr\u00e0", "D\u00eddac Sur\u00eds", "Marius Miron", "Alexandros Karatzoglou"], "title": ["Overcoming catastrophic forgetting with hard attention to the task"], "date": ["2018-01-04T16:22:22Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.01423v2"], "summary": ["  Catastrophic forgetting occurs when a neural network loses the information\nlearned in a previous task after training on subsequent tasks. This problem\nremains a hurdle for artificial intelligence systems with sequential learning\ncapabilities. In this paper, we propose a task-based hard attention mechanism\nthat preserves previous tasks' information without affecting the current task's\nlearning. A hard attention mask is learned concurrently to every task, through\nstochastic gradient descent, and previous masks are exploited to condition such\nlearning. We show that the proposed mechanism is effective for reducing\ncatastrophic forgetting, cutting current rates by 45 to 80%. We also show that\nit is robust to different hyperparameter choices, and that it offers a number\nof monitoring capabilities. The approach features the possibility to control\nboth the stability and compactness of the learned knowledge, which we believe\nmakes it also attractive for online learning or network compression\napplications.\n"]},
{"authors": ["Marcell Vazquez-Chanlatte", "Susmit Jha", "Ashish Tiwari", "Sanjit A. Seshia"], "title": ["Specification Inference from Demonstrations"], "date": ["2017-10-11T01:31:14Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.03875v2"], "summary": ["  Learning from expert demonstrations has received a lot of attention in\nartificial intelligence and machine learning. The goal is to infer the\nunderlying reward function that an agent is optimizing given a set of\nobservations of the agent's behavior over time in a variety of circumstances,\nthe system state trajectories, and a plant model specifying the evolution of\nthe system state for different agent's actions. The system is often modeled as\na Markov decision process, that is, the next state depends only on the current\nstate and agent's action, and the the agent's choice of action depends only on\nthe current state. While the former is a Markovian assumption on the evolution\nof system state, the later assumes that the target reward function is itself\nMarkovian. In this work, we explore learning a class of non-Markovian reward\nfunctions, known in the formal methods literature as specifications. These\nspecifications offer better composition, transferability, and interpretability.\nWe then show that inferring the specification can be done efficiently without\nunrolling the transition system. We demonstrate on a 2-d grid world example.\n"]},
{"authors": ["Arbaaz Khan", "Clark Zhang", "Nikolay Atanasov", "Konstantinos Karydis", "Vijay Kumar", "Daniel D. Lee"], "title": ["Memory Augmented Control Networks"], "date": ["2017-09-17T19:06:13Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1709.05706v6"], "summary": ["  Planning problems in partially observable environments cannot be solved\ndirectly with convolutional networks and require some form of memory. But, even\nmemory networks with sophisticated addressing schemes are unable to learn\nintelligent reasoning satisfactorily due to the complexity of simultaneously\nlearning to access memory and plan. To mitigate these challenges we introduce\nthe Memory Augmented Control Network (MACN). The proposed network architecture\nconsists of three main parts. The first part uses convolutions to extract\nfeatures and the second part uses a neural network-based planning module to\npre-plan in the environment. The third part uses a network controller that\nlearns to store those specific instances of past information that are necessary\nfor planning. The performance of the network is evaluated in discrete grid\nworld environments for path planning in the presence of simple and complex\nobstacles. We show that our network learns to plan and can generalize to new\nenvironments.\n"]},
{"authors": ["Yuan Jin", "Mark Carman", "Ye Zhu", "Wray Buntine"], "title": ["Distinguishing Question Subjectivity from Difficulty for Improved\n  Crowdsourcing"], "date": ["2018-02-12T12:39:28Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04009v2"], "summary": ["  The questions in a crowdsourcing task typically exhibit varying degrees of\ndifficulty and subjectivity. Their joint effects give rise to the variation in\nresponses to the same question by different crowd-workers. This variation is\nlow when the question is easy to answer and objective, and high when it is\ndifficult and subjective. Unfortunately, current quality control methods for\ncrowdsourcing consider only the question difficulty to account for the\nvariation. As a result,these methods cannot distinguish workers personal\npreferences for different correct answers of a partially subjective question\nfrom their ability/expertise to avoid objectively wrong answers for that\nquestion. To address this issue, we present a probabilistic model which (i)\nexplicitly encodes question difficulty as a model parameter and (ii) implicitly\nencodes question subjectivity via latent preference factors for crowd-workers.\nWe show that question subjectivity induces grouping of crowd-workers, revealed\nthrough clustering of their latent preferences. Moreover, we develop a\nquantitative measure of the subjectivity of a question. Experiments show that\nour model(1) improves the performance of both quality control for crowd-sourced\nanswers and next answer prediction for crowd-workers,and (2) can potentially\nprovide coherent rankings of questions in terms of their difficulty and\nsubjectivity, so that task providers can refine their designs of the\ncrowdsourcing tasks, e.g. by removing highly subjective questions or\ninappropriately difficult questions.\n"]},
{"authors": ["Songguang Ho", "Sarat Chandra Nagavarapu", "Ramesh Ramasamy Pandi", "Justin Dauwels"], "title": ["An Improved Tabu Search Heuristic for Static Dial-A-Ride Problem"], "date": ["2018-01-25T09:46:42Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.09547v5"], "summary": ["  Multi-vehicle routing has become increasingly important with the rapid\ndevelopment of autonomous vehicle technology. Dial-a-ride problem, a variant of\nvehicle routing problem (VRP), deals with the allocation of customer requests\nto vehicles, scheduling the pick-up and drop-off times and the sequence of\nserving those requests by ensuring high customer satisfaction with minimized\ntravel cost. In this paper, we propose an improved tabu search (ITS) heuristic\nfor static dial-a-ride problem (DARP) with the objective of obtaining\nhigh-quality solutions in short time. Two new techniques, initialization\nheuristic, and time window adjustment are proposed to achieve faster\nconvergence to the global optimum. Various numerical experiments are conducted\nfor the proposed solution methodology using DARP test instances from the\nliterature and the convergence speed up is validated.\n"]},
{"authors": ["Tian Qi Chen", "Xuechen Li", "Roger Grosse", "David Duvenaud"], "title": ["Isolating Sources of Disentanglement in Variational Autoencoders"], "date": ["2018-02-14T03:48:06Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04942v1"], "summary": ["  We decompose the evidence lower bound to show the existence of a term\nmeasuring the total correlation between latent variables. We use this to\nmotivate our $\\beta$-TCVAE (Total Correlation Variational Autoencoder), a\nrefinement of the state-of-the-art $\\beta$-VAE objective for learning\ndisentangled representations, requiring no additional hyperparameters during\ntraining. We further propose a principled classifier-free measure of\ndisentanglement called the mutual information gap (MIG). We perform extensive\nquantitative and qualitative experiments, in both restricted and non-restricted\nsettings, and show a strong relation between total correlation and\ndisentanglement, when the latent variables model is trained using our\nframework.\n"]},
{"authors": ["David M. Blum", "M. Elisabeth Pate-Cornell"], "title": ["Probabilistic Warnings in National Security Crises: Pearl Harbor\n  Revisited"], "date": ["2018-02-13T22:54:28Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04887v1"], "summary": ["  Imagine a situation where a group of adversaries is preparing an attack on\nthe United States or U.S. interests. An intelligence analyst has observed some\nsignals, but the situation is rapidly changing. The analyst faces the decision\nto alert a principal decision maker that an attack is imminent, or to wait\nuntil more is known about the situation. This warning decision is based on the\nanalyst's observation and evaluation of signals, independent or correlated, and\non her updating of the prior probabilities of possible scenarios and their\noutcomes. The warning decision also depends on the analyst's assessment of the\ncrisis' dynamics and perception of the preferences of the principal decision\nmaker, as well as the lead time needed for an appropriate response. This\narticle presents a model to support this analyst's dynamic warning decision. As\nwith most problems involving warning, the key is to manage the tradeoffs\nbetween false positives and false negatives given the probabilities and the\nconsequences of intelligence failures of both types. The model is illustrated\nby revisiting the case of the attack on Pearl Harbor in December 1941. It shows\nthat the radio silence of the Japanese fleet carried considerable information\n(Sir Arthur Conan Doyle's \"dog in the night\" problem), which was misinterpreted\nat the time. Even though the probabilities of different attacks were relatively\nlow, their consequences were such that the Bayesian dynamic reasoning described\nhere may have provided valuable information to key decision makers.\n"]},
{"authors": ["Daniel Selsam", "Matthew Lamm", "Benedikt B\u00fcnz", "Percy Liang", "Leonardo de Moura", "David L. Dill"], "title": ["Learning a SAT Solver from Single-Bit Supervision"], "date": ["2018-02-11T03:04:28Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.03685v2"], "summary": ["  We present NeuroSAT, a message passing neural network that learns to solve\nSAT problems after only being trained as a classifier to predict\nsatisfiability. Although it is not competitive with state-of-the-art SAT\nsolvers, NeuroSAT can solve problems that are substantially larger and more\ndifficult than it ever saw during training by simply running for more\niterations. Moreover, NeuroSAT generalizes to novel distributions; after\ntraining only on random SAT problems, at test time it can solve SAT problems\nencoding graph coloring, clique detection, dominating set, and vertex cover\nproblems, all on a range of distributions over small random graphs.\n"]},
{"authors": ["Amir Rosenfeld", "John K. Tsotsos"], "title": ["Challenging Images For Minds and Machines"], "date": ["2018-02-13T19:50:41Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04834v1"], "summary": ["  There is no denying the tremendous leap in the performance of machine\nlearning methods in the past half-decade. Some might even say that specific\nsub-fields in pattern recognition, such as machine-vision, are as good as\nsolved, reaching human and super-human levels. Arguably, lack of training data\nand computation power are all that stand between us and solving the remaining\nones. In this position paper we underline cases in vision which are challenging\nto machines and even to human observers. This is to show limitations of\ncontemporary models that are hard to ameliorate by following the current trend\nto increase training data, network capacity or computational power. Moreover,\nwe claim that attempting to do so is in principle a suboptimal approach. We\nprovide a taster of such examples in hope to encourage and challenge the\nmachine learning community to develop new directions to solve the said\ndifficulties.\n"]},
{"authors": ["Rein Houthooft", "Richard Y. Chen", "Phillip Isola", "Bradly C. Stadie", "Filip Wolski", "Jonathan Ho", "Pieter Abbeel"], "title": ["Evolved Policy Gradients"], "date": ["2018-02-13T19:07:43Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04821v1"], "summary": ["  We propose a meta-learning approach for learning gradient-based reinforcement\nlearning (RL) algorithms. The idea is to evolve a differentiable loss function,\nsuch that an agent, which optimizes its policy to minimize this loss, will\nachieve high rewards. The loss is parametrized via temporal convolutions over\nthe agent's experience. Because this loss is highly flexible in its ability to\ntake into account the agent's history, it enables fast task learning and\neliminates the need for reward shaping at test time. Empirical results show\nthat our evolved policy gradient algorithm achieves faster learning on several\nrandomized environments compared to an off-the-shelf policy gradient method.\nMoreover, at test time, our learner optimizes only its learned loss function,\nand requires no explicit reward signal. In effect, the agent internalizes the\nreward structure, suggesting a direction toward agents that learn to solve new\ntasks simply from intrinsic motivation.\n"]},
{"authors": ["Peter Clark"], "title": ["Story Generation and Aviation Incident Representation"], "date": ["2018-02-13T19:03:21Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04818v1"], "summary": ["  This working note discusses the topic of story generation, with a view to\nidentifying the knowledge required to understand aviation incident narratives\n(which have structural similarities to stories), following the premise that to\nunderstand aviation incidents, one should at least be able to generate examples\nof them. We give a brief overview of aviation incidents and their relation to\nstories, and then describe two of our earlier attempts (using `scripts' and\n`story grammars') at incident generation which did not evolve promisingly.\nFollowing this, we describe a simple incident generator which did work (at a\n`toy' level), using a `world simulation' approach. This generator is based on\nMeehan's TALE-SPIN story generator (1977). We conclude with a critique of the\napproach.\n"]},
{"authors": ["David Dao", "Dan Alistarh", "Claudiu Musat", "Ce Zhang"], "title": ["DataBright: Towards a Global Exchange for Decentralized Data Ownership\n  and Trusted Computation"], "date": ["2018-02-13T18:20:07Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04780v1"], "summary": ["  It is safe to assume that, for the foreseeable future, machine learning,\nespecially deep learning will remain both data- and computation-hungry. In this\npaper, we ask: Can we build a global exchange where everyone can contribute\ncomputation and data to train the next generation of machine learning\napplications?\n  We present an early, but running prototype of DataBright, a system that turns\nthe creation of training examples and the sharing of computation into an\ninvestment mechanism. Unlike most crowdsourcing platforms, where the\ncontributor gets paid when they submit their data, DataBright pays dividends\nwhenever a contributor's data or hardware is used by someone to train a machine\nlearning model. The contributor becomes a shareholder in the dataset they\ncreated. To enable the measurement of usage, a computation platform that\ncontributors can trust is also necessary. DataBright thus merges both a data\nmarket and a trusted computation market.\n  We illustrate that trusted computation can enable the creation of an AI\nmarket, where each data point has an exact value that should be paid to its\ncreator. DataBright allows data creators to retain ownership of their\ncontribution and attaches to it a measurable value. The value of the data is\ngiven by its utility in subsequent distributed computation done on the\nDataBright computation market. The computation market allocates tasks and\nsubsequent payments to pooled hardware. This leads to the creation of a\ndecentralized AI cloud. Our experiments show that trusted hardware such as\nIntel SGX can be added to the usual ML pipeline with no additional costs. We\nuse this setting to orchestrate distributed computation that enables the\ncreation of a computation market. DataBright is available for download at\nhttps://github.com/ds3lab/databright.\n"]},
{"authors": ["Glen Berseth", "Cheng Xie", "Paul Cernek", "Michiel Van de Panne"], "title": ["Progressive Reinforcement Learning with Distillation for Multi-Skilled\n  Motion Control"], "date": ["2018-02-13T17:57:21Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04765v1"], "summary": ["  Deep reinforcement learning has demonstrated increasing capabilities for\ncontinuous control problems, including agents that can move with skill and\nagility through their environment. An open problem in this setting is that of\ndeveloping good strategies for integrating or merging policies for multiple\nskills, where each individual skill is a specialist in a specific skill and its\nassociated state distribution. We extend policy distillation methods to the\ncontinuous action setting and leverage this technique to combine expert\npolicies, as evaluated in the domain of simulated bipedal locomotion across\ndifferent classes of terrain. We also introduce an input injection method for\naugmenting an existing policy network to exploit new input features. Lastly,\nour method uses transfer learning to assist in the efficient acquisition of new\nskills. The combination of these methods allows a policy to be incrementally\naugmented with new skills. We compare our progressive learning and integration\nvia distillation (PLAID) method against three alternative baselines.\n"]},
{"authors": ["Thomas Vandal", "Evan Kodra", "Jennifer Dy", "Sangram Ganguly", "Ramakrishna Nemani", "Auroop R. Ganguly"], "title": ["Quantifying Uncertainty in Discrete-Continuous and Skewed Data with\n  Bayesian Deep Learning"], "date": ["2018-02-13T17:07:13Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04742v1"], "summary": ["  Deep Learning (DL) methods have been transforming computer vision with\ninnovative adaptations to other domains including climate change. For DL to\npervade Science and Engineering (S\\&E) applications where risk management is a\ncore component, well-characterized uncertainty estimates must accompany\npredictions. However, S\\&E observations and model-simulations often follow\nheavily skewed distributions and are not well modeled with DL approaches, since\nthey usually optimize a Gaussian, or Euclidean, likelihood loss. Recent\ndevelopments in Bayesian Deep Learning (BDL), which attempts to capture\nuncertainties from noisy observations, aleatoric, and from unknown model\nparameters, epistemic, provide us a foundation. Here we present a\ndiscrete-continuous BDL model with Gaussian and lognormal likelihoods for\nuncertainty quantification (UQ). We demonstrate the approach by developing UQ\nestimates on \"DeepSD\", a super-resolution based DL model for Statistical\nDownscaling (SD) in climate applied to precipitation, which follows an\nextremely skewed distribution. We find that the discrete-continuous models\noutperform a basic Gaussian distribution in terms of predictive accuracy and\nuncertainty calibration. Furthermore, we find that the lognormal distribution,\nwhich can handle skewed distributions, produces quality uncertainty estimates\nat the extremes. Such results may be important across S\\&E, as well as other\ndomains such as finance and economics, where extremes are often of significant\ninterest. Furthermore, to our knowledge, this is the first UQ model in SD where\nboth aleatoric and epistemic uncertainties are characterized.\n"]},
{"authors": ["Arthur Guez", "Th\u00e9ophane Weber", "Ioannis Antonoglou", "Karen Simonyan", "Oriol Vinyals", "Daan Wierstra", "R\u00e9mi Munos", "David Silver"], "title": ["Learning to Search with MCTSnets"], "date": ["2018-02-13T16:10:10Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04697v1"], "summary": ["  Planning problems are among the most important and well-studied problems in\nartificial intelligence. They are most typically solved by tree search\nalgorithms that simulate ahead into the future, evaluate future states, and\nback-up those evaluations to the root of a search tree. Among these algorithms,\nMonte-Carlo tree search (MCTS) is one of the most general, powerful and widely\nused. A typical implementation of MCTS uses cleverly designed rules, optimized\nto the particular characteristics of the domain. These rules control where the\nsimulation traverses, what to evaluate in the states that are reached, and how\nto back-up those evaluations. In this paper we instead learn where, what and\nhow to search. Our architecture, which we call an MCTSnet, incorporates\nsimulation-based search inside a neural network, by expanding, evaluating and\nbacking-up a vector embedding. The parameters of the network are trained\nend-to-end using gradient-based optimisation. When applied to small searches in\nthe well known planning problem Sokoban, the learned search algorithm\nsignificantly outperformed MCTS baselines.\n"]},
{"authors": ["Parth Mehta", "Gaurav Arora", "Prasenjit Majumder"], "title": ["Attention based Sentence Extraction from Scientific Articles using\n  Pseudo-Labeled data"], "date": ["2018-02-13T15:13:28Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04675v1"], "summary": ["  In this work, we present a weakly supervised sentence extraction technique\nfor identifying important sentences in scientific papers that are worthy of\ninclusion in the abstract. We propose a new attention based deep learning\narchitecture that jointly learns to identify important content, as well as the\ncue phrases that are indicative of summary worthy sentences. We propose a new\ncontext embedding technique for determining the focus of a given paper using\ntopic models and use it jointly with an LSTM based sequence encoder to learn\nattention weights across the sentence words. We use a collection of articles\npublicly available through ACL anthology for our experiments. Our system\nachieves a performance that is better, in terms of several ROUGE metrics, as\ncompared to several state of art extractive techniques. It also generates more\ncoherent summaries and preserves the overall structure of the document.\n"]},
{"authors": ["Marta Sanzari", "Valsamis Ntouskos", "Simone Grazioso", "Francesco Puja", "Fiora Pirri"], "title": ["Human motion primitive discovery and recognition"], "date": ["2017-09-29T16:59:06Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1709.10494v3"], "summary": ["  We present a novel framework for the automatic discovery and recognition of\nhuman motion primitives from motion capture data. Human motion primitives are\ndiscovered by optimizing the 'motion flux', a quantity which depends on the\nmotion of a group of skeletal joints. Models of each primitive category are\ncomputed via non-parametric Bayes methods and recognition is performed based on\ntheir geometric properties. A normalization of the primitives is proposed in\norder to make them invariant with respect to anatomical variations and data\nsampling rate. Using our framework we build a publicly available dataset of\nhuman motion primitives based on motion capture sequences taken from well-known\ndatasets. We expect that our framework, by providing an objective way for\ndiscovering and categorizing human motion, will be a useful tool in numerous\nresearch fields related to Robotics including human inspired motion generation,\nlearning by demonstration, and intuitive human-robot interaction.\n"]},
{"authors": ["Tommaso Soru", "Andr\u00e9 Valdestilhas", "Edgard Marx", "Axel-Cyrille Ngonga Ngomo"], "title": ["Beyond Markov Logic: Efficient Mining of Prediction Rules in Large\n  Graphs"], "date": ["2018-02-10T18:46:54Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.03638v2"], "summary": ["  Graph representations of large knowledge bases may comprise billions of\nedges. Usually built upon human-generated ontologies, several knowledge bases\ndo not feature declared ontological rules and are far from being complete.\nCurrent rule mining approaches rely on schemata or store the graph in-memory,\nwhich can be unfeasible for large graphs. In this paper, we introduce\nHornConcerto, an algorithm to discover Horn clauses in large graphs without the\nneed of a schema. Using a standard fact-based confidence score, we can mine\nclose Horn rules having an arbitrary body size. We show that our method can\noutperform existing approaches in terms of runtime and memory consumption and\nmine high-quality rules for the link prediction task, achieving\nstate-of-the-art results on a widely-used benchmark. Moreover, we find that\nrules alone can perform inference significantly faster than embedding-based\nmethods and achieve accuracies on link prediction comparable to\nresource-demanding approaches such as Markov Logic Networks.\n"]},
{"authors": ["Yunlong Mi", "Yong Shi", "Jinhai Li", "Jiabin Liu", "Biao Li"], "title": ["A generalized concept-cognitive learning: A machine learning viewpoint"], "date": ["2018-01-08T08:16:57Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.02334v2"], "summary": ["  Concept-cognitive learning (CCL) is a hot topic in recent years, and it has\nattracted much attention from the communities of formal concept analysis,\ngranular computing and cognitive computing. However, the relationship among\ncognitive computing (CC), concept-cognitive computing (CCC) and CCL is not\nclearly described. To this end, we explain the relationship of CC, CCC and CCL.\nThen, we propose a generalized concept-cognitive learning (GCCL) from the point\nof view of machine learning. Finally, experiments on some data sets are\nconducted to evaluate concept formation and concept-cognitive processes of the\nproposed GCCL.\n"]},
{"authors": ["Ling Pan", "Qingpeng Cai", "Zhixuan Fang", "Pingzhong Tang", "Longbo Huang"], "title": ["Rebalancing Dockless Bike Sharing Systems"], "date": ["2018-02-13T12:43:03Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04592v1"], "summary": ["  Bike sharing provides an environment-friendly way for traveling and is\nbooming all over the world. Yet, due to the high similarity of user travel\npatterns, the bike imbalance problem constantly occurs, especially for dockless\nbike sharing systems, causing significant impact on service quality and company\nrevenue. Thus, it has become a critical task for bike sharing systems to\nresolve such imbalance efficiently. We model this problem as a Markov decision\nprocess (MDP), which takes both temporal and spatial features into\nconsideration. We propose a novel deep reinforcement learning algorithm called\nLoss-Reduced Reinforcement Pricing (LRP), which builds upon the deterministic\npolicy gradient algorithm. Different from existing methods that often ignore\nspatial information and rely heavily on accurate prediction, LRP is embedded\nwith a novel network architecture to incorporate the dependence of neighboring\nregions, for reducing the training loss in Q-function learning. We conduct\nextensive experiments to evaluate the performance of the LRP algorithm, based\non trajectory data from Mobike, a major Chinese dockless bike sharing company.\nResults show that LRP performs close to the 24-timeslot look-ahead\noptimization, and outperforms state-of-the-art methods in both service level\nand bike distribution. It also transfers well when applied to unseen areas, and\ncan even make additional profit with the given budget. We further propose the\nfirst hybrid rebalancing system, which take advantages of both the truck-based\nand user-based approaches, and outperforms each individual approach.\n"]},
{"authors": ["Zhang-Wei Hong", "Tzu-Yun Shann", "Shih-Yang Su", "Yi-Hsiang Chang", "Chun-Yi Lee"], "title": ["Diversity-Driven Exploration Strategy for Deep Reinforcement Learning"], "date": ["2018-02-13T11:18:41Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04564v1"], "summary": ["  Efficient exploration remains a challenging research problem in reinforcement\nlearning, especially when an environment contains large state spaces, deceptive\nlocal optima, or sparse rewards. To tackle this problem, we present a\ndiversity-driven approach for exploration, which can be easily combined with\nboth off- and on-policy reinforcement learning algorithms. We show that by\nsimply adding a distance measure to the loss function, the proposed methodology\nsignificantly enhances an agent's exploratory behaviors, and thus preventing\nthe policy from being trapped in local optima. We further propose an adaptive\nscaling method for stabilizing the learning process. Our experimental results\nin Atari 2600 show that our method outperforms baseline approaches in several\ntasks in terms of mean scores and exploration efficiency.\n"]},
{"authors": ["Beate Bollig", "Matthias Buttkus"], "title": ["On the Relative Succinctness of Sentential Decision Diagrams"], "date": ["2018-02-13T10:34:27Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04544v1"], "summary": ["  Sentential decision diagrams (SDDs) introduced by Darwiche in 2011 are a\npromising representation type used in knowledge compilation. The relative\nsuccinctness of representation types is an important subject in this area. The\naim of the paper is to identify which kind of Boolean functions can be\nrepresented by SDDs of small size with respect to the number of variables the\nfunctions are defined on. For this reason the sets of Boolean functions\nrepresentable by different representation types in polynomial size are\ninvestigated and SDDs are compared with representation types from the classical\nknowledge compilation map of Darwiche and Marquis. Ordered binary decision\ndiagrams (OBDDs) which are a popular data structure for Boolean functions are\none of these representation types. SDDs are more general than OBDDs by\ndefinition but only recently, a Boolean function was presented with polynomial\nSDD size but exponential OBDD size. This result is strengthened in several\nways. The main result is a quasipolynomial simulation of SDDs by equivalent\nunambiguous nondeterministic OBDDs, a nondeterministic variant where there\nexists exactly one accepting computation for each satisfying input. As a side\neffect an open problem about the relative succinctness between SDDs and free\nbinary decision diagrams (FBDDs) which are more general than OBDDs is answered.\n"]},
{"authors": ["A. V. Palagin", "N. G. Petrenko", "V. Yu. Velychko", "K. S. Malakhov", "O. V. Karun"], "title": ["Principles of design and software development models of\n  ontological-driven computer systems"], "date": ["2018-02-13T10:20:44Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.06829v1"], "summary": ["  This paper describes the design principles of methodology of\nknowledge-oriented information systems based on ontological approach. Such\nsystems implement technology subject-oriented extraction of knowledge from the\nset of natural language texts and their formal and logical presentation and\napplication processing\n"]},
{"authors": ["Yi Tay", "Anh Tuan Luu", "Siu Cheung Hui"], "title": ["Latent Relational Metric Learning via Memory-based Attention for\n  Collaborative Ranking"], "date": ["2017-07-17T14:19:49Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1707.05176v3"], "summary": ["  This paper proposes a new neural architecture for collaborative ranking with\nimplicit feedback. Our model, LRML (\\textit{Latent Relational Metric Learning})\nis a novel metric learning approach for recommendation. More specifically,\ninstead of simple push-pull mechanisms between user and item pairs, we propose\nto learn latent relations that describe each user item interaction. This helps\nto alleviate the potential geometric inflexibility of existing metric learing\napproaches. This enables not only better performance but also a greater extent\nof modeling capability, allowing our model to scale to a larger number of\ninteractions. In order to do so, we employ a augmented memory module and learn\nto attend over these memory blocks to construct latent relations. The\nmemory-based attention module is controlled by the user-item interaction,\nmaking the learned relation vector specific to each user-item pair. Hence, this\ncan be interpreted as learning an exclusive and optimal relational translation\nfor each user-item interaction. The proposed architecture demonstrates the\nstate-of-the-art performance across multiple recommendation benchmarks. LRML\noutperforms other metric learning models by $6\\%-7.5\\%$ in terms of Hits@10 and\nnDCG@10 on large datasets such as Netflix and MovieLens20M. Moreover,\nqualitative studies also demonstrate evidence that our proposed model is able\nto infer and encode explicit sentiment, temporal and attribute information\ndespite being only trained on implicit feedback. As such, this ascertains the\nability of LRML to uncover hidden relational structure within implicit\ndatasets.\n"]},
{"authors": ["Xuelin Qian", "Yanwei Fu", "Wenxuan Wang", "Tao Xiang", "Yang Wu", "Yu-Gang Jiang", "Xiangyang Xue"], "title": ["Pose-Normalized Image Generation for Person Re-identification"], "date": ["2017-12-06T15:18:53Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1712.02225v5"], "summary": ["  Person Re-identification (re-id) faces two major challenges: the lack of\ncross-view paired training data and learning discriminative identity-sensitive\nand view-invariant features in the presence of large pose variations. In this\nwork, we address both problems by proposing a novel deep person image\ngeneration model for synthesizing realistic person images conditional on pose.\nThe model is based on a generative adversarial network (GAN) and used\nspecifically for pose normalization in re-id, thus termed pose-normalization\nGAN (PN-GAN). With the synthesized images, we can learn a new type of deep\nre-id feature free of the influence of pose variations. We show that this\nfeature is strong on its own and highly complementary to features learned with\nthe original images. Importantly, we now have a model that generalizes to any\nnew re-id dataset without the need for collecting any training data for model\nfine-tuning, thus making a deep re-id model truly scalable. Extensive\nexperiments on five benchmarks show that our model outperforms the\nstate-of-the-art models, often significantly. In particular, the features\nlearned on Market-1501 can achieve a Rank-1 accuracy of 68.67% on VIPeR without\nany model fine-tuning, beating almost all existing models fine-tuned on the\ndataset.\n"]},
{"authors": ["Ron Amit", "Ron Meir"], "title": ["Meta-Learning by Adjusting Priors Based on Extended PAC-Bayes Theory"], "date": ["2017-11-03T17:14:14Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.01244v3"], "summary": ["  In meta-learning an agent extracts knowledge from observed tasks, aiming to\nfacilitate learning of novel future tasks. Under the assumption that future\ntasks are 'related' to previous tasks, representations should be learned in a\nway which captures the common structure across learned tasks, while allowing\nthe learner sufficient flexibility to adapt to novel aspects of new tasks. We\npresent a framework for meta-learning that is based on generalization error\nbounds, allowing us to extend various PAC-Bayes bounds to meta-learning.\nLearning takes place through the construction of a distribution over hypotheses\nbased on the observed tasks, and its utilization for learning a new task. Thus,\nprior knowledge is incorporated through setting an experience-dependent prior\nfor novel tasks. We develop a gradient-based algorithm which minimizes an\nobjective function derived from the bounds and demonstrate its effectiveness\nnumerically with deep neural networks. In addition to establishing the improved\nperformance available through meta-learning, we demonstrate the intuitive way\nby which prior information is manifested at different levels of the network.\n"]},
{"authors": ["Tshilidzi Marwala", "Bo Xing"], "title": ["Blockchain and Artificial Intelligence"], "date": ["2018-02-13T03:10:59Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04451v1"], "summary": ["  It is undeniable that artificial intelligence (AI) and blockchain concepts\nare spreading at a phenomenal rate. Both technologies have distinct degree of\ntechnological complexity and multi-dimensional business implications. However,\na common misunderstanding about blockchain concept, in particular, is that\nblockchain is decentralized and is not controlled by anyone. But the underlying\ndevelopment of a blockchain system is still attributed to a cluster of core\ndevelopers. Take smart contract as an example, it is essentially a collection\nof codes (or functions) and data (or states) that are programmed and deployed\non a blockchain (say, Ethereum) by different human programmers. It is thus,\nunfortunately, less likely to be free of loopholes and flaws. In this article,\nthrough a brief overview about how artificial intelligence could be used to\ndeliver bug-free smart contract so as to achieve the goal of blockchain 2.0, we\nto emphasize that the blockchain implementation can be assisted or enhanced via\nvarious AI techniques. The alliance of AI and blockchain is expected to create\nnumerous possibilities.\n"]},
{"authors": ["Jeremy Bernstein", "Yu-Xiang Wang", "Kamyar Azizzadenesheli", "Anima Anandkumar"], "title": ["signSGD: compressed optimisation for non-convex problems"], "date": ["2018-02-13T02:14:35Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04434v1"], "summary": ["  Training large neural networks requires distributing learning across multiple\nworkers, where the cost of communicating gradients can be a significant\nbottleneck. signSGD alleviates this problem by transmitting just the sign of\neach minibatch stochastic gradient. We prove that it can get the best of both\nworlds: compressed gradients and SGD-level convergence rate. signSGD can\nexploit mismatches between L1 and L2 geometry: when noise and curvature are\nmuch sparser than the gradients, signSGD is expected to converge at the same\nrate or faster than full-precision SGD. Measurements of the L1 versus L2\ngeometry of real networks support our theoretical claims, and we find that the\nmomentum counterpart of signSGD is able to match the accuracy and convergence\nspeed of Adam on deep Imagenet models. We extend our theory to the distributed\nsetting, where the parameter server uses majority vote to aggregate gradient\nsigns from each worker enabling 1-bit compression of worker-server\ncommunication in both directions. Using a theorem by Gauss, we prove that the\nnon-convex convergence rate of majority vote matches that of distributed SGD.\nThus, there is great promise for sign-based optimisation schemes to achieve\nboth communication efficiency and high accuracy.\n"]},
{"authors": ["Elliot Meyerson", "Risto Miikkulainen"], "title": ["Beyond Shared Hierarchies: Deep Multitask Learning through Soft Layer\n  Ordering"], "date": ["2017-10-31T20:55:06Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.00108v2"], "summary": ["  Existing deep multitask learning (MTL) approaches align layers shared between\ntasks in a parallel ordering. Such an organization significantly constricts the\ntypes of shared structure that can be learned. The necessity of parallel\nordering for deep MTL is first tested by comparing it with permuted ordering of\nshared layers. The results indicate that a flexible ordering can enable more\neffective sharing, thus motivating the development of a soft ordering approach,\nwhich learns how shared layers are applied in different ways for different\ntasks. Deep MTL with soft ordering outperforms parallel ordering methods across\na series of domains. These results suggest that the power of deep MTL comes\nfrom learning highly general building blocks that can be assembled to meet the\ndemands of each task.\n"]},
{"authors": ["Hannah Morrison", "Chris Martens"], "title": ["\"How Was Your Weekend?\" A Generative Model of Phatic Conversation"], "date": ["2018-02-13T01:43:44Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04425v1"], "summary": ["  Unspoken social rules, such as those that govern choosing a proper discussion\ntopic and when to change discussion topics, guide conversational behaviors. We\npropose a computational model of conversation that can follow or break such\nrules, with participant agents that respond accordingly. Additionally, we\ndemonstrate an application of the model: the Experimental Social Tutor (EST), a\nfirst step toward a social skills training tool that generates human-readable\nconversation and a conversational guideline at each point in the dialogue.\nFinally, we discuss the design and results of a pilot study evaluating the EST.\nResults show that our model is capable of producing conversations that follow\nsocial norms.\n"]},
{"authors": ["Kamyar Azizzadenesheli", "Emma Brunskill", "Animashree Anandkumar"], "title": ["Efficient Exploration through Bayesian Deep Q-Networks"], "date": ["2018-02-13T00:48:17Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04412v1"], "summary": ["  We propose Bayesian Deep Q-Network (BDQN), a practical Thompson sampling\nbased Reinforcement Learning (RL) Algorithm. Thompson sampling allows for\ntargeted exploration in high dimensions through posterior sampling but is\nusually computationally expensive. We address this limitation by introducing\nuncertainty only at the output layer of the network through a Bayesian Linear\nRegression (BLR) model. This layer can be trained with fast closed-form updates\nand its samples can be drawn efficiently through the Gaussian distribution. We\napply our method to a wide range of Atari games in Arcade Learning\nEnvironments. Since BDQN carries out more efficient exploration, it is able to\nreach higher rewards substantially faster than a key baseline, the double deep\nQ network (DDQN).\n"]},
{"authors": ["Jeevana Priya Inala", "Sicun Gao", "Soonho Kong", "Armando Solar-Lezama"], "title": ["REAS: Combining Numerical Optimization with SAT Solving"], "date": ["2018-02-13T00:29:31Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04408v1"], "summary": ["  In this paper, we present ReaS, a technique that combines numerical\noptimization with SAT solving to synthesize unknowns in a program that involves\ndiscrete and floating point computation. ReaS makes the program end-to-end\ndifferentiable by smoothing any Boolean expression that introduces\ndiscontinuity such as conditionals and relaxing the Boolean unknowns so that\nnumerical optimization can be performed. On top of this, ReaS uses a SAT solver\nto help the numerical search overcome local solutions by incrementally fixing\nvalues to the Boolean expressions. We evaluated the approach on 5 case studies\ninvolving hybrid systems and show that ReaS can synthesize programs that could\nnot be solved by previous SMT approaches.\n"]},
{"authors": ["Bryon Aragam", "Chen Dan", "Pradeep Ravikumar", "Eric P. Xing"], "title": ["Identifiability of Nonparametric Mixture Models and Bayes Optimal\n  Clustering"], "date": ["2018-02-12T23:53:52Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04397v1"], "summary": ["  Motivated by problems in data clustering, we establish general conditions\nunder which families of nonparametric mixture models are identifiable by\nintroducing a novel framework for clustering overfitted \\emph{parametric} (i.e.\nmisspecified) mixture models. These conditions generalize existing conditions\nin the literature, and are flexible enough to include for example mixtures of\nGaussian mixtures. In contrast to the recent literature on estimating\nnonparametric mixtures, we allow for general nonparametric mixture components,\nand instead impose regularity assumptions on the underlying mixing measure. As\nour primary application, we apply these results to partition-based clustering,\ngeneralizing the well-known notion of a Bayes optimal partition from classical\nmodel-based clustering to nonparametric settings. Furthermore, this framework\nis constructive in that it yields a practical algorithm for learning identified\nmixtures, which is illustrated through several examples. The key conceptual\ndevice in the analysis is the convex, metric geometry of probability\ndistributions on metric spaces and its connection to optimal transport and the\nWasserstein convergence of mixing measures. The result is a flexible framework\nfor nonparametric clustering with formal consistency guarantees.\n"]},
{"authors": ["Yelong Shen", "Jianshu Chen", "Po-Sen Huang", "Yuqing Guo", "Jianfeng Gao"], "title": ["ReinforceWalk: Learning to Walk in Graph with Monte Carlo Tree Search"], "date": ["2018-02-12T23:27:23Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04394v1"], "summary": ["  Learning to walk over a graph towards a target node for a given input query\nand a source node is an important problem in applications such as knowledge\ngraph reasoning. It can be formulated as a reinforcement learning (RL) problem\nthat has a known state transition model, but with partial observability and\nsparse reward. To overcome these challenges, we develop a graph walking agent\ncalled ReinforceWalk, which consists of a deep recurrent neural network (RNN)\nand a Monte Carlo Tree Search (MCTS). To address partial observability, the RNN\nencodes the history of observations and map it into the Q-value, the policy and\nthe state value. In order to effectively train the agent from sparse reward, we\ncombine MCTS with the RNN policy to generate trajectories with more positive\nrewards. From these trajectories, we update the network in an off-policy manner\nusing Q-learning and improves the RNN policy. Our proposed RL algorithm\nrepeatedly applies this policy improvement step to learn the entire model. At\ntesting stage, the MCTS is also combined with the RNN to predict the target\nnode with higher accuracy. Experiment results on several graph-walking\nbenchmarks show that we are able to learn better policies from less number of\nrollouts compared to other baseline methods, which are mainly based on policy\ngradient method.\n"]},
{"authors": ["Matthew Ricci", "Junkyung Kim", "Thomas Serre"], "title": ["Not-So-CLEVR: Visual Relations Strain Feedforward Neural Networks"], "date": ["2018-02-09T18:55:34Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.03390v2"], "summary": ["  The robust and efficient recognition of visual relations in images is a\nhallmark of biological vision. Here, we argue that, despite recent progress in\nvisual recognition, modern machine vision algorithms are severely limited in\ntheir ability to learn visual relations. Through controlled experiments, we\ndemonstrate that visual-relation problems strain convolutional neural networks\n(CNNs). The networks eventually break altogether when rote memorization becomes\nimpossible such as when the intra-class variability exceeds their capacity. We\nfurther show that another type of feedforward network, called a relational\nnetwork (RN), which was shown to successfully solve seemingly difficult visual\nquestion answering (VQA) problems on the CLEVR datasets, suffers similar\nlimitations. Motivated by the comparable success of biological vision, we argue\nthat feedback mechanisms including working memory and attention are the key\ncomputational components underlying abstract visual reasoning.\n"]},
{"authors": ["Tianqi Chen", "Thierry Moreau", "Ziheng Jiang", "Haichen Shen", "Eddie Yan", "Leyuan Wang", "Yuwei Hu", "Luis Ceze", "Carlos Guestrin", "Arvind Krishnamurthy"], "title": ["TVM: End-to-End Optimization Stack for Deep Learning"], "date": ["2018-02-12T20:49:34Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04799v1"], "summary": ["  Scalable frameworks, such as TensorFlow, MXNet, Caffe, and PyTorch drive the\ncurrent popularity and utility of deep learning. However, these frameworks are\noptimized for a narrow range of server-class GPUs and deploying workloads to\nother platforms such as mobile phones, embedded devices, and specialized\naccelerators (e.g., FPGAs, ASICs) requires laborious manual effort. We propose\nTVM, an end-to-end optimization stack that exposes graph-level and\noperator-level optimizations to provide performance portability to deep\nlearning workloads across diverse hardware back-ends. We discuss the\noptimization challenges specific to deep learning that TVM solves: high-level\noperator fusion, low-level memory reuse across threads, mapping to arbitrary\nhardware primitives, and memory latency hiding. Experimental results\ndemonstrate that TVM delivers performance across hardware back-ends that are\ncompetitive with state-of-the-art libraries for low-power CPU and server-class\nGPUs. We also demonstrate TVM's ability to target new hardware accelerator\nback-ends by targeting an FPGA-based generic deep learning accelerator. The\ncompiler infrastructure is open sourced.\n"]},
{"authors": ["Illia Polosukhin", "Alexander Skidanov"], "title": ["Neural Program Search: Solving Programming Tasks from Description and\n  Examples"], "date": ["2018-02-12T20:05:26Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04335v1"], "summary": ["  We present a Neural Program Search, an algorithm to generate programs from\nnatural language description and a small number of input/output examples. The\nalgorithm combines methods from Deep Learning and Program Synthesis fields by\ndesigning rich domain-specific language (DSL) and defining efficient search\nalgorithm guided by a Seq2Tree model on it. To evaluate the quality of the\napproach we also present a semi-synthetic dataset of descriptions with test\nexamples and corresponding programs. We show that our algorithm significantly\noutperforms a sequence-to-sequence model with attention baseline.\n"]},
{"authors": ["Dane Corneil", "Wulfram Gerstner", "Johanni Brea"], "title": ["Efficient Model-Based Deep Reinforcement Learning with Variational State\n  Tabulation"], "date": ["2018-02-12T19:38:44Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04325v1"], "summary": ["  Modern reinforcement learning algorithms reach super-human performance in\nmany board and video games, but they are sample inefficient, i.e. they\ntypically require significantly more playing experience than humans to reach an\nequal performance level. To improve sample efficiency, an agent may build a\nmodel of the environment and use planning methods to update its policy. In this\narticle we introduce VaST (Variational State Tabulation), which maps an\nenvironment with a high-dimensional state space (e.g. the space of visual\ninputs) to an abstract tabular environment. Prioritized sweeping with small\nbackups, a highly efficient planning method, can then be used to update\nstate-action values. We show how VaST can rapidly learn to maximize reward in\ntasks like 3D navigation and efficiently adapt to sudden changes in rewards or\ntransition probabilities.\n"]},
{"authors": ["Mohammadreza Nazari", "Afshin Oroojlooy", "Lawrence V. Snyder", "Martin Tak\u00e1\u010d"], "title": ["Deep Reinforcement Learning for Solving the Vehicle Routing Problem"], "date": ["2018-02-12T18:41:57Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04240v1"], "summary": ["  We present an end-to-end framework for solving Vehicle Routing Problem (VRP)\nusing deep reinforcement learning. In this approach, we train a single model\nthat finds near-optimal solutions for problem instances sampled from a given\ndistribution, only by observing the reward signals and following feasibility\nrules. Our model represents a parameterized stochastic policy, and by applying\na policy gradient algorithm to optimize its parameters, the trained model\nproduces the solution as a sequence of consecutive actions in real time,\nwithout the need to re-train for every new problem instance. Our method is\nfaster in both training and inference than a recent method that solves the\nTraveling Salesman Problem (TSP), with nearly identical solution quality. On\nthe more general VRP, our approach outperforms classical heuristics on\nmedium-sized instances in both solution quality and computation time (after\ntraining). Our proposed framework can be applied to variants of the VRP such as\nthe stochastic VRP, and has the potential to be applied more generally to\ncombinatorial optimization problems.\n"]},
{"authors": ["Timoth\u00e9e Lesort", "Natalia D\u00edaz-Rodr\u00edguez", "Jean-Fran\u00e7ois Goudou", "David Filliat"], "title": ["State Representation Learning for Control: An Overview"], "date": ["2018-02-12T16:53:48Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04181v1"], "summary": ["  Representation learning algorithms are designed to learn abstract features\nthat characterize data. State representation learning (SRL) focuses on a\nparticular kind of representation learning where learned features are in low\ndimension, evolve through time, and are influenced by actions of an agent. As\nthe representation learned captures the variation in the environment generated\nby agents, this kind of representation is particularly suitable for robotics\nand control scenarios. In particular, the low dimension helps to overcome the\ncurse of dimensionality, provides easier interpretation and utilization by\nhumans and can help improve performance and speed in policy learning algorithms\nsuch as reinforcement learning.\n  This survey aims at covering the state-of-the-art on state representation\nlearning in the most recent years. It reviews different SRL methods that\ninvolve interaction with the environment, their implementations and their\napplications in robotics control tasks (simulated or real). In particular, it\nhighlights how generic learning objectives are differently exploited in the\nreviewed algorithms. Finally, it discusses evaluation methods to assess the\nrepresentation learned and summarizes current and future lines of research.\n"]},
{"authors": ["Elias Alevizos", "Alexander Artikis", "Nikos Katzouris", "Evangelos Michelioudakis", "Georgios Paliouras"], "title": ["The Complex Event Recognition Group"], "date": ["2018-02-12T14:54:30Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04086v1"], "summary": ["  The Complex Event Recognition (CER) group is a research team, affiliated with\nthe National Centre of Scientific Research \"Demokritos\" in Greece. The CER\ngroup works towards advanced and efficient methods for the recognition of\ncomplex events in a multitude of large, heterogeneous and interdependent data\nstreams. Its research covers multiple aspects of complex event recognition,\nfrom efficient detection of patterns on event streams to handling uncertainty\nand noise in streams, and machine learning techniques for inferring interesting\npatterns. Lately, it has expanded to methods for forecasting the occurrence of\nevents. It was founded in 2009 and currently hosts 3 senior researchers, 5 PhD\nstudents and works regularly with under-graduate students.\n"]},
{"authors": ["Tom Young", "Erik Cambria", "Iti Chaturvedi", "Minlie Huang", "Hao Zhou", "Subham Biswas"], "title": ["Augmenting End-to-End Dialog Systems with Commonsense Knowledge"], "date": ["2017-09-16T04:14:53Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1709.05453v3"], "summary": ["  Building dialog agents that can converse naturally with humans is a\nchallenging yet intriguing problem of artificial intelligence. In open-domain\nhuman-computer conversation, where the conversational agent is expected to\nrespond to human responses in an interesting and engaging way, commonsense\nknowledge has to be integrated into the model effectively. In this paper, we\ninvestigate the impact of providing commonsense knowledge about the concepts\ncovered in the dialog. Our model represents the first attempt to integrating a\nlarge commonsense knowledge base into end-to-end conversational models. In the\nretrieval-based scenario, we propose the Tri-LSTM model to jointly take into\naccount message and commonsense for selecting an appropriate response. Our\nexperiments suggest that the knowledge-augmented models are superior to their\nknowledge-free counterparts in automatic evaluation.\n"]},
{"authors": ["Giacomo Kahn", "Alexandre Bazin"], "title": ["Average Size of Implicational Bases"], "date": ["2018-02-12T13:31:27Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04032v1"], "summary": ["  Implicational bases are objects of interest in formal concept analysis and\nits applications. Unfortunately, even the smallest base, the Duquenne-Guigues\nbase, has an exponential size in the worst case. In this paper, we use results\non the average number of minimal transversals in random hypergraphs to show\nthat the base of proper premises is, on average, of quasi-polynomial size.\n"]},
{"authors": ["Giacomo Kahn", "Alexandre Bazin"], "title": ["Introducer Concepts in n-Dimensional Contexts"], "date": ["2018-02-12T13:29:46Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04030v1"], "summary": ["  Concept lattices are well-known conceptual structures that organise\ninteresting patterns-the concepts-extracted from data. In some applications,\nsuch as software engineering or data mining, the size of the lattice can be a\nproblem, as it is often too large to be efficiently computed, and too complex\nto be browsed. For this reason, the Galois Sub-Hierarchy, a restriction of the\nconcept lattice to introducer concepts, has been introduced as a smaller\nalternative. In this paper, we generalise the Galois Sub-Hierarchy to\nn-lattices, conceptual structures obtained from multidimensional data in the\nsame way that concept lattices are obtained from binary relations.\n"]},
{"authors": ["Zarathustra Goertzel", "Jan Jakub\u016fv", "Stephan Schulz", "Josef Urban"], "title": ["ProofWatch: Watchlist Guidance for Large Theories in E"], "date": ["2018-02-12T12:38:55Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04007v1"], "summary": ["  Watchlist (also hint list) is a mechanism that allows related proofs to guide\na proof search for a new conjecture. This mechanism has been used with the\nOtter and Prover9 theorem provers, both for interactive formalizations and for\nhuman-assisted proving of open conjectures in small theories. In this work we\nexplore the use of watchlists in large theories coming from first-order\ntranslations of large ITP libraries, aiming at improving hammer-style\nautomation by smarter internal guidance of the ATP systems. In particular, we\n(i) design watchlist-based clause evaluation heuristics inside the E ATP\nsystem, and (ii) develop new proof guiding algorithms that load many previous\nproofs inside the ATP and focus the proof search using a dynamically updated\nnotion of proof matching. The methods are evaluated on a large set of problems\ncoming from the Mizar library, showing significant improvement of E's standard\nportfolio of strategies, and also of the previous best set of strategies\ninvented for Mizar by evolutionary methods.\n"]},
{"authors": ["Mohammed Amin Abdullah", "Aldo Pacchiano", "Moez Draief"], "title": ["A note on reinforcement learning with Wasserstein distance\n  regularisation, with applications to multipolicy learning"], "date": ["2018-02-12T11:08:43Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.03976v1"], "summary": ["  In this note we describe an application of Wasserstein distance to\nReinforcement Learning. The Wasserstein distance in question is between the\ndistribution of mappings of trajectories of a policy into some metric space,\nand some other fixed distribution (which may, for example, come from another\npolicy). Different policies induce different distributions, so given an\nunderlying metric, the Wasserstein distance quantifies how different policies\nare. This can be used to learn multiple polices which are different in terms of\nsuch Wasserstein distances by using a Wasserstein regulariser. Changing the\nsign of the regularisation parameter, one can learn a policy for which its\ntrajectory mapping distribution is attracted to a given fixed distribution.\n"]},
{"authors": ["Ahmed Elgammal", "Marian Mazzone", "Bingchen Liu", "Diana Kim", "Mohamed Elhoseiny"], "title": ["The Shape of Art History in the Eyes of the Machine"], "date": ["2018-01-23T19:05:21Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.07729v2"], "summary": ["  How does the machine classify styles in art? And how does it relate to art\nhistorians' methods for analyzing style? Several studies have shown the ability\nof the machine to learn and predict style categories, such as Renaissance,\nBaroque, Impressionism, etc., from images of paintings. This implies that the\nmachine can learn an internal representation encoding discriminative features\nthrough its visual analysis. However, such a representation is not necessarily\ninterpretable. We conducted a comprehensive study of several of the\nstate-of-the-art convolutional neural networks applied to the task of style\nclassification on 77K images of paintings, and analyzed the learned\nrepresentation through correlation analysis with concepts derived from art\nhistory. Surprisingly, the networks could place the works of art in a smooth\ntemporal arrangement mainly based on learning style labels, without any a\npriori knowledge of time of creation, the historical time and context of\nstyles, or relations between styles. The learned representations showed that\nthere are few underlying factors that explain the visual variations of style in\nart. Some of these factors were found to correlate with style patterns\nsuggested by Heinrich W\\\"olfflin (1846-1945). The learned representations also\nconsistently highlighted certain artists as the extreme distinctive\nrepresentative of their styles, which quantitatively confirms art historian\nobservations.\n"]},
{"authors": ["Simyung Chang", "YoungJoon Yoo", "Jaeseok Choi", "Nojun Kwak"], "title": ["BOOK: Storing Algorithm-Invariant Episodes for Deep Reinforcement\n  Learning"], "date": ["2017-09-05T09:47:41Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1709.01308v3"], "summary": ["  We introduce a novel method to train agents of reinforcement learning (RL) by\nsharing knowledge in a way similar to the concept of using a book. The recorded\ninformation in the form of a book is the main means by which humans learn\nknowledge. Nevertheless, the conventional deep RL methods have mainly focused\neither on experiential learning where the agent learns through interactions\nwith the environment from the start or on imitation learning that tries to\nmimic the teacher. Contrary to these, our proposed book learning shares key\ninformation among different agents in a book-like manner by delving into the\nfollowing two characteristic features: (1) By defining the linguistic function,\ninput states can be clustered semantically into a relatively small number of\ncore clusters, which are forwarded to other RL agents in a prescribed manner.\n(2) By defining state priorities and the contents for recording, core\nexperiences can be selected and stored in a small container. We call this\ncontainer as `BOOK'. Our method learns hundreds to thousand times faster than\nthe conventional methods by learning only a handful of core cluster\ninformation, which shows that deep RL agents can effectively learn through the\nshared knowledge from other agents.\n"]},
{"authors": ["Vijay Manikandan Janakiraman"], "title": ["Explaining Aviation Safety Incidents Using Deep Temporal Multiple\n  Instance Learning"], "date": ["2017-10-12T23:42:00Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.04749v2"], "summary": ["  Although aviation accidents are rare, safety incidents occur more frequently\nand require a careful analysis to detect and mitigate risks in a timely manner.\nAnalyzing safety incidents using operational data and producing event-based\nexplanations is invaluable to airline companies as well as to governing\norganizations such as the Federal Aviation Administration (FAA) in the United\nStates. However, this task is challenging because of the complexity involved in\nmining multi-dimensional heterogeneous time series data, the lack of\ntime-step-wise annotation of events in a flight, and the lack of scalable tools\nto perform analysis over a large number of events. In this work, we propose a\nprecursor mining algorithm that identifies events in the multidimensional time\nseries that are correlated with the safety incident. Precursors are valuable to\nsystems health and safety monitoring and in explaining and forecasting safety\nincidents. Current methods suffer from poor scalability to high dimensional\ntime series data and are inefficient in capturing temporal behavior. We propose\nan approach by combining multiple-instance learning (MIL) and deep recurrent\nneural networks (DRNN) to take advantage of MIL's ability to learn using weakly\nsupervised data and DRNN's ability to model temporal behavior. We describe the\nalgorithm, the data, the intuition behind taking a MIL approach, and a\ncomparative analysis of the proposed algorithm with baseline models. We also\ndiscuss the application to a real-world aviation safety problem using data from\na commercial airline company and discuss the model's abilities and\nshortcomings, with some final remarks about possible deployment directions.\n"]},
{"authors": ["Sang-Woo Lee", "Yu-Jung Heo", "Byoung-Tak Zhang"], "title": ["Answerer in Questioner's Mind for Goal-Oriented Visual Dialogue"], "date": ["2018-02-12T04:08:06Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.03881v1"], "summary": ["  Goal-oriented dialogue has been paid attention for its numerous applications\nin artificial intelligence. To solve this task, deep learning and reinforcement\nlearning have recently been applied. However, these approaches struggle to find\na competent recurrent neural questioner, owing to the complexity of learning a\nseries of sentences. Motivated by theory of mind, we propose \"Answerer in\nQuestioner's Mind\" (AQM), a novel algorithm for goal-oriented dialogue. With\nAQM, a questioner asks and infers based on an approximated probabilistic model\nof the answerer. The questioner figures out the answerer's intent via selecting\na plausible question by explicitly calculating the information gain of the\ncandidate intentions and possible answers to each question. We test our\nframework on two goal-oriented visual dialogue tasks: \"MNIST Counting Dialog\"\nand \"GuessWhat?!.\" In our experiments, AQM outperforms comparative algorithms\nand makes human-like dialogue. We further use AQM as a tool for analyzing the\nmechanism of deep reinforcement learning approach and discuss the future\ndirection of practical goal-oriented neural dialogue systems.\n"]},
{"authors": ["Craig Atkinson", "Brendan McCane", "Lech Szymanski", "Anthony Robins"], "title": ["Pseudo-Recursal: Solving the Catastrophic Forgetting Problem in Deep\n  Neural Networks"], "date": ["2018-02-12T03:51:41Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.03875v1"], "summary": ["  In general, neural networks are not currently capable of learning tasks in a\nsequential fashion. When a novel, unrelated task is learnt by a neural network,\nit substantially forgets how to solve previously learnt tasks. One of the\noriginal solutions to this problem is pseudo-rehearsal, which involves learning\nthe new task while rehearsing generated items representative of the previous\ntask/s. This is very effective for simple tasks. However, pseudo-rehearsal has\nnot yet been successfully applied to very complex tasks because in these tasks\nit is difficult to generate representative items. We accomplish\npseudo-rehearsal by using a Generative Adversarial Network to generate items so\nthat our deep network can learn to sequentially classify the CIFAR-10, SVHN and\nMNIST datasets. After training on all tasks, our network loses only 1.67%\nabsolute accuracy on CIFAR-10 and gains 0.24% absolute accuracy on SVHN. Our\nmodel's performance is a substantial improvement compared to the current state\nof the art solution.\n"]},
{"authors": ["Feichen Shen", "Yugyung Lee"], "title": ["MedTQ: Dynamic Topic Discovery and Query Generation for Medical\n  Ontologies"], "date": ["2018-02-12T01:22:10Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.03855v1"], "summary": ["  Biomedical ontology refers to a shared conceptualization for a biomedical\ndomain of interest that has vastly improved data management and data sharing\nthrough the open data movement. The rapid growth and availability of biomedical\ndata make it impractical and computationally expensive to perform manual\nanalysis and query processing with the large scale ontologies. The lack of\nability in analyzing ontologies from such a variety of sources, and supporting\nknowledge discovery for clinical practice and biomedical research should be\novercome with new technologies. In this study, we developed a Medical Topic\ndiscovery and Query generation framework (MedTQ), which was composed by a\nseries of approaches and algorithms. A predicate neighborhood pattern-based\napproach introduced has the ability to compute the similarity of predicates\n(relations) in ontologies. Given a predicate similarity metric, machine\nlearning algorithms have been developed for automatic topic discovery and query\ngeneration. The topic discovery algorithm, called the hierarchical K-Means\nalgorithm was designed by extending an existing supervised algorithm (K-means\nclustering) for the construction of a topic hierarchy. In the hierarchical\nK-Means algorithm, a level-by-level optimization strategy was selected for\nconsistent with the strongly association between elements within a topic.\nAutomatic query generation was facilitated for discovered topic that could be\nguided users for interactive query design and processing. Evaluation was\nconducted to generate topic hierarchy for DrugBank ontology as a case study.\nResults demonstrated that the MedTQ framework can enhance knowledge discovery\nby capturing underlying structures from domain specific data and ontologies.\n"]},
{"authors": ["Mohamed El Halaby"], "title": ["Solving the Course-timetabling Problem of Cairo University Using Max-SAT"], "date": ["2018-02-11T23:40:25Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1803.05027v1"], "summary": ["  Due to the good performance of current SAT (satisfiability) and Max-SAT\n(maximum ssatisfiability) solvers, many real-life optimization problems such as\nscheduling can be solved by encoding them into Max-SAT. In this paper we tackle\nthe course timetabling problem of the department of mathematics, Cairo\nUniversity by encoding it into Max-SAT. Generating timetables for the\ndepartment by hand has proven to be cumbersome and the generated timetable\nalmost always contains conflicts. We show how the constraints can be modelled\nas a Max-SAT instance.\n"]},
{"authors": ["Xiujun Li", "Yun-Nung Chen", "Lihong Li", "Jianfeng Gao", "Asli Celikyilmaz"], "title": ["End-to-End Task-Completion Neural Dialogue Systems"], "date": ["2017-03-03T01:29:11Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1703.01008v4"], "summary": ["  One of the major drawbacks of modularized task-completion dialogue systems is\nthat each module is trained individually, which presents several challenges.\nFor example, downstream modules are affected by earlier modules, and the\nperformance of the entire system is not robust to the accumulated errors. This\npaper presents a novel end-to-end learning framework for task-completion\ndialogue systems to tackle such issues. Our neural dialogue system can directly\ninteract with a structured database to assist users in accessing information\nand accomplishing certain tasks. The reinforcement learning based dialogue\nmanager offers robust capabilities to handle noises caused by other components\nof the dialogue system. Our experiments in a movie-ticket booking domain show\nthat our end-to-end system not only outperforms modularized dialogue system\nbaselines for both objective and subjective evaluation, but also is robust to\nnoises as demonstrated by several systematic experiments with different error\ngranularity and rates specific to the language understanding module.\n"]},
{"authors": ["Tae Jun Lee", "Justin Gottschlich", "Nesime Tatbul", "Eric Metcalf", "Stan Zdonik"], "title": ["Greenhouse: A Zero-Positive Machine Learning System for Time-Series\n  Anomaly Detection"], "date": ["2018-01-09T22:44:21Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.03168v3"], "summary": ["  This short paper describes our ongoing research on Greenhouse - a\nzero-positive machine learning system for time-series anomaly detection.\n"]},
{"authors": ["Tae Jun Lee", "Justin Gottschlich", "Nesime Tatbul", "Eric Metcalf", "Stan Zdonik"], "title": ["Precision and Recall for Range-Based Anomaly Detection"], "date": ["2018-01-09T23:01:07Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.03175v3"], "summary": ["  Classical anomaly detection is principally concerned with point-based\nanomalies, anomalies that occur at a single data point. In this paper, we\npresent a new mathematical model to express range-based anomalies, anomalies\nthat occur over a range (or period) of time.\n"]},
{"authors": ["Brenden M. Lake", "Marco Baroni"], "title": ["Generalization without systematicity: On the compositional skills of\n  sequence-to-sequence recurrent networks"], "date": ["2017-10-31T01:50:02Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.00350v2"], "summary": ["  Humans can understand and produce new utterances effortlessly, thanks to\ntheir compositional skills. Once a person learns the meaning of a new verb\n\"dax,\" he or she can immediately understand the meaning of \"dax twice\" or \"sing\nand dax.\" In this paper, we introduce the SCAN domain, consisting of a set of\nsimple compositional navigation commands paired with the corresponding action\nsequences. We then test the zero-shot generalization capabilities of a variety\nof recurrent neural networks (RNNs) trained on SCAN with sequence-to-sequence\nmethods. We find that RNNs can make successful zero-shot generalizations when\nthe differences between training and test commands are small, so that they can\napply \"mix-and-match\" strategies to solve the task. However, when\ngeneralization requires systematic compositional skills (as in the \"dax\"\nexample above), RNNs fail spectacularly. We conclude with a proof-of-concept\nexperiment in neural machine translation, suggesting that lack of systematicity\nmight be partially responsible for neural networks' notorious training data\nthirst.\n"]},
{"authors": ["Klas Leino", "Linyi Li", "Shayak Sen", "Anupam Datta", "Matt Fredrikson"], "title": ["Influence-Directed Explanations for Deep Convolutional Networks"], "date": ["2018-02-11T18:28:56Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.03788v1"], "summary": ["  We study the problem of explaining a rich class of behavioral properties of\ndeep neural networks. Distinctively, our influence-directed explanations\napproach this problem by peering inside the net- work to identify neurons with\nhigh influence on the property and distribution of interest using an\naxiomatically justified influence measure, and then providing an interpretation\nfor the concepts these neurons represent. We evaluate our approach by training\nconvolutional neural net- works on MNIST, ImageNet, Pubfig, and Diabetic\nRetinopathy datasets. Our evaluation demonstrates that influence-directed\nexplanations (1) identify influential concepts that generalize across\ninstances, (2) help extract the essence of what the network learned about a\nclass, (3) isolate individual features the network uses to make decisions and\ndistinguish related instances, and (4) assist in understanding\nmisclassifications.\n"]},
{"authors": ["Wei Wen", "Yuxiong He", "Samyam Rajbhandari", "Minjia Zhang", "Wenhan Wang", "Fang Liu", "Bin Hu", "Yiran Chen", "Hai Li"], "title": ["Learning Intrinsic Sparse Structures within Long Short-Term Memory"], "date": ["2017-09-15T01:10:23Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1709.05027v7"], "summary": ["  Model compression is significant for the wide adoption of Recurrent Neural\nNetworks (RNNs) in both user devices possessing limited resources and business\nclusters requiring quick responses to large-scale service requests. This work\naims to learn structurally-sparse Long Short-Term Memory (LSTM) by reducing the\nsizes of basic structures within LSTM units, including input updates, gates,\nhidden states, cell states and outputs. Independently reducing the sizes of\nbasic structures can result in inconsistent dimensions among them, and\nconsequently, end up with invalid LSTM units. To overcome the problem, we\npropose Intrinsic Sparse Structures (ISS) in LSTMs. Removing a component of ISS\nwill simultaneously decrease the sizes of all basic structures by one and\nthereby always maintain the dimension consistency. By learning ISS within LSTM\nunits, the obtained LSTMs remain regular while having much smaller basic\nstructures. Based on group Lasso regularization, our method achieves 10.59x\nspeedup without losing any perplexity of a language modeling of Penn TreeBank\ndataset. It is also successfully evaluated through a compact model with only\n2.69M weights for machine Question Answering of SQuAD dataset. Our approach is\nsuccessfully extended to non- LSTM RNNs, like Recurrent Highway Networks\n(RHNs). Our source code is publicly available at\nhttps://github.com/wenwei202/iss-rnns\n"]},
{"authors": ["Gell\u00e9rt Weisz", "Pawe\u0142 Budzianowski", "Pei-Hao Su", "Milica Ga\u0161i\u0107"], "title": ["Sample Efficient Deep Reinforcement Learning for Dialogue Systems with\n  Large Action Spaces"], "date": ["2018-02-11T15:37:37Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.03753v1"], "summary": ["  In spoken dialogue systems, we aim to deploy artificial intelligence to build\nautomated dialogue agents that can converse with humans. A part of this effort\nis the policy optimisation task, which attempts to find a policy describing how\nto respond to humans, in the form of a function taking the current state of the\ndialogue and returning the response of the system. In this paper, we\ninvestigate deep reinforcement learning approaches to solve this problem.\nParticular attention is given to actor-critic methods, off-policy reinforcement\nlearning with experience replay, and various methods aimed at reducing the bias\nand variance of estimators. When combined, these methods result in the\npreviously proposed ACER algorithm that gave competitive results in gaming\nenvironments. These environments however are fully observable and have a\nrelatively small action set so in this paper we examine the application of ACER\nto dialogue policy optimisation. We show that this method beats the current\nstate-of-the-art in deep learning approaches for spoken dialogue systems. This\nnot only leads to a more sample efficient algorithm that can train faster, but\nalso allows us to apply the algorithm in more difficult environments than\nbefore. We thus experiment with learning in a very large action space, which\nhas two orders of magnitude more actions than previously considered. We find\nthat ACER trains significantly faster than the current state-of-the-art.\n"]},
{"authors": ["Bernd Malle", "Nicola Giuliani", "Peter Kieseberg", "Andreas Holzinger"], "title": ["The Need for Speed of AI Applications: Performance Comparison of Native\n  vs. Browser-based Algorithm Implementations"], "date": ["2018-02-11T08:09:17Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.03707v1"], "summary": ["  AI applications pose increasing demands on performance, so it is not\nsurprising that the era of client-side distributed software is becoming\nimportant. On top of many AI applications already using mobile hardware, and\neven browsers for computationally demanding AI applications, we are already\nwitnessing the emergence of client-side (federated) machine learning\nalgorithms, driven by the interests of large corporations and startups alike.\nApart from mathematical and algorithmic concerns, this trend especially demands\nnew levels of computational efficiency from client environments. Consequently,\nthis paper deals with the question of state-of-the-art performance by\npresenting a comparison study between native code and different browser-based\nimplementations: JavaScript, ASM.js as well as WebAssembly on a representative\nmix of algorithms. Our results show that current efforts in runtime\noptimization push the boundaries well towards (and even beyond) native binary\nperformance. We analyze the results obtained and speculate on the reasons\nbehind some surprises, rounding the paper off by outlining future possibilities\nas well as some of our own research efforts.\n"]},
{"authors": ["Sourish Dasgupta", "Ankur Padia", "Gaurav Maheshwari", "Priyansh Trivedi", "Jens Lehmann"], "title": ["Formal Ontology Learning from English IS-A Sentences"], "date": ["2018-02-11T06:41:54Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.03701v1"], "summary": ["  Ontology learning (OL) is the process of automatically generating an\nontological knowledge base from a plain text document. In this paper, we\npropose a new ontology learning approach and tool, called DLOL, which generates\na knowledge base in the description logic (DL) SHOQ(D) from a collection of\nfactual non-negative IS-A sentences in English. We provide extensive\nexperimental results on the accuracy of DLOL, giving experimental comparisons\nto three state-of-the-art existing OL tools, namely Text2Onto, FRED, and LExO.\nHere, we use the standard OL accuracy measure, called lexical accuracy, and a\nnovel OL accuracy measure, called instance-based inference model. In our\nexperimental results, DLOL turns out to be about 21% and 46%, respectively,\nbetter than the best of the other three approaches.\n"]},
{"authors": ["Xinyun Chen", "Chang Liu", "Dawn Song"], "title": ["Tree-to-tree Neural Networks for Program Translation"], "date": ["2018-02-11T04:42:03Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.03691v1"], "summary": ["  Program translation is an important tool to migrate legacy code in one\nlanguage into an ecosystem built in a different language. In this work, we are\nthe first to consider employing deep neural networks toward tackling this\nproblem. We observe that program translation is a modular procedure, in which a\nsub-tree of the source tree is translated into the corresponding target\nsub-tree at each step. To capture this intuition, we design a tree-to-tree\nneural network as an encoder-decoder architecture to translate a source tree\ninto a target one. Meanwhile, we develop an attention mechanism for the\ntree-to-tree model, so that when the decoder expands one non-terminal in the\ntarget tree, the attention mechanism locates the corresponding sub-tree in the\nsource tree to guide the expansion of the decoder. We evaluate the program\ntranslation capability of our tree-to-tree model against several\nstate-of-the-art approaches. Compared against other neural translation models,\nwe observe that our approach is consistently better than the baselines with a\nmargin of up to 15 points. Further, our approach can improve the previous\nstate-of-the-art program translation approaches by a margin of 20 points on the\ntranslation of real-world projects.\n"]},
{"authors": ["Chengliang Yang", "Anand Rangarajan", "Sanjay Ranka"], "title": ["Global Model Interpretation via Recursive Partitioning"], "date": ["2018-02-11T00:24:32Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04253v1"], "summary": ["  In this work, we propose a simple but effective method to interpret black-box\nmachine learning models globally. That is, we use a compact binary tree, the\ninterpretation tree, to explicitly represent the most important decision rules\nthat are implicitly contained in the black-box machine learning models. This\ntree is learned from the contribution matrix which consists of the\ncontributions of input variables to predicted scores for each single\nprediction. To generate the interpretation tree, a unified process recursively\npartitions the input variable space by maximizing the difference in the average\ncontribution of the split variable between the divided spaces. We demonstrate\nthe effectiveness of our method in diagnosing machine learning models on\nmultiple tasks. Also, it is useful for new knowledge discovery as such insights\nare not easily identifiable when only looking at single predictions. In\ngeneral, our work makes it easier and more efficient for human beings to\nunderstand machine learning models.\n"]},
{"authors": ["Yonathan Efroni", "Gal Dalal", "Bruno Scherrer", "Shie Mannor"], "title": ["Beyond the One Step Greedy Approach in Reinforcement Learning"], "date": ["2018-02-10T22:22:03Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.03654v1"], "summary": ["  The famous Policy Iteration algorithm alternates between policy improvement\nand policy evaluation. Implementations of this algorithm with several variants\nof the latter evaluation stage, e.g, $n$-step and trace-based returns, have\nbeen analyzed in previous works. However, the case of multiple-step lookahead\npolicy improvement, despite the recent increase in empirical evidence of its\nstrength, has to our knowledge not been carefully analyzed yet. In this work,\nwe introduce the first such analysis. Namely, we formulate variants of\nmultiple-step policy improvement, derive new algorithms using these definitions\nand prove their convergence. Moreover, we show that recent prominent\nReinforcement Learning algorithms are, in fact, instances of our framework. We\nthus shed light on their empirical success and give a recipe for deriving new\nalgorithms for future study.\n"]},
{"authors": ["Krishnendu Chatterjee", "Laurent Doyen"], "title": ["Graph Planning with Expected Finite Horizon"], "date": ["2018-02-10T19:12:03Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.03642v1"], "summary": ["  Graph planning gives rise to fundamental algorithmic questions such as\nshortest path, traveling salesman problem, etc. A classical problem in discrete\nplanning is to consider a weighted graph and construct a path that maximizes\nthe sum of weights for a given time horizon $T$. However, in many scenarios,\nthe time horizon is not fixed, but the stopping time is chosen according to\nsome distribution such that the expected stopping time is $T$. If the stopping\ntime distribution is not known, then to ensure robustness, the distribution is\nchosen by an adversary, to represent the worst-case scenario.\n  A stationary plan for every vertex always chooses the same outgoing edge. For\nfixed horizon or fixed stopping-time distribution, stationary plans are not\nsufficient for optimality. Quite surprisingly we show that when an adversary\nchooses the stopping-time distribution with expected stopping time $T$, then\nstationary plans are sufficient. While computing optimal stationary plans for\nfixed horizon is NP-complete, we show that computing optimal stationary plans\nunder adversarial stopping-time distribution can be achieved in polynomial\ntime. Consequently, our polynomial-time algorithm for adversarial stopping time\nalso computes an optimal plan among all possible plans.\n"]},
{"authors": ["Ofir Nachum", "Yinlam Chow", "Mohammad Ghavamzadeh"], "title": ["Path Consistency Learning in Tsallis Entropy Regularized MDPs"], "date": ["2018-02-10T01:57:49Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.03501v1"], "summary": ["  We study the sparse entropy-regularized reinforcement learning (ERL) problem\nin which the entropy term is a special form of the Tsallis entropy. The optimal\npolicy of this formulation is sparse, i.e.,~at each state, it has non-zero\nprobability for only a small number of actions. This addresses the main\ndrawback of the standard Shannon entropy-regularized RL (soft ERL) formulation,\nin which the optimal policy is softmax, and thus, may assign a non-negligible\nprobability mass to non-optimal actions. This problem is aggravated as the\nnumber of actions is increased. In this paper, we follow the work of Nachum et\nal. (2017) in the soft ERL setting, and propose a class of novel path\nconsistency learning (PCL) algorithms, called {\\em sparse PCL}, for the sparse\nERL problem that can work with both on-policy and off-policy data. We first\nderive a {\\em sparse consistency} equation that specifies a relationship\nbetween the optimal value function and policy of the sparse ERL along any\nsystem trajectory. Crucially, a weak form of the converse is also true, and we\nquantify the sub-optimality of a policy which satisfies sparse consistency, and\nshow that as we increase the number of actions, this sub-optimality is better\nthan that of the soft ERL optimal policy. We then use this result to derive the\nsparse PCL algorithms. We empirically compare sparse PCL with its soft\ncounterpart, and show its advantage, especially in problems with a large number\nof actions.\n"]},
{"authors": ["Chuanyun Xu", "Yang Zhang", "Xin Feng", "YongXing Ge", "Yihao Zhang", "Jianwu Long"], "title": ["Local Contrast Learning"], "date": ["2018-02-10T01:54:44Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.03499v1"], "summary": ["  Learning a deep model from small data is yet an opening and challenging\nproblem. We focus on one-shot classification by deep learning approach based on\na small quantity of training samples. We proposed a novel deep learning\napproach named Local Contrast Learning (LCL) based on the key insight about a\nhuman cognitive behavior that human recognizes the objects in a specific\ncontext by contrasting the objects in the context or in her/his memory. LCL is\nused to train a deep model that can contrast the recognizing sample with a\ncouple of contrastive samples randomly drawn and shuffled. On one-shot\nclassification task on Omniglot, the deep model based LCL with 122 layers and\n1.94 millions of parameters, which was trained on a tiny dataset with only 60\nclasses and 20 samples per class, achieved the accuracy 97.99% that outperforms\nhuman and state-of-the-art established by Bayesian Program Learning (BPL)\ntrained on 964 classes. LCL is a fundamental idea which can be applied to\nalleviate parametric model's overfitting resulted by lack of training samples.\n"]},
{"authors": ["Zilong Zhong", "Jonathan Li"], "title": ["Generative Adversarial Networks and Probabilistic Graph Models for\n  Hyperspectral Image Classification"], "date": ["2018-02-10T01:33:52Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.03495v1"], "summary": ["  High spectral dimensionality and the shortage of annotations make\nhyperspectral image (HSI) classification a challenging problem. Recent studies\nsuggest that convolutional neural networks can learn discriminative spatial\nfeatures, which play a paramount role in HSI interpretation. However, most of\nthese methods ignore the distinctive spectral-spatial characteristic of\nhyperspectral data. In addition, a large amount of unlabeled data remains an\nunexploited gold mine for efficient data use. Therefore, we proposed an\nintegration of generative adversarial networks (GANs) and probabilistic\ngraphical models for HSI classification. Specifically, we used a\nspectral-spatial generator and a discriminator to identify land cover\ncategories of hyperspectral cubes. Moreover, to take advantage of a large\namount of unlabeled data, we adopted a conditional random field to refine the\npreliminary classification results generated by GANs. Experimental results\nobtained using two commonly studied datasets demonstrate that the proposed\nframework achieved encouraging classification accuracy using a small number of\ndata for training.\n"]},
{"authors": ["Mehrdad Farajtabar", "Yinlam Chow", "Mohammad Ghavamzadeh"], "title": ["More Robust Doubly Robust Off-policy Evaluation"], "date": ["2018-02-10T01:32:03Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.03493v1"], "summary": ["  We study the problem of off-policy evaluation (OPE) in reinforcement learning\n(RL), where the goal is to estimate the performance of a policy from the data\ngenerated by another policy(ies). In particular, we focus on the doubly robust\n(DR) estimators that consist of an importance sampling (IS) component and a\nperformance model, and utilize the low (or zero) bias of IS and low variance of\nthe model at the same time. Although the accuracy of the model has a huge\nimpact on the overall performance of DR, most of the work on using the DR\nestimators in OPE has been focused on improving the IS part, and not much on\nhow to learn the model. In this paper, we propose alternative DR estimators,\ncalled more robust doubly robust (MRDR), that learn the model parameter by\nminimizing the variance of the DR estimator. We first present a formulation for\nlearning the DR model in RL. We then derive formulas for the variance of the DR\nestimator in both contextual bandits and RL, such that their gradients\nw.r.t.~the model parameters can be estimated from the samples, and propose\nmethods to efficiently minimize the variance. We prove that the MRDR estimators\nare strongly consistent and asymptotically optimal. Finally, we evaluate MRDR\nin bandits and RL benchmark problems, and compare its performance with the\nexisting methods.\n"]},
{"authors": ["Heung-Yeung Shum", "Xiaodong He", "Di Li"], "title": ["From Eliza to XiaoIce: Challenges and Opportunities with Social Chatbots"], "date": ["2018-01-06T03:14:22Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.01957v2"], "summary": ["  Conversational systems have come a long way since their inception in the\n1960s. After decades of research and development, we've seen progress from\nEliza and Parry in the 60's and 70's, to task-completion systems as in the\nDARPA Communicator program in the 2000s, to intelligent personal assistants\nsuch as Siri in the 2010s, to today's social chatbots like XiaoIce. Social\nchatbots' appeal lies not only in their ability to respond to users' diverse\nrequests, but also in being able to establish an emotional connection with\nusers. The latter is done by satisfying users' need for communication,\naffection, as well as social belonging. To further the advancement and adoption\nof social chatbots, their design must focus on user engagement and take both\nintellectual quotient (IQ) and emotional quotient (EQ) into account. Users\nshould want to engage with a social chatbot; as such, we define the success\nmetric for social chatbots as conversation-turns per session (CPS). Using\nXiaoIce as an illustrative example, we discuss key technologies in building\nsocial chatbots from core chat to visual awareness to skills. We also show how\nXiaoIce can dynamically recognize emotion and engage the user throughout long\nconversations with appropriate interpersonal responses. As we become the first\ngeneration of humans ever living with AI, we have a responsibility to design\nsocial chatbots to be both useful and empathetic, so they will become\nubiquitous and help society as a whole.\n"]},
{"authors": ["Mathias Lecuyer", "Vaggelis Atlidakis", "Roxana Geambasu", "Daniel Hsu", "Suman Jana"], "title": ["On the Connection between Differential Privacy and Adversarial\n  Robustness in Machine Learning"], "date": ["2018-02-09T22:24:50Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.03471v1"], "summary": ["  Adversarial examples in machine learning has been a topic of intense research\ninterest, with attacks and defenses being developed in a tight back-and-forth.\nMost past defenses are best-effort, heuristic approaches that have all been\nshown to be vulnerable to sophisticated attacks. More recently, rigorous\ndefenses that provide formal guarantees have emerged, but are hard to scale or\ngeneralize. A rigorous and general foundation for designing defenses is\nrequired to get us off this arms race trajectory. We propose leveraging\ndifferential privacy (DP) as a formal building block for robustness against\nadversarial examples. We observe that the semantic of DP is closely aligned\nwith the formal definition of robustness to adversarial examples. We propose\nPixelDP, a strategy for learning robust deep neural networks based on formal DP\nguarantees. PixelDP networks give theoretical guarantees for a subset of their\npredictions regarding the robustness against adversarial perturbations of\nbounded size. Our evaluation with MNIST, CIFAR-10, and CIFAR-100 shows that\nPixelDP networks achieve accuracy under attack on par with the best-performing\ndefense to date, but additionally certify robustness against meaningful-size\n1-norm and 2-norm attacks for 40-60% of their predictions. Our experience\npoints to DP as a rigorous, broadly applicable, and mechanism-rich foundation\nfor robust machine learning.\n"]},
{"authors": ["C\u00e9dric Beaulac", "Fabrice Larribe"], "title": ["Narrow Artificial Intelligence with Machine Learning for Real-Time\n  Estimation of a Mobile Agents Location Using Hidden Markov Models"], "date": ["2018-02-09T19:18:21Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.03417v1"], "summary": ["  We propose to use a supervised machine learning technique to track the\nlocation of a mobile agent in real time. Hidden Markov Models are used to build\nartificial intelligence that estimates the unknown position of a mobile target\nmoving in a defined environment. This narrow artificial intelligence performs\ntwo distinct tasks. First, it provides real-time estimation of the mobile\nagent's position using the forward algorithm. Second, it uses the Baum-Welch\nalgorithm as a statistical learning tool to gain knowledge of the mobile\ntarget. Finally, an experimental environment is proposed, namely a video game\nthat we use to test our artificial intelligence. We present statistical and\ngraphical results to illustrate the efficiency of our method.\n"]},
{"authors": ["Bartosz Piotrowski", "Josef Urban"], "title": ["ATPboost: Learning Premise Selection in Binary Setting with ATP Feedback"], "date": ["2018-02-09T18:29:26Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.03375v1"], "summary": ["  ATPboost is a system for solving sets of large-theory problems by\ninterleaving ATP runs with state-of-the-art machine learning of premise\nselection from the proofs. Unlike many previous approaches that use multi-label\nsetting, the learning is implemented as binary classification that estimates\nthe pairwise-relevance of (theorem, premise) pairs. ATPboost uses for this the\nXGBoost gradient boosting algorithm, which is fast and has state-of-the-art\nperformance on many tasks. Learning in the binary setting however requires\nnegative examples, which is nontrivial due to many alternative proofs. We\ndiscuss and implement several solutions in the context of the ATP/ML feedback\nloop, and show that ATPboost with such methods significantly outperforms the\nk-nearest neighbors multilabel classifier.\n"]},
{"authors": ["Bryan Gregory"], "title": ["Predicting Customer Churn: Extreme Gradient Boosting with Temporal Data"], "date": ["2018-02-09T17:24:27Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.03396v1"], "summary": ["  Accurately predicting customer churn using large scale time-series data is a\ncommon problem facing many business domains. The creation of model features\nacross various time windows for training and testing can be particularly\nchallenging due to temporal issues common to time-series data. In this paper,\nwe will explore the application of extreme gradient boosting (XGBoost) on a\ncustomer dataset with a wide-variety of temporal features in order to create a\nhighly-accurate customer churn model. In particular, we describe an effective\nmethod for handling temporally sensitive feature engineering. The proposed\nmodel was submitted in the WSDM Cup 2018 Churn Challenge and achieved\nfirst-place out of 575 teams.\n"]},
{"authors": ["Audrey G. Chung", "Paul Fieguth", "Alexander Wong"], "title": ["Nature vs. Nurture: The Role of Environmental Resources in Evolutionary\n  Deep Intelligence"], "date": ["2018-02-09T15:58:58Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.03318v1"], "summary": ["  Evolutionary deep intelligence synthesizes highly efficient deep neural\nnetworks architectures over successive generations. Inspired by the nature\nversus nurture debate, we propose a study to examine the role of external\nfactors on the network synthesis process by varying the availability of\nsimulated environmental resources. Experimental results were obtained for\nnetworks synthesized via asexual evolutionary synthesis (1-parent) and sexual\nevolutionary synthesis (2-parent, 3-parent, and 5-parent) using a 10% subset of\nthe MNIST dataset. Results show that a lower environmental factor model\nresulted in a more gradual loss in performance accuracy and decrease in storage\nsize. This potentially allows significantly reduced storage size with minimal\nto no drop in performance accuracy, and the best networks were synthesized\nusing the lowest environmental factor models.\n"]},
{"authors": ["Stefano V. Albrecht", "Peter Stone"], "title": ["Autonomous Agents Modelling Other Agents: A Comprehensive Survey and\n  Open Problems"], "date": ["2017-09-23T16:10:52Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1709.08071v2"], "summary": ["  Much research in artificial intelligence is concerned with the development of\nautonomous agents that can interact effectively with other agents. An important\naspect of such agents is the ability to reason about the behaviours of other\nagents, by constructing models which make predictions about various properties\nof interest (such as actions, goals, beliefs) of the modelled agents. A variety\nof modelling approaches now exist which vary widely in their methodology and\nunderlying assumptions, catering to the needs of the different sub-communities\nwithin which they were developed and reflecting the different practical uses\nfor which they are intended. The purpose of the present article is to provide a\ncomprehensive survey of the salient modelling methods which can be found in the\nliterature. The article concludes with a discussion of open problems which may\nform the basis for fruitful future research.\n"]},
{"authors": ["Lasse Espeholt", "Hubert Soyer", "Remi Munos", "Karen Simonyan", "Volodymir Mnih", "Tom Ward", "Yotam Doron", "Vlad Firoiu", "Tim Harley", "Iain Dunning", "Shane Legg", "Koray Kavukcuoglu"], "title": ["IMPALA: Scalable Distributed Deep-RL with Importance Weighted\n  Actor-Learner Architectures"], "date": ["2018-02-05T18:47:30Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.01561v2"], "summary": ["  In this work we aim to solve a large collection of tasks using a single\nreinforcement learning agent with a single set of parameters. A key challenge\nis to handle the increased amount of data and extended training time. We have\ndeveloped a new distributed agent IMPALA (Importance Weighted Actor-Learner\nArchitecture) that not only uses resources more efficiently in single-machine\ntraining but also scales to thousands of machines without sacrificing data\nefficiency or resource utilisation. We achieve stable learning at high\nthroughput by combining decoupled acting and learning with a novel off-policy\ncorrection method called V-trace. We demonstrate the effectiveness of IMPALA\nfor multi-task reinforcement learning on DMLab-30 (a set of 30 tasks from the\nDeepMind Lab environment (Beattie et al., 2016)) and Atari-57 (all available\nAtari games in Arcade Learning Environment (Bellemare et al., 2013a)). Our\nresults show that IMPALA is able to achieve better performance than previous\nagents with less data, and crucially exhibits positive transfer between tasks\nas a result of its multi-task approach.\n"]},
{"authors": ["Nicolas Bredeche", "Evert Haasdijk", "Abraham Prieto"], "title": ["Embodied Evolution in Collective Robotics: A Review"], "date": ["2017-09-26T13:08:27Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1709.08992v2"], "summary": ["  This paper provides an overview of evolutionary robotics techniques applied\nto on-line distributed evolution for robot collectives -- namely, embodied\nevolution. It provides a definition of embodied evolution as well as a thorough\ndescription of the underlying concepts and mechanisms. The paper also presents\na comprehensive summary of research published in the field since its inception\n(1999-2017), providing various perspectives to identify the major trends. In\nparticular, we identify a shift from considering embodied evolution as a\nparallel search method within small robot collectives (fewer than 10 robots) to\nembodied evolution as an on-line distributed learning method for designing\ncollective behaviours in swarm-like collectives. The paper concludes with a\ndiscussion of applications and open questions, providing a milestone for past\nand an inspiration for future research.\n"]},
{"authors": ["Oliver Mueller", "Michael Ying Yang", "Bodo Rosenhahn"], "title": ["Slice Sampling Particle Belief Propagation"], "date": ["2018-02-09T14:27:58Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.03275v1"], "summary": ["  Inference in continuous label Markov random fields is a challenging task. We\nuse particle belief propagation (PBP) for solving the inference problem in\ncontinuous label space. Sampling particles from the belief distribution is\ntypically done by using Metropolis-Hastings Markov chain Monte Carlo methods\nwhich involves sampling from a proposal distribution. This proposal\ndistribution has to be carefully designed depending on the particular model and\ninput data to achieve fast convergence. We propose to avoid dependence on a\nproposal distribution by introducing a slice sampling based PBP algorithm. The\nproposed approach shows superior convergence performance on an image denoising\ntoy example. Our findings are validated on a challenging relational 2D feature\ntracking application.\n"]},
{"authors": ["Avi Rosenfeld", "Ron Illuz", "Dovid Gottesman", "Mark Last"], "title": ["Using Discretization for Extending the Set of Predictive Features"], "date": ["2018-02-09T13:00:44Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.03239v1"], "summary": ["  To date, attribute discretization is typically performed by replacing the\noriginal set of continuous features with a transposed set of discrete ones.\nThis paper provides support for a new idea that discretized features should\noften be used in addition to existing features and as such, datasets should be\nextended, and not replaced, by discretization. We also claim that\ndiscretization algorithms should be developed with the explicit purpose of\nenriching a non-discretized dataset with discretized values. We present such an\nalgorithm, D-MIAT, a supervised algorithm that discretizes data based on\nMinority Interesting Attribute Thresholds. D-MIAT only generates new features\nwhen strong indications exist for one of the target values needing to be\nlearned and thus is intended to be used in addition to the original data. We\npresent extensive empirical results demonstrating the success of using D-MIAT\non $ 28 $ benchmark datasets. We also demonstrate that $ 10 $ other\ndiscretization algorithms can also be used to generate features that yield\nimproved performance when used in combination with the original non-discretized\ndata. Our results show that the best predictive performance is attained using a\ncombination of the original dataset with added features from a \"standard\"\nsupervised discretization algorithm and D-MIAT.\n"]},
{"authors": ["Daniel J. Mankowitz", "Timothy A. Mann", "Pierre-Luc Bacon", "Doina Precup", "Shie Mannor"], "title": ["Learning Robust Options"], "date": ["2018-02-09T12:52:06Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.03236v1"], "summary": ["  Robust reinforcement learning aims to produce policies that have strong\nguarantees even in the face of environments/transition models whose parameters\nhave strong uncertainty. Existing work uses value-based methods and the usual\nprimitive action setting. In this paper, we propose robust methods for learning\ntemporally abstract actions, in the framework of options. We present a Robust\nOptions Policy Iteration (ROPI) algorithm with convergence guarantees, which\nlearns options that are robust to model uncertainty. We utilize ROPI to learn\nrobust options with the Robust Options Deep Q Network (RO-DQN) that solves\nmultiple tasks and mitigates model misspecification due to model uncertainty.\nWe present experimental results which suggest that policy iteration with linear\nfeatures may have an inherent form of robustness when using coarse feature\nrepresentations. In addition, we present experimental results which demonstrate\nthat robustness helps policy iteration implemented on top of deep neural\nnetworks to generalize over a much broader range of dynamics than non-robust\npolicy iteration.\n"]},
{"authors": ["Jordi Grau-Moya", "Felix Leibfried", "Haitham Bou-Ammar"], "title": ["Balancing Two-Player Stochastic Games with Soft Q-Learning"], "date": ["2018-02-09T12:03:15Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.03216v1"], "summary": ["  Within the context of video games the notion of perfectly rational agents can\nbe undesirable as it leads to uninteresting situations, where humans face tough\nadversarial decision makers. Current frameworks for stochastic games and\nreinforcement learning prohibit tuneable strategies as they seek optimal\nperformance. In this paper, we enable such tuneable behaviour by generalising\nsoft Q-learning to stochastic games, where more than one agent interact\nstrategically. We contribute both theoretically and empirically. On the theory\nside, we show that games with soft Q-learning exhibit a unique value and\ngeneralise team games and zero-sum games far beyond these two extremes to cover\na continuous spectrum of gaming behaviour. Experimentally, we show how tuning\nagents' constraints affect performance and demonstrate, through a neural\nnetwork architecture, how to reliably balance games with high-dimensional\nrepresentations.\n"]},
{"authors": ["Long Yang", "Minhao Shi", "Qian Zheng", "Wenjia Meng", "Gang Pan"], "title": ["A Unified Approach for Multi-step Temporal-Difference Learning with\n  Eligibility Traces in Reinforcement Learning"], "date": ["2018-02-09T08:46:21Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.03171v1"], "summary": ["  Recently, a new multi-step temporal learning algorithm, called $Q(\\sigma)$,\nunifies $n$-step Tree-Backup (when $\\sigma=0$) and $n$-step Sarsa (when\n$\\sigma=1$) by introducing a sampling parameter $\\sigma$. However, similar to\nother multi-step temporal-difference learning algorithms, $Q(\\sigma)$ needs\nmuch memory consumption and computation time. Eligibility trace is an important\nmechanism to transform the off-line updates into efficient on-line ones which\nconsume less memory and computation time. In this paper, we further develop the\noriginal $Q(\\sigma)$, combine it with eligibility traces and propose a new\nalgorithm, called $Q(\\sigma ,\\lambda)$, in which $\\lambda$ is trace-decay\nparameter. This idea unifies Sarsa$(\\lambda)$ (when $\\sigma =1$) and\n$Q^{\\pi}(\\lambda)$ (when $\\sigma =0$). Furthermore, we give an upper error\nbound of $Q(\\sigma ,\\lambda)$ policy evaluation algorithm. We prove that\n$Q(\\sigma,\\lambda)$ control algorithm can converge to the optimal value\nfunction exponentially. We also empirically compare it with conventional\ntemporal-difference learning methods. Results show that, with an intermediate\nvalue of $\\sigma$, $Q(\\sigma ,\\lambda)$ creates a mixture of the existing\nalgorithms that can learn the optimal value significantly faster than the\nextreme end ($\\sigma=0$, or $1$).\n"]},
{"authors": ["Christian J. Walder", "Dongwoo Kim"], "title": ["Neural Dynamic Programming for Musical Self Similarity"], "date": ["2018-02-09T06:37:05Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.03144v1"], "summary": ["  We present a neural sequence model designed specifically for symbolic music.\nThe model is based on a learned edit distance mechanism which generalises a\nclassic recursion from computer science, leading to a neural dynamic program.\nRepeated motifs are detected by learning the transformations between them. We\nrepresent the arising computational dependencies using a novel data structure,\nthe edit tree; this perspective suggests natural approximations which afford\nthe scaling up of our otherwise cubic time algorithm. We demonstrate our model\non real and synthetic data; in all cases it out-performs a strong stacked long\nshort-term memory benchmark.\n"]},
{"authors": ["Xiaoqin Zhang", "Huimin Ma"], "title": ["Pretraining Deep Actor-Critic Reinforcement Learning Algorithms With\n  Expert Demonstrations"], "date": ["2018-01-31T14:30:00Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.10459v2"], "summary": ["  Pretraining with expert demonstrations have been found useful in speeding up\nthe training process of deep reinforcement learning algorithms since less\nonline simulation data is required. Some people use supervised learning to\nspeed up the process of feature learning, others pretrain the policies by\nimitating expert demonstrations. However, these methods are unstable and not\nsuitable for actor-critic reinforcement learning algorithms. Also, some\nexisting methods rely on the global optimum assumption, which is not true in\nmost scenarios. In this paper, we employ expert demonstrations in a\nactor-critic reinforcement learning framework, and meanwhile ensure that the\nperformance is not affected by the fact that expert demonstrations are not\nglobal optimal. We theoretically derive a method for computing policy gradients\nand value estimators with only expert demonstrations. Our method is\ntheoretically plausible for actor-critic reinforcement learning algorithms that\npretrains both policy and value functions. We apply our method to two of the\ntypical actor-critic reinforcement learning algorithms, DDPG and ACER, and\ndemonstrate with experiments that our method not only outperforms the RL\nalgorithms without pretraining process, but also is more simulation efficient.\n"]},
{"authors": ["Peter A. Jansen", "Elizabeth Wainwright", "Steven Marmorstein", "Clayton T. Morrison"], "title": ["WorldTree: A Corpus of Explanation Graphs for Elementary Science\n  Questions supporting Multi-Hop Inference"], "date": ["2018-02-08T21:26:03Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.03052v1"], "summary": ["  Developing methods of automated inference that are able to provide users with\ncompelling human-readable justifications for why the answer to a question is\ncorrect is critical for domains such as science and medicine, where user trust\nand detecting costly errors are limiting factors to adoption. One of the\ncentral barriers to training question answering models on explainable inference\ntasks is the lack of gold explanations to serve as training data. In this paper\nwe present a corpus of explanations for standardized science exams, a recent\nchallenge task for question answering. We manually construct a corpus of\ndetailed explanations for nearly all publicly available standardized elementary\nscience question (approximately 1,680 3rd through 5th grade questions) and\nrepresent these as \"explanation graphs\" -- sets of lexically overlapping\nsentences that describe how to arrive at the correct answer to a question\nthrough a combination of domain and world knowledge. We also provide an\nexplanation-centered tablestore, a collection of semi-structured tables that\ncontain the knowledge to construct these elementary science explanations.\nTogether, these two knowledge resources map out a substantial portion of the\nknowledge required for answering and explaining elementary science exams, and\nprovide both structured and free-text training data for the explainable\ninference task.\n"]},
{"authors": ["Grant Molnar"], "title": ["A Savage-Like Axiomatization for Nonstandard Expected Utility"], "date": ["2017-01-12T20:39:03Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1701.03500v7"], "summary": ["  Since Leonard Savage's epoch-making \"Foundations of Statistics\", Subjective\nExpected Utility Theory has been the presumptive model for decision-making.\nSavage provided an act-based axiomatization of standard expected utility\ntheory. In this article, we provide a Savage-like axiomatization of nonstandard\nexpected utility theory. It corresponds to a weakening of Savage's 6th axiom.\n"]},
{"authors": ["Tevfik Bulut"], "title": ["A New Multi Criteria Decision Making Method: Approach of Logarithmic\n  Concept (APLOCO)"], "date": ["2018-02-08T20:19:34Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04095v1"], "summary": ["  The primary aim of the study is to introduce APLOCO method which is developed\nfor the solution of multicriteria decision making problems both theoretically\nand practically. In this context, application subject of APLACO constitutes\nevaluation of investment potential of different cities in metropolitan status\nin Turkey. The secondary purpose of the study is to identify the independent\nvariables affecting the factories in the operating phase and to estimate the\neffect levels of independent variables on the dependent variable in the\norganized industrial zones (OIZs), whose mission is to reduce regional\ndevelopment disparities and to mobilize local production dynamics. For this\npurpose, the effect levels of independent variables on dependent variables have\nbeen determined using the multilayer perceptron (MLP) method, which has a wide\nuse in artificial neural networks (ANNs). The effect levels derived from MLP\nhave been then used as the weight levels of the decision criteria in APLOCO.\nThe independent variables included in MLP are also used as the decision\ncriteria in APLOCO. According to the results obtained from APLOCO, Istanbul\ncity is the best alternative in term of the investment potential and other\nalternatives are Manisa, Denizli, Izmir, Kocaeli, Bursa, Ankara, Adana, and\nAntalya, respectively. Although APLOCO is used to solve the ranking problem in\norder to show application process in the paper, it can be employed easily in\nthe solution of classification and selection problems. On the other hand, the\nstudy also shows a rare example of the nested usage of APLOCO which is one of\nthe methods of operation research as well as MLP used in determination of\nweights.\n"]},
{"authors": ["Baolin Peng", "Xiujun Li", "Jianfeng Gao", "Jingjing Liu", "Yun-Nung Chen", "Kam-Fai Wong"], "title": ["Adversarial Advantage Actor-Critic Model for Task-Completion Dialogue\n  Policy Learning"], "date": ["2017-10-31T00:25:03Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.11277v2"], "summary": ["  This paper presents a new method --- adversarial advantage actor-critic\n(Adversarial A2C), which significantly improves the efficiency of dialogue\npolicy learning in task-completion dialogue systems. Inspired by generative\nadversarial networks (GAN), we train a discriminator to differentiate\nresponses/actions generated by dialogue agents from responses/actions by\nexperts. Then, we incorporate the discriminator as another critic into the\nadvantage actor-critic (A2C) framework, to encourage the dialogue agent to\nexplore state-action within the regions where the agent takes actions similar\nto those of the experts. Experimental results in a movie-ticket booking domain\nshow that the proposed Adversarial A2C can accelerate policy exploration\nefficiently.\n"]},
{"authors": ["Tathagata Chakraborti", "Kshitij P. Fadnis", "Kartik Talamadupula", "Mishal Dholakia", "Biplav Srivastava", "Jeffrey O. Kephart", "Rachel K. E. Bellamy"], "title": ["Visualizations for an Explainable Planning Agent"], "date": ["2017-09-13T19:50:44Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1709.04517v2"], "summary": ["  In this paper, we report on the visualization capabilities of an Explainable\nAI Planning (XAIP) agent that can support human in the loop decision making.\nImposing transparency and explainability requirements on such agents is\nespecially important in order to establish trust and common ground with the\nend-to-end automated planning system. Visualizing the agent's internal\ndecision-making processes is a crucial step towards achieving this. This may\ninclude externalizing the \"brain\" of the agent -- starting from its sensory\ninputs, to progressively higher order decisions made by it in order to drive\nits planning components. We also show how the planner can bootstrap on the\nlatest techniques in explainable planning to cast plan visualization as a plan\nexplanation problem, and thus provide concise model-based visualization of its\nplans. We demonstrate these functionalities in the context of the automated\nplanning components of a smart assistant in an instrumented meeting space.\n"]},
{"authors": ["HyeonSeok Lee", "Hyo Seon Park"], "title": ["A Generalization Method of Partitioned Activation Function for Complex\n  Number"], "date": ["2018-02-08T17:57:58Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.02987v1"], "summary": ["  A method to convert real number partitioned activation function into complex\nnumber one is provided. The method has 4em variations; 1 has potential to get\nholomorphic activation, 2 has potential to conserve complex angle, and the last\n1 guarantees interaction between real and imaginary parts. The method has been\napplied to LReLU and SELU as examples. The complex number activation function\nis an building block of complex number ANN, which has potential to properly\ndeal with complex number problems. But the complex activation is not well\nestablished yet. Therefore, we propose a way to extend the partitioned real\nactivation to complex number.\n"]},
{"authors": ["Christian Bessiere", "Nadjib Lazaar", "Yahia Lebbah", "Mehdi Maamar"], "title": ["Users Constraints in Itemset Mining"], "date": ["2017-12-31T19:55:52Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.00345v2"], "summary": ["  Discovering significant itemsets is one of the fundamental problems in data\nmining. It has recently been shown that constraint programming is a flexible\nway to tackle data mining tasks. With a constraint programming approach, we can\neasily express and efficiently answer queries with users constraints on items.\nHowever, in many practical cases it is possible that queries also express users\nconstraints on the dataset itself. For instance, asking for a particular\nitemset in a particular part of the dataset. This paper presents a general\nconstraint programming model able to handle any kind of query on the items or\nthe dataset for itemset mining.\n"]},
{"authors": ["Alexey A. Melnikov", "Hendrik Poulsen Nautrup", "Mario Krenn", "Vedran Dunjko", "Markus Tiersch", "Anton Zeilinger", "Hans J. Briegel"], "title": ["Active learning machine learns to create new quantum experiments"], "date": ["2017-06-02T22:35:41Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1706.00868v3"], "summary": ["  How useful can machine learning be in a quantum laboratory? Here we raise the\nquestion of the potential of intelligent machines in the context of scientific\nresearch. A major motivation for the present work is the unknown reachability\nof various entanglement classes in quantum experiments. We investigate this\nquestion by using the projective simulation model, a physics-oriented approach\nto artificial intelligence. In our approach, the projective simulation system\nis challenged to design complex photonic quantum experiments that produce\nhigh-dimensional entangled multiphoton states, which are of high interest in\nmodern quantum experiments. The artificial intelligence system learns to create\na variety of entangled states, and improves the efficiency of their\nrealization. In the process, the system autonomously (re)discovers experimental\ntechniques which are only now becoming standard in modern quantum optical\nexperiments - a trait which was not explicitly demanded from the system but\nemerged through the process of learning. Such features highlight the\npossibility that machines could have a significantly more creative role in\nfuture research.\n"]},
{"authors": ["Felix Leibfried", "Jordi Grau-Moya", "Haitham Bou-Ammar"], "title": ["An Information-Theoretic Optimality Principle for Deep Reinforcement\n  Learning"], "date": ["2017-08-06T09:23:22Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1708.01867v3"], "summary": ["  We methodologically address the problem of Q-value overestimation in deep\nreinforcement learning to handle high-dimensional state spaces efficiently. By\nadapting concepts from information theory, we introduce an intrinsic penalty\nsignal encouraging reduced Q-value estimates. The resultant algorithm\nencompasses a wide range of learning outcomes containing deep Q-networks as a\nspecial case. Different learning outcomes can be demonstrated by tuning a\nLagrange multiplier accordingly. We furthermore propose a novel scheduling\nscheme for this Lagrange multiplier to ensure efficient and robust learning. In\nexperiments on Atari games, our algorithm outperforms other algorithms (e.g.\ndeep and double deep Q-networks) in terms of both game-play performance and\nsample complexity.\n"]},
{"authors": ["Dario Zanca", "Valeria Serchi", "Pietro Piu", "Francesca Rosini", "Alessandra Rufa"], "title": ["FixaTons: A collection of Human Fixations Datasets and Metrics for\n  Scanpath Similarity"], "date": ["2018-02-07T17:20:31Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.02534v2"], "summary": ["  In the last three decades, human visual attention has been a topic of great\ninterest in various disciplines. In computer vision, many models have been\nproposed to predict the distribution of human fixations on a visual input.\nRecently, thanks to the creation of large collections of data, machine learning\nalgorithms have obtained state-of-the-art performance on the task of saliency\nmap estimation. On the other hand, computational models of scanpath are much\nless studied. Works are often only descriptive or task specific. Computational\nmodels of scanpath with general purpose are present in the literature, but are\nthen evaluated in tasks of saliency prediction, losing therefore information\nabout the dynamics and the behaviour. This is due to the fact that the scanpath\nis harder to model because it must include the description of a dynamic. In\naddition to the difficulty of the problem itself, two technical reasons have\nlimited the research. The first reason is the lack of robust and uniformly used\nset of metrics to compare the similarity between scanpath. The second reason is\nthe lack of sufficiently large and varied scanpath datasets. In this report we\nwant to help in both directions. We present FixaTons, a large collection of\nhuman scanpaths (and saliency maps). It comes along with a software library for\neasy data usage, statistics calculation and measures for scanpaths (and\nsaliency maps) similarity.\n"]},
{"authors": ["Johan Bjorck", "Yiwei Bai", "Xiaojian Wu", "Yexiang Xue", "Mark C. Whitmore", "Carla Gomes"], "title": ["Scalable Relaxations of Sparse Packing Constraints: Optimal Biocontrol\n  in Predator-Prey Network"], "date": ["2017-11-18T02:47:41Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.06800v3"], "summary": ["  Cascades represent rapid changes in networks. A cascading phenomenon of\necological and economic impact is the spread of invasive species in geographic\nlandscapes. The most promising management strategy is often biocontrol, which\nentails introducing a natural predator able to control the invading population,\na setting that can be treated as two interacting cascades of predator and prey\npopulations. We formulate and study a nonlinear problem of optimal biocontrol:\noptimally seeding the predator cascade over time to minimize the harmful prey\npopulation. Recurring budgets, which typically face conservation organizations,\nnaturally leads to sparse constraints which make the problem amenable to\napproximation algorithms. Available methods based on continuous relaxations\nscale poorly, to remedy this we develop a novel and scalable randomized\nalgorithm based on a width relaxation, applicable to a broad class of\ncombinatorial optimization problems. We evaluate our contributions in the\ncontext of biocontrol for the insect pest Hemlock Wolly Adelgid (HWA) in\neastern North America. Our algorithm outperforms competing methods in terms of\nscalability and solution quality, and finds near optimal strategies for the\ncontrol of the HWA for fine-grained networks -- an important problem in\ncomputational sustainability.\n"]},
{"authors": ["Alexander Steen", "Christoph Benzm\u00fcller"], "title": ["The Higher-Order Prover Leo-III"], "date": ["2018-02-08T07:48:31Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.02732v1"], "summary": ["  The automated theorem prover Leo-III for classical higher-order logic with\nHenkin semantics and choice is presented. Leo-III is based on extensional\nhigher-order paramodulation and accepts every common TPTP dialect (FOF, TFF,\nTHF), including their recent extensions to rank-1 polymorphism (TF1, TH1). In\naddition, the prover natively supports almost every normal higher-order modal\nlogic. Leo-III cooperates with first-order reasoning tools using translations\nto (polymorphic) many-sorted first-order logic and produces verifiable proof\ncertificates. The prover is evaluated on heterogeneous benchmark sets.\n"]},
{"authors": ["Alexey Drutsa"], "title": ["On consistency of optimal pricing algorithms in repeated posted-price\n  auctions with strategic buyer"], "date": ["2017-07-17T11:29:14Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1707.05101v2"], "summary": ["  We study revenue optimization learning algorithms for repeated posted-price\nauctions where a seller interacts with a single strategic buyer that holds a\nfixed private valuation for a good and seeks to maximize his cumulative\ndiscounted surplus. For this setting, first, we propose a novel algorithm that\nnever decreases offered prices and has a tight strategic regret bound in\n$\\Theta(\\log\\log T)$ under some mild assumptions on the buyer surplus\ndiscounting. This result closes the open research question on the existence of\na no-regret horizon-independent weakly consistent pricing. The proposed\nalgorithm is inspired by our observation that a double decrease of offered\nprices in a weakly consistent algorithm is enough to cause a linear regret.\nThis motivates us to construct a novel transformation that maps a\nright-consistent algorithm to a weakly consistent one that never decreases\noffered prices.\n  Second, we outperform the previously known strategic regret upper bound of\nthe algorithm PRRFES, where the improvement is achieved by means of a finer\nconstant factor $C$ of the principal term $C\\log\\log T$ in this upper bound.\nFinally, we generalize results on strategic regret previously known for\ngeometric discounting of the buyer's surplus to discounting of other types,\nnamely: the optimality of the pricing PRRFES to the case of geometrically\nconcave decreasing discounting; and linear lower bound on the strategic regret\nof a wide range of horizon-independent weakly consistent algorithms to the case\nof arbitrary discounts.\n"]},
{"authors": ["Sridhar Chimalakonda", "Kesav V. Nori"], "title": ["An Ontology Based Modeling Framework for Design of Educational\n  Technologies"], "date": ["2018-02-07T23:57:44Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04337v1"], "summary": ["  Despite rapid progress, most of the educational technologies today lack a\nstrong instructional design knowledge basis leading to questionable quality of\ninstruction. In addition, a major challenge is to customize these educational\ntechnologies for a wide range of instructional designs. Ontologies are one of\nthe pertinent mechanisms to represent instructional design in the literature.\nHowever, existing approaches do not support modeling of flexible instructional\ndesigns. To address this problem, in this paper, we propose an ontology based\nframework for systematic modeling of different aspects of instructional design\nknowledge based on domain patterns. As part of the framework, we present\nontologies for modeling goals, instructional processes and instructional\nmaterials. We demonstrate the ontology framework by presenting instances of the\nontology for the large scale case study of adult literacy in India (287 million\nlearners spread across 22 Indian Languages), which requires creation of 1000\nsimilar but varied eLearning Systems based on flexible instructional designs.\nThe implemented framework is available at http://rice.iiit.ac.in and is\ntransferred to National Literacy Mission of Government of India. This framework\ncould be used for modeling instructional design knowledge of systems for\nskills, school education and beyond.\n"]},
{"authors": ["Siddhartha Verma", "Guido Novati", "Petros Koumoutsakos"], "title": ["Efficient collective swimming by harnessing vortices through deep\n  reinforcement learning"], "date": ["2018-02-07T23:42:42Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.02674v1"], "summary": ["  Fish in schooling formations navigate complex flow-fields replete with\nmechanical energy in the vortex wakes of their companions. Their schooling\nbehaviour has been associated with evolutionary advantages including collective\nenergy savings. How fish harvest energy from their complex fluid environment\nand the underlying physical mechanisms governing energy-extraction during\ncollective swimming, is still unknown. Here we show that fish can improve their\nsustained propulsive efficiency by actively following, and judiciously\nintercepting, vortices in the wake of other swimmers. This swimming strategy\nleads to collective energy-savings and is revealed through the first ever\ncombination of deep reinforcement learning with high-fidelity flow simulations.\nWe find that a `smart-swimmer' can adapt its position and body deformation to\nsynchronise with the momentum of the oncoming vortices, improving its average\nswimming-efficiency at no cost to the leader. The results show that fish may\nharvest energy deposited in vortices produced by their peers, and support the\nconjecture that swimming in formation is energetically advantageous. Moreover,\nthis study demonstrates that deep reinforcement learning can produce navigation\nalgorithms for complex flow-fields, with promising implications for energy\nsavings in autonomous robotic swarms.\n"]},
{"authors": ["Subhash Kak"], "title": ["Reasoning in a Hierarchical System with Missing Group Size Information"], "date": ["2018-02-07T23:08:31Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.04093v1"], "summary": ["  The paper analyzes the problem of judgments or preferences subsequent to\ninitial analysis by autonomous agents in a hierarchical system where the higher\nlevel agents does not have access to group size information. We propose methods\nthat reduce instances of preference reversal of the kind encountered in\nSimpson's paradox.\n"]},
{"authors": ["Nathalia Nascimento", "Carlos Lucena", "Paulo Alencar", "Donald Cowan"], "title": ["Software Engineers vs. Machine Learning Algorithms: An Empirical Study\n  Assessing Performance and Reuse Tasks"], "date": ["2018-02-04T09:38:48Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.01096v2"], "summary": ["  Several papers have recently contained reports on applying machine learning\n(ML) to the automation of software engineering (SE) tasks, such as project\nmanagement, modeling and development. However, there appear to be no approaches\ncomparing how software engineers fare against machine-learning algorithms as\napplied to specific software development tasks. Such a comparison is essential\nto gain insight into which tasks are better performed by humans and which by\nmachine learning and how cooperative work or human-in-the-loop processes can be\nimplemented more effectively. In this paper, we present an empirical study that\ncompares how software engineers and machine-learning algorithms perform and\nreuse tasks. The empirical study involves the synthesis of the control\nstructure of an autonomous streetlight application. Our approach consists of\nfour steps. First, we solved the problem using machine learning to determine\nspecific performance and reuse tasks. Second, we asked software engineers with\ndifferent domain knowledge levels to provide a solution to the same tasks.\nThird, we compared how software engineers fare against machine-learning\nalgorithms when accomplishing the performance and reuse tasks based on criteria\nsuch as energy consumption and safety. Finally, we analyzed the results to\nunderstand which tasks are better performed by either humans or algorithms so\nthat they can work together more effectively. Such an understanding and the\nresulting human-in-the-loop approaches, which take into account the strengths\nand weaknesses of humans and machine-learning algorithms, are fundamental not\nonly to provide a basis for cooperative work in support of software\nengineering, but also, in other areas.\n"]},
{"authors": ["Johannes Wagner", "Tobias Baur", "Yue Zhang", "Michel F. Valstar", "Bj\u00f6rn Schuller", "Elisabeth Andr\u00e9"], "title": ["Applying Cooperative Machine Learning to Speed Up the Annotation of\n  Social Signals in Large Multi-modal Corpora"], "date": ["2018-02-07T18:47:49Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.02565v1"], "summary": ["  Scientific disciplines, such as Behavioural Psychology, Anthropology and\nrecently Social Signal Processing are concerned with the systematic exploration\nof human behaviour. A typical work-flow includes the manual annotation (also\ncalled coding) of social signals in multi-modal corpora of considerable size.\nFor the involved annotators this defines an exhausting and time-consuming task.\nIn the article at hand we present a novel method and also provide the tools to\nspeed up the coding procedure. To this end, we suggest and evaluate the use of\nCooperative Machine Learning (CML) techniques to reduce manual labelling\nefforts by combining the power of computational capabilities and human\nintelligence. The proposed CML strategy starts with a small number of labelled\ninstances and concentrates on predicting local parts first. Afterwards, a\nsession-independent classification model is created to finish the remaining\nparts of the database. Confidence values are computed to guide the manual\ninspection and correction of the predictions. To bring the proposed approach\ninto application we introduce NOVA - an open-source tool for collaborative and\nmachine-aided annotations. In particular, it gives labellers immediate access\nto CML strategies and directly provides visual feedback on the results. Our\nexperiments show that the proposed method has the potential to significantly\nreduce human labelling efforts.\n"]},
{"authors": ["Adnan Siraj Rakin", "Zhezhi He", "Boqing Gong", "Deliang Fan"], "title": ["Blind Pre-Processing: A Robust Defense Method Against Adversarial\n  Examples"], "date": ["2018-02-05T18:21:31Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.01549v2"], "summary": ["  Deep learning algorithms and networks are vulnerable to perturbed inputs\nwhich is known as the adversarial attack. Many defense methodologies have been\ninvestigated to defend against such adversarial attack. In this work, we\npropose a novel methodology to defend the existing powerful attack model. We\nfor the first time introduce a new attacking scheme for the attacker and set a\npractical constraint for white box attack. Under this proposed attacking\nscheme, we present the best defense ever reported against some of the recent\nstrong attacks. It consists of a set of nonlinear function to process the input\ndata which will make it more robust over the adversarial attack. However, we\nmake this processing layer completely hidden from the attacker. Blind\npre-processing improves the white box attack accuracy of MNIST from 94.3\\% to\n98.7\\%. Even with increasing defense when others defenses completely fail,\nblind pre-processing remains one of the strongest ever reported. Another\nstrength of our defense is that it eliminates the need for adversarial training\nas it can significantly increase the MNIST accuracy without adversarial\ntraining as well. Additionally, blind pre-processing can also increase the\ninference accuracy in the face of a powerful attack on CIFAR-10 and SVHN data\nset as well without much sacrificing clean data accuracy.\n"]},
{"authors": ["Rahul Parundekar"], "title": ["Classification of Things in DBpedia using Deep Neural Networks"], "date": ["2018-02-07T17:12:54Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.02528v1"], "summary": ["  The Semantic Web aims at representing knowledge about the real world at web\nscale - things, their attributes and relationships among them can be\nrepresented as nodes and edges in an inter-linked semantic graph. In the\npresence of noisy data, as is typical of data on the Semantic Web, a software\nAgent needs to be able to robustly infer one or more associated actionable\nclasses for the individuals in order to act automatically on it. We model this\nproblem as a multi-label classification task where we want to robustly identify\ntypes of the individuals in a semantic graph such as DBpedia, which we use as\nan exemplary dataset on the Semantic Web. Our approach first extracts multiple\nfeatures for the individuals using random walks and then performs multi-label\nclassification using fully-connected Neural Networks. Through systematic\nexploration and experimentation, we identify the effect of hyper-parameters of\nthe feature extraction and the fully-connected Neural Network structure on the\nclassification performance. Our final results show that our method performs\nbetter than state-of-the-art inferencing systems like SDtype and SLCN, from\nwhich we can conclude that random-walk-based feature extraction of individuals\nand their multi-label classification using Deep Neural Networks is a promising\nalternative to these systems for type classification of individuals on the\nSemantic Web. The main contribution of our work is to introduce a novel\napproach that allows us to use Deep Neural Networks to identify types of\nindividuals in a noisy semantic graph by extracting features using random walks\n"]},
{"authors": ["Brandon Ballinger", "Johnson Hsieh", "Avesh Singh", "Nimit Sohoni", "Jack Wang", "Geoffrey H. Tison", "Gregory M. Marcus", "Jose M. Sanchez", "Carol Maguire", "Jeffrey E. Olgin", "Mark J. Pletcher"], "title": ["DeepHeart: Semi-Supervised Sequence Learning for Cardiovascular Risk\n  Prediction"], "date": ["2018-02-07T16:31:50Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.02511v1"], "summary": ["  We train and validate a semi-supervised, multi-task LSTM on 57,675\nperson-weeks of data from off-the-shelf wearable heart rate sensors, showing\nhigh accuracy at detecting multiple medical conditions, including diabetes\n(0.8451), high cholesterol (0.7441), high blood pressure (0.8086), and sleep\napnea (0.8298). We compare two semi-supervised train- ing methods,\nsemi-supervised sequence learning and heuristic pretraining, and show they\noutperform hand-engineered biomarkers from the medical literature. We believe\nour work suggests a new approach to patient risk stratification based on\ncardiovascular risk scores derived from popular wearables such as Fitbit, Apple\nWatch, or Android Wear.\n"]},
{"authors": ["Mauro Scanagatta", "Giorgio Corani", "Marco Zaffalon", "Jaemin Yoo", "U Kang"], "title": ["Efficient Learning of Bounded-Treewidth Bayesian Networks from Complete\n  and Incomplete Data Sets"], "date": ["2018-02-07T15:09:32Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.02468v1"], "summary": ["  Learning a Bayesian networks with bounded treewidth is important for reducing\nthe complexity of the inferences. We present a novel anytime algorithm (k-MAX)\nmethod for this task, which scales up to thousands of variables. Through\nextensive experiments we show that it consistently yields higher-scoring\nstructures than its competitors on complete data sets. We then consider the\nproblem of structure learning from incomplete data sets. This can be addressed\nby structural EM, which however is computationally very demanding. We thus\nadopt the novel k-MAX algorithm in the maximization step of structural EM,\nobtaining an efficient computation of the expected sufficient statistics. We\ntest the resulting structural EM method on the task of imputing missing data,\ncomparing it against the state-of-the-art approach based on random forests. Our\napproach achieves the same imputation accuracy of the competitors, but in about\none tenth of the time. Furthermore we show that it has worst-case complexity\nlinear in the input size, and that it is easily parallelizable.\n"]},
{"authors": ["Junhua Wu", "Sergey Polyakovskiy", "Markus Wagner", "Frank Neumann"], "title": ["Evolutionary Computation plus Dynamic Programming for the Bi-Objective\n  Travelling Thief Problem"], "date": ["2018-02-07T14:34:53Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.02434v1"], "summary": ["  This research proposes a novel indicator-based hybrid evolutionary approach\nthat combines approximate and exact algorithms. We apply it to a new\nbi-criteria formulation of the travelling thief problem, which is known to the\nEvolutionary Computation community as a benchmark multi-component optimisation\nproblem that interconnects two classical NP-hard problems: the travelling\nsalesman problem and the 0-1 knapsack problem. Our approach employs the exact\ndynamic programming algorithm for the underlying Packing-While-Travelling (PWT)\nproblem as a subroutine within a bi-objective evolutionary algorithm. This\ndesign takes advantage of the data extracted from Pareto fronts generated by\nthe dynamic program to achieve better solutions. Furthermore, we develop a\nnumber of novel indicators and selection mechanisms to strengthen synergy of\nthe two algorithmic components of our approach. The results of computational\nexperiments show that the approach is capable to outperform the\nstate-of-the-art results for the single-objective case of the problem.\n"]},
{"authors": ["Neel Kant"], "title": ["Recent Advances in Neural Program Synthesis"], "date": ["2018-02-07T08:44:38Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.02353v1"], "summary": ["  In recent years, deep learning has made tremendous progress in a number of\nfields that were previously out of reach for artificial intelligence. The\nsuccesses in these problems has led researchers to consider the possibilities\nfor intelligent systems to tackle a problem that humans have only recently\nthemselves considered: program synthesis. This challenge is unlike others such\nas object recognition and speech translation, since its abstract nature and\ndemand for rigor make it difficult even for human minds to attempt. While it is\nstill far from being solved or even competitive with most existing methods,\nneural program synthesis is a rapidly growing discipline which holds great\npromise if completely realized. In this paper, we start with exploring the\nproblem statement and challenges of program synthesis. Then, we examine the\nfascinating evolution of program induction models, along with how they have\nsucceeded, failed and been reimagined since. Finally, we conclude with a\ncontrastive look at program synthesis and future research recommendations for\nthe field.\n"]},
{"authors": ["Saptarshi Pal", "Soumya K Ghosh"], "title": ["Learning Representations from Road Network for End-to-End Urban Growth\n  Simulation"], "date": ["2017-12-19T04:36:24Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1712.06778v3"], "summary": ["  From our experiences in the past, we have seen that the growth of cities is\nvery much dependent on the transportation networks. In mega cities,\ntransportation networks determine to a significant extent as to where the\npeople will move and houses will be built. Hence, transportation network data\nis crucial to an urban growth prediction system. Existing works have used\nmanually derived distance based features based on the road networks to build\nmodels on urban growth. But due to the non-generic and laborious nature of the\nmanual feature engineering process, we can shift to End-to-End systems which do\nnot rely on manual feature engineering. In this paper, we propose a method to\nintegrate road network data to an existing Rule based End-to-End framework\nwithout manual feature engineering. Our method employs recurrent neural\nnetworks to represent road networks in a structured way such that it can be\nplugged into the previously proposed End-to-End framework. The proposed\napproach enhances the performance in terms of Figure of Merit, Producer's\naccuracy, User's accuracy and Overall accuracy of the existing Rule based\nEnd-to-End framework.\n"]},
{"authors": ["Jian Wu", "Matthias Poloczek", "Andrew Gordon Wilson", "Peter I. Frazier"], "title": ["Bayesian Optimization with Gradients"], "date": ["2017-03-13T13:45:13Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1703.04389v3"], "summary": ["  Bayesian optimization has been successful at global optimization of\nexpensive-to-evaluate multimodal objective functions. However, unlike most\noptimization methods, Bayesian optimization typically does not use derivative\ninformation. In this paper we show how Bayesian optimization can exploit\nderivative information to decrease the number of objective function evaluations\nrequired for good performance. In particular, we develop a novel Bayesian\noptimization algorithm, the derivative-enabled knowledge-gradient (dKG), for\nwhich we show one-step Bayes-optimality, asymptotic consistency, and greater\none-step value of information than is possible in the derivative-free setting.\nOur procedure accommodates noisy and incomplete derivative information, comes\nin both sequential and batch forms, and can optionally reduce the computational\ncost of inference through automatically selected retention of a single\ndirectional derivative. We also compute the d-KG acquisition function and its\ngradient using a novel fast discretization-free technique. We show d-KG\nprovides state-of-the-art performance compared to a wide range of optimization\nprocedures with and without gradients, on benchmarks including logistic\nregression, deep learning, kernel learning, and k-nearest neighbors.\n"]},
{"authors": ["Ildefons Magrans de Abril", "Ryota Kanai"], "title": ["Curiosity-driven reinforcement learning with homeostatic regulation"], "date": ["2018-01-23T08:52:22Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.07440v2"], "summary": ["  We propose a curiosity reward based on information theory principles and\nconsistent with the animal instinct to maintain certain critical parameters\nwithin a bounded range. Our experimental validation shows the added value of\nthe additional homeostatic drive to enhance the overall information gain of a\nreinforcement learning agent interacting with a complex environment using\ncontinuous actions. Our method builds upon two ideas: i) To take advantage of a\nnew Bellman-like equation of information gain and ii) to simplify the\ncomputation of the local rewards by avoiding the approximation of complex\ndistributions over continuous states and actions.\n"]},
{"authors": ["Vikas Dhiman", "Shurjo Banerjee", "Brent Griffin", "Jeffrey M Siskind", "Jason J Corso"], "title": ["A Critical Investigation of Deep Reinforcement Learning for Navigation"], "date": ["2018-02-07T00:44:59Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.02274v1"], "summary": ["  The navigation problem is classically approached in two steps: an exploration\nstep, where map-information about the environment is gathered; and an\nexploitation step, where this information is used to navigate efficiently. Deep\nreinforcement learning (DRL) algorithms, alternatively, approach the problem of\nnavigation in an end-to-end fashion. Inspired by the classical approach, we ask\nwhether DRL algorithms are able to inherently explore, gather and exploit\nmap-information over the course of navigation. We build upon Mirowski et al.\n[2017] work and introduce a systematic suite of experiments that vary three\nparameters: the agent's starting location, the agent's target location, and the\nmaze structure. We choose evaluation metrics that explicitly measure the\nalgorithm's ability to gather and exploit map-information. Our experiments show\nthat when trained and tested on the same maps, the algorithm successfully\ngathers and exploits map-information. However, when trained and tested on\ndifferent sets of maps, the algorithm fails to transfer the ability to gather\nand exploit map-information to unseen maps. Furthermore, we find that when the\ngoal location is randomized and the map is kept static, the algorithm is able\nto gather and exploit map-information but the exploitation is far from optimal.\nWe open-source our experimental suite in the hopes that it serves as a\nframework for the comparison of future algorithms and leads to the discovery of\nrobust alternatives to classical navigation methods.\n"]},
{"authors": ["Nesreen K. Ahmed", "Ryan Rossi", "John Boaz Lee", "Xiangnan Kong", "Theodore L. Willke", "Rong Zhou", "Hoda Eldardiry"], "title": ["Learning Role-based Graph Embeddings"], "date": ["2018-02-07T00:29:44Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.02896v1"], "summary": ["  Random walks are at the heart of many existing network embedding methods.\nHowever, such algorithms have many limitations that arise from the use of\nrandom walks, e.g., the features resulting from these methods are unable to\ntransfer to new nodes and graphs as they are tied to vertex identity. In this\nwork, we introduce the Role2Vec framework which uses the flexible notion of\nattributed random walks, and serves as a basis for generalizing existing\nmethods such as DeepWalk, node2vec, and many others that leverage random walks.\nOur proposed framework enables these methods to be more widely applicable for\nboth transductive and inductive learning as well as for use on graphs with\nattributes (if available). This is achieved by learning functions that\ngeneralize to new nodes and graphs. We show that our proposed framework is\neffective with an average AUC improvement of 16:55% while requiring on average\n853x less space than existing methods on a variety of graphs.\n"]},
{"authors": ["Matthias Feurer", "Benjamin Letham", "Eytan Bakshy"], "title": ["Scalable Meta-Learning for Bayesian Optimization"], "date": ["2018-02-06T21:02:59Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.02219v1"], "summary": ["  Bayesian optimization has become a standard technique for hyperparameter\noptimization, including data-intensive models such as deep neural networks that\nmay take days or weeks to train. We consider the setting where previous\noptimization runs are available, and we wish to use their results to warm-start\na new optimization run. We develop an ensemble model that can incorporate the\nresults of past optimization runs, while avoiding the poor scaling that comes\nwith putting all results into a single Gaussian process model. The ensemble\ncombines models from past runs according to estimates of their generalization\nperformance on the current optimization. Results from a large collection of\nhyperparameter optimization benchmark problems and from optimization of a\nproduction computer vision platform at Facebook show that the ensemble can\nsubstantially reduce the time it takes to obtain near-optimal configurations,\nand is useful for warm-starting expensive searches or running quick\nre-optimizations.\n"]},
{"authors": ["D. Kiela", "E. Grave", "A. Joulin", "T. Mikolov"], "title": ["Efficient Large-Scale Multi-Modal Classification"], "date": ["2018-02-06T20:30:59Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.02892v1"], "summary": ["  While the incipient internet was largely text-based, the modern digital world\nis becoming increasingly multi-modal. Here, we examine multi-modal\nclassification where one modality is discrete, e.g. text, and the other is\ncontinuous, e.g. visual representations transferred from a convolutional neural\nnetwork. In particular, we focus on scenarios where we have to be able to\nclassify large quantities of data quickly. We investigate various methods for\nperforming multi-modal fusion and analyze their trade-offs in terms of\nclassification accuracy and computational efficiency. Our findings indicate\nthat the inclusion of continuous information improves performance over\ntext-only on a range of multi-modal classification tasks, even with simple\nfusion methods. In addition, we experiment with discretizing the continuous\nfeatures in order to speed up and simplify the fusion process even further. Our\nresults show that fusion with discretized features outperforms text-only\nclassification, at a fraction of the computational cost of full multi-modal\nfusion, with the additional benefit of improved interpretability.\n"]},
{"authors": ["Patrick Schwab", "Walter Karlen"], "title": ["Granger-causal Attentive Mixtures of Experts"], "date": ["2018-02-06T20:21:30Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.02195v1"], "summary": ["  Several methods have recently been proposed to detect salient input features\nfor outputs of neural networks. Those methods offer a qualitative glimpse at\nfeature importance, but they fall short of providing quantifiable attributions\nthat can be compared across decisions and measures of the expected quality of\ntheir explanations. To address these shortcomings, we present an attentive\nmixture of experts (AME) that couples attentive gating with a Granger-causal\nobjective to jointly produce accurate predictions as well as measures of\nfeature importance. We demonstrate the utility of AMEs by determining factors\ndriving demand for medical prescriptions, comparing predictive features for\nParkinson's disease and pinpointing discriminatory genes across cancer types.\n"]},
{"authors": ["Weichao Zhou", "Wenchao Li"], "title": ["Safety-Aware Apprenticeship Learning"], "date": ["2017-10-22T17:29:16Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.07983v3"], "summary": ["  Apprenticeship learning (AL) is a class of \"learning from demonstrations\"\ntechniques where the reward function of a Markov Decision Process (MDP) is\nunknown to the learning agent and the agent has to derive a good policy by\nobserving an expert's demonstrations. In this paper, we study the problem of\nhow to make AL algorithms inherently safe while still meeting its learning\nobjective. We consider a setting where the unknown reward function is assumed\nto be a linear combination of a set of state features, and the safety property\nis specified in Probabilistic Computation Tree Logic (PCTL). By embedding\nprobabilistic model checking inside AL, we propose a novel\ncounterexample-guided approach that can ensure both safety and performance of\nthe learnt policy. We demonstrate the effectiveness of our approach on several\nchallenging AL scenarios where safety is essential.\n"]},
{"authors": ["Xiaoyu Shen", "Hui Su", "Shuzi Niu", "Vera Demberg"], "title": ["Improving Variational Encoder-Decoders in Dialogue Generation"], "date": ["2018-02-06T16:19:05Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.02032v1"], "summary": ["  Variational encoder-decoders (VEDs) have shown promising results in dialogue\ngeneration. However, the latent variable distributions are usually approximated\nby a much simpler model than the powerful RNN structure used for encoding and\ndecoding, yielding the KL-vanishing problem and inconsistent training\nobjective. In this paper, we separate the training step into two phases: The\nfirst phase learns to autoencode discrete texts into continuous embeddings,\nfrom which the second phase learns to generalize latent representations by\nreconstructing the encoded embedding. In this case, latent variables are\nsampled by transforming Gaussian noise through multi-layer perceptrons and are\ntrained with a separate VED model, which has the potential of realizing a much\nmore flexible distribution. We compare our model with current popular models\nand the experiment demonstrates substantial improvement in both metric-based\nand human evaluations.\n"]},
{"authors": ["Wang-Zhou Dai", "Qiu-Ling Xu", "Yang Yu", "Zhi-Hua Zhou"], "title": ["Tunneling Neural Perception and Logic Reasoning through Abductive\n  Learning"], "date": ["2018-02-04T18:27:53Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.01173v2"], "summary": ["  Perception and reasoning are basic human abilities that are seamlessly\nconnected as part of human intelligence. However, in current machine learning\nsystems, the perception and reasoning modules are incompatible. Tasks requiring\njoint perception and reasoning ability are difficult to accomplish autonomously\nand still demand human intervention. Inspired by the way language experts\ndecoded Mayan scripts by joining two abilities in an abductive manner, this\npaper proposes the abductive learning framework. The framework learns\nperception and reasoning simultaneously with the help of a trial-and-error\nabductive process. We present the Neural-Logical Machine as an implementation\nof this novel learning framework. We demonstrate that--using human-like\nabductive learning--the machine learns from a small set of simple hand-written\nequations and then generalizes well to complex equations, a feat that is beyond\nthe capability of state-of-the-art neural network models. The abductive\nlearning framework explores a new direction for approaching human-level\nlearning ability.\n"]},
{"authors": ["Daniel Hein", "Stefan Depeweg", "Michel Tokic", "Steffen Udluft", "Alexander Hentschel", "Thomas A. Runkler", "Volkmar Sterzing"], "title": ["A Benchmark Environment Motivated by Industrial Control Problems"], "date": ["2017-09-27T13:03:52Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1709.09480v2"], "summary": ["  In the research area of reinforcement learning (RL), frequently novel and\npromising methods are developed and introduced to the RL community. However,\nalthough many researchers are keen to apply their methods on real-world\nproblems, implementing such methods in real industry environments often is a\nfrustrating and tedious process. Generally, academic research groups have only\nlimited access to real industrial data and applications. For this reason, new\nmethods are usually developed, evaluated and compared by using artificial\nsoftware benchmarks. On one hand, these benchmarks are designed to provide\ninterpretable RL training scenarios and detailed insight into the learning\nprocess of the method on hand. On the other hand, they usually do not share\nmuch similarity with industrial real-world applications. For this reason we\nused our industry experience to design a benchmark which bridges the gap\nbetween freely available, documented, and motivated artificial benchmarks and\nproperties of real industrial problems. The resulting industrial benchmark (IB)\nhas been made publicly available to the RL community by publishing its Java and\nPython code, including an OpenAI Gym wrapper, on Github. In this paper we\nmotivate and describe in detail the IB's dynamics and identify prototypic\nexperimental settings that capture common situations in real-world industry\ncontrol problems.\n"]},
{"authors": ["Muhammad Zubair Malik", "Muhammad Nawaz", "Nimrah Mustafa", "Junaid Haroon Siddiqui"], "title": ["Search Based Code Generation for Machine Learning Programs"], "date": ["2018-01-29T06:28:47Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.09373v2"], "summary": ["  Machine Learning (ML) has revamped every domain of life as it provides\npowerful tools to build complex systems that learn and improve from experience\nand data. Our key insight is that to solve a machine learning problem, data\nscientists do not invent a new algorithm each time, but evaluate a range of\nexisting models with different configurations and select the best one. This\ntask is laborious, error-prone, and drains a large chunk of project budget and\ntime. In this paper we present a novel framework inspired by programming by\nSketching and Partial Evaluation to minimize human intervention in developing\nML solutions. We templatize machine learning algorithms to expose configuration\nchoices as holes to be searched. We share code and computation between\ndifferent algorithms, and only partially evaluate configuration space of\nalgorithms based on information gained from initial algorithm evaluations. We\nalso employ hierarchical and heuristic based pruning to reduce the search\nspace. Our initial findings indicate that our approach can generate highly\naccurate ML models. Interviews with data scientists show that they feel our\nframework can eliminate sources of common errors and significantly reduce\ndevelopment time.\n"]},
{"authors": ["Junyang Lin", "Shuming Ma", "Qi Su", "Xu Sun"], "title": ["Decoding-History-Based Adaptive Control of Attention for Neural Machine\n  Translation"], "date": ["2018-02-06T06:18:56Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.01812v1"], "summary": ["  Attention-based sequence-to-sequence model has proved successful in Neural\nMachine Translation (NMT). However, the attention without consideration of\ndecoding history, which includes the past information in the decoder and the\nattention mechanism, often causes much repetition. To address this problem, we\npropose the decoding-history-based Adaptive Control of Attention (ACA) for the\nNMT model. ACA learns to control the attention by keeping track of the decoding\nhistory and the current information with a memory vector, so that the model can\ntake the translated contents and the current information into consideration.\nExperiments on Chinese-English translation and the English-Vietnamese\ntranslation have demonstrated that our model significantly outperforms the\nstrong baselines. The analysis shows that our model is capable of generating\ntranslation with less repetition and higher accuracy. The code will be\navailable at https://github.com/lancopku\n"]},
{"authors": ["Chang Liu", "Jessica B. Hamrick", "Jaime F. Fisac", "Anca D. Dragan", "J. Karl Hedrick", "S. Shankar Sastry", "Thomas L. Griffiths"], "title": ["Goal Inference Improves Objective and Perceived Performance in\n  Human-Robot Collaboration"], "date": ["2018-02-06T03:31:23Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.01780v1"], "summary": ["  The study of human-robot interaction is fundamental to the design and use of\nrobotics in real-world applications. Robots will need to predict and adapt to\nthe actions of human collaborators in order to achieve good performance and\nimprove safety and end-user adoption. This paper evaluates a human-robot\ncollaboration scheme that combines the task allocation and motion levels of\nreasoning: the robotic agent uses Bayesian inference to predict the next goal\nof its human partner from his or her ongoing motion, and re-plans its own\nactions in real time. This anticipative adaptation is desirable in many\npractical scenarios, where humans are unable or unwilling to take on the\ncognitive overhead required to explicitly communicate their intent to the\nrobot. A behavioral experiment indicates that the combination of goal inference\nand dynamic task planning significantly improves both objective and perceived\nperformance of the human-robot team. Participants were highly sensitive to the\ndifferences between robot behaviors, preferring to work with a robot that\nadapted to their actions over one that did not.\n"]},
{"authors": ["Maxime Bouton", "Kyle Julian", "Alireza Nakhaei", "Kikuo Fujimura", "Mykel J. Kochenderfer"], "title": ["Utility Decomposition with Deep Corrections for Scalable Planning under\n  Uncertainty"], "date": ["2018-02-06T03:02:22Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.01772v1"], "summary": ["  Decomposition methods have been proposed in the past to approximate solutions\nto large sequential decision making problems. In contexts where an agent\ninteracts with multiple entities, utility decomposition can be used where each\nindividual entity is considered independently. The individual utility functions\nare then combined in real time to solve the global problem. Although these\ntechniques can perform well empirically, they sacrifice optimality. This paper\nproposes an approach inspired from multi-fidelity optimization to learn a\ncorrection term with a neural network representation. Learning this correction\ncan significantly improve performance. We demonstrate this approach on a\npedestrian avoidance problem for autonomous driving. By leveraging strategies\nto avoid a single pedestrian, the decomposition method can scale to avoid\nmultiple pedestrians. We verify empirically that the proposed correction method\nleads to a significant improvement over the decomposition method alone and\noutperforms a policy trained on the full scale problem without utility\ndecomposition.\n"]},
{"authors": ["Xu Sun"], "title": ["Towards Shockingly Easy Structured Classification: A Search-based\n  Probabilistic Online Learning Framework"], "date": ["2015-03-29T03:41:03Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1503.08381v2"], "summary": ["  There are two major approaches for structured classification. One is the\nprobabilistic gradient-based methods such as conditional random fields (CRF),\nwhich has high accuracy but with drawbacks: slow training, and no support of\nsearch-based optimization (which is important in many cases). The other one is\nthe search-based learning methods such as perceptrons and margin infused\nrelaxed algorithm (MIRA), which have fast training but also with drawbacks: low\naccuracy, no probabilistic information, and non-convergence in real-world\ntasks. We propose a novel and \"shockingly easy\" solution, a search-based\nprobabilistic online learning method, to address most of those issues. This\nmethod searches the output candidates, derives probabilities, and conduct\nefficient online learning. We show that this method is with fast training,\nsupport search-based optimization, very easy to implement, with top accuracy,\nwith probabilities, and with theoretical guarantees of convergence. Experiments\non well-known tasks show that our method has better accuracy than CRF and\nalmost as fast training speed as perceptron and MIRA. Results also show that\nSAPO can easily beat the state-of-the-art systems on those highly-competitive\ntasks, achieving record-breaking accuracies. The codes can be found at\nhttps://github.com/lancopku\n"]},
{"authors": ["Fl\u00e1vio L. Pinheiro", "Fernando P. Santos"], "title": ["Local Wealth Redistribution Promotes Cooperation in Multiagent Systems"], "date": ["2018-02-05T23:30:55Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.01730v1"], "summary": ["  Designing mechanisms that leverage cooperation between agents has been a\nlong-lasting goal in Multiagent Systems. The task is especially challenging\nwhen agents are selfish, lack common goals and face social dilemmas, i.e.,\nsituations in which individual interest conflicts with social welfare. Past\nworks explored mechanisms that explain cooperation in biological and social\nsystems, providing important clues for the aim of designing cooperative\nartificial societies. In particular, several works show that cooperation is\nable to emerge when specific network structures underlie agents' interactions.\nNotwithstanding, social dilemmas in which defection is highly tempting still\npose challenges concerning the effective sustainability of cooperation. Here we\npropose a new redistribution mechanism that can be applied in structured\npopulations of agents. Importantly, we show that, when implemented locally\n(i.e., agents share a fraction of their wealth surplus with their nearest\nneighbors), redistribution excels in promoting cooperation under regimes where,\nbefore, only defection prevailed.\n"]},
{"authors": ["Michael Janner", "Jiajun Wu", "Tejas D. Kulkarni", "Ilker Yildirim", "Joshua B. Tenenbaum"], "title": ["Self-Supervised Intrinsic Image Decomposition"], "date": ["2017-11-10T03:31:27Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.03678v2"], "summary": ["  Intrinsic decomposition from a single image is a highly challenging task, due\nto its inherent ambiguity and the scarcity of training data. In contrast to\ntraditional fully supervised learning approaches, in this paper we propose\nlearning intrinsic image decomposition by explaining the input image. Our\nmodel, the Rendered Intrinsics Network (RIN), joins together an image\ndecomposition pipeline, which predicts reflectance, shape, and lighting\nconditions given a single image, with a recombination function, a learned\nshading model used to recompose the original input based off of intrinsic image\npredictions. Our network can then use unsupervised reconstruction error as an\nadditional signal to improve its intermediate representations. This allows\nlarge-scale unlabeled data to be useful during training, and also enables\ntransferring learned knowledge to images of unseen object categories, lighting\nconditions, and shapes. Extensive experiments demonstrate that our method\nperforms well on both intrinsic image decomposition and knowledge transfer.\n"]},
{"authors": ["Jaime F. Fisac", "Monica A. Gates", "Jessica B. Hamrick", "Chang Liu", "Dylan Hadfield-Menell", "Malayandi Palaniappan", "Dhruv Malik", "S. Shankar Sastry", "Thomas L. Griffiths", "Anca D. Dragan"], "title": ["Pragmatic-Pedagogic Value Alignment"], "date": ["2017-07-20T03:07:19Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1707.06354v2"], "summary": ["  As intelligent systems gain autonomy and capability, it becomes vital to\nensure that their objectives match those of their human users; this is known as\nthe value-alignment problem. In robotics, value alignment is key to the design\nof collaborative robots that can integrate into human workflows, successfully\ninferring and adapting to their users' objectives as they go. We argue that a\nmeaningful solution to value alignment must combine multi-agent decision theory\nwith rich mathematical models of human cognition, enabling robots to tap into\npeople's natural collaborative capabilities. We present a solution to the\ncooperative inverse reinforcement learning (CIRL) dynamic game based on\nwell-established cognitive models of decision making and theory of mind. The\nsolution captures a key reciprocity relation: the human will not plan her\nactions in isolation, but rather reason pedagogically about how the robot might\nlearn from them; the robot, in turn, can anticipate this and interpret the\nhuman's actions pragmatically. To our knowledge, this work constitutes the\nfirst formal analysis of value alignment grounded in empirically validated\ncognitive models.\n"]},
{"authors": ["Chandrayee Basu", "Mukesh Singhal", "Anca D. Dragan"], "title": ["Learning from Richer Human Guidance: Augmenting Comparison-Based\n  Learning with Feature Queries"], "date": ["2018-02-05T19:03:26Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.01604v1"], "summary": ["  We focus on learning the desired objective function for a robot. Although\ntrajectory demonstrations can be very informative of the desired objective,\nthey can also be difficult for users to provide. Answers to comparison queries,\nasking which of two trajectories is preferable, are much easier for users, and\nhave emerged as an effective alternative. Unfortunately, comparisons are far\nless informative. We propose that there is much richer information that users\ncan easily provide and that robots ought to leverage. We focus on augmenting\ncomparisons with feature queries, and introduce a unified formalism for\ntreating all answers as observations about the true desired reward. We derive\nan active query selection algorithm, and test these queries in simulation and\non real users. We find that richer, feature-augmented queries can extract more\ninformation faster, leading to robots that better match user preferences in\ntheir behavior.\n"]},
{"authors": ["Tianhe Yu", "Chelsea Finn", "Annie Xie", "Sudeep Dasari", "Tianhao Zhang", "Pieter Abbeel", "Sergey Levine"], "title": ["One-Shot Imitation from Observing Humans via Domain-Adaptive\n  Meta-Learning"], "date": ["2018-02-05T18:36:19Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.01557v1"], "summary": ["  Humans and animals are capable of learning a new behavior by observing others\nperform the skill just once. We consider the problem of allowing a robot to do\nthe same -- learning from a raw video pixels of a human, even when there is\nsubstantial domain shift in the perspective, environment, and embodiment\nbetween the robot and the observed human. Prior approaches to this problem have\nhand-specified how human and robot actions correspond and often relied on\nexplicit human pose detection systems. In this work, we present an approach for\none-shot learning from a video of a human by using human and robot\ndemonstration data from a variety of previous tasks to build up prior knowledge\nthrough meta-learning. Then, combining this prior knowledge and only a single\nvideo demonstration from a human, the robot can perform the task that the human\ndemonstrated. We show experiments on both a PR2 arm and a Sawyer arm,\ndemonstrating that after meta-learning, the robot can learn to place, push, and\npick-and-place new objects using just one video of a human performing the\nmanipulation.\n"]},
{"authors": ["Ryuta Arisaka", "Jeremie Dauphin"], "title": ["Abstractly Interpreting Argumentation Frameworks for Sharpening\n  Extensions"], "date": ["2018-02-05T17:36:40Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.01526v1"], "summary": ["  Cycles of attacking arguments pose non-trivial issues in Dung style\nargumentation theory, apparent behavioural difference between odd and even\nlength cycles being a notable one. While a few methods were proposed for\ntreating them, to - in particular - enable selection of acceptable arguments in\nan odd-length cycle when Dung semantics could select none, so far the issues\nhave been observed from a purely argument-graph-theoretic perspective. Per\ncontra, we consider argument graphs together with a certain lattice like\nsemantic structure over arguments e.g. ontology. As we show, the\nsemantic-argumentgraphic hybrid theory allows us to apply abstract\ninterpretation, a widely known methodology in static program analysis, to\nformal argumentation. With this, even where no arguments in a cycle could be\nselected sensibly, we could say more about arguments acceptability of an\nargument framework that contains it. In a certain sense, we can verify Dung\nextensions with respect to a semantic structure in this hybrid theory, to\nconsolidate our confidence in their suitability. By defining the theory, and by\nmaking comparisons to existing approaches, we ultimately discover that whether\nDung semantics, or an alternative semantics such as cf2, is adequate or\nproblematic depends not just on an argument graph but also on the semantic\nrelation among the arguments in the graph.\n"]},
{"authors": ["Isaac J. Sledge", "Matthew S. Emigh", "Jose C. Principe"], "title": ["Guided Policy Exploration for Markov Decision Processes using an\n  Uncertainty-Based Value-of-Information Criterion"], "date": ["2018-02-05T17:24:13Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.01518v1"], "summary": ["  Reinforcement learning in environments with many action-state pairs is\nchallenging. At issue is the number of episodes needed to thoroughly search the\npolicy space. Most conventional heuristics address this search problem in a\nstochastic manner. This can leave large portions of the policy space unvisited\nduring the early training stages. In this paper, we propose an\nuncertainty-based, information-theoretic approach for performing guided\nstochastic searches that more effectively cover the policy space. Our approach\nis based on the value of information, a criterion that provides the optimal\ntrade-off between expected costs and the granularity of the search process. The\nvalue of information yields a stochastic routine for choosing actions during\nlearning that can explore the policy space in a coarse to fine manner. We\naugment this criterion with a state-transition uncertainty factor, which guides\nthe search process into previously unexplored regions of the policy space.\n"]},
{"authors": ["Victor Campos", "Brendan Jou", "Xavier Giro-i-Nieto", "Jordi Torres", "Shih-Fu Chang"], "title": ["Skip RNN: Learning to Skip State Updates in Recurrent Neural Networks"], "date": ["2017-08-22T21:53:34Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1708.06834v3"], "summary": ["  Recurrent Neural Networks (RNNs) continue to show outstanding performance in\nsequence modeling tasks. However, training RNNs on long sequences often face\nchallenges like slow inference, vanishing gradients and difficulty in capturing\nlong term dependencies. In backpropagation through time settings, these issues\nare tightly coupled with the large, sequential computational graph resulting\nfrom unfolding the RNN in time. We introduce the Skip RNN model which extends\nexisting RNN models by learning to skip state updates and shortens the\neffective size of the computational graph. This model can also be encouraged to\nperform fewer state updates through a budget constraint. We evaluate the\nproposed model on various tasks and show how it can reduce the number of\nrequired RNN updates while preserving, and sometimes even improving, the\nperformance of the baseline RNN models. Source code is publicly available at\nhttps://imatge-upc.github.io/skiprnn-2017-telecombcn/ .\n"]},
{"authors": ["Jo\u00e3o Pedro Pedroso", "Alpar Vajk Kramer", "Ke Zhang"], "title": ["The Sea Exploration Problem: Data-driven Orienteering on a Continuous\n  Surface"], "date": ["2018-02-05T15:57:15Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.01482v1"], "summary": ["  This paper describes a problem arising in sea exploration, where the aim is\nto schedule the expedition of a ship for collecting information about the\nresources on the seafloor. The aim is to collect data by probing on a set of\ncarefully chosen locations, so that the information available is optimally\nenriched. This problem has similarities with the orienteering problem, where\nthe aim is to plan a time-limited trip for visiting a set of vertices,\ncollecting a prize at each of them, in such a way that the total value\ncollected is maximum. In our problem, the score at each vertex is associated\nwith an estimation of the level of the resource on the given surface, which is\ndone by regression using Gaussian processes. Hence, there is a correlation\namong scores on the selected vertices; this is a first difference with respect\nto the standard orienteering problem. The second difference is the location of\neach vertex, which in our problem is a freely chosen point on a given surface.\n"]},
{"authors": ["Alexey Chaplygin", "Joshua Chacksfield"], "title": ["A Method for Restoring the Training Set Distribution in an Image\n  Classifier"], "date": ["2018-02-05T14:49:06Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.01435v1"], "summary": ["  Convolutional Neural Networks are a well-known staple of modern image\nclassification. However, it can be difficult to assess the quality and\nrobustness of such models. Deep models are known to perform well on a given\ntraining and estimation set, but can easily be fooled by data that is\nspecifically generated for the purpose. It has been shown that one can produce\nan artificial example that does not represent the desired class, but activates\nthe network in the desired way. This paper describes a new way of\nreconstructing a sample from the training set distribution of an image\nclassifier without deep knowledge about the underlying distribution. This\nenables access to the elements of images that most influence the decision of a\nconvolutional network and to extract meaningful information about the training\ndistribution.\n"]},
{"authors": ["Guillaume Bellec", "David Kappel", "Wolfgang Maass", "Robert Legenstein"], "title": ["Deep Rewiring: Training very sparse deep networks"], "date": ["2017-11-14T15:02:47Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.05136v4"], "summary": ["  Neuromorphic hardware tends to pose limits on the connectivity of deep\nnetworks that one can run on them. But also generic hardware and software\nimplementations of deep learning run more efficiently for sparse networks.\nSeveral methods exist for pruning connections of a neural network after it was\ntrained without connectivity constraints. We present an algorithm, DEEP R, that\nenables us to train directly a sparsely connected neural network. DEEP R\nautomatically rewires the network during supervised training so that\nconnections are there where they are most needed for the task, while its total\nnumber is all the time strictly bounded. We demonstrate that DEEP R can be used\nto train very sparse feedforward and recurrent neural networks on standard\nbenchmark tasks with just a minor loss in performance. DEEP R is based on a\nrigorous theoretical foundation that views rewiring as stochastic sampling of\nnetwork configurations from a posterior.\n"]},
{"authors": ["Vinod Kumar Chauhan", "Kalpana Dahiya", "Anuj Sharma"], "title": ["Faster Algorithms for Large-scale Machine Learning using Simple Sampling\n  Techniques"], "date": ["2018-01-18T04:31:40Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.05931v2"], "summary": ["  Now a days, the major challenge in machine learning is the `Big~Data'\nchallenge. The big data problems due to large number of data points or large\nnumber of features in each data point, or both, the training of models have\nbecome very slow. The training time has two major components: Time to access\nthe data and time to process (learn from) the data. In this paper, we have\nproposed one possible solution to handle the big data problems in machine\nlearning. The idea is to reduce the training time through reducing data access\ntime by proposing systematic sampling and cyclic/sequential sampling to select\nmini-batches from the dataset. To prove the effectiveness of proposed sampling\ntechniques, we have used Empirical Risk Minimization, which is commonly used\nmachine learning problem, for strongly convex and smooth case. The problem has\nbeen solved using SAG, SAGA, SVRG, SAAG-II and MBSGD (Mini-batched SGD), each\nusing two step determination techniques, namely, constant step size and\nbacktracking line search method. Theoretical results prove the same convergence\nfor systematic sampling, cyclic sampling and the widely used random sampling\ntechnique, in expectation. Experimental results with bench marked datasets\nprove the efficacy of the proposed sampling techniques.\n"]},
{"authors": ["Maria Dimakopoulou", "Benjamin Van Roy"], "title": ["Coordinated Exploration in Concurrent Reinforcement Learning"], "date": ["2018-02-05T06:51:12Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.01282v1"], "summary": ["  We consider a team of reinforcement learning agents that concurrently learn\nto operate in a common environment. We identify three properties - adaptivity,\ncommitment, and diversity - which are necessary for efficient coordinated\nexploration and demonstrate that straightforward extensions to single-agent\noptimistic and posterior sampling approaches fail to satisfy them. As an\nalternative, we propose seed sampling, which extends posterior sampling in a\nmanner that meets these requirements. Simulation results investigate how\nper-agent regret decreases as the number of agents grows, establishing\nsubstantial advantages of seed sampling over alternative exploration schemes.\n"]},
{"authors": ["Hang Qi", "Yuanlu Xu", "Tao Yuan", "Tianfu Wu", "Song-Chun Zhu"], "title": ["Scene-centric Joint Parsing of Cross-view Videos"], "date": ["2017-09-16T00:21:29Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1709.05436v3"], "summary": ["  Cross-view video understanding is an important yet under-explored area in\ncomputer vision. In this paper, we introduce a joint parsing framework that\nintegrates view-centric proposals into scene-centric parse graphs that\nrepresent a coherent scene-centric understanding of cross-view scenes. Our key\nobservations are that overlapping fields of views embed rich appearance and\ngeometry correlations and that knowledge fragments corresponding to individual\nvision tasks are governed by consistency constraints available in commonsense\nknowledge. The proposed joint parsing framework represents such correlations\nand constraints explicitly and generates semantic scene-centric parse graphs.\nQuantitative experiments show that scene-centric predictions in the parse graph\noutperform view-centric predictions.\n"]},
{"authors": ["Emily L. Spratt"], "title": ["Dream Formulations and Deep Neural Networks: Humanistic Themes in the\n  Iconology of the Machine-Learned Image"], "date": ["2018-02-05T05:57:40Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.01274v1"], "summary": ["  This paper addresses the interpretability of deep learning-enabled image\nrecognition processes in computer vision science in relation to theories in art\nhistory and cognitive psychology on the vision-related perceptual capabilities\nof humans. Examination of what is determinable about the machine-learned image\nin comparison to humanistic theories of visual perception, particularly in\nregard to art historian Erwin Panofsky's methodology for image analysis and\npsychologist Eleanor Rosch's theory of graded categorization according to\nprototypes, finds that there are surprising similarities between the two that\nsuggest that researchers in the arts and the sciences would have much to\nbenefit from closer collaborations. Utilizing the examples of Google's\nDeepDream and the Machine Learning and Perception Lab at Georgia Tech's\nGrad-CAM: Gradient-weighted Class Activation Mapping programs, this study\nsuggests that a revival of art historical research in iconography and formalism\nin the age of AI is essential for shaping the future navigation and\ninterpretation of all machine-learned images, given the rapid developments in\nimage recognition technologies.\n"]},
{"authors": ["AmirEmad Ghassami", "Saber Salehkaleybar", "Negar Kiyavash"], "title": ["Counting and Uniform Sampling from Markov Equivalent DAGs"], "date": ["2018-02-05T02:32:05Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.01239v1"], "summary": ["  We propose an exact solution for the problem of finding the size of a Markov\nequivalence class (MEC). For the bounded degree graphs, the proposed solution\nis capable of computing the size of the MEC in polynomial time. Our proposed\napproach is based on a recursive method for counting the number of the elements\nof the MEC when a specific vertex is set as the source variable. We will\nfurther use the idea to design a sampler, which is capable of sampling from an\nMEC uniformly in polynomial time.\n"]},
{"authors": ["Francois Petitjean", "Tao Li", "Nikolaj Tatti", "Geoffrey I. Webb"], "title": ["Skopus: Mining top-k sequential patterns under leverage"], "date": ["2015-06-26T09:36:10Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1506.08009v4"], "summary": ["  This paper presents a framework for exact discovery of the top-k sequential\npatterns under Leverage. It combines (1) a novel definition of the expected\nsupport for a sequential pattern - a concept on which most interestingness\nmeasures directly rely - with (2) SkOPUS: a new branch-and-bound algorithm for\nthe exact discovery of top-k sequential patterns under a given measure of\ninterest. Our interestingness measure employs the partition approach. A pattern\nis interesting to the extent that it is more frequent than can be explained by\nassuming independence between any of the pairs of patterns from which it can be\ncomposed. The larger the support compared to the expectation under\nindependence, the more interesting is the pattern. We build on these two\nelements to exactly extract the k sequential patterns with highest leverage,\nconsistent with our definition of expected support. We conduct experiments on\nboth synthetic data with known patterns and real-world datasets; both\nexperiments confirm the consistency and relevance of our approach with regard\nto the state of the art. This article was published in Data Mining and\nKnowledge Discovery and is accessible at\nhttp://dx.doi.org/10.1007/s10618-016-0467-9.\n"]},
{"authors": ["Damien Anderson", "Matthew Stephenson", "Julian Togelius", "Christian Salge", "John Levine", "Jochen Renz"], "title": ["Deceptive Games"], "date": ["2018-01-31T20:06:05Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.00048v2"], "summary": ["  Deceptive games are games where the reward structure or other aspects of the\ngame are designed to lead the agent away from a globally optimal policy. While\nmany games are already deceptive to some extent, we designed a series of games\nin the Video Game Description Language (VGDL) implementing specific types of\ndeception, classified by the cognitive biases they exploit. VGDL games can be\nrun in the General Video Game Artificial Intelligence (GVGAI) Framework, making\nit possible to test a variety of existing AI agents that have been submitted to\nthe GVGAI Competition on these deceptive games. Our results show that all\ntested agents are vulnerable to several kinds of deception, but that different\nagents have different weaknesses. This suggests that we can use deception to\nunderstand the capabilities of a game-playing algorithm, and game-playing\nalgorithms to characterize the deception displayed by a game.\n"]},
{"authors": ["Ognjen Rudovic", "Jaeryoung Lee", "Miles Dai", "Bjorn Schuller", "Rosalind Picard"], "title": ["Personalized Machine Learning for Robot Perception of Affect and\n  Engagement in Autism Therapy"], "date": ["2018-02-04T20:05:26Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.01186v1"], "summary": ["  Robots have great potential to facilitate future therapies for children on\nthe autism spectrum. However, existing robots lack the ability to automatically\nperceive and respond to human affect, which is necessary for establishing and\nmaintaining engaging interactions. Moreover, their inference challenge is made\nharder by the fact that many individuals with autism have atypical and\nunusually diverse styles of expressing their affective-cognitive states. To\ntackle the heterogeneity in behavioral cues of children with autism, we use the\nlatest advances in deep learning to formulate a personalized machine learning\n(ML) framework for automatic perception of the childrens affective states and\nengagement during robot-assisted autism therapy. The key to our approach is a\nnovel shift from the traditional ML paradigm - instead of using\n'one-size-fits-all' ML models, our personalized ML framework is optimized for\neach child by leveraging relevant contextual information (demographics and\nbehavioral assessment scores) and individual characteristics of each child. We\ndesigned and evaluated this framework using a dataset of multi-modal audio,\nvideo and autonomic physiology data of 35 children with autism (age 3-13) and\nfrom 2 cultures (Asia and Europe), participating in a 25-minute child-robot\ninteraction (~500k datapoints). Our experiments confirm the feasibility of the\nrobot perception of affect and engagement, showing clear improvements due to\nthe model personalization. The proposed approach has potential to improve\nexisting therapies for autism by offering more efficient monitoring and\nsummarization of the therapy progress.\n"]},
{"authors": ["Joel Z. Leibo", "Cyprien de Masson d'Autume", "Daniel Zoran", "David Amos", "Charles Beattie", "Keith Anderson", "Antonio Garc\u00eda Casta\u00f1eda", "Manuel Sanchez", "Simon Green", "Audrunas Gruslys", "Shane Legg", "Demis Hassabis", "Matthew M. Botvinick"], "title": ["Psychlab: A Psychology Laboratory for Deep Reinforcement Learning Agents"], "date": ["2018-01-24T18:31:51Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.08116v2"], "summary": ["  Psychlab is a simulated psychology laboratory inside the first-person 3D game\nworld of DeepMind Lab (Beattie et al. 2016). Psychlab enables implementations\nof classical laboratory psychological experiments so that they work with both\nhuman and artificial agents. Psychlab has a simple and flexible API that\nenables users to easily create their own tasks. As examples, we are releasing\nPsychlab implementations of several classical experimental paradigms including\nvisual search, change detection, random dot motion discrimination, and multiple\nobject tracking. We also contribute a study of the visual psychophysics of a\nspecific state-of-the-art deep reinforcement learning agent: UNREAL (Jaderberg\net al. 2016). This study leads to the surprising conclusion that UNREAL learns\nmore quickly about larger target stimuli than it does about smaller stimuli. In\nturn, this insight motivates a specific improvement in the form of a simple\nmodel of foveal vision that turns out to significantly boost UNREAL's\nperformance, both on Psychlab tasks, and on standard DeepMind Lab tasks. By\nopen-sourcing Psychlab we hope to facilitate a range of future such studies\nthat simultaneously advance deep reinforcement learning and improve its links\nwith cognitive science.\n"]},
{"authors": ["Jochen Burghardt"], "title": ["A Scheme-Driven Approach to Learning Programs from Input/Output\n  Equations"], "date": ["2018-02-04T19:17:57Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.01177v1"], "summary": ["  We describe an approach to learn, in a term-rewriting setting, function\ndefinitions from input/output equations. By confining ourselves to structurally\nrecursive definitions we obtain a fairly fast learning algorithm that often\nyields definitions close to intuitive expectations. We provide a Prolog\nprototype implementation of our approach, and indicate open issues of further\ninvestigation.\n"]},
{"authors": ["Petar Veli\u010dkovi\u0107", "Guillem Cucurull", "Arantxa Casanova", "Adriana Romero", "Pietro Li\u00f2", "Yoshua Bengio"], "title": ["Graph Attention Networks"], "date": ["2017-10-30T12:41:12Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1710.10903v3"], "summary": ["  We present graph attention networks (GATs), novel neural network\narchitectures that operate on graph-structured data, leveraging masked\nself-attentional layers to address the shortcomings of prior methods based on\ngraph convolutions or their approximations. By stacking layers in which nodes\nare able to attend over their neighborhoods' features, we enable (implicitly)\nspecifying different weights to different nodes in a neighborhood, without\nrequiring any kind of costly matrix operation (such as inversion) or depending\non knowing the graph structure upfront. In this way, we address several key\nchallenges of spectral-based graph neural networks simultaneously, and make our\nmodel readily applicable to inductive as well as transductive problems. Our GAT\nmodels have achieved or matched state-of-the-art results across four\nestablished transductive and inductive graph benchmarks: the Cora, Citeseer and\nPubmed citation network datasets, as well as a protein-protein interaction\ndataset (wherein test graphs remain unseen during training).\n"]},
{"authors": ["Suttinee Sawadsitang", "Rakpong Kaewpuang", "Siwei Jiang", "Dusit Niyato", "Ping Wang"], "title": ["Optimal Stochastic Delivery Planning in Full-Truckload and\n  Less-Than-Truckload Delivery"], "date": ["2018-02-04T08:45:19Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.08540v1"], "summary": ["  With an increasing demand from emerging logistics businesses, Vehicle Routing\nProblem with Private fleet and common Carrier (VRPPC) has been introduced to\nmanage package delivery services from a supplier to customers. However, almost\nall of existing studies focus on the deterministic problem that assumes all\nparameters are known perfectly at the time when the planning and routing\ndecisions are made. In reality, some parameters are random and unknown.\nTherefore, in this paper, we consider VRPPC with hard time windows and random\ndemand, called Optimal Delivery Planning (ODP). The proposed ODP aims to\nminimize the total package delivery cost while meeting the customer time window\nconstraints. We use stochastic integer programming to formulate the\noptimization problem incorporating the customer demand uncertainty. Moreover,\nwe evaluate the performance of the ODP using test data from benchmark dataset\nand from actual Singapore road map.\n"]},
{"authors": ["Hsin-Yuan Huang", "Chenguang Zhu", "Yelong Shen", "Weizhu Chen"], "title": ["FusionNet: Fusing via Fully-Aware Attention with Application to Machine\n  Comprehension"], "date": ["2017-11-16T03:52:41Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1711.07341v2"], "summary": ["  This paper introduces a new neural structure called FusionNet, which extends\nexisting attention approaches from three perspectives. First, it puts forward a\nnovel concept of \"history of word\" to characterize attention information from\nthe lowest word-level embedding up to the highest semantic-level\nrepresentation. Second, it introduces an improved attention scoring function\nthat better utilizes the \"history of word\" concept. Third, it proposes a\nfully-aware multi-level attention mechanism to capture the complete information\nin one text (such as a question) and exploit it in its counterpart (such as\ncontext or passage) layer by layer. We apply FusionNet to the Stanford Question\nAnswering Dataset (SQuAD) and it achieves the first position for both single\nand ensemble model on the official SQuAD leaderboard at the time of writing\n(Oct. 4th, 2017). Meanwhile, we verify the generalization of FusionNet with two\nadversarial SQuAD datasets and it sets up the new state-of-the-art on both\ndatasets: on AddSent, FusionNet increases the best F1 metric from 46.6% to\n51.4%; on AddOneSent, FusionNet boosts the best F1 metric from 56.0% to 60.7%.\n"]},
{"authors": ["Nayyar A. Zaidi", "Geoffrey I. Webb", "Francois Petitjean", "Germain Forestier"], "title": ["On the Inter-relationships among Drift rate, Forgetting rate,\n  Bias/variance profile and Error"], "date": ["2018-01-29T03:35:55Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.09354v2"], "summary": ["  We propose two general and falsifiable hypotheses about expectations on\ngeneralization error when learning in the context of concept drift. One posits\nthat as drift rate increases, the forgetting rate that minimizes generalization\nerror will also increase and vice versa. The other posits that as a learner's\nforgetting rate increases, the bias/variance profile that minimizes\ngeneralization error will have lower variance and vice versa. These hypotheses\nlead to the concept of the sweet path, a path through the 3-d space of\nalternative drift rates, forgetting rates and bias/variance profiles on which\ngeneralization error will be minimized, such that slow drift is coupled with\nlow forgetting and low bias, while rapid drift is coupled with fast forgetting\nand low variance. We present experiments that support the existence of such a\nsweet path. We also demonstrate that simple learners that select appropriate\nforgetting rates and bias/variance profiles are highly competitive with the\nstate-of-the-art in incremental learners for concept drift on real-world drift\nproblems.\n"]},
{"authors": ["Tathagata Chakraborti", "Sarath Sreedharan", "Sachin Grover", "Subbarao Kambhampati"], "title": ["Plan Explanations as Model Reconciliation -- An Empirical Study"], "date": ["2018-02-03T19:17:58Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.01013v1"], "summary": ["  Recent work in explanation generation for decision making agents has looked\nat how unexplained behavior of autonomous systems can be understood in terms of\ndifferences in the model of the system and the human's understanding of the\nsame, and how the explanation process as a result of this mismatch can be then\nseen as a process of reconciliation of these models. Existing algorithms in\nsuch settings, while having been built on contrastive, selective and social\nproperties of explanations as studied extensively in the psychology literature,\nhave not, to the best of our knowledge, been evaluated in settings with actual\nhumans in the loop. As such, the applicability of such explanations to human-AI\nand human-robot interactions remains suspect. In this paper, we set out to\nevaluate these explanation generation algorithms in a series of studies in a\nmock search and rescue scenario with an internal semi-autonomous robot and an\nexternal human commander. We demonstrate to what extent the properties of these\nalgorithms hold as they are evaluated by humans, and how the dynamics of trust\nbetween the human and the robot evolve during the process of these\ninteractions.\n"]},
{"authors": ["Tathagata Chakraborti", "Sarath Sreedharan", "Subbarao Kambhampati"], "title": ["Balancing Explicability and Explanation in Human-Aware Planning"], "date": ["2017-08-01T22:47:42Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1708.00543v2"], "summary": ["  Human aware planning requires an agent to be aware of the intentions,\ncapabilities and mental model of the human in the loop during its decision\nprocess. This can involve generating plans that are explicable to a human\nobserver as well as the ability to provide explanations when such plans cannot\nbe generated. This has led to the notion \"multi-model planning\" which aim to\nincorporate effects of human expectation in the deliberative process of a\nplanner - either in the form of explicable task planning or explanations\nproduced thereof. In this paper, we bring these two concepts together and show\nhow a planner can account for both these needs and achieve a trade-off during\nthe plan generation process itself by means of a model-space search method\nMEGA. This in effect provides a comprehensive perspective of what it means for\na decision making agent to be \"human-aware\" by bringing together existing\nprinciples of planning under the umbrella of a single plan generation process.\nWe situate our discussion specifically keeping in mind the recent work on\nexplicable planning and explanation generation, and illustrate these concepts\nin modified versions of two well known planning domains, as well as a\ndemonstration on a robot involved in a typical search and reconnaissance task\nwith an external supervisor.\n"]},
{"authors": ["Baihan Lin", "Guillermo Cecchi", "Djallel Bouneffouf", "Irina Rish"], "title": ["Adaptive Representation Selection in Contextual Bandit with Unlabeled\n  History"], "date": ["2018-02-03T14:44:51Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.00981v1"], "summary": ["  We consider an extension of the contextual bandit setting, motivated by\nseveral practical applications, where an unlabeled history of contexts can\nbecome available for pre-training before the online decision-making begins. We\npropose an approach for improving the performance of contextual bandit in such\nsetting, via adaptive, dynamic representation learning, which combines offline\npre-training on unlabeled history of contexts with online selection and\nmodification of embedding functions. Our experiments on a variety of datasets\nand in different nonstationary environments demonstrate clear advantages of our\napproach over the standard contextual bandit.\n"]},
{"authors": ["Yuliang Xiu", "Jiefeng Li", "Haoyu Wang", "Yinghong Fang", "Cewu Lu"], "title": ["Pose Flow: Efficient Online Pose Tracking"], "date": ["2018-02-03T14:08:36Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.00977v1"], "summary": ["  Multi-person articulated pose tracking in complex unconstrained videos is an\nimportant and challenging problem. In this paper, going along the road of\ntop-down approaches, we propose a decent and efficient pose tracker based on\npose flows. First, we design an online optimization framework to build\nassociation of cross-frame poses and form pose flows. Second, a novel pose flow\nnon maximum suppression (NMS) is designed to robustly reduce redundant pose\nflows and re-link temporal disjoint pose flows. Extensive experiments show our\nmethod significantly outperforms best reported results on two standard Pose\nTracking datasets (PoseTrack dataset and PoseTrack Challenge dataset) by 13 mAP\n25 MOTA and 6 mAP 3 MOTA respectively. Moreover, in the case of working on\ndetected poses in individual frames, the extra computation of proposed pose\ntracker is very minor, requiring 0.01 second per frame only.\n"]},
{"authors": ["Yang Liu", "Mirella Lapata"], "title": ["Learning Structured Text Representations"], "date": ["2017-05-25T14:54:07Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1705.09207v4"], "summary": ["  In this paper, we focus on learning structure-aware document representations\nfrom data without recourse to a discourse parser or additional annotations.\nDrawing inspiration from recent efforts to empower neural networks with a\nstructural bias, we propose a model that can encode a document while\nautomatically inducing rich structural dependencies. Specifically, we embed a\ndifferentiable non-projective parsing algorithm into a neural model and use\nattention mechanisms to incorporate the structural biases. Experimental\nevaluation across different tasks and datasets shows that the proposed model\nachieves state-of-the-art results on document modeling tasks while inducing\nintermediate structures which are both interpretable and meaningful.\n"]},
{"authors": ["Nick Bassiliades"], "title": ["SWRL2SPIN: A tool for transforming SWRL rule bases in OWL ontologies to\n  object-oriented SPIN rules"], "date": ["2018-01-27T09:36:22Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1801.09061v2"], "summary": ["  SWRL is a semantic web rule language that combines OWL ontologies with Horn\nLogic rules of the RuleML family of rule languages, extending the set of OWL\naxioms to include Horn-like rules. Being supported by the Prot\\'eg\\'e ontology\neditor as well as by popular rule engines and ontology reasoners, such as Jess,\nDrools and Pellet, SWRL has become a very popular choice for developing\nrule-based applications on top of ontologies. However, SWRL being around for\nmore than 10 years now, it is most probable that it will never become a W3C\nstandard; therefore, its scope is difficult to reach out to the industrial\nworld. On the other hand, SPIN has become a de-facto industry standard to\nrepresent SPARQL rules and constraints on Semantic Web models, building on the\nwidespread acceptance of the SPARQL query language for querying and processing\nLinked Open Data. In this paper, we argue that the life of existing SWRL\nrule-based ontology applications can be prolonged by being transformed into\nSPIN. To this end, we have developed a prototype tool using SWI-Prolog that\ntakes as in-put an OWL ontology with a SWRL rule base and transforms SWRL rules\ninto SPIN rules in the same ontology, taking into consideration the\nobject-oriented scent of SPIN, i.e. linking rules to the appropriate ontology\nclasses as derived by analyzing the rule conditions.\n"]},
{"authors": ["Agustinus Kristiadi", "Mohammad Asif Khan", "Denis Lukovnikov", "Jens Lehmann", "Asja Fischer"], "title": ["Incorporating Literals into Knowledge Graph Embeddings"], "date": ["2018-02-03T08:16:31Z"], "category": "cs.AI", "url": ["http://arxiv.org/abs/1802.00934v1"], "summary": ["  Knowledge graphs, on top of entities and their relationships, contain another\nimportant element: literals. Literals encode interesting properties (e.g. the\nheight) of entities that are not captured by links between entities alone. Most\nof the existing work on embedding (or latent feature) based knowledge graph\nmodeling focuses mainly on the relations between entities. In this work, we\nstudy the effect of incorporating literal information into existing knowledge\ngraph models. Our approach, which we name LiteralE, is an extension that can be\nplugged into existing latent feature methods. LiteralE merges entity embeddings\nwith their literal information using a learnable, parametrized function, such\nas a simple linear or nonlinear transformation, or a multilayer neural network.\nWe extend several popular embedding models using LiteralE and evaluate the\nperformance on the task of link prediction. Despite its simplicity, LiteralE\nproves to be an effective way to incorporate literal information into existing\nembedding based models, improving their performance on different standard\ndatasets, which we augmented with their literals and provide as testbed for\nfurther research.\n"]}
]