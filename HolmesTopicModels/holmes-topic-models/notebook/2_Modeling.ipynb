{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "ML Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc count: 60\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "\n",
    "corpus = load_files(\"../data/\")\n",
    "\n",
    "doc_count = len(corpus.data)\n",
    "print(\"Doc count:\", doc_count)\n",
    "assert doc_count is 60, \"Wrong number of documents loaded, should be 60 (4 novels + 56 stories)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to nltk/...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to nltk/...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['dat', 'descr', 'filenam', 'target', 'target_names']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tokenizer import TextWrangler\n",
    "\n",
    "tfidf_stem = TfidfVectorizer(strip_accents=\"ascii\", tokenizer=TextWrangler(kind=\"stem\"))\n",
    "tfidf_stem.fit(corpus)\n",
    "\n",
    "tfidf_stem.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD, NMF\n",
    "\n",
    "n_topics = 20 #FIXME GridSearch\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=n_topics)\n",
    "lsa = TruncatedSVD(n_components=n_topics)\n",
    "nmf = NMF(n_components=n_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"tfidf\", tfidf_stem),\n",
    "    (\"model\", lda)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/datadonk23/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       " ...ol=0.1, random_state=None,\n",
       "             topic_word_prior=None, total_samples=1000000.0, verbose=0))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(corpus.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Likelelihood: -146556.86892199639\n"
     ]
    }
   ],
   "source": [
    "print(\"Log Likelelihood:\", model.score(corpus.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "corp mathem dusky casket penang acquit fiery ardo end rak\n",
      "Topic #1:\n",
      "sway unty haughty nucle said dessert rift suicid leath phas\n",
      "Topic #2:\n",
      "holm said man littl ey fury toujo rosyth brunton paddington\n",
      "Topic #3:\n",
      "stylestown parlia lich breez gar bob hostel crop faird conquest\n",
      "Topic #4:\n",
      "embed montagu nat din overdid piano turquo pint borough ffolliot\n",
      "Topic #5:\n",
      "disgrac obl possess briarbra improv miss sect sutherland mongoos violin\n",
      "Topic #6:\n",
      "radi lombard wok precipit snatch hostil swath trait fastidy horr\n",
      "Topic #7:\n",
      "outbreak nod rais littl whiplash meagr nicknam meantim insinu xx\n",
      "Topic #8:\n",
      "program claim valentin dutch doggy exam paragon serv fresno snap\n",
      "Topic #9:\n",
      "klux dutchm apply thankless pithy mem midland alib tapanul penny\n",
      "Topic #10:\n",
      "holm said man mr hand room door com know watson\n",
      "Topic #11:\n",
      "shun pray big creak subcut dismay abernetty ribston upstair mistress\n",
      "Topic #12:\n",
      "amberley wantin train button us ryd holm swain chancellery roadsid\n",
      "Topic #13:\n",
      "peel castalot envelop lanky laught untoward desp devin im admir\n",
      "Topic #14:\n",
      "holm said man mr com hand room watson know look\n",
      "Topic #15:\n",
      "shrink quench friendless marm cro month shorst negoty abyss jap\n",
      "Topic #16:\n",
      "ging imprec toddl ricolett vii rul triangl potato finest recoil\n",
      "Topic #17:\n",
      "circlet conf desult took discount cavend shat invidy hart cleans\n",
      "Topic #18:\n",
      "holm man simon fal said mr window gown marry just\n",
      "Topic #19:\n",
      "shrunk strictly cas let turn nonpareil holm ratcliff good disfig\n"
     ]
    }
   ],
   "source": [
    "# Inspect topics\n",
    "names = tfidf_stem.get_feature_names()\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "\n",
    "print_top_words(lda, names, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
